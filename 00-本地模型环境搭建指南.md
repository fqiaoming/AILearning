# æœ¬åœ°AIå¼€å‘ç¯å¢ƒæ­å»ºæŒ‡å—ï¼ˆLM Studioï¼‰

> ğŸ“Œ **é‡è¦**ï¼šè¿™æ˜¯å¼€å§‹å­¦ä¹ å‰å¿…é¡»å®Œæˆçš„å‡†å¤‡å·¥ä½œ
> 
> â° **é¢„è®¡æ—¶é—´**ï¼š30-60åˆ†é’Ÿ
> 
> ğŸ¯ **ç›®æ ‡**ï¼šæ­å»ºå®Œæ•´çš„æœ¬åœ°AIå¼€å‘ç¯å¢ƒï¼Œèƒ½è¿è¡Œæœ¬åœ°å¤§æ¨¡å‹

---

## ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©æœ¬åœ°æ¨¡å‹ï¼Ÿ

### âœ… æœ¬åœ°æ¨¡å‹çš„ä¼˜åŠ¿

1. **å®Œå…¨å…è´¹** - æ— éœ€æ”¯ä»˜APIè´¹ç”¨
2. **æ•°æ®å®‰å…¨** - æ‰€æœ‰æ•°æ®åœ¨æœ¬åœ°ï¼Œä¸ä¼šæ³„éœ²
3. **æ— ç½‘ç»œé™åˆ¶** - éšæ—¶å¯ç”¨ï¼Œä¸å—ç½‘ç»œå½±å“
4. **çœŸå®å­¦ä¹ ** - äº†è§£å®Œæ•´çš„AIéƒ¨ç½²æµç¨‹
5. **æ€§èƒ½å¯æ§** - å¯ä»¥æ ¹æ®ç¡¬ä»¶é€‰æ‹©åˆé€‚çš„æ¨¡å‹

### ğŸ“Š æˆæœ¬å¯¹æ¯”

| æ–¹æ¡ˆ | æˆæœ¬ | æ•°æ®å®‰å…¨ | ä½¿ç”¨é™åˆ¶ | å­¦ä¹ ä»·å€¼ |
|------|------|----------|----------|----------|
| æœ¬åœ°æ¨¡å‹ï¼ˆLM Studioï¼‰ | 0å…ƒ | âœ… é«˜ | âŒ æ—  | â­â­â­â­â­ |
| OpenAI API | 100-300å…ƒ/æœˆ | âš ï¸ ä¸­ | âš ï¸ æœ‰é™é¢ | â­â­â­ |
| äº‘ç«¯è®­ç»ƒ/éƒ¨ç½² | 500+å…ƒ/æœˆ | âš ï¸ ä¸­ | âš ï¸ æœ‰é™é¢ | â­â­â­â­ |

---

## ğŸ’» ç¡¬ä»¶è¦æ±‚

### æœ€ä½é…ç½®ï¼ˆå¯è¿è¡Œ7Bæ¨¡å‹ï¼‰
- **CPU**: 4æ ¸ä»¥ä¸Š
- **å†…å­˜**: 16GB
- **å­˜å‚¨**: 20GBå¯ç”¨ç©ºé—´
- **ç³»ç»Ÿ**: Windows 10+ã€macOS 12+ã€Linux

**é€‚åˆæ¨¡å‹**: Qwen2.5-7Bã€Llama-3.1-8Bã€Gemma-7B

### æ¨èé…ç½®ï¼ˆå¯è¿è¡Œ14Bæ¨¡å‹ï¼‰
- **CPU**: 8æ ¸ä»¥ä¸Š
- **å†…å­˜**: 32GB
- **æ˜¾å¡**: NVIDIA GPUï¼ˆ8GB+ VRAMï¼‰
- **å­˜å‚¨**: 50GBå¯ç”¨ç©ºé—´

**é€‚åˆæ¨¡å‹**: Qwen2.5-14Bã€Llama-3.1-70B-Q4

### é«˜é…ï¼ˆå¯è¿è¡Œ70Bæ¨¡å‹ï¼‰
- **CPU**: 16æ ¸ä»¥ä¸Š
- **å†…å­˜**: 64GB+
- **æ˜¾å¡**: NVIDIA GPUï¼ˆ24GB+ VRAMï¼‰
- **å­˜å‚¨**: 100GB+

**é€‚åˆæ¨¡å‹**: Qwen2.5-72Bã€Llama-3.1-70B

---

## ğŸ“¦ ç¬¬ä¸€æ­¥ï¼šå®‰è£…Pythonç¯å¢ƒ

âš ï¸ **é‡è¦**ï¼šæœ¬è¯¾ç¨‹è¦æ±‚Python **3.12**ï¼ˆæ¨èï¼‰æˆ–3.10-3.11

> ğŸ’¡ **ä¸ºä»€ä¹ˆæ˜¯3.12ï¼Ÿ**
> - LangChain v1.xå®Œå…¨æ”¯æŒ
> - chromadbå®Œå…¨å…¼å®¹ï¼ˆ3.13+ä¸å…¼å®¹ï¼‰
> - æ‰€æœ‰ä¾èµ–éƒ½èƒ½æ­£å¸¸å®‰è£…
> - æ¨èä½¿ç”¨3.12è·å¾—æœ€ä½³ä½“éªŒ

### æ£€æŸ¥å½“å‰Pythonç‰ˆæœ¬

```bash
python3 --version
# å¦‚æœä¸æ˜¯3.12ï¼Œå»ºè®®å®‰è£…3.12
```

### Windowsç”¨æˆ·

1. **ä¸‹è½½Python**
   - è®¿é—®ï¼šhttps://www.python.org/downloads/
   - **ä¸‹è½½Python 3.12**ï¼ˆæ¨èç‰ˆæœ¬ï¼‰
   - âš ï¸ æ³¨æ„ï¼šå‹¾é€‰"Add Python to PATH"

2. **éªŒè¯å®‰è£…**
   ```bash
   # æ‰“å¼€CMDæˆ–PowerShell
   python --version
   # åº”è¯¥æ˜¾ç¤ºï¼šPython 3.12.x
   ```

### macOSç”¨æˆ·

1. **å®‰è£…Homebrewï¼ˆå¦‚æœæ²¡æœ‰ï¼‰**
   ```bash
   /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
   ```

2. **å®‰è£…Python 3.12**
   ```bash
   # å®‰è£…Python 3.12
   brew install python@3.12
   
   # éªŒè¯ç‰ˆæœ¬
   /opt/homebrew/bin/python3.12 --version
   # åº”è¯¥æ˜¾ç¤ºï¼šPython 3.12.x
   ```

3. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒæ—¶ä½¿ç”¨Python 3.12**
   ```bash
   # ä½¿ç”¨æŒ‡å®šç‰ˆæœ¬çš„Python
   /opt/homebrew/bin/python3.12 -m venv .venv
   ```

### Linuxç”¨æˆ·

```bash
# Ubuntu/Debian - å®‰è£…Python 3.12
sudo apt update
sudo apt install python3.12 python3.12-venv python3-pip

# CentOS/RHEL
sudo yum install python3.12 python3.12-pip

# éªŒè¯
python3.12 --version
# åº”è¯¥æ˜¾ç¤ºï¼šPython 3.12.x
```

---

## ğŸš€ ç¬¬äºŒæ­¥ï¼šå®‰è£…LM Studio

### ä»€ä¹ˆæ˜¯LM Studioï¼Ÿ

LM Studioæ˜¯ä¸€ä¸ª**æ¡Œé¢åº”ç”¨**ï¼Œè®©ä½ èƒ½è½»æ¾ï¼š
- ä¸‹è½½å’Œè¿è¡Œæœ¬åœ°å¤§æ¨¡å‹
- æä¾›OpenAIå…¼å®¹çš„APIæ¥å£
- å¯è§†åŒ–ç®¡ç†æ¨¡å‹
- æ”¯æŒGPUåŠ é€Ÿ

### ä¸‹è½½å®‰è£…

1. **è®¿é—®å®˜ç½‘**
   - https://lmstudio.ai/
   - ç‚¹å‡»"Download"æŒ‰é’®

2. **é€‰æ‹©ç³»ç»Ÿç‰ˆæœ¬**
   - Windows: lmstudio-windows.exe
   - macOS: lmstudio-mac.dmgï¼ˆæ”¯æŒApple Siliconï¼‰
   - Linux: lmstudio-linux.AppImage

3. **å®‰è£…**
   - Windows: åŒå‡»è¿è¡Œå®‰è£…ç¨‹åº
   - macOS: æ‹–åˆ°Applicationsæ–‡ä»¶å¤¹
   - Linux: æ·»åŠ æ‰§è¡Œæƒé™ `chmod +x lmstudio-linux.AppImage`

4. **é¦–æ¬¡è¿è¡Œ**
   - æ‰“å¼€LM Studio
   - å¯èƒ½éœ€è¦å…è®¸ç³»ç»Ÿæƒé™
   - çœ‹åˆ°ä¸»ç•Œé¢è¯´æ˜å®‰è£…æˆåŠŸ

---

## ğŸ“¥ ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½æœ¬åœ°æ¨¡å‹

### æ¨èæ¨¡å‹åˆ—è¡¨

#### å…¥é—¨æ¨èï¼ˆ7B-8Bï¼Œ16GBå†…å­˜å¯ç”¨ï¼‰

1. **Qwen2.5-7B-Instruct**
   - æ¨¡å‹å¤§å°ï¼š~4.5GB
   - æ¨èé‡åŒ–ï¼šQ4_K_M
   - ç‰¹ç‚¹ï¼šä¸­æ–‡æ•ˆæœæœ€å¥½
   - ä¸‹è½½åï¼š`Qwen/Qwen2.5-7B-Instruct-GGUF`

2. **Llama-3.1-8B-Instruct**
   - æ¨¡å‹å¤§å°ï¼š~4.8GB
   - æ¨èé‡åŒ–ï¼šQ4_K_M
   - ç‰¹ç‚¹ï¼šé€šç”¨æ€§èƒ½å‡è¡¡
   - ä¸‹è½½åï¼š`meta-llama/Llama-3.1-8B-Instruct-GGUF`

3. **Gemma-2-9B-Instruct**
   - æ¨¡å‹å¤§å°ï¼š~5.5GB
   - æ¨èé‡åŒ–ï¼šQ4_K_M
   - ç‰¹ç‚¹ï¼šGoogleå‡ºå“ï¼Œæ¨ç†èƒ½åŠ›å¼º
   - ä¸‹è½½åï¼š`google/gemma-2-9b-it-GGUF`

#### è¿›é˜¶æ¨èï¼ˆ14B-32Bï¼Œ32GBå†…å­˜æ¨èï¼‰

1. **Qwen2.5-14B-Instruct**
   - æ¨¡å‹å¤§å°ï¼š~8.5GB
   - æ¨èé‡åŒ–ï¼šQ4_K_M
   - ç‰¹ç‚¹ï¼šä¸­æ–‡æœ€å¼ºï¼Œæ€§ä»·æ¯”é«˜

2. **Llama-3.1-70B-Instruct-Q4**
   - æ¨¡å‹å¤§å°ï¼š~40GB
   - æ¨èé‡åŒ–ï¼šQ4_K_M
   - ç‰¹ç‚¹ï¼šæ€§èƒ½æ¥è¿‘GPT-4

#### ä»£ç ä¸“ç”¨æ¨¡å‹

1. **DeepSeek-Coder-V2-Lite**
   - æ¨¡å‹å¤§å°ï¼š~8GB
   - ç‰¹ç‚¹ï¼šä»£ç ç”Ÿæˆä¼˜ç§€
   - ä¸‹è½½åï¼š`deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct-GGUF`

2. **CodeLlama-13B**
   - æ¨¡å‹å¤§å°ï¼š~7.5GB
   - ç‰¹ç‚¹ï¼šMetaå®˜æ–¹ä»£ç æ¨¡å‹

### ä¸‹è½½æ­¥éª¤

1. **æ‰“å¼€LM Studio**

2. **è¿›å…¥æ¨¡å‹å•†åº—**
   - ç‚¹å‡»å·¦ä¾§"ğŸ” Search"å›¾æ ‡

3. **æœç´¢æ¨¡å‹**
   ```
   æœç´¢ï¼šQwen2.5-7B-Instruct
   ```

4. **é€‰æ‹©é‡åŒ–ç‰ˆæœ¬**
   - æ‰¾åˆ°æ¨¡å‹åï¼Œä¼šçœ‹åˆ°å¤šä¸ªç‰ˆæœ¬
   - é€‰æ‹©ï¼š`qwen2.5-7b-instruct-q4_k_m.gguf`
   - ç‚¹å‡»"Download"

5. **ç­‰å¾…ä¸‹è½½**
   - æ˜¾ç¤ºä¸‹è½½è¿›åº¦
   - ä¸‹è½½å®Œæˆåè‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°

6. **éªŒè¯ä¸‹è½½**
   - ç‚¹å‡»å·¦ä¾§"ğŸ’¬ Chat"å›¾æ ‡
   - é¡¶éƒ¨ä¸‹æ‹‰èœå•é€‰æ‹©åˆšä¸‹è½½çš„æ¨¡å‹
   - å‡ºç°æ¨¡å‹åç§°è¯´æ˜ä¸‹è½½æˆåŠŸ

### é‡åŒ–ç‰ˆæœ¬è¯´æ˜

| é‡åŒ–ç±»å‹ | æ–‡ä»¶å¤§å° | è´¨é‡ | é€Ÿåº¦ | æ¨èåœºæ™¯ |
|---------|---------|------|------|---------|
| Q2_K | æœ€å° | â­â­ | æœ€å¿« | æµ‹è¯•ç”¨ |
| Q4_K_M | ä¸­ç­‰ | â­â­â­â­ | å¿« | **æ¨èæ—¥å¸¸ä½¿ç”¨** |
| Q5_K_M | è¾ƒå¤§ | â­â­â­â­â­ | ä¸­ | è¿½æ±‚è´¨é‡ |
| Q8_0 | å¾ˆå¤§ | â­â­â­â­â­ | æ…¢ | æœ€é«˜è´¨é‡ |
| F16 | æœ€å¤§ | â­â­â­â­â­ | æœ€æ…¢ | åŸå§‹è´¨é‡ |

**å»ºè®®**ï¼šæ–°æ‰‹ç›´æ¥é€‰ **Q4_K_M**ï¼Œæ€§èƒ½å’Œè´¨é‡å¹³è¡¡æœ€å¥½ã€‚

---

## ğŸ”§ ç¬¬å››æ­¥ï¼šå¯åŠ¨æœ¬åœ°APIæœåŠ¡

### å¯åŠ¨æœåŠ¡

1. **åŠ è½½æ¨¡å‹**
   - æ‰“å¼€LM Studio
   - ç‚¹å‡»å·¦ä¾§"ğŸ”Œ Local Server"
   - é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¦‚Qwen2.5-7B-Instruct-Q4ï¼‰
   - ç‚¹å‡»"Load Model"

2. **é…ç½®å‚æ•°**ï¼ˆå¯é€‰ï¼‰
   - **Context Length**: 4096ï¼ˆä¸Šä¸‹æ–‡é•¿åº¦ï¼‰
   - **GPU Offload**: æ ¹æ®ä½ çš„GPUæƒ…å†µè°ƒæ•´
     - æ²¡æœ‰GPU: 0
     - æœ‰GPU: è°ƒåˆ°æœ€å¤§å€¼
   - **Temperature**: 0.7ï¼ˆé»˜è®¤ï¼‰

3. **å¯åŠ¨æœåŠ¡å™¨**
   - ç‚¹å‡»"Start Server"
   - çœ‹åˆ°"Server running on http://localhost:1234"
   - è¯´æ˜æœåŠ¡å¯åŠ¨æˆåŠŸï¼

4. **éªŒè¯æœåŠ¡**
   - æµè§ˆå™¨è®¿é—®ï¼šhttp://localhost:1234/v1/models
   - åº”è¯¥çœ‹åˆ°JSONå“åº”ï¼ŒåŒ…å«æ¨¡å‹ä¿¡æ¯

### APIæ¥å£è¯´æ˜

LM Studioæä¾›**OpenAIå…¼å®¹çš„API**ï¼Œè¿™æ„å‘³ç€ï¼š
- å¯ä»¥ä½¿ç”¨OpenAIçš„SDK
- å¯ä»¥ä½¿ç”¨LangChainç­‰æ¡†æ¶
- åªéœ€è¦æ”¹å˜APIåœ°å€ï¼Œä»£ç å‡ ä¹ä¸ç”¨æ”¹

**APIåœ°å€**ï¼š`http://localhost:1234/v1`

---

## ğŸ§ª ç¬¬äº”æ­¥ï¼šæµ‹è¯•æœ¬åœ°API

### ä½¿ç”¨curlæµ‹è¯•

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5-7b-instruct",
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ],
    "temperature": 0.7,
    "max_tokens": 200
  }'
```

### ä½¿ç”¨Pythonæµ‹è¯•

åˆ›å»ºæ–‡ä»¶ `test_local_llm.py`ï¼š

```python
from openai import OpenAI

# è¿æ¥åˆ°æœ¬åœ°LM Studio
client = OpenAI(
    base_url="http://localhost:1234/v1",  # LM Studioåœ°å€
    api_key="lm-studio"  # æœ¬åœ°æ¨¡å‹ä¸éœ€è¦çœŸå®çš„keyï¼Œéšä¾¿å†™
)

# æµ‹è¯•å¯¹è¯
response = client.chat.completions.create(
    model="qwen2.5-7b-instruct",  # ä½¿ç”¨ä½ ä¸‹è½½çš„æ¨¡å‹å
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹"},
        {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ],
    temperature=0.7,
)

print("AIå›ç­”ï¼š")
print(response.choices[0].message.content)
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
# å…ˆå®‰è£…openaiåº“
pip install openai

# è¿è¡Œæµ‹è¯•
python test_local_llm.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
AIå›ç­”ï¼š
ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œç”±é˜¿é‡Œäº‘å¼€å‘...
```

---

## ğŸ“š ç¬¬å…­æ­¥ï¼šå®‰è£…LangChain v1.x

> ğŸ“Œ **é‡è¦**ï¼šæœ¬è¯¾ç¨‹ä½¿ç”¨LangChain v1.xæœ€æ–°ç‰ˆæœ¬
> 
> - **ç‰ˆæœ¬**ï¼šv1.xï¼ˆæœ€æ–°ç¨³å®šç‰ˆï¼‰
> - **Pythonè¦æ±‚**ï¼š3.10ã€3.11æˆ–3.12ï¼ˆ**ä¸æ”¯æŒ3.13+**ï¼‰
> - **æ¶æ„**ï¼šå…¨æ–°æ¨¡å—åŒ–è®¾è®¡ï¼Œæ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹åŒ…
> - **æ–‡æ¡£**ï¼šhttps://docs.langchain.com/oss/python/langchain/overview

### åˆ›å»ºé¡¹ç›®ç¯å¢ƒ

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir ai_learning
cd ai_learning

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆä½¿ç”¨Python 3.12ï¼‰
# macOS:
/opt/homebrew/bin/python3.12 -m venv .venv

# Linux:
python3.12 -m venv .venv

# Windows:
python -m venv .venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows:
.venv\Scripts\activate

# macOS/Linux:
source .venv/bin/activate

# ä½ ä¼šçœ‹åˆ°å‘½ä»¤è¡Œå‰é¢å‡ºç° (.venv)ï¼Œè¯´æ˜è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
```

### å®‰è£…LangChain v1.xåŠç›¸å…³åº“

âš ï¸ **é‡è¦**ï¼š
1. ç¡®ä¿Pythonç‰ˆæœ¬ä¸º3.10+ï¼ˆv1.xè¦æ±‚ï¼‰
2. ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»ï¼ˆå‘½ä»¤è¡Œå‰é¢æœ‰`(venv)`æ ‡è¯†ï¼‰

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆå¿…é¡»3.10+ï¼‰
python --version
# å¦‚æœç‰ˆæœ¬ä½äº3.10ï¼Œéœ€è¦å‡çº§Python

# å‡çº§pipåˆ°æœ€æ–°ç‰ˆæœ¬
pip install --upgrade pip

# å®‰è£…LangChain v1.xï¼ˆæœ€æ–°ç‰ˆï¼‰
pip install -U langchain

# å®‰è£…LangChain OpenAIé›†æˆï¼ˆç”¨äºè°ƒç”¨OpenAIå…¼å®¹APIï¼‰
pip install -U langchain-openai

# å®‰è£…LangChainç¤¾åŒºæ‰©å±•
pip install -U langchain-community

# å®‰è£…Anthropicé›†æˆï¼ˆå¯é€‰ï¼Œå¦‚æœè¦ç”¨Claudeï¼‰
pip install -U langchain-anthropic

# å®‰è£…å‘é‡æ•°æ®åº“ï¼ˆå‘é‡æ•°æ®åº“è¯¾ç¨‹éœ€è¦ï¼Œç¬¬41-70è¯¾ï¼‰
pip install -U chromadb

# å®‰è£…å·¥å…·åº“
pip install -U tiktoken
pip install -U python-dotenv

# å®‰è£…OpenAI SDKï¼ˆä¸LM Studioå…¼å®¹ï¼‰
pip install -U openai

# å®‰è£…pytestï¼ˆPyCharmè¿è¡Œæµ‹è¯•éœ€è¦ï¼‰
pip install -U pytest

# å®‰è£…requestsï¼ˆAPIæµ‹è¯•éœ€è¦ï¼‰
pip install -U requests
```

ğŸ’¡ **è¯´æ˜**ï¼šä½¿ç”¨ `-U` å‚æ•°ç¡®ä¿å®‰è£…æœ€æ–°çš„v1.xç‰ˆæœ¬

### éªŒè¯å®‰è£…

```bash
# éªŒè¯LangChainç‰ˆæœ¬ï¼ˆåº”è¯¥æ˜¾ç¤º1.x.xï¼‰
python -c "import langchain; print('LangChainç‰ˆæœ¬:', langchain.__version__)"

# éªŒè¯langchain-openaiï¼ˆå¯¼å…¥æµ‹è¯•ï¼‰
python -c "import langchain_openai; print('langchain-openai å®‰è£…æˆåŠŸ')"

# éªŒè¯æ ¸å¿ƒåŒ…
python -c "import langchain_core; print('langchain-coreç‰ˆæœ¬:', langchain_core.__version__)"

# æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆç¡®ä¿æ˜¯3.10-3.12ï¼‰
python -c "import sys; print('Pythonç‰ˆæœ¬:', sys.version)"

# å¦‚æœéƒ½æ²¡æŠ¥é”™ï¼Œè¯´æ˜å®‰è£…æˆåŠŸï¼
```

**é¢„æœŸè¾“å‡º**ï¼š
```
LangChainç‰ˆæœ¬: 1.x.x
langchain-openai å®‰è£…æˆåŠŸ
langchain-coreç‰ˆæœ¬: 1.x.x
Pythonç‰ˆæœ¬: 3.12.x (æˆ–3.11.xã€3.10.x)
```

âœ… çœ‹åˆ°LangChainç‰ˆæœ¬å·ä»¥ `1.` å¼€å¤´ï¼Œä¸”Pythonç‰ˆæœ¬æ˜¯3.10-3.12å°±å¯¹äº†ï¼

### åˆ›å»ºé…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

åœ¨ `ai_learning` ç›®å½•ä¸‹åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# æœ¬åœ°LM Studioé…ç½®
LOCAL_LLM_BASE_URL=http://localhost:1234/v1
LOCAL_LLM_API_KEY=lm-studio
LOCAL_LLM_MODEL=qwen2.5-7b-instruct

# OpenAIé…ç½®ï¼ˆå¯é€‰ï¼Œå¦‚æœä½ ä¹Ÿæƒ³ç”¨OpenAIï¼‰
# OPENAI_API_KEY=sk-your-key-here
```

**æ³¨æ„**ï¼šå¦‚æœä¸åˆ›å»º.envæ–‡ä»¶ï¼Œä»£ç ä¼šä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆä¹Ÿèƒ½æ­£å¸¸è¿è¡Œï¼‰

### æµ‹è¯•LangChain v1.x + æœ¬åœ°æ¨¡å‹

âš ï¸ **é‡è¦**ï¼šè¿è¡Œå‰ç¡®ä¿LM Studioçš„APIæœåŠ¡å·²å¯åŠ¨ï¼ˆç›‘å¬åœ¨http://localhost:1234ï¼‰

åˆ›å»º `test_langchain_local.py`ï¼š

```python
"""æµ‹è¯•LangChain v1.x + æœ¬åœ°LM Studio"""
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv
import os

# åŠ è½½é…ç½®ï¼ˆå¦‚æœ.envæ–‡ä»¶å­˜åœ¨ï¼‰
load_dotenv()

# åˆ›å»ºæœ¬åœ°æ¨¡å‹å®ä¾‹ï¼ˆè¿æ¥åˆ°LM Studioï¼‰
# LangChain v1.xä½¿ç”¨ç›¸åŒçš„ChatOpenAIæ¥å£
llm = ChatOpenAI(
    base_url=os.getenv("LOCAL_LLM_BASE_URL", "http://localhost:1234/v1"),
    api_key=os.getenv("LOCAL_LLM_API_KEY", "lm-studio"),
    model=os.getenv("LOCAL_LLM_MODEL", "qwen2.5-7b-instruct"),
    temperature=0.7
)

# æµ‹è¯•å¯¹è¯
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¼–ç¨‹åŠ©æ‰‹"),
    HumanMessage(content="è¯·ç”¨Pythonå†™ä¸€ä¸ªå¿«é€Ÿæ’åºå‡½æ•°")
]

print("æ­£åœ¨è°ƒç”¨æœ¬åœ°æ¨¡å‹...")
print(f"LangChainç‰ˆæœ¬: {__import__('langchain').__version__}")
response = llm.invoke(messages)

print("\n" + "="*50)
print("AIå›ç­”ï¼š")
print("="*50)
print(response.content)
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
# ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
source .venv/bin/activate  # macOS/Linux
# æˆ–
.venv\Scripts\activate  # Windows

# è¿è¡Œæµ‹è¯•è„šæœ¬
python test_langchain_local.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
æ­£åœ¨è°ƒç”¨æœ¬åœ°æ¨¡å‹...
LangChainç‰ˆæœ¬: 1.x.x
==================================================
AIå›ç­”ï¼š
==================================================
å¥½çš„ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªPythonå¿«é€Ÿæ’åºçš„å®ç°ï¼š

def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quick_sort(left) + middle + quick_sort(right)

# æµ‹è¯•
test_array = [3, 6, 8, 10, 1, 2, 1]
print(quick_sort(test_array))
```

---

## âœ… ç¯å¢ƒæ£€æŸ¥æ¸…å•

å®Œæˆæ‰€æœ‰æ­¥éª¤åï¼Œè¯·é€ä¸€æ£€æŸ¥ï¼š

### 1. Pythonç¯å¢ƒ
```bash
python3 --version
# æ¨èï¼šPython 3.12.x
# ä¹Ÿå¯ä»¥ï¼šPython 3.10.x æˆ– 3.11.x
```
- [ ] Python 3.12 (æ¨è) æˆ– 3.10-3.11 å·²å®‰è£…å¹¶å¯ç”¨

### 2. LM Studio
- [ ] LM Studio å·²å®‰è£…å¹¶èƒ½æ‰“å¼€
- [ ] è‡³å°‘ä¸‹è½½äº†1ä¸ªæ¨¡å‹ï¼ˆæ¨èQwen2.5-7B-Instruct-Q4ï¼‰
- [ ] LM Studio APIæœåŠ¡å¯ä»¥å¯åŠ¨ï¼ˆæ˜¾ç¤º http://localhost:1234ï¼‰

### 3. è™šæ‹Ÿç¯å¢ƒ
```bash
cd ai_learning
source .venv/bin/activate  # macOS/Linux
# çœ‹åˆ° (.venv) å‰ç¼€
```
- [ ] è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º
- [ ] è™šæ‹Ÿç¯å¢ƒå¯ä»¥æ¿€æ´»

### 4. ä¾èµ–å®‰è£…
```bash
# åœ¨è™šæ‹Ÿç¯å¢ƒä¸­æ£€æŸ¥
pip list | grep langchain
# åº”è¯¥çœ‹åˆ°ï¼š
# langchain                 1.x.x
# langchain-community       1.x.x
# langchain-core            1.x.x
# langchain-openai          1.x.x
```

```bash
# éªŒè¯å¯¼å…¥ï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
python -c "import langchain; import langchain_openai; import langchain_core; import chromadb; print('âœ… æ‰€æœ‰åŒ…å¯¼å…¥æˆåŠŸ')"
```
- [ ] LangChain v1.x å®‰è£…æˆåŠŸ
- [ ] langchain-openai å¯ä»¥æˆåŠŸå¯¼å…¥
- [ ] chromadb å¯ä»¥æˆåŠŸå¯¼å…¥
- [ ] å…¶ä»–ä¾èµ–å®‰è£…æˆåŠŸ

### 5. APIæµ‹è¯•
```bash
curl http://localhost:1234/v1/models
# åº”è¯¥è¿”å›JSONæ ¼å¼çš„æ¨¡å‹ä¿¡æ¯
```
- [ ] curlæµ‹è¯•APIæˆåŠŸ

### 6. Pythonä»£ç æµ‹è¯•
```bash
python test_local_llm.py
# åº”è¯¥çœ‹åˆ°AIå›ç­”
```
- [ ] Python + OpenAI SDK æµ‹è¯•æˆåŠŸ

### 7. LangChainæµ‹è¯•
```bash
python test_langchain_local.py
# åº”è¯¥çœ‹åˆ°LangChainç‰ˆæœ¬ï¼ˆ1.x.xï¼‰å’ŒAIå›ç­”ï¼ˆå¿«é€Ÿæ’åºä»£ç ï¼‰
```
- [ ] LangChain v1.x + æœ¬åœ°æ¨¡å‹æµ‹è¯•æˆåŠŸ

**âœ… å…¨éƒ¨æ‰“å‹¾ï¼Ÿæ­å–œï¼ä½ å·²ç»å®Œæˆç¯å¢ƒæ­å»ºï¼ğŸ‰**

---

## ğŸ” å®Œæ•´æµ‹è¯•è„šæœ¬

å¦‚æœæƒ³ä¸€æ¬¡æ€§æµ‹è¯•æ‰€æœ‰åŠŸèƒ½ï¼Œåˆ›å»º `test_all.py`ï¼š

```python
"""å®Œæ•´ç¯å¢ƒæµ‹è¯•è„šæœ¬"""
import sys

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…éœ€çš„åº“æ˜¯å¦å·²å®‰è£…"""
    print("="*60)
    print("æµ‹è¯•1ï¼šæ£€æŸ¥ä¾èµ–åŒ…")
    print("="*60)
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    py_version = f"{sys.version_info.major}.{sys.version_info.minor}"
    print(f"Pythonç‰ˆæœ¬: {py_version}")
    
    if sys.version_info >= (3, 13):
        print(f"âš ï¸  è­¦å‘Šï¼šPython {py_version} å¯èƒ½ä¸è¢«LangChain v1.xå®Œå…¨æ”¯æŒ")
        print(f"   æ¨èä½¿ç”¨Python 3.10-3.12")
    
    # å¿…éœ€åŒ…ï¼ˆæ‰€æœ‰è¯¾ç¨‹éƒ½éœ€è¦ï¼‰
    required_packages = [
        "langchain",
        "langchain_openai",
        "langchain_community",
        "langchain_core",
        "openai",
        "tiktoken",
    ]
    
    # å¯é€‰åŒ…ï¼ˆç‰¹å®šè¯¾ç¨‹éœ€è¦ï¼‰
    optional_packages = [
        ("chromadb", "å‘é‡æ•°æ®åº“è¯¾ç¨‹ï¼ˆç¬¬41-70è¯¾ï¼‰éœ€è¦"),
    ]
    
    all_ok = True
    
    print("å¿…éœ€åŒ…ï¼š")
    for package in required_packages:
        try:
            module = __import__(package)
            version = getattr(module, "__version__", "å·²å®‰è£…")
            print(f"âœ… {package:25s} {version}")
        except ImportError:
            print(f"âŒ {package:25s} æœªå®‰è£…")
            all_ok = False
        except Exception as e:
            print(f"âŒ {package:25s} å¯¼å…¥å¼‚å¸¸: {e}")
            all_ok = False
    
    print(f"\nå¯é€‰åŒ…ï¼š")
    for package, note in optional_packages:
        try:
            module = __import__(package)
            version = getattr(module, "__version__", "å·²å®‰è£…")
            print(f"âœ… {package:25s} {version}")
        except ImportError:
            print(f"âš ï¸  {package:25s} æœªå®‰è£… - {note}")
        except Exception as e:
            print(f"âš ï¸  {package:25s} å¯¼å…¥å¼‚å¸¸ - {note}")
    
    return all_ok

def test_local_api():
    """æµ‹è¯•LM Studio APIè¿æ¥"""
    print("\n" + "="*60)
    print("æµ‹è¯•2ï¼šLM Studio APIè¿æ¥")
    print("="*60)
    
    try:
        import requests
        response = requests.get("http://localhost:1234/v1/models", timeout=5)
        if response.status_code == 200:
            models = response.json()
            print(f"âœ… LM Studio APIè¿æ¥æˆåŠŸ")
            print(f"   å¯ç”¨æ¨¡å‹æ•°: {len(models.get('data', []))}")
            return True
        else:
            print(f"âŒ LM Studio APIå“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°LM Studio: {e}")
        print(f"   è¯·ç¡®ä¿LM Studioå·²å¯åŠ¨å¹¶å¼€å¯APIæœåŠ¡")
        return False

def test_langchain():
    """æµ‹è¯•LangChain + æœ¬åœ°æ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯•3ï¼šLangChain v1.x + æœ¬åœ°æ¨¡å‹")
    print("="*60)
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import HumanMessage
        
        llm = ChatOpenAI(
            base_url="http://localhost:1234/v1",
            api_key="lm-studio",
            model="qwen2.5-7b-instruct",
            temperature=0.7,
            timeout=30
        )
        
        print("æ­£åœ¨è°ƒç”¨æ¨¡å‹...")
        response = llm.invoke([HumanMessage(content="1+1ç­‰äºå‡ ï¼Ÿåªå›ç­”æ•°å­—")])
        
        print(f"âœ… LangChainè°ƒç”¨æˆåŠŸ")
        print(f"   æ¨¡å‹å›ç­”: {response.content[:50]}")
        return True
        
    except Exception as e:
        print(f"âŒ LangChainè°ƒç”¨å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹ç¯å¢ƒæµ‹è¯•...\n")
    
    results = []
    
    # æµ‹è¯•1ï¼šä¾èµ–åŒ…
    results.append(("ä¾èµ–åŒ…æ£€æŸ¥", test_imports()))
    
    # æµ‹è¯•2ï¼šAPIè¿æ¥
    results.append(("LM Studio API", test_local_api()))
    
    # æµ‹è¯•3ï¼šLangChain
    results.append(("LangChainè°ƒç”¨", test_langchain()))
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    for name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{name:20s} {status}")
    
    all_passed = all(result[1] for result in results)
    
    print("\n" + "="*60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒé…ç½®å®Œæˆï¼")
        print("âœ… ä½ å¯ä»¥å¼€å§‹å­¦ä¹ ç¬¬ä¸€è¯¾äº†ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯")
        print("ğŸ’¡ å¸¸è§é—®é¢˜ï¼š")
        print("   1. ç¡®ä¿LM Studioå·²å¯åŠ¨å¹¶å¼€å¯APIæœåŠ¡")
        print("   2. ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»")
        print("   3. ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²æ­£ç¡®å®‰è£…")
    print("="*60)
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    sys.exit(main())
```

è¿è¡Œå®Œæ•´æµ‹è¯•ï¼š

```bash
# ç¡®ä¿åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
source .venv/bin/activate  # macOS/Linux

# è¿è¡Œæµ‹è¯•
python test_all.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
ğŸš€ å¼€å§‹ç¯å¢ƒæµ‹è¯•...

============================================================
æµ‹è¯•1ï¼šæ£€æŸ¥ä¾èµ–åŒ…
============================================================
Pythonç‰ˆæœ¬: 3.12
âœ… langchain                 1.1.0
âœ… langchain_openai          å·²å®‰è£…
âœ… langchain_community       0.4.1
âœ… langchain_core            1.1.0
âœ… openai                    2.8.1
âœ… chromadb                  1.3.5
âœ… tiktoken                  0.12.0

============================================================
æµ‹è¯•2ï¼šLM Studio APIè¿æ¥
============================================================
âœ… LM Studio APIè¿æ¥æˆåŠŸ
   å¯ç”¨æ¨¡å‹æ•°: 1

============================================================
æµ‹è¯•3ï¼šLangChain v1.x + æœ¬åœ°æ¨¡å‹
============================================================
æ­£åœ¨è°ƒç”¨æ¨¡å‹...
âœ… LangChainè°ƒç”¨æˆåŠŸ
   æ¨¡å‹å›ç­”: 2

============================================================
æµ‹è¯•æ€»ç»“
============================================================
ä¾èµ–åŒ…æ£€æŸ¥             âœ… é€šè¿‡
LM Studio API         âœ… é€šè¿‡
LangChainè°ƒç”¨         âœ… é€šè¿‡

============================================================
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒé…ç½®å®Œæˆï¼
âœ… ä½ å¯ä»¥å¼€å§‹å­¦ä¹ ç¬¬ä¸€è¯¾äº†ï¼
============================================================
```

---

## ğŸš¨ å¸¸è§é—®é¢˜

### Q1: LM Studioæ— æ³•ä¸‹è½½æ¨¡å‹ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. å°è¯•ä½¿ç”¨ä»£ç†
3. æ‰‹åŠ¨ä¸‹è½½ï¼šè®¿é—® https://huggingface.co/
4. å°†ä¸‹è½½çš„æ¨¡å‹æ”¾åˆ°LM Studioçš„æ¨¡å‹ç›®å½•

### Q2: æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ˜¾ç¤ºå†…å­˜ä¸è¶³ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. é€‰æ‹©æ›´å°çš„æ¨¡å‹ï¼ˆ7Bè€Œä¸æ˜¯14Bï¼‰
2. é€‰æ‹©æ›´å°çš„é‡åŒ–ç‰ˆæœ¬ï¼ˆQ4è€Œä¸æ˜¯Q8ï¼‰
3. å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº
4. è°ƒä½GPU Offloadå‚æ•°

### Q3: APIè°ƒç”¨è¶…æ—¶æˆ–æ— å“åº”ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®è®¤LM StudioæœåŠ¡å™¨å·²å¯åŠ¨
2. æ£€æŸ¥ç«¯å£1234æ˜¯å¦è¢«å ç”¨
3. å°è¯•é‡å¯LM Studio
4. æŸ¥çœ‹LM Studioçš„æ—¥å¿—è¾“å‡º

### Q4: å¦‚ä½•éªŒè¯Pythonç‰ˆæœ¬æ˜¯å¦æ­£ç¡®ï¼Ÿ

**æ£€æŸ¥å‘½ä»¤**ï¼š
```bash
python3 --version
# æ¨èæ˜¾ç¤ºï¼šPython 3.12.x
```

**å¦‚æœç‰ˆæœ¬ä¸å¯¹**ï¼š
```bash
# macOS
brew install python@3.12
/opt/homebrew/bin/python3.12 --version

# Linux
sudo apt install python3.12
python3.12 --version

# Windows
# ä»python.orgä¸‹è½½3.12å®‰è£…åŒ…
```

**åˆ›å»ºè™šæ‹Ÿç¯å¢ƒæ—¶æŒ‡å®šç‰ˆæœ¬**ï¼š
```bash
# macOS
/opt/homebrew/bin/python3.12 -m venv .venv

# Linux
python3.12 -m venv .venv

# Windows
py -3.12 -m venv .venv
```

### Q5: Pythonæ— æ³•æ‰¾åˆ°openaiæ¨¡å—ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„pip
pip install --upgrade pip
pip install openai

# æˆ–è€…ä½¿ç”¨python -m pip
python -m pip install openai
```

### Q5: æ¨¡å‹å“åº”é€Ÿåº¦å¤ªæ…¢ï¼Ÿ

**ä¼˜åŒ–æ–¹æ¡ˆï¼š**
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆ7Bè€Œä¸æ˜¯14Bï¼‰
2. ä½¿ç”¨æ›´å°çš„é‡åŒ–ï¼ˆQ4_K_Mè€Œä¸æ˜¯Q5ï¼‰
3. å¦‚æœæœ‰GPUï¼Œåœ¨LM Studioä¸­å¯ç”¨GPUåŠ é€Ÿ
4. å‡å°‘max_tokenså‚æ•°
5. å‡å°‘context_lengthå‚æ•°

### Q6: ä¸­æ–‡å›ç­”æ•ˆæœä¸å¥½ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–çš„æ¨¡å‹ï¼ˆQwenç³»åˆ—ï¼‰
2. åœ¨æç¤ºè¯ä¸­æ˜ç¡®è¦æ±‚ç”¨ä¸­æ–‡å›ç­”
3. è°ƒæ•´temperatureå‚æ•°ï¼ˆ0.7-0.9ï¼‰

---

## ğŸ¯ æ¨¡å‹é€‰æ‹©å»ºè®®

### æ ¹æ®ä»»åŠ¡é€‰æ‹©

| ä»»åŠ¡ç±»å‹ | æ¨èæ¨¡å‹ | ç†ç”± |
|---------|---------|------|
| ä¸­æ–‡å¯¹è¯ | Qwen2.5-7B/14B | ä¸­æ–‡æ•ˆæœæœ€å¥½ |
| è‹±æ–‡å¯¹è¯ | Llama-3.1-8B | Metaå®˜æ–¹ï¼Œé€šç”¨æ€§å¼º |
| ä»£ç ç”Ÿæˆ | DeepSeek-Coderã€CodeLlama | ä¸“é—¨ä¼˜åŒ–è¿‡ä»£ç èƒ½åŠ› |
| æ¨ç†ä»»åŠ¡ | Gemma-2-9B | Googleå‡ºå“ï¼Œæ¨ç†å¼º |
| å¤šè¯­è¨€ | Llama-3.1ç³»åˆ— | æ”¯æŒå¤šç§è¯­è¨€ |

### æ ¹æ®ç¡¬ä»¶é€‰æ‹©

| å†…å­˜ | æ¨èæ¨¡å‹ | é‡åŒ–ç‰ˆæœ¬ |
|------|---------|---------|
| 16GB | 7B-8B | Q4_K_M |
| 32GB | 14B-32B | Q4_K_M |
| 64GB+ | 70B | Q4_K_M |

---

## ğŸ“– ä¸‹ä¸€æ­¥

ç¯å¢ƒæ­å»ºå®Œæˆåï¼Œä½ å¯ä»¥ï¼š

1. **å¼€å§‹ç¬¬ä¸€è¯¾**
   - ğŸ“– æ‰“å¼€ï¼š`ç¬¬ä¸€æ¨¡å—/ç¬¬01è¯¾-AIå¤§æ¨¡å‹æ˜¯ä»€ä¹ˆ.md`

2. **åˆ›å»ºå­¦ä¹ ç¬”è®°**
   - è®°å½•ä½ çš„å­¦ä¹ å¿ƒå¾—
   - è®°å½•é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

3. **åŠ å…¥å­¦ä¹ ç¤¾ç¾¤**ï¼ˆå¯é€‰ï¼‰
   - ä¸å…¶ä»–å­¦ä¹ è€…äº¤æµ
   - åˆ†äº«å­¦ä¹ ç»éªŒ

---

---

## ğŸŒ äº‘ç«¯APIé…ç½®ï¼ˆå¯é€‰ï¼‰

è™½ç„¶æœ¬è¯¾ç¨‹ä»¥æœ¬åœ°æ¨¡å‹ä¸ºä¸»ï¼Œä½†ä¹Ÿä¼šä»‹ç»äº‘ç«¯APIçš„ä½¿ç”¨æ–¹æ³•ï¼Œè®©ä½ äº†è§£å…¨é¢çš„å¼€å‘æ–¹å¼ã€‚

### OpenAI APIé…ç½®

#### 1. è·å–API Key
- è®¿é—®ï¼šhttps://platform.openai.com/
- æ³¨å†Œè´¦å·å¹¶åˆ›å»ºAPI Key
- æ–°ç”¨æˆ·é€šå¸¸æœ‰$5å…è´¹é¢åº¦

#### 2. é…ç½®ç¯å¢ƒå˜é‡

åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```bash
# OpenAIé…ç½®
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
```

#### 3. æµ‹è¯•OpenAI API

```python
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

response = client.chat.completions.create(
    model="gpt-3.5-turbo",  # æˆ– gpt-4
    messages=[
        {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ]
)

print(response.choices[0].message.content)
```

#### æ¨èæ¨¡å‹ï¼š
- **gpt-3.5-turbo**: ä¾¿å®œã€å¿«é€Ÿï¼Œé€‚åˆæ—¥å¸¸å¼€å‘
- **gpt-4**: èƒ½åŠ›å¼ºï¼Œé€‚åˆå¤æ‚ä»»åŠ¡
- **gpt-4-turbo**: æ€§ä»·æ¯”é«˜ï¼Œæ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡

---

### DeepSeek APIé…ç½®

#### 1. è·å–API Key
- è®¿é—®ï¼šhttps://platform.deepseek.com/
- æ³¨å†Œè´¦å·å¹¶åˆ›å»ºAPI Key
- æ–°ç”¨æˆ·æœ‰å…è´¹é¢åº¦

#### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
# DeepSeeké…ç½®
DEEPSEEK_API_KEY=your-deepseek-api-key
DEEPSEEK_API_BASE=https://api.deepseek.com/v1
```

#### 3. æµ‹è¯•DeepSeek API

```python
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

# DeepSeekå…¼å®¹OpenAIæ¥å£
client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url=os.getenv("DEEPSEEK_API_BASE")
)

response = client.chat.completions.create(
    model="deepseek-chat",  # æˆ– deepseek-coder
    messages=[
        {"role": "user", "content": "ç”¨Pythonå†™ä¸€ä¸ªå¿«é€Ÿæ’åº"}
    ]
)

print(response.choices[0].message.content)
```

#### æ¨èæ¨¡å‹ï¼š
- **deepseek-chat**: é€šç”¨å¯¹è¯ï¼Œæ€§ä»·æ¯”æé«˜
- **deepseek-coder**: ä»£ç ä¸“ç”¨ï¼Œç¼–ç¨‹èƒ½åŠ›å¼º

---

### Claude APIé…ç½®

#### 1. è·å–API Key
- è®¿é—®ï¼šhttps://console.anthropic.com/
- æ³¨å†Œè´¦å·å¹¶åˆ›å»ºAPI Key
- æ–°ç”¨æˆ·æœ‰å…è´¹é¢åº¦

#### 2. å®‰è£…Anthropic SDK

```bash
pip install anthropic
```

#### 3. é…ç½®ç¯å¢ƒå˜é‡

```bash
# Claudeé…ç½®
ANTHROPIC_API_KEY=your-anthropic-api-key
```

#### 4. æµ‹è¯•Claude API

```python
from anthropic import Anthropic
import os
from dotenv import load_dotenv

load_dotenv()

client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

response = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ]
)

print(response.content[0].text)
```

#### æ¨èæ¨¡å‹ï¼š
- **claude-3-5-sonnet**: æœ€å¼ºï¼Œæ¨ç†èƒ½åŠ›å‡ºè‰²
- **claude-3-haiku**: å¿«é€Ÿã€ä¾¿å®œï¼Œé€‚åˆç®€å•ä»»åŠ¡

---

### APIæˆæœ¬å¯¹æ¯”

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼(Â¥/1M tokens) | è¾“å‡ºä»·æ ¼(Â¥/1M tokens) | ç‰¹ç‚¹ |
|------|----------------------|---------------------|------|
| GPT-3.5-Turbo | ~7å…ƒ | ~14å…ƒ | ä¾¿å®œã€å¿«é€Ÿ |
| GPT-4-Turbo | ~70å…ƒ | ~210å…ƒ | èƒ½åŠ›å¼º |
| DeepSeek-Chat | ~1å…ƒ | ~2å…ƒ | **æ€§ä»·æ¯”æœ€é«˜** |
| DeepSeek-Coder | ~1å…ƒ | ~2å…ƒ | ä»£ç ä¸“ç”¨ |
| Claude-3.5-Sonnet | ~21å…ƒ | ~105å…ƒ | æ¨ç†æœ€å¼º |
| Claude-3-Haiku | ~1.75å…ƒ | ~8.75å…ƒ | å¿«é€Ÿä¾¿å®œ |
| **æœ¬åœ°æ¨¡å‹** | **0å…ƒ** | **0å…ƒ** | **å®Œå…¨å…è´¹** |

---

## ğŸ³ Ollamaï¼šå¦ä¸€ä¸ªæœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ

### ä»€ä¹ˆæ˜¯Ollamaï¼Ÿ

Ollamaæ˜¯ä¸€ä¸ª**å‘½ä»¤è¡Œå·¥å…·**ï¼Œè®©ä½ èƒ½è½»æ¾è¿è¡Œæœ¬åœ°å¤§æ¨¡å‹ï¼š
- å‘½ä»¤è¡Œæ–¹å¼ç®¡ç†æ¨¡å‹
- æä¾›REST APIæ¥å£
- æ”¯æŒå¤šç§å¼€æºæ¨¡å‹
- è½»é‡çº§ï¼Œæ˜“äºä½¿ç”¨

### Ollama vs LM Studio

| ç‰¹æ€§ | LM Studio | Ollama |
|------|-----------|--------|
| ç•Œé¢ | å›¾å½¢ç•Œé¢ï¼ˆGUIï¼‰ | å‘½ä»¤è¡Œï¼ˆCLIï¼‰ |
| ä¸Šæ‰‹éš¾åº¦ | â­ ç®€å• | â­â­ ä¸­ç­‰ |
| æ¨¡å‹ç®¡ç† | å¯è§†åŒ– | å‘½ä»¤è¡Œ |
| è·¨å¹³å° | âœ… å…¨å¹³å° | âœ… å…¨å¹³å° |
| APIæ¥å£ | OpenAIå…¼å®¹ | REST API |
| é€‚åˆäººç¾¤ | æ–°æ‰‹å‹å¥½ | å–œæ¬¢å‘½ä»¤è¡Œ |

**æœ¬è¯¾ç¨‹æ¨è**ï¼šLM Studioï¼ˆæ–°æ‰‹å‹å¥½ï¼‰
**è¿›é˜¶å¯é€‰**ï¼šOllamaï¼ˆæ›´çµæ´»ï¼‰

### å®‰è£…Ollama

#### macOS / Linux

```bash
# macOS
curl -fsSL https://ollama.com/install.sh | sh

# æˆ–ä½¿ç”¨Homebrew
brew install ollama
```

#### Windows

- è®¿é—®ï¼šhttps://ollama.com/download
- ä¸‹è½½Windowså®‰è£…åŒ…
- è¿è¡Œå®‰è£…ç¨‹åº

### ä½¿ç”¨Ollama

#### 1. ä¸‹è½½å¹¶è¿è¡Œæ¨¡å‹

```bash
# ä¸‹è½½Qwen2.5-7Bæ¨¡å‹
ollama pull qwen2.5:7b

# è¿è¡Œæ¨¡å‹ï¼ˆäº¤äº’å¼ï¼‰
ollama run qwen2.5:7b

# é€€å‡ºäº¤äº’å¼ç•Œé¢
/bye
```

#### 2. å¯åŠ¨APIæœåŠ¡

```bash
# Ollamaä¼šè‡ªåŠ¨åœ¨åå°è¿è¡ŒAPIæœåŠ¡
# é»˜è®¤åœ°å€ï¼šhttp://localhost:11434

# æµ‹è¯•API
curl http://localhost:11434/api/generate -d '{
  "model": "qwen2.5:7b",
  "prompt": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
  "stream": false
}'
```

#### 3. ä½¿ç”¨Pythonè°ƒç”¨

```python
import requests
import json

def chat_with_ollama(prompt, model="qwen2.5:7b"):
    url = "http://localhost:11434/api/generate"
    
    data = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }
    
    response = requests.post(url, json=data)
    result = response.json()
    
    return result["response"]

# æµ‹è¯•
answer = chat_with_ollama("ç”¨Pythonå†™ä¸€ä¸ªå¿«é€Ÿæ’åº")
print(answer)
```

#### 4. LangChainé›†æˆOllama

```python
from langchain_community.llms import Ollama

# åˆ›å»ºOllamaæ¨¡å‹å®ä¾‹
llm = Ollama(
    model="qwen2.5:7b",
    base_url="http://localhost:11434"
)

# ä½¿ç”¨
response = llm.invoke("ä»‹ç»ä¸€ä¸‹Pythonçš„è£…é¥°å™¨")
print(response)
```

### Ollamaå¸¸ç”¨å‘½ä»¤

```bash
# æŸ¥çœ‹å·²å®‰è£…çš„æ¨¡å‹
ollama list

# ä¸‹è½½æ¨¡å‹
ollama pull qwen2.5:7b

# è¿è¡Œæ¨¡å‹
ollama run qwen2.5:7b

# åˆ é™¤æ¨¡å‹
ollama rm qwen2.5:7b

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
ollama show qwen2.5:7b

# åœæ­¢æ‰€æœ‰æ¨¡å‹
ollama stop -a
```

### Ollamaæ¨èæ¨¡å‹

```bash
# ä¸­æ–‡é€šç”¨
ollama pull qwen2.5:7b      # 7Bï¼Œé€‚åˆ16GBå†…å­˜
ollama pull qwen2.5:14b     # 14Bï¼Œé€‚åˆ32GBå†…å­˜

# è‹±æ–‡é€šç”¨
ollama pull llama3.1:8b     # Metaå®˜æ–¹
ollama pull gemma2:9b       # Googleå‡ºå“

# ä»£ç ä¸“ç”¨
ollama pull deepseek-coder:6.7b
ollama pull codellama:13b

# è½»é‡çº§
ollama pull phi3:3.8b       # å¾®è½¯ï¼Œè½»é‡ä½†å¼ºå¤§
```

---

## ğŸ“Š éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“

### æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåœºæ™¯ |
|------|------|------|----------|
| **LM Studio** | å›¾å½¢ç•Œé¢å‹å¥½<br>OpenAIå…¼å®¹API<br>æ¨¡å‹ç®¡ç†æ–¹ä¾¿ | å ç”¨å†…å­˜ç¨å¤š | âœ… **æ–°æ‰‹é¦–é€‰**<br>æ—¥å¸¸å­¦ä¹ å¼€å‘ |
| **Ollama** | è½»é‡çº§<br>å‘½ä»¤è¡Œçµæ´»<br>æ˜“äºè„šæœ¬åŒ– | éœ€è¦å‘½ä»¤è¡ŒåŸºç¡€<br>APIæ ¼å¼ä¸åŒ | è¿›é˜¶ç”¨æˆ·<br>æœåŠ¡å™¨éƒ¨ç½² |

### äº‘ç«¯APIæ–¹æ¡ˆ

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåœºæ™¯ |
|------|------|------|----------|
| **DeepSeek** | æ€§ä»·æ¯”æœ€é«˜<br>ä»£ç èƒ½åŠ›å¼º<br>ä¸­æ–‡å‹å¥½ | ç›¸å¯¹è¾ƒæ–° | âœ… **æ€§ä»·æ¯”é¦–é€‰**<br>æ—¥å¸¸å¼€å‘ |
| **OpenAI** | ç”Ÿæ€æœ€å®Œå–„<br>æ–‡æ¡£æœ€å…¨<br>èƒ½åŠ›æœ€å¼º | ä»·æ ¼è¾ƒè´µ<br>å›½å†…è®¿é—®éœ€ä»£ç† | å­¦ä¹ å‚è€ƒ<br>é«˜è¦æ±‚ä»»åŠ¡ |
| **Claude** | æ¨ç†èƒ½åŠ›å¼º<br>é•¿æ–‡æœ¬å¤„ç†å¥½ | ä»·æ ¼è¾ƒè´µ<br>å›½å†…è®¿é—®éœ€ä»£ç† | å¤æ‚æ¨ç†ä»»åŠ¡ |

---

## ğŸ¯ å­¦ä¹ å»ºè®®

### è¯¾ç¨‹ä¸­çš„æ¨¡å‹ä½¿ç”¨ç­–ç•¥

æœ¬è¯¾ç¨‹é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼Œè®©ä½ å…¨é¢æŒæ¡ï¼š

#### åŸºç¡€é˜¶æ®µï¼ˆç¬¬1-40è¯¾ï¼‰
- âœ… **ä¸»ç”¨**ï¼šLM Studio + Qwen2.5-7Bï¼ˆå®Œå…¨å…è´¹ï¼‰
- âœ… **å¯¹æ¯”**ï¼šå±•ç¤ºOpenAI APIçš„ä»£ç ï¼ˆäº†è§£å·®å¼‚ï¼‰

#### è¿›é˜¶é˜¶æ®µï¼ˆç¬¬41-90è¯¾ï¼‰
- âœ… **ä¸»ç”¨**ï¼šLM Studioï¼ˆæ‰€æœ‰ç¤ºä¾‹ä»£ç ï¼‰
- âœ… **å¯é€‰**ï¼šDeepSeek APIï¼ˆæ€§ä»·æ¯”é«˜ï¼Œå¯é€‰å°è¯•ï¼‰
- âœ… **å¯¹æ¯”**ï¼šOllamaä½¿ç”¨æ–¹æ³•ï¼ˆå‘½ä»¤è¡Œæ–¹å¼ï¼‰

#### é«˜çº§é˜¶æ®µï¼ˆç¬¬91-165è¯¾ï¼‰
- âœ… **ä¸»ç”¨**ï¼šLM Studioï¼ˆé¡¹ç›®å¼€å‘ï¼‰
- âœ… **ä»‹ç»**ï¼šç”Ÿäº§ç¯å¢ƒçš„å¤šç§éƒ¨ç½²æ–¹æ¡ˆ
- âœ… **å¯¹æ¯”**ï¼šå„ç§APIçš„é€‚ç”¨åœºæ™¯

### ä½ çš„å­¦ä¹ è·¯å¾„

```
ç¬¬1æ­¥ï¼šå®‰è£…LM Studio + ä¸‹è½½Qwen2.5-7B
       â†“
ç¬¬2æ­¥ï¼šå­¦ä¹ è¯¾ç¨‹ï¼ˆæ‰€æœ‰ç¤ºä¾‹åŸºäºLM Studioï¼‰
       â†“
ç¬¬3æ­¥ï¼šï¼ˆå¯é€‰ï¼‰å°è¯•Ollamaï¼ˆå‘½ä»¤è¡Œæ–¹å¼ï¼‰
       â†“
ç¬¬4æ­¥ï¼šï¼ˆå¯é€‰ï¼‰å°è¯•DeepSeek APIï¼ˆæ€§ä»·æ¯”æœ€é«˜ï¼‰
       â†“
ç¬¬5æ­¥ï¼šæ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©åˆé€‚æ–¹æ¡ˆ
```

### æˆæœ¬å»ºè®®

**å®Œå…¨å…è´¹å­¦ä¹ è·¯å¾„**ï¼š
- âœ… LM Studio + æœ¬åœ°æ¨¡å‹
- âœ… æ‰€æœ‰åŠŸèƒ½éƒ½èƒ½å®ç°
- âœ… 0å…ƒæˆæœ¬

**è¿›é˜¶å­¦ä¹ è·¯å¾„**ï¼ˆå¯é€‰ï¼‰ï¼š
- âœ… ä¸»è¦ç”¨æœ¬åœ°æ¨¡å‹
- âœ… å…³é”®ä»»åŠ¡ç”¨DeepSeek APIï¼ˆæœˆæˆæœ¬10-50å…ƒï¼‰
- âœ… ä½“éªŒæœ€æ–°GPT-4æˆ–Claudeï¼ˆå¶å°”ç”¨ï¼‰

---

## ğŸ”— æœ‰ç”¨çš„èµ„æº

### å®˜æ–¹æ–‡æ¡£
- **LM Studio**: https://lmstudio.ai/docs
- **Ollama**: https://ollama.com/
- **LangChain**: https://python.langchain.com/
- **OpenAI API**: https://platform.openai.com/docs
- **DeepSeek**: https://platform.deepseek.com/
- **Claude**: https://docs.anthropic.com/

### æ¨¡å‹ä¸‹è½½
- **Hugging Face**: https://huggingface.co/models
- **LM Studioå†…ç½®å•†åº—**ï¼ˆæ¨èï¼‰
- **Ollamaå®˜æ–¹åº“**: https://ollama.com/library

### å­¦ä¹ èµ„æº
- **LangChainæ•™ç¨‹**: https://python.langchain.com/docs/get_started
- **Chromaæ–‡æ¡£**: https://docs.trychroma.com/

---

## ğŸ’ª å‡†å¤‡å¥½äº†ï¼

ç¯å¢ƒå·²ç»æ­å»ºå®Œæˆï¼Œç°åœ¨ä½ å¯ä»¥ï¼š

âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œå­¦ä¹ ï¼ˆLM Studioï¼Œå®Œå…¨å…è´¹ï¼‰
âœ… ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼ˆOllamaï¼Œè¿›é˜¶é€‰é¡¹ï¼‰
âœ… è°ƒç”¨äº‘ç«¯APIï¼ˆDeepSeek/OpenAI/Claudeï¼Œå¯é€‰ï¼‰
âœ… ä½¿ç”¨LangChainç­‰æ¡†æ¶ï¼ˆæ— ç¼é›†æˆæ‰€æœ‰æ–¹æ¡ˆï¼‰
âœ… ä¿æŠ¤æ•°æ®éšç§ï¼ˆæœ¬åœ°æ–¹æ¡ˆï¼‰

### æ¨èé…ç½®ï¼ˆæ–°æ‰‹ï¼‰

```env
# .env æ–‡ä»¶é…ç½®

# 1. æœ¬åœ°æ¨¡å‹ï¼ˆä¸»ç”¨ï¼Œå…è´¹ï¼‰
LOCAL_LLM_BASE_URL=http://localhost:1234/v1
LOCAL_LLM_API_KEY=lm-studio
LOCAL_LLM_MODEL=qwen2.5-7b-instruct

# 2. DeepSeekï¼ˆå¯é€‰ï¼Œæ€§ä»·æ¯”é«˜ï¼‰
# DEEPSEEK_API_KEY=your-key-here
# DEEPSEEK_API_BASE=https://api.deepseek.com/v1

# 3. OpenAIï¼ˆå¯é€‰ï¼Œå­¦ä¹ å‚è€ƒï¼‰
# OPENAI_API_KEY=your-key-here
```

**ä¸‹ä¸€æ­¥ï¼šå¼€å§‹ç¬¬ä¸€è¯¾çš„å­¦ä¹ ï¼**

ğŸ‘‰ æ‰“å¼€ï¼š`ç¬¬ä¸€é˜¶æ®µ-åŸºç¡€å…¥é—¨/æ¨¡å—1-AIåŸºç¡€ä¸ç¯å¢ƒæ­å»º/ç¬¬01è¯¾-AIå¤§æ¨¡å‹æ˜¯ä»€ä¹ˆ.md`

---

**åŠ æ²¹ï¼ä½ å·²ç»è¿ˆå‡ºäº†æœ€é‡è¦çš„ä¸€æ­¥ï¼ğŸš€**

