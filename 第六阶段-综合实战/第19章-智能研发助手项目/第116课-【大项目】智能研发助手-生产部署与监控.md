![智能研发助手架构](./images/project.svg)
*图：智能研发助手架构*

# 第116课：【大项目】智能研发助手-生产部署与监控

> **本课目标**：将系统部署到生产环境并建立完善的监控体系
> 
> **核心技能**：Docker容器化、K8s部署、监控告警、日志分析
> 
> **学习时长**：120分钟

---

## 📖 口播文案（10分钟）
![Agent Impl](./images/agent_impl.svg)
*图：Agent Impl*


### 🎯 前言

"前面几节课，我们完成了系统的所有核心功能。

现在最后一步：**部署到生产环境！**

**开发完成 ≠ 可以上线**

```
开发环境：
• 单机运行
• 数据量小
• 没有并发
• 不考虑故障
✓ 功能OK

生产环境需要：
• 高可用（99.9%）
• 高性能（100+ QPS）
• 可扩展（动态伸缩）
• 可观测（监控告警）
• 安全可靠（备份恢复）

差距巨大！
```

**生产部署的挑战：**

```
挑战1：性能要求
• 响应时间 < 2秒
• 支持100+并发
• GPU资源优化

挑战2：高可用
• 服务不能停
• 故障自动恢复
• 数据不能丢

挑战3：可扩展
• 用户增长
• 数据增长
• 功能增长

挑战4：运维成本
• 部署复杂
• 升级困难
• 故障定位慢
```

**我们的解决方案：**

```
方案架构：

容器化：Docker
• 环境一致
• 快速部署
• 资源隔离

编排：Kubernetes
• 自动扩缩容
• 服务发现
• 健康检查
• 滚动更新

监控：Prometheus + Grafana
• 指标采集
• 实时监控
• 告警通知

日志：ELK Stack
• 日志聚合
• 全文检索
• 问题追踪

CI/CD：GitLab CI
• 自动构建
• 自动测试
• 自动部署
```

**部署架构：**

```
┌─────────────────────────────────────────────────┐
│              Nginx Ingress                      │
│          (负载均衡 + SSL终止)                    │
└────────────┬────────────────────────────────────┘
             ↓
┌────────────────────────────────────────────────┐
│           Kubernetes集群                        │
│                                                 │
│  ┌──────────────┐  ┌──────────────┐           │
│  │ Frontend Pod │  │ Frontend Pod │ (副本)    │
│  │  React应用   │  │  React应用   │           │
│  └──────────────┘  └──────────────┘           │
│                                                 │
│  ┌──────────────┐  ┌──────────────┐           │
│  │ Backend Pod  │  │ Backend Pod  │ (副本)    │
│  │  FastAPI服务 │  │  FastAPI服务 │           │
│  └──────────────┘  └──────────────┘           │
│                                                 │
│  ┌──────────────┐  ┌──────────────┐           │
│  │  vLLM Pod    │  │  vLLM Pod    │ (GPU)     │
│  │  模型推理    │  │  模型推理    │           │
│  └──────────────┘  └──────────────┘           │
│                                                 │
│  ┌──────────────┐  ┌──────────────┐           │
│  │ Qdrant Pod   │  │ PostgreSQL   │           │
│  │  向量库      │  │  关系数据库  │           │
│  └──────────────┘  └──────────────┘           │
│                                                 │
│  ┌──────────────┐  ┌──────────────┐           │
│  │  Redis Pod   │  │  MinIO Pod   │           │
│  │  缓存+队列   │  │  对象存储    │           │
│  └──────────────┘  └──────────────┘           │
└─────────────────────────────────────────────────┘
             ↓
┌─────────────────────────────────────────────────┐
│              监控层                              │
│  ┌──────────────┐  ┌──────────────┐           │
│  │ Prometheus   │  │   Grafana    │           │
│  │  指标采集    │  │  可视化展示  │           │
│  └──────────────┘  └──────────────┘           │
│                                                 │
│  ┌──────────────┐  ┌──────────────┐           │
│  │ Elasticsearch│  │    Kibana    │           │
│  │  日志存储    │  │  日志查询    │           │
│  └──────────────┘  └──────────────┘           │
└─────────────────────────────────────────────────┘
```

**监控指标：**

```
【系统指标】

• CPU使用率
  - 平均：< 70%
  - 峰值：< 90%

• 内存使用率
  - 平均：< 80%
  - 峰值：< 95%

• GPU使用率
  - 推理时：> 70%
  - 空闲时：< 20%

• 网络流量
  - 入站：监控
  - 出站：监控

【应用指标】

• 请求QPS
  - 正常：50-100
  - 峰值：< 200

• 响应时间
  - P50：< 1s
  - P95：< 2s
  - P99：< 3s

• 错误率
  - 4xx：< 1%
  - 5xx：< 0.1%

• 并发数
  - 正常：50-100
  - 最大：200

【业务指标】

• 查询成功率：> 99%
• RAG检索时间：< 500ms
• Agent执行成功率：> 95%
• 用户满意度：> 85%
```

**告警规则：**

```
【紧急告警】(P0)
• 服务不可用（立即电话）
• GPU OOM（立即电话）
• 数据库连接失败（立即电话）

【重要告警】(P1)
• 响应时间 > 5s
• 错误率 > 5%
• CPU > 90%
• 内存 > 95%
→ 5分钟内处理

【一般告警】(P2)
• 响应时间 > 3s
• 错误率 > 2%
• 磁盘 > 80%
→ 30分钟内处理

【提示告警】(P3)
• 响应时间异常
• 流量异常
• 资源使用趋势
→ 当天处理
```

**部署流程：**

```
步骤1：准备阶段
• 准备K8s集群
• 配置镜像仓库
• 准备配置文件

步骤2：构建镜像
• 构建前端镜像
• 构建后端镜像
• 构建模型镜像
• 推送到仓库

步骤3：部署基础服务
• 部署PostgreSQL
• 部署Redis
• 部署Qdrant
• 部署MinIO

步骤4：部署应用服务
• 部署vLLM
• 部署Backend
• 部署Frontend

步骤5：配置Ingress
• 配置域名
• 配置SSL
• 配置路由

步骤6：部署监控
• 部署Prometheus
• 部署Grafana
• 配置告警

步骤7：验证测试
• 健康检查
• 功能测试
• 性能测试
• 压力测试
```

**今天这一课，我要带你：**

**第一部分：Docker容器化**
- Dockerfile编写
- 镜像构建
- 镜像优化
- 多阶段构建

**第二部分：Kubernetes部署**
- Deployment配置
- Service配置
- Ingress配置
- ConfigMap/Secret

**第三部分：监控告警**
- Prometheus配置
- Grafana面板
- 告警规则
- 通知渠道

**第四部分：日志分析**
- ELK配置
- 日志格式
- 日志查询
- 问题追踪

**第五部分：CI/CD**
- GitLab CI配置
- 自动化测试
- 自动化部署
- 回滚策略

从开发到生产，完整闭环！"

---

## 📚 第一部分：Docker容器化

### 一、Dockerfile编写

```dockerfile
# ============= 后端服务 Dockerfile =============
# backend/Dockerfile

# 多阶段构建：构建阶段
FROM python:3.10-slim as builder

WORKDIR /app

# 安装构建依赖
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .

# 安装Python依赖
RUN pip install --no-cache-dir --user -r requirements.txt

# 多阶段构建：运行阶段
FROM python:3.10-slim

WORKDIR /app

# 只复制必要的依赖
COPY --from=builder /root/.local /root/.local

# 添加到PATH
ENV PATH=/root/.local/bin:$PATH

# 复制应用代码
COPY . .

# 创建非root用户
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app

USER appuser

# 暴露端口
EXPOSE 8000

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8000/ || exit 1

# 启动命令
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

# ============= vLLM模型服务 Dockerfile =============
# vllm/Dockerfile

FROM vllm/vllm-openai:latest

# 设置工作目录
WORKDIR /app

# 复制模型文件（如果本地有）
# COPY models/ /models/

# 暴露端口
EXPOSE 8000

# 环境变量
ENV MODEL_NAME="Qwen/Qwen2-7B-Instruct"
ENV TENSOR_PARALLEL_SIZE=1
ENV GPU_MEMORY_UTILIZATION=0.95

# 启动命令
CMD ["python", "-m", "vllm.entrypoints.openai.api_server", \
     "--model", "${MODEL_NAME}", \
     "--tensor-parallel-size", "${TENSOR_PARALLEL_SIZE}", \
     "--gpu-memory-utilization", "${GPU_MEMORY_UTILIZATION}", \
     "--host", "0.0.0.0", \
     "--port", "8000"]

# ============= 前端应用 Dockerfile =============
# frontend/Dockerfile

# 构建阶段
FROM node:18-alpine as builder

WORKDIR /app

# 复制package文件
COPY package*.json ./

# 安装依赖
RUN npm ci

# 复制源代码
COPY . .

# 构建生产版本
RUN npm run build

# 运行阶段
FROM nginx:alpine

# 复制构建产物
COPY --from=builder /app/build /usr/share/nginx/html

# 复制nginx配置
COPY nginx.conf /etc/nginx/conf.d/default.conf

# 暴露端口
EXPOSE 80

# 启动nginx
CMD ["nginx", "-g", "daemon off;"]
```

### 二、Docker Compose（开发环境）

```yaml
# docker-compose.yml

version: '3.8'

services:
  # PostgreSQL数据库
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ai_assistant
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis缓存
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Qdrant向量数据库
  qdrant:
    image: qdrant/qdrant:latest
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334

  # MinIO对象存储
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"

  # vLLM模型服务
  vllm:
    build:
      context: ./vllm
      dockerfile: Dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - MODEL_NAME=Qwen/Qwen2-7B-Instruct
      - TENSOR_PARALLEL_SIZE=1
      - GPU_MEMORY_UTILIZATION=0.95
    ports:
      - "8001:8000"
    depends_on:
      - redis

  # 后端API服务
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/ai_assistant
      - REDIS_URL=redis://redis:6379
      - QDRANT_URL=http://qdrant:6333
      - VLLM_URL=http://vllm:8000
      - MINIO_URL=http://minio:9000
    ports:
      - "8000:8000"
    depends_on:
      - postgres
      - redis
      - qdrant
      - minio
      - vllm
    volumes:
      - ./backend:/app
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # 前端应用
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend

  # Prometheus监控
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"

  # Grafana可视化
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3001:3000"
    depends_on:
      - prometheus

volumes:
  postgres_data:
  redis_data:
  qdrant_data:
  minio_data:
  prometheus_data:
  grafana_data:

# 启动所有服务：
# docker-compose up -d

# 查看日志：
# docker-compose logs -f backend

# 停止服务：
# docker-compose down
```

---

## 💻 第二部分：Kubernetes部署

### 一、K8s配置文件

```yaml
# k8s/backend-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-deployment
  namespace: ai-assistant
  labels:
    app: backend
spec:
  replicas: 3  # 3个副本
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: registry.company.com/ai-assistant/backend:v1.0.0
        ports:
        - containerPort: 8000
          protocol: TCP
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: backend-secrets
              key: database-url
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        - name: QDRANT_URL
          value: "http://qdrant-service:6333"
        - name: VLLM_URL
          value: "http://vllm-service:8000"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 2
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: ai-assistant
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 8000
    targetPort: 8000
  type: ClusterIP

---
# k8s/vllm-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-deployment
  namespace: ai-assistant
spec:
  replicas: 2  # 2个GPU节点
  selector:
    matchLabels:
      app: vllm
  template:
    metadata:
      labels:
        app: vllm
    spec:
      containers:
      - name: vllm
        image: registry.company.com/ai-assistant/vllm:v1.0.0
        ports:
        - containerPort: 8000
        env:
        - name: MODEL_NAME
          value: "Qwen/Qwen2-7B-Instruct"
        - name: TENSOR_PARALLEL_SIZE
          value: "1"
        - name: GPU_MEMORY_UTILIZATION
          value: "0.95"
        resources:
          limits:
            nvidia.com/gpu: 1  # 每个Pod 1张GPU
        volumeMounts:
        - name: model-cache
          mountPath: /root/.cache
      volumes:
      - name: model-cache
        persistentVolumeClaim:
          claimName: model-cache-pvc
      nodeSelector:
        gpu: "true"  # 只调度到GPU节点
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-service
  namespace: ai-assistant
spec:
  selector:
    app: vllm
  ports:
  - protocol: TCP
    port: 8000
    targetPort: 8000
  type: ClusterIP

---
# k8s/ingress.yaml

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ai-assistant-ingress
  namespace: ai-assistant
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/websocket-services: backend-service
spec:
  tls:
  - hosts:
    - ai-assistant.company.com
    secretName: ai-assistant-tls
  rules:
  - host: ai-assistant.company.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 8000
      - path: /ws
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 8000
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80

---
# k8s/hpa.yaml (水平自动扩缩容)

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
  namespace: ai-assistant
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend-deployment
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

### 二、部署脚本

```bash
#!/bin/bash
# deploy.sh - 一键部署脚本

set -e

echo "="============================================================
echo "AI智能研发助手 - 生产部署"
echo "="============================================================

# 配置
NAMESPACE="ai-assistant"
REGISTRY="registry.company.com"
VERSION="v1.0.0"

# 1. 创建命名空间
echo -e "\n[1/8] 创建命名空间..."
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# 2. 创建Secrets
echo -e "\n[2/8] 创建Secrets..."
kubectl create secret generic backend-secrets \
  --from-literal=database-url="postgresql://..." \
  --namespace=$NAMESPACE \
  --dry-run=client -o yaml | kubectl apply -f -

# 3. 部署基础服务
echo -e "\n[3/8] 部署基础服务..."
kubectl apply -f k8s/postgres.yaml -n $NAMESPACE
kubectl apply -f k8s/redis.yaml -n $NAMESPACE
kubectl apply -f k8s/qdrant.yaml -n $NAMESPACE

# 等待基础服务就绪
echo "等待基础服务就绪..."
kubectl wait --for=condition=ready pod -l app=postgres -n $NAMESPACE --timeout=300s
kubectl wait --for=condition=ready pod -l app=redis -n $NAMESPACE --timeout=300s
kubectl wait --for=condition=ready pod -l app=qdrant -n $NAMESPACE --timeout=300s

# 4. 部署vLLM服务
echo -e "\n[4/8] 部署vLLM服务..."
kubectl apply -f k8s/vllm-deployment.yaml -n $NAMESPACE

# 等待vLLM就绪
echo "等待vLLM服务就绪..."
kubectl wait --for=condition=ready pod -l app=vllm -n $NAMESPACE --timeout=600s

# 5. 部署后端服务
echo -e "\n[5/8] 部署后端服务..."
kubectl apply -f k8s/backend-deployment.yaml -n $NAMESPACE

# 6. 部署前端服务
echo -e "\n[6/8] 部署前端服务..."
kubectl apply -f k8s/frontend-deployment.yaml -n $NAMESPACE

# 7. 配置Ingress
echo -e "\n[7/8] 配置Ingress..."
kubectl apply -f k8s/ingress.yaml -n $NAMESPACE

# 8. 配置HPA
echo -e "\n[8/8] 配置自动扩缩容..."
kubectl apply -f k8s/hpa.yaml -n $NAMESPACE

echo -e "\n="============================================================
echo "✅ 部署完成！"
echo "="============================================================

# 显示状态
echo -e "\n服务状态："
kubectl get pods -n $NAMESPACE

echo -e "\n访问地址："
echo "• Web界面：https://ai-assistant.company.com"
echo "• API文档：https://ai-assistant.company.com/api/docs"

echo -e "\n监控地址："
echo "• Prometheus：http://prometheus.company.com"
echo "• Grafana：http://grafana.company.com"
```

---

## 🎯 第三部分：监控告警

### 一、Prometheus配置

```yaml
# monitoring/prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s

# 告警规则文件
rule_files:
  - 'alerts.yml'

# 采集配置
scrape_configs:
  # Prometheus自身
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Kubernetes节点
  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
      - role: node
    relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__

  # Kubernetes Pods
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - ai-assistant
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

  # Backend服务
  - job_name: 'backend'
    static_configs:
      - targets: ['backend-service:8000']
    metrics_path: '/metrics'

  # vLLM服务
  - job_name: 'vllm'
    static_configs:
      - targets: ['vllm-service:8000']
    metrics_path: '/metrics'

# 告警配置
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

---
# monitoring/alerts.yml

groups:
  - name: ai_assistant_alerts
    interval: 30s
    rules:
      # 服务不可用告警 (P0)
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          priority: P0
        annotations:
          summary: "服务 {{ $labels.job }} 不可用"
          description: "{{ $labels.job }} 已经down了 {{ $value }} 秒"

      # 高错误率告警 (P1)
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          priority: P1
        annotations:
          summary: "高错误率：{{ $labels.job }}"
          description: "5xx错误率: {{ $value | humanizePercentage }}"

      # 响应时间过长告警 (P1)
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 3
        for: 5m
        labels:
          severity: warning
          priority: P1
        annotations:
          summary: "响应时间过长：{{ $labels.job }}"
          description: "P95响应时间: {{ $value }}s"

      # CPU使用率过高 (P2)
      - alert: HighCPUUsage
        expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
        for: 10m
        labels:
          severity: warning
          priority: P2
        annotations:
          summary: "CPU使用率过高：{{ $labels.instance }}"
          description: "CPU使用率: {{ $value | humanize }}%"

      # 内存使用率过高 (P2)
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
        for: 10m
        labels:
          severity: warning
          priority: P2
        annotations:
          summary: "内存使用率过高：{{ $labels.instance }}"
          description: "内存使用率: {{ $value | humanize }}%"

      # GPU显存不足 (P1)
      - alert: GPUMemoryLow
        expr: DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_TOTAL > 0.95
        for: 5m
        labels:
          severity: warning
          priority: P1
        annotations:
          summary: "GPU显存不足：{{ $labels.gpu }}"
          description: "显存使用率: {{ $value | humanizePercentage }}"
```

---

## 📝 课后练习

### 练习1：容器化
构建你的应用镜像

### 练习2：K8s部署
部署到K8s集群

### 练习3：监控配置
配置Prometheus监控

---

## 🎓 知识总结

### 核心要点

1. **容器化**
   - Dockerfile最佳实践
   - 多阶段构建
   - 镜像优化

2. **K8s部署**
   - Deployment配置
   - Service暴露
   - Ingress路由
   - HPA自动扩缩容

3. **监控告警**
   - Prometheus采集
   - 告警规则
   - Grafana可视化

4. **生产运维**
   - 健康检查
   - 滚动更新
   - 日志管理
   - 故障恢复

---

## 🚀 下节预告

下一课：**第117课：【大项目】智能研发助手-项目总结与展望**

- 项目回顾
- 技术总结
- 最佳实践
- 未来规划

**智能研发助手项目完美收官！** 🎉

---

**💪 记住：部署只是开始，运维是持续的！**

**下一课见！** 🎉
