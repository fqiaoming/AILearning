![çŸ¥è¯†å›¾è°±æ¶æ„](./images/knowledge_graph.svg)
*å›¾ï¼šçŸ¥è¯†å›¾è°±æ¶æ„*

# ç¬¬70.4è¯¾ï¼šGraph-RAG-çŸ¥è¯†å›¾è°±å¢å¼ºæ£€ç´¢

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŒæ¡Graph-RAGæŠ€æœ¯ï¼ŒèåˆçŸ¥è¯†å›¾è°±ä¸å‘é‡æ£€ç´¢
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šGraph-RAGæ¶æ„ã€æ··åˆæ£€ç´¢ã€å›¾è°±+å‘é‡èåˆã€å®æˆ˜åº”ç”¨
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š100åˆ†é’Ÿ
> 
> **é‡è¦æ€§**ï¼šâ­â­â­â­â­ï¼ˆå·¥ä¸šç•Œçƒ­é—¨æŠ€æœ¯ï¼ŒAIå·¥ç¨‹å¸ˆæ ¸å¿ƒç«äº‰åŠ›ï¼‰

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ8åˆ†é’Ÿï¼‰

### ğŸ¯ å‰è¨€

"**æ¬¢è¿æ¥åˆ°Graph-RAGæ ¸å¿ƒè¯¾ç¨‹ï¼**

å‰é¢æˆ‘ä»¬å­¦ä¹ äº†ï¼š
- ç¬¬54-60è¯¾ï¼šRAGç³»ç»Ÿï¼ˆå‘é‡æ£€ç´¢ï¼‰
- ç¬¬70.1-70.3è¯¾ï¼šçŸ¥è¯†å›¾è°±ï¼ˆå…³ç³»æŸ¥è¯¢ï¼‰

ä»Šå¤©è¦å­¦ä¹ ï¼š**Graph-RAG = çŸ¥è¯†å›¾è°± + å‘é‡æ£€ç´¢**

**è¿™æ˜¯AIå·¥ç¨‹å¸ˆå¿…é¡»æŒæ¡çš„æ ¸å¿ƒæŠ€èƒ½ï¼**

ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºï¼š

**é—®é¢˜1ï¼šçº¯å‘é‡RAGçš„å±€é™**

```
åœºæ™¯ï¼šä¼ä¸šæŠ€æœ¯æ–‡æ¡£é—®ç­”

ç”¨æˆ·é—®ï¼š"LangChainå’ŒLlamaIndexçš„æ€§èƒ½å¯¹æ¯”æ˜¯ä»€ä¹ˆï¼Ÿ"

ä¼ ç»Ÿå‘é‡RAGï¼š
1. æ£€ç´¢åˆ°LangChainç›¸å…³æ–‡æ¡£ âœ…
2. æ£€ç´¢åˆ°LlamaIndexç›¸å…³æ–‡æ¡£ âœ…
3. ä½†æ£€ç´¢ç»“æœæ˜¯ç‹¬ç«‹çš„ç‰‡æ®µ âŒ

ç”Ÿæˆçš„ç­”æ¡ˆï¼š
"LangChainæ˜¯ä¸€ä¸ªæ¡†æ¶...LlamaIndexä¹Ÿæ˜¯ä¸€ä¸ªæ¡†æ¶..."
â†’ ç¼ºå°‘å¯¹æ¯”ç»´åº¦
â†’ ä¿¡æ¯ä¸å®Œæ•´
â†’ éœ€è¦å¤§æ¨¡å‹è‡ªå·±æ¨ç†

Graph-RAGï¼š
1. æ£€ç´¢LangChainå®ä½“åŠå…¶å±æ€§ï¼ˆæ€§èƒ½ã€ç‰¹ç‚¹ï¼‰
2. æ£€ç´¢LlamaIndexå®ä½“åŠå…¶å±æ€§
3. æ£€ç´¢ä¸¤è€…çš„å¯¹æ¯”å…³ç³»
4. ç»“åˆå‘é‡æ£€ç´¢çš„æ–‡æ¡£

ç”Ÿæˆçš„ç­”æ¡ˆï¼š
"å¯¹æ¯”å¦‚ä¸‹ï¼š
æ€§èƒ½ï¼šLangChainå¤„ç†é€Ÿåº¦æ›´å¿«ï¼ˆ2xï¼‰
æ˜“ç”¨æ€§ï¼šLlamaIndexæ–‡æ¡£æ›´å®Œå–„
ç¤¾åŒºï¼šLangChainç¤¾åŒºæ›´æ´»è·ƒï¼ˆ10k stars vs 5kï¼‰
é€‚ç”¨åœºæ™¯ï¼š
- LangChainï¼šå¤æ‚Agentåº”ç”¨
- LlamaIndexï¼šæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿ"

â†’ ç»“æ„åŒ–å¯¹æ¯”
â†’ æœ‰æ•°æ®æ”¯æ’‘
â†’ æ›´å‡†ç¡®å¯ä¿¡ï¼
```

**é—®é¢˜2ï¼šçº¯çŸ¥è¯†å›¾è°±çš„å±€é™**

```
åœºæ™¯ï¼šåŒ»ç–—å’¨è¯¢

ç”¨æˆ·é—®ï¼š"å¦‚ä½•ç¼“è§£é«˜è¡€å‹ç—‡çŠ¶ï¼Ÿ"

çº¯çŸ¥è¯†å›¾è°±ï¼š
â€¢ é«˜è¡€å‹ -[ç—‡çŠ¶]-> å¤´ç—›ã€å¤´æ™•
â€¢ é«˜è¡€å‹ -[æ²»ç–—]-> é™å‹è¯
â€¢ é«˜è¡€å‹ -[é¢„é˜²]-> è¿åŠ¨ã€é¥®é£Ÿ

ä½†ï¼š
â€¢ æ— æ³•æä¾›è¯¦ç»†çš„æ–‡å­—è¯´æ˜
â€¢ æ— æ³•å›ç­”å¼€æ”¾æ€§é—®é¢˜
â€¢ çŸ¥è¯†è¦†ç›–ä¸å…¨

Graph-RAGï¼š
1. ä»å›¾è°±è·å–ç»“æ„åŒ–çŸ¥è¯†ï¼ˆç—‡çŠ¶ã€è¯ç‰©ã€é¢„é˜²ï¼‰
2. ä»å‘é‡åº“æ£€ç´¢è¯¦ç»†æ–‡æ¡£ï¼ˆç”¨è¯è¯´æ˜ã€æ³¨æ„äº‹é¡¹ï¼‰
3. ç»“åˆç”Ÿæˆå®Œæ•´ç­”æ¡ˆ

ç­”æ¡ˆï¼š
"é«˜è¡€å‹ç—‡çŠ¶ç¼“è§£æ–¹æ³•ï¼š
1. è¯ç‰©æ²»ç–—ï¼ˆä»å›¾è°±ï¼‰
   - å¸¸ç”¨è¯ç‰©ï¼šXXé™å‹ç‰‡
   - ç”¨æ³•ç”¨é‡ï¼šæ¯æ—¥ä¸€æ¬¡ï¼Œæ—©é¤å
   
2. ç”Ÿæ´»æ–¹å¼ï¼ˆä»æ–‡æ¡£ï¼‰
   - ä½ç›é¥®é£Ÿï¼šæ¯æ—¥<6g
   - é€‚é‡è¿åŠ¨ï¼šæ¯å‘¨150åˆ†é’Ÿä¸­ç­‰å¼ºåº¦
   - æˆ’çƒŸé™é…’
   
3. æ³¨æ„äº‹é¡¹ï¼ˆä»æ–‡æ¡£ï¼‰
   - å®šæœŸæµ‹è¡€å‹
   - è¯ç‰©å‰¯ä½œç”¨ç›‘æµ‹
   - ..."

â†’ ç»“æ„åŒ– + è¯¦ç»†è¯´æ˜
â†’ å®Œæ•´å…¨é¢ï¼
```

**ä»Šå¤©è¦å­¦ä¹ ï¼šå¦‚ä½•æ„å»ºGraph-RAGç³»ç»Ÿï¼**

---

### ğŸ’¡ ä»€ä¹ˆæ˜¯Graph-RAGï¼Ÿ

**æ ¸å¿ƒæ€æƒ³ï¼š**

```
ä¼ ç»ŸRAGï¼š
Query â†’ å‘é‡æ£€ç´¢ â†’ æ–‡æ¡£ç‰‡æ®µ â†’ LLMç”Ÿæˆ

Graph-RAGï¼š
Query â†’ æ··åˆæ£€ç´¢ â†’ {
  å‘é‡æ£€ç´¢ â†’ æ–‡æ¡£ç‰‡æ®µ
  +
  å›¾è°±æ£€ç´¢ â†’ ç»“æ„åŒ–çŸ¥è¯†
} â†’ LLMç”Ÿæˆ

ä¼˜åŠ¿ï¼š
âœ… ç»“æ„åŒ– + éç»“æ„åŒ–çŸ¥è¯†èåˆ
âœ… ç²¾ç¡®å…³ç³» + è¯­ä¹‰æ£€ç´¢
âœ… å¯è§£é‡Šæ€§æ›´å¼º
âœ… å‡†ç¡®åº¦æ›´é«˜
```

**æŠ€æœ¯æ¶æ„ï¼š**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Graph-RAG System            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Query   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Query Analyzer  â”‚  â† åˆ†ææŸ¥è¯¢æ„å›¾
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ å®ä½“è¯†åˆ«    â”‚    â”‚ å…³ç³»è¯†åˆ«    â”‚   â”‚ å‘é‡æ£€ç´¢    â”‚
    â”‚(NER)       â”‚    â”‚(Relation)  â”‚   â”‚(Vector)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                 â”‚                 â”‚
           â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ çŸ¥è¯†å›¾è°±    â”‚    â”‚ å…³ç³»æŸ¥è¯¢    â”‚   â”‚ å‘é‡æ•°æ®åº“  â”‚
    â”‚(Neo4j)     â”‚    â”‚(Cypher)    â”‚   â”‚(Chroma)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                 â”‚                 â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Context Fusion â”‚  â† èåˆç»“æœ
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   LLM Generate  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Answer â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š æ ¸å¿ƒçŸ¥è¯†

### ä¸€ã€Graph-RAGæ¶æ„è®¾è®¡

#
![Graph-RAGèåˆ](./images/graph_rag.svg)
*å›¾ï¼šGraph-RAGèåˆ*

### 1. åŒè·¯æ£€ç´¢æ¶æ„

```python
class GraphRAG:
    """Graph-RAGæ ¸å¿ƒæ¶æ„"""
    
    def __init__(self, graph_db, vector_db, llm):
        self.graph_db = graph_db  # Neo4j
        self.vector_db = vector_db  # Chroma
        self.llm = llm
        self.ner = self._init_ner()  # å®ä½“è¯†åˆ«
    
    def retrieve(self, query: str):
        """æ··åˆæ£€ç´¢"""
        
        # 1. å®ä½“è¯†åˆ«
        entities = self.ner.extract(query)
        
        # 2. å›¾è°±æ£€ç´¢ï¼ˆç»“æ„åŒ–çŸ¥è¯†ï¼‰
        graph_results = self._graph_retrieve(entities, query)
        
        # 3. å‘é‡æ£€ç´¢ï¼ˆéç»“æ„åŒ–çŸ¥è¯†ï¼‰
        vector_results = self._vector_retrieve(query)
        
        # 4. èåˆç»“æœ
        context = self._fuse_results(graph_results, vector_results)
        
        return context
    
    def _graph_retrieve(self, entities, query):
        """ä»çŸ¥è¯†å›¾è°±æ£€ç´¢"""
        results = []
        
        for entity in entities:
            # æŸ¥è¯¢å®ä½“åŠå…¶é‚»å±…
            cypher = """
            MATCH (e:Entity {name: $entity})
            OPTIONAL MATCH (e)-[r]-(neighbor)
            RETURN e, r, neighbor
            LIMIT 10
            """
            result = self.graph_db.run(cypher, entity=entity)
            results.append(result)
        
        return results
    
    def _vector_retrieve(self, query):
        """ä»å‘é‡åº“æ£€ç´¢"""
        results = self.vector_db.similarity_search(
            query=query,
            k=5
        )
        return results
    
    def _fuse_results(self, graph_results, vector_results):
        """èåˆç»“æœ"""
        context = {
            "structured": self._format_graph(graph_results),
            "unstructured": self._format_vector(vector_results)
        }
        return context
```

#### 2. æ™ºèƒ½è·¯ç”±æ¶æ„

```python
class SmartGraphRAG:
    """æ™ºèƒ½è·¯ç”±Graph-RAG"""
    
    def __init__(self, graph_db, vector_db, llm):
        self.graph_db = graph_db
        self.vector_db = vector_db
        self.llm = llm
    
    def retrieve(self, query: str):
        """æ™ºèƒ½è·¯ç”±æ£€ç´¢"""
        
        # 1. åˆ†ææŸ¥è¯¢ç±»å‹
        query_type = self._analyze_query(query)
        
        # 2. æ ¹æ®ç±»å‹é€‰æ‹©ç­–ç•¥
        if query_type == "relation_query":
            # å…³ç³»æŸ¥è¯¢ï¼šä¸»è¦ç”¨å›¾è°±
            return self._graph_heavy_retrieve(query)
        
        elif query_type == "semantic_query":
            # è¯­ä¹‰æŸ¥è¯¢ï¼šä¸»è¦ç”¨å‘é‡
            return self._vector_heavy_retrieve(query)
        
        else:
            # æ··åˆæŸ¥è¯¢ï¼šä¸¤è€…ç»“åˆ
            return self._balanced_retrieve(query)
    
    def _analyze_query(self, query: str):
        """åˆ†ææŸ¥è¯¢ç±»å‹"""
        
        # å…³é”®è¯è¯†åˆ«
        relation_keywords = ["å…³ç³»", "å¯¹æ¯”", "åŒºåˆ«", "å…±åŒç‚¹", "è°çš„"]
        semantic_keywords = ["å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "æ˜¯ä»€ä¹ˆ", "è§£é‡Š"]
        
        if any(kw in query for kw in relation_keywords):
            return "relation_query"
        elif any(kw in query for kw in semantic_keywords):
            return "semantic_query"
        else:
            return "mixed_query"
```

---

### äºŒã€å®ä½“è¯†åˆ«ä¸é“¾æ¥

#### 1. NERå®ä½“è¯†åˆ«

```python
from typing import List, Dict
import spacy

class EntityExtractor:
    """å®ä½“æå–å™¨"""
    
    def __init__(self):
        # åŠ è½½ä¸­æ–‡NERæ¨¡å‹
        self.nlp = spacy.load("zh_core_web_sm")
    
    def extract(self, text: str) -> List[Dict]:
        """æå–å®ä½“"""
        doc = self.nlp(text)
        
        entities = []
        for ent in doc.ents:
            entities.append({
                "text": ent.text,
                "label": ent.label_,
                "start": ent.start_char,
                "end": ent.end_char
            })
        
        return entities

# ä½¿ç”¨ç¤ºä¾‹
extractor = EntityExtractor()

query = "LangChainå’ŒLlamaIndexçš„æ€§èƒ½å¯¹æ¯”"
entities = extractor.extract(query)
print(entities)
# [
#   {"text": "LangChain", "label": "PRODUCT"},
#   {"text": "LlamaIndex", "label": "PRODUCT"}
# ]
```

#### 2. å®ä½“é“¾æ¥

```python
class EntityLinker:
    """å®ä½“é“¾æ¥å™¨ï¼šå°†æ–‡æœ¬å®ä½“é“¾æ¥åˆ°å›¾è°±å®ä½“"""
    
    def __init__(self, graph_db):
        self.graph_db = graph_db
    
    def link(self, entities: List[Dict]) -> List[Dict]:
        """é“¾æ¥å®ä½“åˆ°çŸ¥è¯†å›¾è°±"""
        linked = []
        
        for entity in entities:
            # æ¨¡ç³ŠåŒ¹é…å›¾è°±ä¸­çš„å®ä½“
            cypher = """
            MATCH (e:Entity)
            WHERE e.name =~ $pattern OR e.alias =~ $pattern
            RETURN e.id, e.name, e.type
            LIMIT 1
            """
            
            pattern = f"(?i).*{entity['text']}.*"
            result = self.graph_db.run(cypher, pattern=pattern)
            
            if result:
                linked.append({
                    "text": entity["text"],
                    "graph_id": result["e.id"],
                    "graph_name": result["e.name"],
                    "type": result["e.type"]
                })
        
        return linked
```

---

### ä¸‰ã€å›¾è°±æ£€ç´¢ç­–ç•¥

#### 1. ä¸€è·³æ£€ç´¢

```python
def one_hop_retrieve(graph_db, entity_id: str):
    """ä¸€è·³æ£€ç´¢ï¼šæŸ¥è¯¢å®ä½“çš„ç›´æ¥é‚»å±…"""
    
    cypher = """
    MATCH (e:Entity {id: $entity_id})-[r]-(neighbor)
    RETURN e, type(r) as relation, neighbor
    """
    
    result = graph_db.run(cypher, entity_id=entity_id)
    return result
```

#### 2. å¤šè·³æ£€ç´¢

```python
def multi_hop_retrieve(graph_db, entity_id: str, max_hops: int = 2):
    """å¤šè·³æ£€ç´¢ï¼šæŸ¥è¯¢å¤šåº¦å…³ç³»"""
    
    cypher = f"""
    MATCH path = (e:Entity {{id: $entity_id}})-[*1..{max_hops}]-(neighbor)
    RETURN path, length(path) as distance
    ORDER BY distance
    LIMIT 20
    """
    
    result = graph_db.run(cypher, entity_id=entity_id)
    return result
```

#### 3. è·¯å¾„æ£€ç´¢

```python
def path_retrieve(graph_db, entity1_id: str, entity2_id: str):
    """è·¯å¾„æ£€ç´¢ï¼šæŸ¥è¯¢ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»è·¯å¾„"""
    
    cypher = """
    MATCH path = shortestPath(
      (e1:Entity {id: $entity1_id})-[*]-(e2:Entity {id: $entity2_id})
    )
    RETURN path, length(path) as distance
    """
    
    result = graph_db.run(cypher, 
                          entity1_id=entity1_id, 
                          entity2_id=entity2_id)
    return result
```

#### 4. å­å›¾æ£€ç´¢

```python
def subgraph_retrieve(graph_db, entity_ids: List[str]):
    """å­å›¾æ£€ç´¢ï¼šæŸ¥è¯¢å¤šä¸ªå®ä½“æ„æˆçš„å­å›¾"""
    
    cypher = """
    MATCH (e:Entity)
    WHERE e.id IN $entity_ids
    OPTIONAL MATCH path = (e)-[r]-(neighbor)
    WHERE neighbor.id IN $entity_ids
    RETURN path
    """
    
    result = graph_db.run(cypher, entity_ids=entity_ids)
    return result
```

---

### å››ã€ç»“æœèåˆç­–ç•¥

#### 1. ç®€å•æ‹¼æ¥

```python
def simple_fusion(graph_results, vector_results):
    """ç®€å•æ‹¼æ¥"""
    
    context = "ã€ç»“æ„åŒ–çŸ¥è¯†ã€‘\n"
    context += format_graph_results(graph_results)
    context += "\n\nã€æ–‡æ¡£å†…å®¹ã€‘\n"
    context += format_vector_results(vector_results)
    
    return context
```

#### 2. åŠ æƒèåˆ

```python
def weighted_fusion(graph_results, vector_results, 
                    graph_weight=0.6, vector_weight=0.4):
    """åŠ æƒèåˆ"""
    
    # è®¡ç®—å›¾è°±ç»“æœçš„é‡è¦æ€§åˆ†æ•°
    graph_scores = score_graph_results(graph_results)
    
    # è®¡ç®—å‘é‡ç»“æœçš„ç›¸ä¼¼åº¦åˆ†æ•°
    vector_scores = score_vector_results(vector_results)
    
    # èåˆ
    all_results = []
    
    for result, score in zip(graph_results, graph_scores):
        all_results.append({
            "content": result,
            "score": score * graph_weight,
            "source": "graph"
        })
    
    for result, score in zip(vector_results, vector_scores):
        all_results.append({
            "content": result,
            "score": score * vector_weight,
            "source": "vector"
        })
    
    # æŒ‰åˆ†æ•°æ’åº
    all_results.sort(key=lambda x: x["score"], reverse=True)
    
    return all_results[:10]  # è¿”å›Top10
```

#### 3. è¯­ä¹‰å»é‡

```python
from sentence_transformers import SentenceTransformer, util

def semantic_dedup_fusion(graph_results, vector_results):
    """è¯­ä¹‰å»é‡èåˆ"""
    
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    all_results = graph_results + vector_results
    
    # è®¡ç®—åµŒå…¥
    embeddings = model.encode([r["content"] for r in all_results])
    
    # å»é‡ï¼šç§»é™¤é«˜åº¦ç›¸ä¼¼çš„ç»“æœ
    selected = [0]  # ä¿ç•™ç¬¬ä¸€ä¸ª
    
    for i in range(1, len(all_results)):
        # è®¡ç®—ä¸å·²é€‰æ‹©ç»“æœçš„ç›¸ä¼¼åº¦
        similarities = util.cos_sim(
            embeddings[i], 
            embeddings[selected]
        )
        
        # å¦‚æœç›¸ä¼¼åº¦éƒ½å°äº0.8ï¼Œåˆ™ä¿ç•™
        if similarities.max() < 0.8:
            selected.append(i)
    
    return [all_results[i] for i in selected]
```

---

## ğŸ’» å®Œæ•´å®æˆ˜ï¼šæ„å»ºGraph-RAGç³»ç»Ÿ

### ç³»ç»Ÿå®ç°

```python
from typing import List, Dict, Optional
from neo4j import GraphDatabase
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

class GraphRAGSystem:
    """å®Œæ•´çš„Graph-RAGç³»ç»Ÿ"""
    
    def __init__(
        self,
        neo4j_uri: str,
        neo4j_user: str,
        neo4j_password: str,
        chroma_path: str,
        llm_model: str = "gpt-3.5-turbo"
    ):
        # åˆå§‹åŒ–å›¾æ•°æ®åº“
        self.graph_driver = GraphDatabase.driver(
            neo4j_uri,
            auth=(neo4j_user, neo4j_password)
        )
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        self.vector_store = Chroma(
            persist_directory=chroma_path,
            embedding_function=embeddings
        )
        
        # åˆå§‹åŒ–LLM
        self.llm = ChatOpenAI(model=llm_model, temperature=0)
        
        # å®ä½“æå–å™¨
        self.entity_extractor = EntityExtractor()
    
    def query(self, question: str) -> Dict:
        """æŸ¥è¯¢æ¥å£"""
        
        print(f"é—®é¢˜ï¼š{question}\n")
        
        # 1. å®ä½“è¯†åˆ«
        entities = self.entity_extractor.extract(question)
        print(f"è¯†åˆ«å®ä½“ï¼š{[e['text'] for e in entities]}\n")
        
        # 2. å›¾è°±æ£€ç´¢
        graph_context = self._retrieve_from_graph(entities)
        print(f"å›¾è°±æ£€ç´¢ç»“æœï¼š\n{graph_context}\n")
        
        # 3. å‘é‡æ£€ç´¢
        vector_context = self._retrieve_from_vector(question)
        print(f"å‘é‡æ£€ç´¢ç»“æœï¼š\n{vector_context}\n")
        
        # 4. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(
            question, 
            graph_context, 
            vector_context
        )
        
        return {
            "question": question,
            "entities": entities,
            "graph_context": graph_context,
            "vector_context": vector_context,
            "answer": answer
        }
    
    def _retrieve_from_graph(self, entities: List[Dict]) -> str:
        """ä»çŸ¥è¯†å›¾è°±æ£€ç´¢"""
        
        if not entities:
            return "æœªæ‰¾åˆ°ç›¸å…³å®ä½“"
        
        context_parts = []
        
        with self.graph_driver.session() as session:
            for entity in entities:
                # æŸ¥è¯¢å®ä½“åŠå…¶å…³ç³»
                result = session.run(
                    """
                    MATCH (e:Entity)
                    WHERE e.name =~ $pattern
                    OPTIONAL MATCH (e)-[r]-(neighbor:Entity)
                    RETURN e, type(r) as relation, neighbor
                    LIMIT 10
                    """,
                    pattern=f"(?i).*{entity['text']}.*"
                )
                
                for record in result:
                    e = record["e"]
                    relation = record["relation"]
                    neighbor = record["neighbor"]
                    
                    if relation and neighbor:
                        context_parts.append(
                            f"{e['name']} -{relation}-> {neighbor['name']}"
                        )
                    else:
                        # å®ä½“å±æ€§
                        props = ", ".join([f"{k}: {v}" for k, v in e.items()])
                        context_parts.append(f"{e['name']}: {props}")
        
        return "\n".join(context_parts) if context_parts else "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†"
    
    def _retrieve_from_vector(self, question: str) -> str:
        """ä»å‘é‡åº“æ£€ç´¢"""
        
        docs = self.vector_store.similarity_search(question, k=3)
        
        context_parts = []
        for i, doc in enumerate(docs, 1):
            context_parts.append(f"[æ–‡æ¡£{i}] {doc.page_content}")
        
        return "\n\n".join(context_parts)
    
    def _generate_answer(
        self, 
        question: str, 
        graph_context: str, 
        vector_context: str
    ) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚
è¯·åŸºäºæä¾›çš„ç»“æ„åŒ–çŸ¥è¯†ï¼ˆæ¥è‡ªçŸ¥è¯†å›¾è°±ï¼‰å’Œæ–‡æ¡£å†…å®¹ï¼ˆæ¥è‡ªå‘é‡æ£€ç´¢ï¼‰å›ç­”é—®é¢˜ã€‚

å›ç­”è¦æ±‚ï¼š
1. ä¼˜å…ˆä½¿ç”¨ç»“æ„åŒ–çŸ¥è¯†ä¸­çš„ç²¾ç¡®ä¿¡æ¯
2. ç”¨æ–‡æ¡£å†…å®¹è¡¥å……è¯¦ç»†è¯´æ˜
3. å¦‚æœä¸¤è€…æœ‰å†²çªï¼Œä»¥ç»“æ„åŒ–çŸ¥è¯†ä¸ºå‡†
4. ç­”æ¡ˆè¦å‡†ç¡®ã€å®Œæ•´ã€æœ‰æ¡ç†
5. æ³¨æ˜ä¿¡æ¯æ¥æº"""),
            
            ("user", """é—®é¢˜ï¼š{question}

ã€ç»“æ„åŒ–çŸ¥è¯†ã€‘ï¼ˆæ¥è‡ªçŸ¥è¯†å›¾è°±ï¼‰
{graph_context}

ã€æ–‡æ¡£å†…å®¹ã€‘ï¼ˆæ¥è‡ªå‘é‡æ£€ç´¢ï¼‰
{vector_context}

è¯·å›ç­”ï¼š""")
        ])
        
        messages = prompt.format_messages(
            question=question,
            graph_context=graph_context,
            vector_context=vector_context
        )
        
        response = self.llm(messages)
        return response.content
    
    def close(self):
        """å…³é—­è¿æ¥"""
        self.graph_driver.close()


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    graph_rag = GraphRAGSystem(
        neo4j_uri="bolt://localhost:7687",
        neo4j_user="neo4j",
        neo4j_password="your_password",
        chroma_path="./chroma_db"
    )
    
    # æŸ¥è¯¢
    question = "LangChainå’ŒLlamaIndexæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
    result = graph_rag.query(question)
    
    print("=" * 50)
    print("æœ€ç»ˆç­”æ¡ˆï¼š")
    print(result["answer"])
    
    # å…³é—­
    graph_rag.close()
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨Graph-RAGï¼Ÿ

âœ… **é€‚åˆåœºæ™¯ï¼š**
- å®ä½“å…³ç³»å¤æ‚ï¼ˆç»„ç»‡æ¶æ„ã€ä¾›åº”é“¾ã€çŸ¥è¯†ä½“ç³»ï¼‰
- éœ€è¦ç²¾ç¡®æ¨ç†ï¼ˆåŒ»ç–—è¯Šæ–­ã€æ³•å¾‹å’¨è¯¢ã€æŠ€æœ¯é€‰å‹ï¼‰
- å¤šè·³æŸ¥è¯¢ï¼ˆ"Açš„æœ‹å‹çš„æœ‹å‹"ï¼‰
- å¯¹æ¯”åˆ†æï¼ˆ"Aå’ŒBçš„åŒºåˆ«"ï¼‰

âš ï¸ **ä¸é€‚åˆåœºæ™¯ï¼š**
- çº¯æ–‡æœ¬æœç´¢ï¼ˆç”¨ä¼ ç»ŸRAGæ›´ç®€å•ï¼‰
- åˆ›æ„å†™ä½œï¼ˆä¸éœ€è¦ç»“æ„åŒ–çŸ¥è¯†ï¼‰
- çŸ¥è¯†å›¾è°±ä¸ºç©ºï¼ˆæ²¡æœ‰æ„å»ºå›¾è°±ï¼‰

### 2. æ€§èƒ½ä¼˜åŒ–

```python
# 1. å›¾è°±æŸ¥è¯¢é™åˆ¶æ·±åº¦
cypher = """
MATCH (e)-[*1..2]-(neighbor)  # é™åˆ¶2è·³
RETURN neighbor
LIMIT 10  # é™åˆ¶è¿”å›æ•°é‡
"""

# 2. å¹¶è¡Œæ£€ç´¢
import asyncio

async def parallel_retrieve(question):
    graph_task = asyncio.create_task(retrieve_from_graph(question))
    vector_task = asyncio.create_task(retrieve_from_vector(question))
    
    graph_result, vector_result = await asyncio.gather(
        graph_task, vector_task
    )
    
    return graph_result, vector_result

# 3. ç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_graph_retrieve(entity_name: str):
    return retrieve_from_graph(entity_name)
```

### 3. æç¤ºè¯ä¼˜åŒ–

```python
GRAPH_RAG_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿èåˆç»“æ„åŒ–çŸ¥è¯†å’Œæ–‡æ¡£å†…å®¹ã€‚

å›ç­”ç­–ç•¥ï¼š
1. å¦‚æœç»“æ„åŒ–çŸ¥è¯†å……åˆ†ï¼š
   - ä¸»è¦ä¾æ®ç»“æ„åŒ–çŸ¥è¯†
   - ç”¨æ–‡æ¡£å†…å®¹è¡¥å……ç»†èŠ‚
   
2. å¦‚æœç»“æ„åŒ–çŸ¥è¯†ä¸è¶³ï¼š
   - ä¸»è¦ä¾æ®æ–‡æ¡£å†…å®¹
   - ç”¨ç»“æ„åŒ–çŸ¥è¯†æä¾›æ¡†æ¶

3. å¦‚æœä¸¤è€…éƒ½å……åˆ†ï¼š
   - ç»“åˆä¸¤è€…ä¼˜åŠ¿
   - ç»“æ„åŒ–çŸ¥è¯†æä¾›æ¡†æ¶
   - æ–‡æ¡£å†…å®¹æä¾›ç»†èŠ‚

4. å›ç­”æ ¼å¼ï¼š
   - å…ˆç»™ç»“è®ºï¼ˆæ¥è‡ªç»“æ„åŒ–çŸ¥è¯†ï¼‰
   - å†è§£é‡ŠåŸå› ï¼ˆæ¥è‡ªæ–‡æ¡£ï¼‰
   - æœ€åè¡¥å……æ³¨æ„äº‹é¡¹

ã€ç»“æ„åŒ–çŸ¥è¯†ã€‘
{graph_context}

ã€æ–‡æ¡£å†…å®¹ã€‘
{vector_context}

é—®é¢˜ï¼š{question}

è¯·å›ç­”ï¼š"""
```

---

## ğŸ¯ æœ¬è¯¾å°ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **Graph-RAG = çŸ¥è¯†å›¾è°± + å‘é‡æ£€ç´¢**
   - ç»“æ„åŒ–çŸ¥è¯†ï¼šç²¾ç¡®ã€å¯æ¨ç†
   - éç»“æ„åŒ–çŸ¥è¯†ï¼šè¯¦ç»†ã€è¯­ä¹‰ä¸°å¯Œ
   - èåˆï¼šäº’è¡¥ä¼˜åŠ¿

2. **å…³é”®æŠ€æœ¯ï¼š**
   - å®ä½“è¯†åˆ«ä¸é“¾æ¥
   - åŒè·¯æ£€ç´¢ï¼ˆå›¾è°±+å‘é‡ï¼‰
   - ç»“æœèåˆ
   - æç¤ºè¯å·¥ç¨‹

3. **é€‚ç”¨åœºæ™¯ï¼š**
   - å…³ç³»å¤æ‚
   - éœ€è¦æ¨ç†
   - å¯¹æ¯”åˆ†æ
   - å¤šè·³æŸ¥è¯¢

4. **å·¥ä¸šç•Œè¶‹åŠ¿ï¼š**
   - å¾®è½¯GraphRAG
   - LlamaIndexæ”¯æŒå›¾è°±
   - LangChainé›†æˆNeo4j
   - æˆä¸ºAIåº”ç”¨æ ‡å‡†æ¶æ„

### ä¸ºä»€ä¹ˆGraph-RAGæ˜¯å¿…å¤‡æŠ€èƒ½ï¼Ÿ

æ ¹æ®AIç¼–ç¨‹å°æœ±åšä¸»çš„åˆ†äº«ï¼š
> "AIåº”ç”¨å¼€å‘å·¥ç¨‹å¸ˆå¿…å¤‡ï¼šAgentæ™ºèƒ½ä½“å¼€å‘ï¼Œä¸€å®šè¦ç»“åˆRAGæŠ€æœ¯ï¼Œ
> è€Œè¿™ä¸ªRAGåˆä¸ä»…ä»…å±€é™äºå‘é‡æ•°æ®åº“ï¼Œç”šè‡³åŒ…å«çŸ¥è¯†å›¾è°±çš„æŠ€æœ¯æ ˆã€‚"

**ç°åœ¨ä½ æŒæ¡äº†ï¼** âœ…

---

## ğŸ“ è¯¾åä½œä¸š

### ä½œä¸šï¼šæ„å»ºæŠ€æœ¯æ ˆå¯¹æ¯”ç³»ç»Ÿ

**éœ€æ±‚ï¼š**
æ„å»ºä¸€ä¸ªæŠ€æœ¯é€‰å‹åŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¯¹æ¯”ä¸åŒçš„AIæ¡†æ¶ï¼ˆLangChain, LlamaIndex, Haystackï¼‰ã€‚

**è¦æ±‚ï¼š**
1. æ„å»ºçŸ¥è¯†å›¾è°±ï¼š
   - å®ä½“ï¼šæ¡†æ¶ã€ç‰¹æ€§ã€å…¬å¸
   - å…³ç³»ï¼šä¾èµ–ã€é€‚ç”¨äºã€ä¼˜äº
   
2. å‡†å¤‡æ–‡æ¡£ï¼š
   - å„æ¡†æ¶çš„è¯¦ç»†æ–‡æ¡£
   - ä½¿ç”¨æ¡ˆä¾‹
   
3. å®ç°Graph-RAGï¼š
   - èƒ½å¤Ÿå›ç­”å¯¹æ¯”é—®é¢˜
   - èƒ½å¤Ÿæ¨èåˆé€‚çš„æ¡†æ¶
   
4. æµ‹è¯•æŸ¥è¯¢ï¼š
   - "LangChainå’ŒLlamaIndexçš„æ€§èƒ½å¯¹æ¯”"
   - "å“ªä¸ªæ¡†æ¶æ›´é€‚åˆAgentå¼€å‘ï¼Ÿ"
   - "Haystackçš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"

---

**Graph-RAGæ˜¯AIå·¥ç¨‹å¸ˆçš„æ ¸å¿ƒç«äº‰åŠ›ï¼ç»§ç»­åŠ æ²¹ï¼** ğŸš€

