![RAGé«˜çº§æ£€ç´¢æµç¨‹](./images/rag_flow.svg)
*å›¾ï¼šRAGé«˜çº§æ£€ç´¢æµç¨‹*

# ç¬¬62è¯¾ï¼šè‡ªæŸ¥è¯¢æ£€ç´¢å™¨

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŒæ¡è‡ªæŸ¥è¯¢æ£€ç´¢æŠ€æœ¯ï¼Œè®©RAGè‡ªåŠ¨ç†è§£å¤æ‚æŸ¥è¯¢
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šQueryè§£æã€å…ƒæ•°æ®æå–ã€ç»“æ„åŒ–æŸ¥è¯¢ç”Ÿæˆ
> 
> **å®æˆ˜æ¡ˆä¾‹**ï¼šæ™ºèƒ½è‡ªæŸ¥è¯¢ç³»ç»Ÿ
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š75åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ5åˆ†é’Ÿ)
![Hyde](./images/hyde.svg)
*å›¾ï¼šHyde*


### ğŸ¯ å‰è¨€

"ä½ æœ‰æ²¡æœ‰é‡åˆ°è¿‡è¿™ç§æƒ…å†µï¼š

ç”¨æˆ·é—®ï¼š'ç»™æˆ‘æ‰¾2023å¹´å…³äºPythonçš„æŠ€æœ¯æ–‡ç« ï¼Œæœ€å¥½æ˜¯ä¸­æ–‡çš„'

è¿™ä¸ªæŸ¥è¯¢åŒ…å«äº†ä»€ä¹ˆä¿¡æ¯ï¼Ÿ
- **è¯­ä¹‰å†…å®¹**ï¼šPythonæŠ€æœ¯æ–‡ç« 
- **æ—¶é—´è¿‡æ»¤**ï¼š2023å¹´
- **è¯­è¨€è¿‡æ»¤**ï¼šä¸­æ–‡

ä¼ ç»Ÿçš„RAGç³»ç»Ÿä¼šæ€ä¹ˆå¤„ç†ï¼Ÿ

**æ–¹æ³•1ï¼šå…¨éƒ¨å½“æˆè¯­ä¹‰æŸ¥è¯¢**
```python
query = "2023å¹´ Python ä¸­æ–‡ æŠ€æœ¯æ–‡ç« "
results = vector_search(query)  # æ•ˆæœå¾ˆå·®ï¼
```

é—®é¢˜ï¼š
- âŒ '2023å¹´'ä¼šå½±å“è¯­ä¹‰ç›¸ä¼¼åº¦
- âŒ 'ä¸­æ–‡'ä¹Ÿä¼šå¹²æ‰°æ£€ç´¢
- âŒ ç›¸å…³çš„è‹±æ–‡æ–‡ç« è¢«æ’é™¤äº†

**æ–¹æ³•2ï¼šæ‰‹åŠ¨æ‹†åˆ†**
```python
semantic_query = "PythonæŠ€æœ¯æ–‡ç« "
filters = {"year": 2023, "language": "ä¸­æ–‡"}
results = vector_search(semantic_query, filters)
```

é—®é¢˜ï¼š
- âŒ éœ€è¦ç”¨æˆ·è‡ªå·±æ‹†åˆ†
- âŒ ä¸åŒå­—æ®µè¦å•ç‹¬ä¼ 
- âŒ ç”¨æˆ·ä½“éªŒå·®

**æœ‰æ²¡æœ‰æ›´å¥½çš„åŠæ³•ï¼Ÿ**

**æœ‰ï¼è¿™å°±æ˜¯è‡ªæŸ¥è¯¢æ£€ç´¢å™¨ï¼ˆSelf-Querying Retrieverï¼‰ï¼**

å®ƒèƒ½è‡ªåŠ¨ï¼š
1. **ç†è§£ç”¨æˆ·æ„å›¾**
2. **æå–å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶**
3. **åˆ†ç¦»è¯­ä¹‰æŸ¥è¯¢å’Œè¿‡æ»¤æ¡ä»¶**
4. **ç”Ÿæˆç»“æ„åŒ–æŸ¥è¯¢**

çœ‹ä¸€ä¸ªçœŸå®ä¾‹å­ï¼š

```python
# ç”¨æˆ·è¾“å…¥
user_query = "2023å¹´å…³äºæ·±åº¦å­¦ä¹ çš„Pythonæ•™ç¨‹ï¼Œåˆå­¦è€…å‹å¥½çš„"

# è‡ªæŸ¥è¯¢æ£€ç´¢å™¨è‡ªåŠ¨è§£æ
{
    "query": "æ·±åº¦å­¦ä¹  Pythonæ•™ç¨‹",  # è¯­ä¹‰éƒ¨åˆ†
    "filter": {                        # è¿‡æ»¤æ¡ä»¶
        "year": 2023,
        "topic": "æ·±åº¦å­¦ä¹ ",
        "language": "Python",
        "level": "åˆå­¦è€…"
    }
}
```

**ä¸ºä»€ä¹ˆè¿™ä¸ªæŠ€æœ¯è¿™ä¹ˆé‡è¦ï¼Ÿ**

æˆ‘åœ¨åšä¼ä¸šçº§RAGé¡¹ç›®æ—¶å‘ç°ï¼š

**80%çš„ç”¨æˆ·æŸ¥è¯¢éƒ½åŒ…å«è¿‡æ»¤æ¡ä»¶ï¼**

ä¾‹å¦‚ï¼š
- "æœ€è¿‘çš„æ–°é—»" â†’ æ—¶é—´è¿‡æ»¤
- "Pythonç›¸å…³çš„æ–‡æ¡£" â†’ æ ‡ç­¾è¿‡æ»¤
- "ä¸­æ–‡æ•™ç¨‹" â†’ è¯­è¨€è¿‡æ»¤
- "é«˜çº§è¯¾ç¨‹" â†’ éš¾åº¦è¿‡æ»¤

å¦‚æœä¸èƒ½æ­£ç¡®å¤„ç†è¿™äº›è¿‡æ»¤æ¡ä»¶ï¼š
- âŒ æ£€ç´¢æ•ˆæœå·®
- âŒ è¿”å›ç»“æœä¸ç›¸å…³
- âŒ ç”¨æˆ·ä½“éªŒç³Ÿç³•

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦æ•™ä½ ï¼š**

**ç¬¬ä¸€éƒ¨åˆ†ï¼šè‡ªæŸ¥è¯¢åŸç†**
- Queryç»“æ„åˆ†æ
- å…ƒæ•°æ®è¯†åˆ«
- LLMé©±åŠ¨çš„è§£æ

**ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒå®ç°**
- Query Parserè®¾è®¡
- å…ƒæ•°æ®Schemaå®šä¹‰
- ç»“æ„åŒ–æŸ¥è¯¢ç”Ÿæˆ

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§æŠ€å·§**
- å¤æ‚æ¡ä»¶å¤„ç†
- æ¨¡ç³ŠåŒ¹é…
- èŒƒå›´æŸ¥è¯¢
- å¤šæ¡ä»¶ç»„åˆ

**ç¬¬å››éƒ¨åˆ†ï¼šç”Ÿäº§ä¼˜åŒ–**
- è§£æå‡†ç¡®æ€§æå‡
- ç¼“å­˜ç­–ç•¥
- é™çº§æ–¹æ¡ˆ

**ç¬¬äº”éƒ¨åˆ†ï¼šå®æˆ˜æ¡ˆä¾‹**
- ä¼ä¸šæ–‡æ¡£æœç´¢
- ç”µå•†äº§å“æ£€ç´¢
- å†…å®¹æ¨èç³»ç»Ÿ

å­¦å®Œè¿™ä¸€è¯¾ï¼Œä½ çš„RAGç³»ç»Ÿå°†èƒ½ç†è§£æ›´å¤æ‚çš„æŸ¥è¯¢ï¼

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ï¼"

---

### ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µ

```
ã€ä¼ ç»Ÿæ£€ç´¢ vs è‡ªæŸ¥è¯¢æ£€ç´¢ã€‘

ä¼ ç»Ÿæ£€ç´¢ï¼š
ç”¨æˆ·: "2023å¹´çš„Pythonæ•™ç¨‹"
ç³»ç»Ÿ: å…¨éƒ¨å½“æˆè¯­ä¹‰æŸ¥è¯¢ âŒ
ç»“æœ: åŒ…å«"2023å¹´"å’Œ"Python"çš„æ–‡æ¡£ï¼ˆä¸å‡†ç¡®ï¼‰

è‡ªæŸ¥è¯¢æ£€ç´¢ï¼š
ç”¨æˆ·: "2023å¹´çš„Pythonæ•™ç¨‹"
ç³»ç»Ÿ: è‡ªåŠ¨è§£æä¸º
  - è¯­ä¹‰: "Pythonæ•™ç¨‹"
  - è¿‡æ»¤: year=2023
ç»“æœ: 2023å¹´çš„Pythonæ•™ç¨‹ï¼ˆå‡†ç¡®ï¼ï¼‰

ã€Queryç»“æ„ã€‘

å®Œæ•´Query = è¯­ä¹‰éƒ¨åˆ† + è¿‡æ»¤æ¡ä»¶

ä¾‹å­ï¼š
"æœ€è¿‘3ä¸ªæœˆå…³äºReactçš„é«˜çº§æ•™ç¨‹"
  â†“
è¯­ä¹‰: "React é«˜çº§æ•™ç¨‹"
è¿‡æ»¤: {
  date: "last_3_months",
  topic: "React",
  level: "é«˜çº§"
}
```

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šè‡ªæŸ¥è¯¢åŸç†

### ä¸€ã€Queryç»“æ„åˆ†æ

```python
from typing import Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum

class QueryType(Enum):
    """æŸ¥è¯¢ç±»å‹"""
    PURE_SEMANTIC = "çº¯è¯­ä¹‰"      # æ²¡æœ‰è¿‡æ»¤æ¡ä»¶
    WITH_FILTER = "å¸¦è¿‡æ»¤"        # æœ‰è¿‡æ»¤æ¡ä»¶
    COMPLEX = "å¤æ‚æŸ¥è¯¢"          # å¤šä¸ªè¿‡æ»¤æ¡ä»¶

@dataclass
class ParsedQuery:
    """è§£æåçš„æŸ¥è¯¢"""
    semantic_query: str              # è¯­ä¹‰æŸ¥è¯¢éƒ¨åˆ†
    filters: Dict[str, Any]          # è¿‡æ»¤æ¡ä»¶
    query_type: QueryType            # æŸ¥è¯¢ç±»å‹
    confidence: float = 1.0          # è§£æç½®ä¿¡åº¦

class QueryAnalyzer:
    """æŸ¥è¯¢åˆ†æå™¨"""
    
    @staticmethod
    def analyze_query_structure(query: str) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢ç»“æ„"""
        analysis = {
            'has_time': False,
            'has_category': False,
            'has_attributes': False,
            'complexity': 'simple'
        }
        
        # æ—¶é—´è¯
        time_words = ['æœ€è¿‘', 'ä»Šå¹´', 'å»å¹´', '2023', '2024', 'æœ€æ–°']
        analysis['has_time'] = any(word in query for word in time_words)
        
        # ç±»åˆ«è¯
        category_words = ['å…³äº', 'ç›¸å…³', 'æœ‰å…³', 'çš„']
        analysis['has_category'] = any(word in query for word in category_words)
        
        # å±æ€§è¯
        attr_words = ['åˆçº§', 'é«˜çº§', 'ä¸­æ–‡', 'è‹±æ–‡', 'è¯¦ç»†', 'ç®€å•']
        analysis['has_attributes'] = any(word in query for word in attr_words)
        
        # å¤æ‚åº¦
        filter_count = sum([
            analysis['has_time'],
            analysis['has_category'],
            analysis['has_attributes']
        ])
        
        if filter_count == 0:
            analysis['complexity'] = 'simple'
        elif filter_count <= 2:
            analysis['complexity'] = 'medium'
        else:
            analysis['complexity'] = 'complex'
        
        return analysis

# ç¤ºä¾‹
def demo_query_analysis():
    """æ¼”ç¤ºæŸ¥è¯¢åˆ†æ"""
    analyzer = QueryAnalyzer()
    
    queries = [
        "äººå·¥æ™ºèƒ½åŸºç¡€çŸ¥è¯†",                    # ç®€å•
        "2023å¹´çš„Pythonæ•™ç¨‹",                 # ä¸­ç­‰
        "æœ€è¿‘çš„å…³äºæ·±åº¦å­¦ä¹ çš„ä¸­æ–‡é«˜çº§æ•™ç¨‹"      # å¤æ‚
    ]
    
    print("="*60)
    print("æŸ¥è¯¢ç»“æ„åˆ†æ")
    print("="*60)
    
    for query in queries:
        analysis = analyzer.analyze_query_structure(query)
        print(f"\næŸ¥è¯¢: {query}")
        print(f"åˆ†æ: {analysis}")

demo_query_analysis()
```

### äºŒã€å…ƒæ•°æ®Schemaå®šä¹‰

```python
from typing import List, Union
from pydantic import BaseModel, Field

class FieldSchema(BaseModel):
    """å­—æ®µSchema"""
    name: str                           # å­—æ®µå
    type: str                           # ç±»å‹: string, number, date, boolean
    description: str                    # æè¿°
    possible_values: Optional[List] = None  # å¯èƒ½çš„å€¼
    
class MetadataSchema(BaseModel):
    """å…ƒæ•°æ®Schema"""
    fields: List[FieldSchema]           # æ‰€æœ‰å­—æ®µ
    
    def get_field(self, name: str) -> Optional[FieldSchema]:
        """è·å–å­—æ®µ"""
        for field in self.fields:
            if field.name == name:
                return field
        return None
    
    def to_prompt(self) -> str:
        """è½¬æ¢ä¸ºPrompt"""
        lines = ["å¯ç”¨çš„å…ƒæ•°æ®å­—æ®µï¼š\n"]
        
        for field in self.fields:
            line = f"- {field.name} ({field.type}): {field.description}"
            if field.possible_values:
                line += f"\n  å¯èƒ½çš„å€¼: {', '.join(map(str, field.possible_values))}"
            lines.append(line)
        
        return "\n".join(lines)

# å®šä¹‰æ–‡æ¡£å…ƒæ•°æ®Schema
document_schema = MetadataSchema(
    fields=[
        FieldSchema(
            name="year",
            type="number",
            description="æ–‡æ¡£å‘å¸ƒå¹´ä»½",
            possible_values=[2020, 2021, 2022, 2023, 2024]
        ),
        FieldSchema(
            name="language",
            type="string",
            description="æ–‡æ¡£è¯­è¨€",
            possible_values=["ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡"]
        ),
        FieldSchema(
            name="category",
            type="string",
            description="æ–‡æ¡£ç±»åˆ«",
            possible_values=["æ•™ç¨‹", "æ–‡æ¡£", "è®ºæ–‡", "åšå®¢"]
        ),
        FieldSchema(
            name="level",
            type="string",
            description="éš¾åº¦çº§åˆ«",
            possible_values=["åˆçº§", "ä¸­çº§", "é«˜çº§"]
        ),
        FieldSchema(
            name="topic",
            type="string",
            description="ä¸»é¢˜",
            possible_values=["Python", "JavaScript", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ "]
        )
    ]
)
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒå®ç°

### ä¸€ã€LLMé©±åŠ¨çš„Query Parser

```python
from langchain.chat_models import ChatOpenAI
import json

class SelfQueryParser:
    """è‡ªæŸ¥è¯¢è§£æå™¨"""
    
    def __init__(self, llm, metadata_schema: MetadataSchema):
        self.llm = llm
        self.schema = metadata_schema
    
    def parse(self, query: str, verbose: bool = False) -> ParsedQuery:
        """è§£ææŸ¥è¯¢"""
        if verbose:
            print("="*60)
            print("ğŸ” è‡ªæŸ¥è¯¢è§£æ")
            print("="*60)
            print(f"åŸå§‹æŸ¥è¯¢: {query}\n")
        
        # 1. æ„å»ºPrompt
        prompt = self._build_parse_prompt(query)
        
        if verbose:
            print("ã€æ­¥éª¤1ã€‘è°ƒç”¨LLMè§£æ...")
        
        # 2. è°ƒç”¨LLM
        response = self.llm.invoke(prompt)
        
        # 3. è§£æç»“æœ
        try:
            result = json.loads(response.content)
            
            parsed = ParsedQuery(
                semantic_query=result.get('semantic_query', query),
                filters=result.get('filters', {}),
                query_type=QueryType.WITH_FILTER if result.get('filters') else QueryType.PURE_SEMANTIC,
                confidence=result.get('confidence', 1.0)
            )
            
            if verbose:
                print("\nã€æ­¥éª¤2ã€‘è§£æç»“æœ")
                print(f"è¯­ä¹‰æŸ¥è¯¢: {parsed.semantic_query}")
                print(f"è¿‡æ»¤æ¡ä»¶: {parsed.filters}")
                print(f"æŸ¥è¯¢ç±»å‹: {parsed.query_type.value}")
                print(f"ç½®ä¿¡åº¦: {parsed.confidence:.2f}")
            
            return parsed
            
        except json.JSONDecodeError as e:
            if verbose:
                print(f"\nâŒ JSONè§£æå¤±è´¥: {e}")
            
            # é™çº§ï¼šè¿”å›åŸå§‹æŸ¥è¯¢
            return ParsedQuery(
                semantic_query=query,
                filters={},
                query_type=QueryType.PURE_SEMANTIC,
                confidence=0.5
            )
    
    def _build_parse_prompt(self, query: str) -> str:
        """æ„å»ºè§£æPrompt"""
        schema_desc = self.schema.to_prompt()
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢è§£æä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æä¸ºç»“æ„åŒ–æŸ¥è¯¢ã€‚

{schema_desc}

ä»»åŠ¡ï¼š
1. æå–æ ¸å¿ƒè¯­ä¹‰æŸ¥è¯¢ï¼ˆå»é™¤è¿‡æ»¤æ¡ä»¶ï¼‰
2. è¯†åˆ«å¹¶æå–æ‰€æœ‰è¿‡æ»¤æ¡ä»¶
3. è¯„ä¼°è§£æçš„ç½®ä¿¡åº¦(0-1)

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "semantic_query": "æ ¸å¿ƒæŸ¥è¯¢å†…å®¹",
    "filters": {{
        "field_name": "value",
        ...
    }},
    "confidence": 0.95
}}

æ³¨æ„ï¼š
- åªæå–Schemaä¸­å®šä¹‰çš„å­—æ®µ
- è¿‡æ»¤æ¡ä»¶çš„å€¼è¦åŒ¹é…possible_values
- å¦‚æœæ²¡æœ‰è¿‡æ»¤æ¡ä»¶ï¼Œfiltersä¸ºç©ºå¯¹è±¡

JSONç»“æœï¼š"""
        
        return prompt

# ä½¿ç”¨ç¤ºä¾‹
def demo_self_query_parser():
    """æ¼”ç¤ºè‡ªæŸ¥è¯¢è§£æ"""
    
    # åˆå§‹åŒ–
    llm = ChatOpenAI(
        base_url="http://localhost:1234/v1",
        api_key="lm-studio",
        temperature=0
    )
    
    parser = SelfQueryParser(llm, document_schema)
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "PythonåŸºç¡€æ•™ç¨‹",
        "2023å¹´çš„æœºå™¨å­¦ä¹ æ•™ç¨‹",
        "æœ€è¿‘çš„ä¸­æ–‡æ·±åº¦å­¦ä¹ é«˜çº§æ•™ç¨‹"
    ]
    
    for query in test_queries:
        result = parser.parse(query, verbose=True)
        print("\n" + "="*60 + "\n")

demo_self_query_parser()
```

### äºŒã€å®Œæ•´çš„è‡ªæŸ¥è¯¢æ£€ç´¢å™¨

```python
class SelfQueryRetriever:
    """è‡ªæŸ¥è¯¢æ£€ç´¢å™¨"""
    
    def __init__(
        self,
        llm,
        vectorstore,
        metadata_schema: MetadataSchema
    ):
        self.llm = llm
        self.vectorstore = vectorstore
        self.parser = SelfQueryParser(llm, metadata_schema)
    
    def retrieve(
        self,
        query: str,
        k: int = 5,
        verbose: bool = False
    ) -> List[Tuple[str, float]]:
        """
        è‡ªæŸ¥è¯¢æ£€ç´¢
        
        æµç¨‹ï¼š
        1. è§£ææŸ¥è¯¢
        2. ç”¨è¯­ä¹‰æŸ¥è¯¢æ£€ç´¢
        3. åº”ç”¨è¿‡æ»¤æ¡ä»¶
        4. è¿”å›ç»“æœ
        """
        if verbose:
            print("\n" + "ğŸ”"*30)
            print("è‡ªæŸ¥è¯¢æ£€ç´¢")
            print("ğŸ”"*30)
        
        # 1. è§£ææŸ¥è¯¢
        parsed = self.parser.parse(query, verbose=verbose)
        
        # 2. è¯­ä¹‰æ£€ç´¢
        if verbose:
            print(f"\nã€æ­¥éª¤3ã€‘è¯­ä¹‰æ£€ç´¢")
            print(f"  æŸ¥è¯¢: {parsed.semantic_query}")
        
        results = self.vectorstore.similarity_search(
            parsed.semantic_query,
            k=k * 2  # æ£€ç´¢æ›´å¤šï¼Œç•™å¾…è¿‡æ»¤
        )
        
        # 3. åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if parsed.filters:
            if verbose:
                print(f"\nã€æ­¥éª¤4ã€‘åº”ç”¨è¿‡æ»¤æ¡ä»¶")
                print(f"  è¿‡æ»¤: {parsed.filters}")
            
            filtered_results = self._apply_filters(results, parsed.filters)
            
            if verbose:
                print(f"  è¿‡æ»¤å‰: {len(results)}ä¸ª")
                print(f"  è¿‡æ»¤å: {len(filtered_results)}ä¸ª")
        else:
            filtered_results = results
        
        # 4. è¿”å›Top-k
        final_results = filtered_results[:k]
        
        if verbose:
            print(f"\nã€æ­¥éª¤5ã€‘è¿”å›Top-{len(final_results)}ç»“æœ")
            for i, (doc, score) in enumerate(final_results):
                print(f"\n  {i+1}. åˆ†æ•°={score:.4f}")
                print(f"     å†…å®¹: {doc.page_content[:80]}...")
                print(f"     å…ƒæ•°æ®: {doc.metadata}")
        
        return final_results
    
    def _apply_filters(
        self,
        results: List,
        filters: Dict[str, Any]
    ) -> List:
        """åº”ç”¨è¿‡æ»¤æ¡ä»¶"""
        filtered = []
        
        for doc in results:
            if self._matches_filters(doc.metadata, filters):
                filtered.append(doc)
        
        return filtered
    
    def _matches_filters(
        self,
        metadata: Dict[str, Any],
        filters: Dict[str, Any]
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ¹é…è¿‡æ»¤æ¡ä»¶"""
        for key, value in filters.items():
            # å­—æ®µä¸å­˜åœ¨
            if key not in metadata:
                return False
            
            # å€¼ä¸åŒ¹é…
            if isinstance(value, list):
                # åˆ—è¡¨ï¼šinæŸ¥è¯¢
                if metadata[key] not in value:
                    return False
            else:
                # ç²¾ç¡®åŒ¹é…
                if metadata[key] != value:
                    return False
        
        return True
```

---

## ğŸ¯ ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§æŠ€å·§

### ä¸€ã€å¤æ‚æ¡ä»¶å¤„ç†

```python
class AdvancedFilterParser:
    """é«˜çº§è¿‡æ»¤æ¡ä»¶è§£æå™¨"""
    
    @staticmethod
    def parse_range_filter(value: str) -> Dict:
        """
        è§£æèŒƒå›´è¿‡æ»¤
        
        ä¾‹å­ï¼š
        - "2020-2023" â†’ {gte: 2020, lte: 2023}
        - ">100" â†’ {gt: 100}
        - "<=50" â†’ {lte: 50}
        """
        # èŒƒå›´ï¼š2020-2023
        if '-' in value and value.replace('-', '').isdigit():
            parts = value.split('-')
            return {
                'gte': int(parts[0]),
                'lte': int(parts[1])
            }
        
        # å¤§äºï¼š>100
        if value.startswith('>'):
            num = value[1:].strip()
            if num.startswith('='):
                return {'gte': int(num[1:])}
            return {'gt': int(num)}
        
        # å°äºï¼š<100
        if value.startswith('<'):
            num = value[1:].strip()
            if num.startswith('='):
                return {'lte': int(num[1:])}
            return {'lt': int(num)}
        
        # ç²¾ç¡®å€¼
        return {'eq': value}
    
    @staticmethod
    def parse_date_filter(text: str) -> Dict:
        """
        è§£ææ—¥æœŸè¿‡æ»¤
        
        ä¾‹å­ï¼š
        - "æœ€è¿‘7å¤©" â†’ last_n_days: 7
        - "æœ¬æœˆ" â†’ this_month
        - "å»å¹´" â†’ last_year
        """
        import re
        from datetime import datetime, timedelta
        
        today = datetime.now()
        
        # æœ€è¿‘Nå¤©
        match = re.search(r'æœ€è¿‘(\d+)å¤©', text)
        if match:
            days = int(match.group(1))
            start_date = today - timedelta(days=days)
            return {
                'gte': start_date.strftime('%Y-%m-%d'),
                'lte': today.strftime('%Y-%m-%d')
            }
        
        # æœ¬æœˆ
        if 'æœ¬æœˆ' in text or 'è¿™ä¸ªæœˆ' in text:
            start_of_month = today.replace(day=1)
            return {
                'gte': start_of_month.strftime('%Y-%m-%d'),
                'lte': today.strftime('%Y-%m-%d')
            }
        
        # å»å¹´
        if 'å»å¹´' in text:
            last_year = today.year - 1
            return {
                'gte': f'{last_year}-01-01',
                'lte': f'{last_year}-12-31'
            }
        
        return {}

class EnhancedSelfQueryRetriever(SelfQueryRetriever):
    """å¢å¼ºçš„è‡ªæŸ¥è¯¢æ£€ç´¢å™¨"""
    
    def _matches_filters(
        self,
        metadata: Dict[str, Any],
        filters: Dict[str, Any]
    ) -> bool:
        """å¢å¼ºçš„è¿‡æ»¤åŒ¹é…ï¼ˆæ”¯æŒå¤æ‚æ¡ä»¶ï¼‰"""
        for key, value in filters.items():
            if key not in metadata:
                return False
            
            meta_value = metadata[key]
            
            # å¤„ç†å¤æ‚è¿‡æ»¤æ¡ä»¶
            if isinstance(value, dict):
                # èŒƒå›´æŸ¥è¯¢
                if 'gte' in value and meta_value < value['gte']:
                    return False
                if 'lte' in value and meta_value > value['lte']:
                    return False
                if 'gt' in value and meta_value <= value['gt']:
                    return False
                if 'lt' in value and meta_value >= value['lt']:
                    return False
            elif isinstance(value, list):
                # INæŸ¥è¯¢
                if meta_value not in value:
                    return False
            else:
                # ç²¾ç¡®åŒ¹é…
                if meta_value != value:
                    return False
        
        return True
```

### äºŒã€æ¨¡ç³ŠåŒ¹é…

```python
class FuzzyMatcher:
    """æ¨¡ç³ŠåŒ¹é…å™¨"""
    
    @staticmethod
    def fuzzy_match(value: str, target: str, threshold: float = 0.8) -> bool:
        """
        æ¨¡ç³ŠåŒ¹é…
        
        ä½¿ç”¨ç¼–è¾‘è·ç¦»è®¡ç®—ç›¸ä¼¼åº¦
        """
        from difflib import SequenceMatcher
        
        similarity = SequenceMatcher(None, value.lower(), target.lower()).ratio()
        return similarity >= threshold
    
    @staticmethod
    def match_with_synonyms(
        value: str,
        target: str,
        synonyms: Dict[str, List[str]]
    ) -> bool:
        """ä½¿ç”¨åŒä¹‰è¯åŒ¹é…"""
        # ç²¾ç¡®åŒ¹é…
        if value == target:
            return True
        
        # åŒä¹‰è¯åŒ¹é…
        for standard, syns in synonyms.items():
            if value in syns and target == standard:
                return True
            if target in syns and value == standard:
                return True
        
        return False

# ä½¿ç”¨ç¤ºä¾‹
synonyms = {
    "Python": ["python", "py", "Python3"],
    "JavaScript": ["javascript", "js", "JS"],
    "æœºå™¨å­¦ä¹ ": ["ML", "machine learning", "æœºå™¨å­¦ä¹ "],
}

class FuzzyFilterMatcher:
    """æ¨¡ç³Šè¿‡æ»¤åŒ¹é…"""
    
    def __init__(self, synonyms: Dict = None):
        self.synonyms = synonyms or {}
        self.fuzzy = FuzzyMatcher()
    
    def matches(self, meta_value: str, filter_value: str) -> bool:
        """æ¨¡ç³ŠåŒ¹é…"""
        # 1. ç²¾ç¡®åŒ¹é…
        if meta_value == filter_value:
            return True
        
        # 2. åŒä¹‰è¯åŒ¹é…
        if self.fuzzy.match_with_synonyms(meta_value, filter_value, self.synonyms):
            return True
        
        # 3. æ¨¡ç³ŠåŒ¹é…
        if self.fuzzy.fuzzy_match(meta_value, filter_value):
            return True
        
        return False
```

---

## âš¡ ç¬¬å››éƒ¨åˆ†ï¼šç”Ÿäº§ä¼˜åŒ–

### ä¸€ã€è§£æå‡†ç¡®æ€§æå‡

```python
class ImprovedSelfQueryParser(SelfQueryParser):
    """æ”¹è¿›çš„è‡ªæŸ¥è¯¢è§£æå™¨"""
    
    def __init__(
        self,
        llm,
        metadata_schema: MetadataSchema,
        use_few_shot: bool = True
    ):
        super().__init__(llm, metadata_schema)
        self.use_few_shot = use_few_shot
        self.examples = self._get_examples()
    
    def _get_examples(self) -> List[Dict]:
        """Few-shotç¤ºä¾‹"""
        return [
            {
                "query": "2023å¹´çš„Pythonæ•™ç¨‹",
                "result": {
                    "semantic_query": "Pythonæ•™ç¨‹",
                    "filters": {"year": 2023, "topic": "Python"},
                    "confidence": 0.95
                }
            },
            {
                "query": "æœ€è¿‘çš„æœºå™¨å­¦ä¹ ä¸­æ–‡é«˜çº§è¯¾ç¨‹",
                "result": {
                    "semantic_query": "æœºå™¨å­¦ä¹ è¯¾ç¨‹",
                    "filters": {
                        "topic": "æœºå™¨å­¦ä¹ ",
                        "language": "ä¸­æ–‡",
                        "level": "é«˜çº§"
                    },
                    "confidence": 0.9
                }
            }
        ]
    
    def _build_parse_prompt(self, query: str) -> str:
        """æ„å»ºæ”¹è¿›çš„Promptï¼ˆå¸¦Few-shotï¼‰"""
        schema_desc = self.schema.to_prompt()
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢è§£æä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æä¸ºç»“æ„åŒ–æŸ¥è¯¢ã€‚

{schema_desc}

"""
        
        # æ·»åŠ Few-shotç¤ºä¾‹
        if self.use_few_shot:
            prompt += "\nç¤ºä¾‹ï¼š\n"
            for i, example in enumerate(self.examples):
                prompt += f"\nç¤ºä¾‹{i+1}:\n"
                prompt += f"æŸ¥è¯¢: {example['query']}\n"
                prompt += f"ç»“æœ: {json.dumps(example['result'], ensure_ascii=False)}\n"
        
        prompt += f"""
ç°åœ¨è¯·è§£æä»¥ä¸‹æŸ¥è¯¢ï¼š

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "semantic_query": "æ ¸å¿ƒæŸ¥è¯¢å†…å®¹",
    "filters": {{}},
    "confidence": 0.95
}}

JSONç»“æœï¼š"""
        
        return prompt
```

### äºŒã€ç¼“å­˜å’Œé™çº§

```python
class ProductionSelfQueryRetriever:
    """ç”Ÿäº§çº§è‡ªæŸ¥è¯¢æ£€ç´¢å™¨"""
    
    def __init__(
        self,
        llm,
        vectorstore,
        metadata_schema: MetadataSchema,
        enable_cache: bool = True,
        fallback_to_semantic: bool = True
    ):
        self.llm = llm
        self.vectorstore = vectorstore
        self.parser = ImprovedSelfQueryParser(llm, metadata_schema)
        
        self.enable_cache = enable_cache
        self.fallback_to_semantic = fallback_to_semantic
        
        if enable_cache:
            from functools import lru_cache
            self.parse_cache = {}
        
        # æŒ‡æ ‡
        self.metrics = {
            'total_queries': 0,
            'parse_success': 0,
            'parse_failure': 0,
            'cache_hits': 0,
            'fallback_count': 0
        }
    
    def retrieve(
        self,
        query: str,
        k: int = 5,
        timeout: int = 10
    ) -> List:
        """ç”Ÿäº§çº§æ£€ç´¢"""
        self.metrics['total_queries'] += 1
        
        try:
            # 1. æ£€æŸ¥ç¼“å­˜
            if self.enable_cache and query in self.parse_cache:
                self.metrics['cache_hits'] += 1
                parsed = self.parse_cache[query]
            else:
                # 2. è§£ææŸ¥è¯¢ï¼ˆå¸¦è¶…æ—¶ï¼‰
                import signal
                
                def timeout_handler(signum, frame):
                    raise TimeoutError("è§£æè¶…æ—¶")
                
                signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(timeout)
                
                try:
                    parsed = self.parser.parse(query)
                    self.metrics['parse_success'] += 1
                    
                    # ç¼“å­˜
                    if self.enable_cache:
                        self.parse_cache[query] = parsed
                finally:
                    signal.alarm(0)
            
            # 3. æ£€ç´¢
            results = self._retrieve_with_parsed(parsed, k)
            
            return results
            
        except Exception as e:
            self.metrics['parse_failure'] += 1
            
            if self.fallback_to_semantic:
                # é™çº§åˆ°çº¯è¯­ä¹‰æ£€ç´¢
                self.metrics['fallback_count'] += 1
                print(f"âš ï¸  è‡ªæŸ¥è¯¢å¤±è´¥ï¼Œé™çº§åˆ°è¯­ä¹‰æ£€ç´¢: {e}")
                
                return self.vectorstore.similarity_search(query, k=k)
            else:
                raise
    
    def _retrieve_with_parsed(
        self,
        parsed: ParsedQuery,
        k: int
    ) -> List:
        """ç”¨è§£æåçš„æŸ¥è¯¢æ£€ç´¢"""
        # è¯­ä¹‰æ£€ç´¢
        results = self.vectorstore.similarity_search(
            parsed.semantic_query,
            k=k * 2
        )
        
        # åº”ç”¨è¿‡æ»¤
        if parsed.filters:
            results = [
                doc for doc in results
                if self._matches_filters(doc.metadata, parsed.filters)
            ]
        
        return results[:k]
    
    def _matches_filters(self, metadata: Dict, filters: Dict) -> bool:
        """è¿‡æ»¤åŒ¹é…"""
        # å®ç°åŒå‰
        pass
    
    def get_metrics(self) -> Dict:
        """è·å–æŒ‡æ ‡"""
        total = self.metrics['total_queries']
        return {
            **self.metrics,
            'parse_success_rate': (
                self.metrics['parse_success'] / total if total > 0 else 0
            ),
            'cache_hit_rate': (
                self.metrics['cache_hits'] / total if total > 0 else 0
            ),
            'fallback_rate': (
                self.metrics['fallback_count'] / total if total > 0 else 0
            )
        }
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šå¤šè¯­è¨€æ”¯æŒ
æ‰©å±•è§£æå™¨æ”¯æŒè‹±æ–‡æŸ¥è¯¢

### ç»ƒä¹ 2ï¼šè‡ªç„¶è¯­è¨€æ—¥æœŸ
å®ç°æ›´çµæ´»çš„æ—¥æœŸè§£æï¼ˆ"ä¸Šå‘¨"ã€"3å¤©å‰"ç­‰ï¼‰

### ç»ƒä¹ 3ï¼šORæ¡ä»¶
æ”¯æŒORé€»è¾‘ï¼ˆ"Pythonæˆ–JavaScriptçš„æ•™ç¨‹"ï¼‰

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **è‡ªæŸ¥è¯¢åŸç†**
   - åˆ†ç¦»è¯­ä¹‰å’Œè¿‡æ»¤
   - LLMé©±åŠ¨è§£æ
   - ç»“æ„åŒ–æŸ¥è¯¢

2. **å…³é”®æŠ€æœ¯**
   - Schemaå®šä¹‰
   - Promptå·¥ç¨‹
   - è¿‡æ»¤åŒ¹é…

3. **ç”Ÿäº§å®è·µ**
   - Few-shotæå‡å‡†ç¡®æ€§
   - ç¼“å­˜åŠ é€Ÿ
   - é™çº§ä¿è¯å¯ç”¨æ€§

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬63è¯¾ï¼šä¸Šä¸‹æ–‡å‹ç¼©**

- ä¸ºä»€ä¹ˆéœ€è¦å‹ç¼©
- å‹ç¼©ç­–ç•¥
- LLMé©±åŠ¨çš„å‹ç¼©

**è®©RAGåªä¿ç•™æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼** ğŸ¯

---

**ğŸ’ª è®°ä½ï¼šè‡ªæŸ¥è¯¢è®©RAGæ›´æ™ºèƒ½åœ°ç†è§£ç”¨æˆ·éœ€æ±‚ï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
