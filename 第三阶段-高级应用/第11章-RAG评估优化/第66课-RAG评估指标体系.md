![RAGè¯„ä¼°ä½“ç³»](./images/evaluation.svg)
*å›¾ï¼šRAGè¯„ä¼°ä½“ç³»*

# ç¬¬66è¯¾ï¼šRAGè¯„ä¼°æŒ‡æ ‡ä½“ç³»

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŒæ¡RAGç³»ç»Ÿè¯„ä¼°çš„å®Œæ•´æŒ‡æ ‡ä½“ç³»
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šæ£€ç´¢è¯„ä¼°ã€ç”Ÿæˆè¯„ä¼°ã€ç«¯åˆ°ç«¯è¯„ä¼°
> 
> **å®æˆ˜æ¡ˆä¾‹**ï¼šæ„å»ºRAGè¯„ä¼°ç³»ç»Ÿ
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š75åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ5åˆ†é’Ÿï¼‰
![Generation Eval](./images/generation_eval.svg)
*å›¾ï¼šGeneration Eval*


### ğŸ¯ å‰è¨€

"åšäº†è¿™ä¹ˆå¤šRAGç³»ç»Ÿä¼˜åŒ–ï¼Œä½ æœ‰æ²¡æœ‰æƒ³è¿‡ä¸€ä¸ªé—®é¢˜ï¼š

**æ€ä¹ˆçŸ¥é“ç³»ç»Ÿåˆ°åº•å¥½ä¸å¥½ï¼Ÿ**

æˆ‘åœ¨åšä¼ä¸šçº§RAGé¡¹ç›®æ—¶ï¼Œæœ€å¸¸è¢«é—®åˆ°çš„é—®é¢˜å°±æ˜¯ï¼š

è€æ¿ï¼š'ä½ è¿™ä¸ªç³»ç»Ÿæ•ˆæœæ€ä¹ˆæ ·ï¼Ÿ'

æˆ‘ï¼š'æ•ˆæœå¾ˆå¥½å•Šï¼'

è€æ¿ï¼š'æœ‰å¤šå¥½ï¼Ÿèƒ½ä¸èƒ½é‡åŒ–ï¼Ÿ'

æˆ‘ï¼š'å‘ƒ...ç”¨æˆ·åé¦ˆä¸é”™...'

è€æ¿ï¼š'ä¸å¤Ÿï¼Œæˆ‘è¦çœ‹æ•°æ®ï¼'

**è¿™å°±æ˜¯é—®é¢˜æ‰€åœ¨ï¼šæ²¡æœ‰è¯„ä¼°ä½“ç³»ï¼**

å¾ˆå¤šåŒå­¦åšRAGé¡¹ç›®æ—¶ä¹Ÿæ˜¯è¿™æ ·ï¼š
- âŒ å‡­æ„Ÿè§‰åˆ¤æ–­æ•ˆæœ
- âŒ çœ‹å‡ ä¸ªcaseå°±è§‰å¾—å¥½äº†
- âŒ æ²¡æœ‰ç³»ç»Ÿçš„è¯„ä¼°æ–¹æ³•
- âŒ æ— æ³•é‡åŒ–ä¼˜åŒ–æ•ˆæœ

**ä¸ºä»€ä¹ˆè¯„ä¼°è¿™ä¹ˆé‡è¦ï¼Ÿ**

ä¸¾ä¸ªçœŸå®ä¾‹å­ï¼š

æˆ‘ä¼˜åŒ–äº†ä¸€ä¸ªRAGç³»ç»Ÿçš„æ£€ç´¢ç®—æ³•ï¼Œè‡ªæˆ‘æ„Ÿè§‰è‰¯å¥½ã€‚

ä½†æ˜¯ï¼å½“æˆ‘ç”¨è¯„ä¼°ç³»ç»Ÿæµ‹è¯•åå‘ç°ï¼š

```
ä¼˜åŒ–å‰ï¼š
  â€¢ æ£€ç´¢å‡†ç¡®ç‡ï¼š75%
  â€¢ ç­”æ¡ˆå‡†ç¡®ç‡ï¼š68%
  â€¢ å¹³å‡å“åº”æ—¶é—´ï¼š3.2ç§’
  â€¢ ç”¨æˆ·æ»¡æ„åº¦ï¼š72%

ä¼˜åŒ–åï¼š
  â€¢ æ£€ç´¢å‡†ç¡®ç‡ï¼š85% â†‘ 13%  âœ…
  â€¢ ç­”æ¡ˆå‡†ç¡®ç‡ï¼š65% â†“ 4%   âŒ
  â€¢ å¹³å‡å“åº”æ—¶é—´ï¼š4.5ç§’ â†‘ 40%  âŒ
  â€¢ ç”¨æˆ·æ»¡æ„åº¦ï¼š68% â†“ 5%   âŒ
```

**æˆ‘çš„ä¼˜åŒ–åè€Œè®©æ•´ä½“æ•ˆæœå˜å·®äº†ï¼**

å¦‚æœæ²¡æœ‰è¯„ä¼°ç³»ç»Ÿï¼Œæˆ‘è¿˜ä»¥ä¸ºè‡ªå·±åšå¾—å¾ˆå¥½å‘¢ï¼

**æ²¡æœ‰è¯„ä¼°å°±æ²¡æœ‰ä¼˜åŒ–ï¼**

**RAGè¯„ä¼°çš„ä¸‰ä¸ªç»´åº¦ï¼š**

```
1. æ£€ç´¢è´¨é‡ (Retrieval Quality)
   â†’ æ£€ç´¢åˆ°çš„æ–‡æ¡£ç›¸å…³å—ï¼Ÿ

2. ç”Ÿæˆè´¨é‡ (Generation Quality)
   â†’ ç”Ÿæˆçš„ç­”æ¡ˆå‡†ç¡®å—ï¼Ÿ

3. ç«¯åˆ°ç«¯è´¨é‡ (End-to-End Quality)
   â†’ æ•´ä½“ç”¨æˆ·ä½“éªŒå¥½å—ï¼Ÿ
```

**æ¯ä¸ªç»´åº¦éƒ½æœ‰ä¸åŒçš„æŒ‡æ ‡ï¼š**

**æ£€ç´¢è´¨é‡æŒ‡æ ‡ï¼š**
- Precision@K: æ£€ç´¢åˆ°çš„Kä¸ªæ–‡æ¡£ä¸­æœ‰å¤šå°‘æ˜¯ç›¸å…³çš„
- Recall@K: æ‰€æœ‰ç›¸å…³æ–‡æ¡£ä¸­æ£€ç´¢åˆ°äº†å¤šå°‘
- MRR: ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ’å
- NDCG: è€ƒè™‘æ’åçš„ç»¼åˆæŒ‡æ ‡

**ç”Ÿæˆè´¨é‡æŒ‡æ ‡ï¼š**
- Faithfulness: ç­”æ¡ˆæ˜¯å¦å¿ äºä¸Šä¸‹æ–‡
- Answer Relevancy: ç­”æ¡ˆæ˜¯å¦å›ç­”äº†é—®é¢˜
- Correctness: ç­”æ¡ˆæ˜¯å¦æ­£ç¡®
- Completeness: ç­”æ¡ˆæ˜¯å¦å®Œæ•´

**ç«¯åˆ°ç«¯æŒ‡æ ‡ï¼š**
- Response Time: å“åº”æ—¶é—´
- Cost per Query: æ¯æ¬¡æŸ¥è¯¢æˆæœ¬
- User Satisfaction: ç”¨æˆ·æ»¡æ„åº¦
- Success Rate: æˆåŠŸç‡

**ä½†æ˜¯ï¼è¯„ä¼°ä¹Ÿæœ‰æŒ‘æˆ˜ï¼š**

**æŒ‘æˆ˜1ï¼šå¦‚ä½•è·å–Ground Truthï¼Ÿ**
- éœ€è¦äººå·¥æ ‡æ³¨
- æˆæœ¬é«˜ã€è€—æ—¶é•¿
- æ ‡æ³¨è´¨é‡å‚å·®ä¸é½

**æŒ‘æˆ˜2ï¼šå¦‚ä½•è‡ªåŠ¨åŒ–è¯„ä¼°ï¼Ÿ**
- äººå·¥è¯„ä¼°ä¸å¯æ‰©å±•
- LLMè¯„ä¼°å¯èƒ½æœ‰åå·®
- éœ€è¦å¹³è¡¡å‡†ç¡®æ€§å’Œæ•ˆç‡

**æŒ‘æˆ˜3ï¼šå¦‚ä½•ç»¼åˆå¤šä¸ªæŒ‡æ ‡ï¼Ÿ**
- ä¸åŒæŒ‡æ ‡å¯èƒ½å†²çª
- éœ€è¦æƒè¡¡å–èˆ
- éš¾ä»¥ç”¨å•ä¸€æ•°å­—è¡¡é‡

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦æ•™ä½ ï¼š**

**ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯„ä¼°æŒ‡æ ‡è¯¦è§£**
- æ£€ç´¢æŒ‡æ ‡
- ç”ŸæˆæŒ‡æ ‡
- ç«¯åˆ°ç«¯æŒ‡æ ‡

**ç¬¬äºŒéƒ¨åˆ†ï¼šè¯„ä¼°æ•°æ®å‡†å¤‡**
- Ground Truthæ„å»º
- æµ‹è¯•é›†è®¾è®¡
- æ ‡æ³¨è§„èŒƒ

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šè‡ªåŠ¨åŒ–è¯„ä¼°**
- åŸºäºè§„åˆ™çš„è¯„ä¼°
- åŸºäºæ¨¡å‹çš„è¯„ä¼°
- LLMä½œä¸ºè¯„ä¼°å™¨

**ç¬¬å››éƒ¨åˆ†ï¼šè¯„ä¼°ç³»ç»Ÿå®ç°**
- è¯„ä¼°æ¡†æ¶
- æŒ‡æ ‡è®¡ç®—
- ç»“æœåˆ†æ

**ç¬¬äº”éƒ¨åˆ†ï¼šæœ€ä½³å®è·µ**
- è¯„ä¼°ç­–ç•¥
- æŒç»­ç›‘æ§
- ä¼˜åŒ–é—­ç¯

å­¦å®Œè¿™ä¸€è¯¾ï¼Œä½ å°†å»ºç«‹å®Œæ•´çš„RAGè¯„ä¼°ä½“ç³»ï¼

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ï¼"

---

### ğŸ’¡ æ ¸å¿ƒç†å¿µ

```
ã€è¯„ä¼°çš„é‡è¦æ€§ã€‘

æ²¡æœ‰è¯„ä¼°ï¼š
  â€¢ ä¸çŸ¥é“ç³»ç»Ÿå¥½å
  â€¢ æ— æ³•é‡åŒ–ä¼˜åŒ–æ•ˆæœ
  â€¢ éš¾ä»¥åšæŠ€æœ¯å†³ç­–

æœ‰è¯„ä¼°ï¼š
  â€¢ æ¸…æ¥šçŸ¥é“å“ªé‡Œå¥½å“ªé‡Œå·®
  â€¢ ä¼˜åŒ–æœ‰çš„æ”¾çŸ¢
  â€¢ æ•°æ®é©±åŠ¨å†³ç­–

ã€è¯„ä¼°çš„ä¸‰ä¸ªå±‚æ¬¡ã€‘

Level 1: ç»„ä»¶è¯„ä¼°
  å•ç‹¬è¯„ä¼°æ£€ç´¢ã€ç”Ÿæˆç­‰ç»„ä»¶

Level 2: é›†æˆè¯„ä¼°
  è¯„ä¼°ç»„ä»¶ä¹‹é—´çš„é…åˆ

Level 3: ç³»ç»Ÿè¯„ä¼°
  è¯„ä¼°æ•´ä½“ç”¨æˆ·ä½“éªŒ
```

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯„ä¼°æŒ‡æ ‡è¯¦è§£

### ä¸€ã€æ£€ç´¢è´¨é‡æŒ‡æ ‡

```python
from typing import List, Set, Dict
import numpy as np

class RetrievalMetrics:
    """æ£€ç´¢è´¨é‡æŒ‡æ ‡"""
    
    @staticmethod
    def precision_at_k(
        retrieved: List[str],
        relevant: Set[str],
        k: int
    ) -> float:
        """
        Precision@K
        
        å®šä¹‰ï¼šæ£€ç´¢åˆ°çš„å‰Kä¸ªæ–‡æ¡£ä¸­ï¼Œç›¸å…³æ–‡æ¡£çš„æ¯”ä¾‹
        
        å…¬å¼ï¼šP@K = (æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£æ•°) / K
        
        ä¾‹å­ï¼š
        æ£€ç´¢åˆ°: [doc1, doc2, doc3, doc4, doc5]
        ç›¸å…³çš„: {doc1, doc3, doc5, doc7}
        P@3 = 2/3 = 0.67 (doc1, doc3æ˜¯ç›¸å…³çš„)
        """
        retrieved_k = retrieved[:k]
        relevant_retrieved = sum(1 for doc in retrieved_k if doc in relevant)
        return relevant_retrieved / k if k > 0 else 0
    
    @staticmethod
    def recall_at_k(
        retrieved: List[str],
        relevant: Set[str],
        k: int
    ) -> float:
        """
        Recall@K
        
        å®šä¹‰ï¼šæ‰€æœ‰ç›¸å…³æ–‡æ¡£ä¸­ï¼Œæ£€ç´¢åˆ°å‰Kä¸ªçš„æ¯”ä¾‹
        
        å…¬å¼ï¼šR@K = (æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£æ•°) / (æ€»ç›¸å…³æ–‡æ¡£æ•°)
        
        ä¾‹å­ï¼š
        æ£€ç´¢åˆ°: [doc1, doc2, doc3]
        ç›¸å…³çš„: {doc1, doc3, doc5, doc7}
        R@3 = 2/4 = 0.5 (æ‰¾åˆ°äº†4ä¸ªç›¸å…³æ–‡æ¡£ä¸­çš„2ä¸ª)
        """
        retrieved_k = set(retrieved[:k])
        relevant_retrieved = retrieved_k & relevant
        return len(relevant_retrieved) / len(relevant) if relevant else 0
    
    @staticmethod
    def f1_at_k(
        retrieved: List[str],
        relevant: Set[str],
        k: int
    ) -> float:
        """
        F1@K
        
        å®šä¹‰ï¼šPrecisionå’ŒRecallçš„è°ƒå’Œå¹³å‡
        
        å…¬å¼ï¼šF1 = 2 * (P * R) / (P + R)
        """
        p = RetrievalMetrics.precision_at_k(retrieved, relevant, k)
        r = RetrievalMetrics.recall_at_k(retrieved, relevant, k)
        
        if p + r == 0:
            return 0
        
        return 2 * (p * r) / (p + r)
    
    @staticmethod
    def mrr(retrieved: List[str], relevant: Set[str]) -> float:
        """
        MRR (Mean Reciprocal Rank)
        
        å®šä¹‰ï¼šç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ’åå€’æ•°
        
        å…¬å¼ï¼šMRR = 1 / (ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ’å)
        
        ä¾‹å­ï¼š
        æ£€ç´¢åˆ°: [doc1, doc2, doc3, doc4]
        ç›¸å…³çš„: {doc3, doc5}
        ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£doc3åœ¨ç¬¬3ä½
        MRR = 1/3 = 0.333
        
        ç›´è§‚ç†è§£ï¼šMRRè¶Šé«˜ï¼Œè¯´æ˜ç›¸å…³æ–‡æ¡£æ’åè¶Šé å‰
        """
        for i, doc in enumerate(retrieved):
            if doc in relevant:
                return 1.0 / (i + 1)
        return 0.0
    
    @staticmethod
    def ndcg_at_k(
        retrieved: List[str],
        relevance_scores: Dict[str, float],
        k: int
    ) -> float:
        """
        NDCG@K (Normalized Discounted Cumulative Gain)
        
        å®šä¹‰ï¼šè€ƒè™‘æ’åä½ç½®å’Œç›¸å…³æ€§ç¨‹åº¦çš„ç»¼åˆæŒ‡æ ‡
        
        ä¼˜ç‚¹ï¼š
        1. è€ƒè™‘äº†æ–‡æ¡£çš„ç›¸å…³æ€§ç¨‹åº¦ï¼ˆä¸åªæ˜¯0/1ï¼‰
        2. è€ƒè™‘äº†æ’åä½ç½®ï¼ˆè¶Šé å‰æƒé‡è¶Šå¤§ï¼‰
        
        å…¬å¼ï¼š
        DCG@K = Î£ (rel_i / log2(i+1))
        NDCG@K = DCG@K / IDCG@K
        
        å…¶ä¸­IDCGæ˜¯ç†æƒ³æƒ…å†µä¸‹çš„DCGï¼ˆæŒ‰ç›¸å…³æ€§æ’åºï¼‰
        """
        # DCG (Discounted Cumulative Gain)
        dcg = 0
        for i, doc in enumerate(retrieved[:k]):
            rel = relevance_scores.get(doc, 0)
            dcg += rel / np.log2(i + 2)  # i+2 because log2(1)=0
        
        # IDCG (Ideal DCG)
        sorted_scores = sorted(relevance_scores.values(), reverse=True)
        idcg = 0
        for i, rel in enumerate(sorted_scores[:k]):
            idcg += rel / np.log2(i + 2)
        
        return dcg / idcg if idcg > 0 else 0

# æ¼”ç¤º
def demo_retrieval_metrics():
    """æ¼”ç¤ºæ£€ç´¢æŒ‡æ ‡"""
    
    # æ£€ç´¢ç»“æœ
    retrieved = ["doc1", "doc2", "doc3", "doc4", "doc5"]
    
    # ç›¸å…³æ–‡æ¡£ï¼ˆGround Truthï¼‰
    relevant = {"doc1", "doc3", "doc5", "doc7", "doc9"}
    
    # ç›¸å…³æ€§åˆ†æ•°ï¼ˆç”¨äºNDCGï¼‰
    relevance_scores = {
        "doc1": 3,  # é«˜åº¦ç›¸å…³
        "doc2": 0,  # ä¸ç›¸å…³
        "doc3": 2,  # ä¸­åº¦ç›¸å…³
        "doc4": 0,
        "doc5": 3,
        "doc7": 2,
        "doc9": 1
    }
    
    print("="*60)
    print("æ£€ç´¢è´¨é‡æŒ‡æ ‡æ¼”ç¤º")
    print("="*60)
    
    print(f"\næ£€ç´¢ç»“æœ: {retrieved}")
    print(f"ç›¸å…³æ–‡æ¡£(çœŸå®): {relevant}")
    
    k = 5
    
    print(f"\nã€Precision@{k}ã€‘")
    p = RetrievalMetrics.precision_at_k(retrieved, relevant, k)
    print(f"  å€¼: {p:.3f}")
    print(f"  å«ä¹‰: æ£€ç´¢åˆ°çš„{k}ä¸ªæ–‡æ¡£ä¸­ï¼Œ{p*100:.0f}%æ˜¯ç›¸å…³çš„")
    
    print(f"\nã€Recall@{k}ã€‘")
    r = RetrievalMetrics.recall_at_k(retrieved, relevant, k)
    print(f"  å€¼: {r:.3f}")
    print(f"  å«ä¹‰: {len(relevant)}ä¸ªç›¸å…³æ–‡æ¡£ä¸­ï¼Œæ‰¾åˆ°äº†{r*100:.0f}%")
    
    print(f"\nã€F1@{k}ã€‘")
    f1 = RetrievalMetrics.f1_at_k(retrieved, relevant, k)
    print(f"  å€¼: {f1:.3f}")
    print(f"  å«ä¹‰: Precisionå’ŒRecallçš„å¹³è¡¡æŒ‡æ ‡")
    
    print(f"\nã€MRRã€‘")
    mrr = RetrievalMetrics.mrr(retrieved, relevant)
    print(f"  å€¼: {mrr:.3f}")
    print(f"  å«ä¹‰: ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£doc1åœ¨ç¬¬{int(1/mrr)}ä½")
    
    print(f"\nã€NDCG@{k}ã€‘")
    ndcg = RetrievalMetrics.ndcg_at_k(retrieved, relevance_scores, k)
    print(f"  å€¼: {ndcg:.3f}")
    print(f"  å«ä¹‰: è€ƒè™‘æ’åå’Œç›¸å…³æ€§ç¨‹åº¦çš„ç»¼åˆå¾—åˆ†")
    
    print("\nã€æŒ‡æ ‡å¯¹æ¯”ã€‘")
    print(f"  Precision@{k}: {p:.3f} - å‡†ç¡®æ€§")
    print(f"  Recall@{k}: {r:.3f} - å¬å›ç‡")
    print(f"  F1@{k}: {f1:.3f} - ç»¼åˆ")
    print(f"  MRR: {mrr:.3f} - æ’åºè´¨é‡")
    print(f"  NDCG@{k}: {ndcg:.3f} - æœ€å…¨é¢")

demo_retrieval_metrics()
```

### äºŒã€ç”Ÿæˆè´¨é‡æŒ‡æ ‡

```python
class GenerationMetrics:
    """ç”Ÿæˆè´¨é‡æŒ‡æ ‡"""
    
    @staticmethod
    def faithfulness(
        answer: str,
        context: str,
        llm
    ) -> float:
        """
        Faithfulness (å¿ å®åº¦)
        
        å®šä¹‰ï¼šç­”æ¡ˆæ˜¯å¦å¿ äºä¸Šä¸‹æ–‡ï¼Œæ²¡æœ‰å¹»è§‰
        
        è¯„ä¼°æ–¹æ³•ï¼š
        1. æå–ç­”æ¡ˆä¸­çš„é™ˆè¿°(statements)
        2. æ£€æŸ¥æ¯ä¸ªé™ˆè¿°æ˜¯å¦èƒ½ä»ä¸Šä¸‹æ–‡æ¨å¯¼
        3. è®¡ç®—è¢«æ”¯æŒçš„é™ˆè¿°æ¯”ä¾‹
        """
        prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹ç­”æ¡ˆæ˜¯å¦å¿ å®äºä¸Šä¸‹æ–‡ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

ç­”æ¡ˆï¼š
{answer}

ä»»åŠ¡ï¼š
1. æå–ç­”æ¡ˆä¸­çš„å…³é”®é™ˆè¿°
2. å¯¹æ¯ä¸ªé™ˆè¿°ï¼Œåˆ¤æ–­æ˜¯å¦èƒ½ä»ä¸Šä¸‹æ–‡æ¨å¯¼å‡º
3. è®¡ç®—å¿ å®åº¦åˆ†æ•°(0-1)

ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "statements": ["é™ˆè¿°1", "é™ˆè¿°2", ...],
    "supported": [true, false, ...],
    "score": 0.8
}}

JSONç»“æœï¼š"""
        
        response = llm.invoke(prompt)
        
        try:
            import json
            result = json.loads(response.content)
            return result.get('score', 0.5)
        except:
            return 0.5
    
    @staticmethod
    def answer_relevancy(
        question: str,
        answer: str,
        llm
    ) -> float:
        """
        Answer Relevancy (ç­”æ¡ˆç›¸å…³æ€§)
        
        å®šä¹‰ï¼šç­”æ¡ˆæ˜¯å¦ç›´æ¥å›ç­”äº†é—®é¢˜
        
        è¯„ä¼°æ–¹æ³•ï¼šä½¿ç”¨LLMåˆ¤æ–­ç­”æ¡ˆå¯¹é—®é¢˜çš„ç›¸å…³ç¨‹åº¦
        """
        prompt = f"""è¯·è¯„ä¼°ç­”æ¡ˆå¯¹é—®é¢˜çš„ç›¸å…³æ€§ã€‚

é—®é¢˜ï¼š{question}

ç­”æ¡ˆï¼š{answer}

è¯·ç»™å‡º0-1ä¹‹é—´çš„ç›¸å…³æ€§åˆ†æ•°ï¼š
- 1.0: å®Œç¾å›ç­”äº†é—®é¢˜
- 0.7-0.9: å¤§éƒ¨åˆ†å›ç­”äº†é—®é¢˜
- 0.4-0.6: éƒ¨åˆ†å›ç­”äº†é—®é¢˜
- 0.1-0.3: å‡ ä¹æ²¡å›ç­”é—®é¢˜
- 0.0: å®Œå…¨ä¸ç›¸å…³

åªè¿”å›ä¸€ä¸ªæ•°å­—ï¼š"""
        
        response = llm.invoke(prompt)
        
        try:
            score = float(response.content.strip())
            return max(0, min(1, score))
        except:
            return 0.5
    
    @staticmethod
    def correctness(
        answer: str,
        ground_truth: str,
        llm
    ) -> float:
        """
        Correctness (æ­£ç¡®æ€§)
        
        å®šä¹‰ï¼šç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„åŒ¹é…ç¨‹åº¦
        
        è¯„ä¼°æ–¹æ³•ï¼šå¯¹æ¯”ç”Ÿæˆç­”æ¡ˆå’Œæ ‡å‡†ç­”æ¡ˆ
        """
        prompt = f"""è¯·è¯„ä¼°ç”Ÿæˆç­”æ¡ˆçš„æ­£ç¡®æ€§ã€‚

æ ‡å‡†ç­”æ¡ˆï¼š
{ground_truth}

ç”Ÿæˆç­”æ¡ˆï¼š
{answer}

è¯·ç»™å‡º0-1ä¹‹é—´çš„æ­£ç¡®æ€§åˆ†æ•°ï¼š
- 1.0: å®Œå…¨æ­£ç¡®
- 0.7-0.9: å¤§éƒ¨åˆ†æ­£ç¡®
- 0.4-0.6: éƒ¨åˆ†æ­£ç¡®
- 0.1-0.3: å¤§éƒ¨åˆ†é”™è¯¯
- 0.0: å®Œå…¨é”™è¯¯

åªè¿”å›ä¸€ä¸ªæ•°å­—ï¼š"""
        
        response = llm.invoke(prompt)
        
        try:
            score = float(response.content.strip())
            return max(0, min(1, score))
        except:
            return 0.5

# æ¼”ç¤º
def demo_generation_metrics():
    """æ¼”ç¤ºç”Ÿæˆè´¨é‡æŒ‡æ ‡"""
    
    from langchain.chat_models import ChatOpenAI
    
    llm = ChatOpenAI(
        base_url="http://localhost:1234/v1",
        api_key="lm-studio",
        temperature=0
    )
    
    # æµ‹è¯•æ•°æ®
    context = """
    Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ã€‚å®ƒç”±Guido van Rossumäº1991å¹´é¦–æ¬¡å‘å¸ƒã€‚
    Pythonè¯­æ³•ç®€æ´æ¸…æ™°ï¼Œéå¸¸é€‚åˆåˆå­¦è€…ã€‚
    Pythonåœ¨æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€Webå¼€å‘ç­‰é¢†åŸŸåº”ç”¨å¹¿æ³›ã€‚
    """
    
    question = "Pythonæ˜¯ä»€ä¹ˆæ—¶å€™å‘å¸ƒçš„ï¼Ÿ"
    
    answer_good = "Pythonç”±Guido van Rossumäº1991å¹´é¦–æ¬¡å‘å¸ƒã€‚"
    answer_bad = "Pythonæ˜¯ä¸€ç§å¾ˆæµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼Œç°åœ¨å¾ˆå¤šå…¬å¸éƒ½åœ¨ä½¿ç”¨ã€‚"
    
    ground_truth = "Pythonäº1991å¹´é¦–æ¬¡å‘å¸ƒã€‚"
    
    print("="*60)
    print("ç”Ÿæˆè´¨é‡æŒ‡æ ‡æ¼”ç¤º")
    print("="*60)
    
    print(f"\né—®é¢˜: {question}")
    print(f"ä¸Šä¸‹æ–‡: {context[:50]}...")
    print(f"æ ‡å‡†ç­”æ¡ˆ: {ground_truth}")
    
    print("\nã€å¥½ç­”æ¡ˆè¯„ä¼°ã€‘")
    print(f"ç­”æ¡ˆ: {answer_good}")
    
    faith_good = GenerationMetrics.faithfulness(answer_good, context, llm)
    rel_good = GenerationMetrics.answer_relevancy(question, answer_good, llm)
    corr_good = GenerationMetrics.correctness(answer_good, ground_truth, llm)
    
    print(f"  Faithfulness: {faith_good:.2f}")
    print(f"  Relevancy: {rel_good:.2f}")
    print(f"  Correctness: {corr_good:.2f}")
    
    print("\nã€å·®ç­”æ¡ˆè¯„ä¼°ã€‘")
    print(f"ç­”æ¡ˆ: {answer_bad}")
    
    faith_bad = GenerationMetrics.faithfulness(answer_bad, context, llm)
    rel_bad = GenerationMetrics.answer_relevancy(question, answer_bad, llm)
    corr_bad = GenerationMetrics.correctness(answer_bad, ground_truth, llm)
    
    print(f"  Faithfulness: {faith_bad:.2f}")
    print(f"  Relevancy: {rel_bad:.2f}")
    print(f"  Correctness: {corr_bad:.2f}")

# demo_generation_metrics()
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šè¯„ä¼°æ•°æ®å‡†å¤‡

### Ground Truthæ„å»º

```python
from dataclasses import dataclass
from typing import List, Dict, Optional

@dataclass
class RAGTestCase:
    """RAGæµ‹è¯•ç”¨ä¾‹"""
    query: str                          # æŸ¥è¯¢
    relevant_docs: Set[str]             # ç›¸å…³æ–‡æ¡£ID
    ground_truth_answer: str            # æ ‡å‡†ç­”æ¡ˆ
    context: str                        # åº”è¯¥æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
    metadata: Dict = None               # å…¶ä»–å…ƒæ•°æ®

class GroundTruthBuilder:
    """Ground Truthæ„å»ºå™¨"""
    
    def __init__(self):
        self.test_cases: List[RAGTestCase] = []
    
    def add_test_case(
        self,
        query: str,
        relevant_docs: Set[str],
        ground_truth_answer: str,
        context: str,
        metadata: Dict = None
    ):
        """æ·»åŠ æµ‹è¯•ç”¨ä¾‹"""
        case = RAGTestCase(
            query=query,
            relevant_docs=relevant_docs,
            ground_truth_answer=ground_truth_answer,
            context=context,
            metadata=metadata or {}
        )
        self.test_cases.append(case)
    
    def save(self, filepath: str):
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        import json
        
        data = [
            {
                'query': case.query,
                'relevant_docs': list(case.relevant_docs),
                'ground_truth_answer': case.ground_truth_answer,
                'context': case.context,
                'metadata': case.metadata
            }
            for case in self.test_cases
        ]
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def load(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½"""
        import json
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.test_cases = [
            RAGTestCase(
                query=item['query'],
                relevant_docs=set(item['relevant_docs']),
                ground_truth_answer=item['ground_truth_answer'],
                context=item['context'],
                metadata=item.get('metadata', {})
            )
            for item in data
        ]

# ç¤ºä¾‹
def demo_ground_truth():
    """æ¼”ç¤ºGround Truthæ„å»º"""
    
    builder = GroundTruthBuilder()
    
    # æ·»åŠ æµ‹è¯•ç”¨ä¾‹
    builder.add_test_case(
        query="Pythonæ˜¯ä»€ä¹ˆæ—¶å€™å‘å¸ƒçš„ï¼Ÿ",
        relevant_docs={"doc1", "doc3"},
        ground_truth_answer="Pythonç”±Guido van Rossumäº1991å¹´é¦–æ¬¡å‘å¸ƒã€‚",
        context="Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ã€‚å®ƒç”±Guido van Rossumäº1991å¹´é¦–æ¬¡å‘å¸ƒã€‚",
        metadata={"difficulty": "easy", "category": "fact"}
    )
    
    builder.add_test_case(
        query="å¦‚ä½•åœ¨Pythonä¸­å¤„ç†å¼‚å¸¸ï¼Ÿ",
        relevant_docs={"doc5", "doc7", "doc9"},
        ground_truth_answer="ä½¿ç”¨try-exceptè¯­å¥å¤„ç†å¼‚å¸¸...",
        context="Pythonä½¿ç”¨try-exceptè¯­å¥å¤„ç†å¼‚å¸¸...",
        metadata={"difficulty": "medium", "category": "how-to"}
    )
    
    print("="*60)
    print("Ground Truthæ„å»º")
    print("="*60)
    print(f"\næµ‹è¯•ç”¨ä¾‹æ•°: {len(builder.test_cases)}")
    
    for i, case in enumerate(builder.test_cases):
        print(f"\nç”¨ä¾‹{i+1}:")
        print(f"  æŸ¥è¯¢: {case.query}")
        print(f"  ç›¸å…³æ–‡æ¡£: {case.relevant_docs}")
        print(f"  æ ‡å‡†ç­”æ¡ˆ: {case.ground_truth_answer[:50]}...")
        print(f"  å…ƒæ•°æ®: {case.metadata}")
    
    # ä¿å­˜
    # builder.save("test_cases.json")

demo_ground_truth()
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šå®ç°MAPæŒ‡æ ‡
å®ç°Mean Average PrecisionæŒ‡æ ‡

### ç»ƒä¹ 2ï¼šè‡ªåŠ¨åŒ–æ ‡æ³¨
ä½¿ç”¨LLMè¾…åŠ©ç”ŸæˆGround Truth

### ç»ƒä¹ 3ï¼šè¯„ä¼°æŠ¥å‘Š
ç”Ÿæˆå¯è§†åŒ–çš„è¯„ä¼°æŠ¥å‘Š

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **è¯„ä¼°çš„é‡è¦æ€§**
   - æ²¡æœ‰è¯„ä¼°å°±æ²¡æœ‰ä¼˜åŒ–
   - æ•°æ®é©±åŠ¨å†³ç­–
   - æŒç»­æ”¹è¿›

2. **ä¸‰å¤§è¯„ä¼°ç»´åº¦**
   - æ£€ç´¢è´¨é‡
   - ç”Ÿæˆè´¨é‡
   - ç«¯åˆ°ç«¯è´¨é‡

3. **å…³é”®æŒ‡æ ‡**
   - Precision/Recall/F1
   - MRR/NDCG
   - Faithfulness/Relevancy

4. **Ground Truth**
   - é«˜è´¨é‡æ ‡æ³¨
   - è¦†ç›–å¤šç§åœºæ™¯
   - æŒç»­æ›´æ–°

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬67è¯¾ï¼šæ£€ç´¢è´¨é‡è¯„ä¼°**

- ç¦»çº¿è¯„ä¼°æ–¹æ³•
- åœ¨çº¿è¯„ä¼°æ–¹æ³•
- æ£€ç´¢è´¨é‡ä¼˜åŒ–

**æ·±å…¥æ£€ç´¢è¯„ä¼°ï¼** ğŸ“Š

---

**ğŸ’ª è®°ä½ï¼šè¯„ä¼°æ˜¯ä¼˜åŒ–çš„å‰æï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
