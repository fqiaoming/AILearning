![RAGè¯„ä¼°ä½“ç³»](./images/evaluation.svg)
*å›¾ï¼šRAGè¯„ä¼°ä½“ç³»*

# ç¬¬70è¯¾ï¼šå®æˆ˜-RAGç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š

> **æœ¬è¯¾ç›®æ ‡**ï¼šæ„å»ºå®Œæ•´çš„RAGè¯„ä¼°æŠ¥å‘Šç³»ç»Ÿï¼Œè¾“å‡ºä¸“ä¸šè¯„ä¼°æ–‡æ¡£
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šè¯„ä¼°æµç¨‹ã€æŠ¥å‘Šç”Ÿæˆã€å¯è§†åŒ–ã€ä¼˜åŒ–å»ºè®®
> 
> **å®æˆ˜æ¡ˆä¾‹**ï¼šä¼ä¸šçº§RAGè¯„ä¼°æŠ¥å‘Šç³»ç»Ÿ
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š90åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ5åˆ†é’Ÿï¼‰
![Generation Eval](./images/generation_eval.svg)
*å›¾ï¼šGeneration Eval*


### ğŸ¯ å‰è¨€

"å‰é¢ä¸‰èŠ‚è¯¾æˆ‘ä»¬å­¦äº†æ£€ç´¢è¯„ä¼°ã€ç”Ÿæˆè¯„ä¼°ã€ç«¯åˆ°ç«¯è¯„ä¼°ï¼Œä»Šå¤©æˆ‘ä»¬è¦æŠŠè¿™äº›çŸ¥è¯†æ•´åˆèµ·æ¥ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„RAGè¯„ä¼°æŠ¥å‘Šï¼

**ä¸ºä»€ä¹ˆéœ€è¦è¯„ä¼°æŠ¥å‘Šï¼Ÿ**

æˆ‘åœ¨ä¼ä¸šåšRAGé¡¹ç›®æ—¶ï¼Œæœ€å¸¸é‡åˆ°çš„åœºæ™¯ï¼š

**åœºæ™¯1ï¼šå‘è€æ¿æ±‡æŠ¥**
```
è€æ¿ï¼š"ç³»ç»Ÿæ•ˆæœæ€ä¹ˆæ ·ï¼Ÿ"
æˆ‘ï¼š"å¾ˆå¥½ï¼"
è€æ¿ï¼š"å¤šå¥½ï¼Ÿ"
æˆ‘ï¼š"å‘ƒ...ç”¨æˆ·åé¦ˆä¸é”™..."
è€æ¿ï¼š"èƒ½ä¸èƒ½ç»™æˆ‘ä¸€ä»½è¯¦ç»†çš„æŠ¥å‘Šï¼Ÿ"
æˆ‘ï¼š"..."
```

**åœºæ™¯2ï¼šæŠ€æœ¯å†³ç­–**
```
åŒäº‹ï¼š"è¦ä¸è¦å‡çº§embeddingæ¨¡å‹ï¼Ÿ"
æˆ‘ï¼š"åº”è¯¥å‡çº§å§..."
åŒäº‹ï¼š"èƒ½æå‡å¤šå°‘ï¼Ÿå€¼å¾—å—ï¼Ÿ"
æˆ‘ï¼š"..."
```

**åœºæ™¯3ï¼šæŒç»­ä¼˜åŒ–**
```
äº§å“ï¼š"ä¸Šä¸ªæœˆåšäº†å“ªäº›ä¼˜åŒ–ï¼Ÿæ•ˆæœå¦‚ä½•ï¼Ÿ"
æˆ‘ï¼š"ä¼˜åŒ–äº†æ£€ç´¢ç®—æ³•..."
äº§å“ï¼š"å…·ä½“æ•°æ®å‘¢ï¼Ÿå¯¹æ¯”å‘¢ï¼Ÿ"
æˆ‘ï¼š"..."
```

**æ²¡æœ‰è¯„ä¼°æŠ¥å‘Šï¼Œå°±æ²¡æœ‰è¯è¯­æƒï¼**

**ä¸€ä»½å¥½çš„è¯„ä¼°æŠ¥å‘Šåº”è¯¥åŒ…å«ä»€ä¹ˆï¼Ÿ**

**1. æ‰§è¡Œæ‘˜è¦ï¼ˆç»™è€æ¿çœ‹çš„ï¼‰**
```
â€¢ æ ¸å¿ƒæŒ‡æ ‡ä¸€ç›®äº†ç„¶
â€¢ å…³é”®å‘ç°
â€¢ æ”¹è¿›å»ºè®®
â€¢ ROIåˆ†æ

ç”¨æœ€ç®€æ´çš„è¯­è¨€è¯´æ¸…æ¥šï¼š
- ç³»ç»Ÿå¥½ä¸å¥½ï¼Ÿ
- é—®é¢˜åœ¨å“ªï¼Ÿ
- æ€ä¹ˆä¼˜åŒ–ï¼Ÿ
```

**2. è¯¦ç»†æŒ‡æ ‡ï¼ˆç»™æŠ€æœ¯çœ‹çš„ï¼‰**
```
â€¢ æ£€ç´¢è´¨é‡
  - Precision@K
  - Recall@K
  - NDCG
  - MRR

â€¢ ç”Ÿæˆè´¨é‡
  - Faithfulness
  - Relevancy
  - Correctness

â€¢ ç³»ç»Ÿæ€§èƒ½
  - Response Time
  - Throughput
  - Error Rate

â€¢ æˆæœ¬åˆ†æ
  - Cost per Query
  - Monthly Cost
```

**3. å¯è§†åŒ–å›¾è¡¨ï¼ˆæœ€ç›´è§‚ï¼‰**
```
â€¢ æ—¶é—´è¶‹åŠ¿å›¾
â€¢ å¯¹æ¯”æŸ±çŠ¶å›¾
â€¢ åˆ†ç±»åˆ†æå›¾
â€¢ æˆæœ¬åˆ†è§£å›¾

ä¸€å¼ å›¾èƒœè¿‡åƒè¨€ä¸‡è¯­ï¼
```

**4. é—®é¢˜è¯Šæ–­ï¼ˆæœ€é‡è¦ï¼‰**
```
â€¢ å¤±è´¥æ¡ˆä¾‹åˆ†æ
â€¢ æ ¹å› å®šä½
â€¢ ä¼˜åŒ–å»ºè®®
â€¢ é¢„æœŸæ”¶ç›Š

ä¸åªæ˜¯æŠ¥å‘Šé—®é¢˜
æ›´è¦ç»™å‡ºè§£å†³æ–¹æ¡ˆï¼
```

**5. å¯¹æ¯”åˆ†æï¼ˆè¯æ˜ä»·å€¼ï¼‰**
```
ä¼˜åŒ–å‰ vs ä¼˜åŒ–å
æ–¹æ¡ˆA vs æ–¹æ¡ˆB
ç«å“å¯¹æ¯”

ç”¨æ•°æ®è¯´è¯ï¼
```

**çœŸå®æ¡ˆä¾‹ï¼š**

**é¡¹ç›®Aï¼šå®¢æœRAGç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š**

```
ã€æ‰§è¡Œæ‘˜è¦ã€‘
ç³»ç»Ÿæ•´ä½“è¡¨ç°ï¼šè‰¯å¥½ï¼ˆ78åˆ†/100åˆ†ï¼‰

æ ¸å¿ƒæŒ‡æ ‡ï¼š
âœ… ç­”æ¡ˆå‡†ç¡®ç‡ï¼š85%ï¼ˆç›®æ ‡80%ï¼‰
âš ï¸ å“åº”æ—¶é—´ï¼š4.2ç§’ï¼ˆç›®æ ‡<3ç§’ï¼‰
âœ… ç”¨æˆ·æ»¡æ„åº¦ï¼š82%ï¼ˆç›®æ ‡80%ï¼‰
âŒ æœˆåº¦æˆæœ¬ï¼š$8,500ï¼ˆé¢„ç®—$5,000ï¼‰

å…³é”®é—®é¢˜ï¼š
1. å“åº”æ—¶é—´åæ…¢ï¼Œå½±å“ç”¨æˆ·ä½“éªŒ
2. æˆæœ¬è¶…å‡ºé¢„ç®—70%

ä¼˜åŒ–å»ºè®®ï¼š
1. å®æ–½ç»“æœç¼“å­˜ï¼ˆé¢„æœŸå“åº”é™è‡³2.5ç§’ï¼‰
2. ä½¿ç”¨å°æ¨¡å‹å¤„ç†ç®€å•é—®é¢˜ï¼ˆé¢„æœŸæˆæœ¬é™è‡³$5,200ï¼‰

é¢„æœŸæ”¶ç›Šï¼š
â€¢ å“åº”æ—¶é—´æå‡40%
â€¢ æˆæœ¬é™ä½39%
â€¢ ç”¨æˆ·æ»¡æ„åº¦æå‡è‡³88%
```

**é¡¹ç›®Bï¼šæ–‡æ¡£é—®ç­”ç³»ç»Ÿå¯¹æ¯”è¯„ä¼°**

```
ã€æ–¹æ¡ˆå¯¹æ¯”ã€‘

æ–¹æ¡ˆAï¼ˆå½“å‰ï¼‰ï¼š
â€¢ Precision@5: 0.75
â€¢ å“åº”æ—¶é—´: 2.8ç§’
â€¢ æˆæœ¬: $0.005/æ¬¡

æ–¹æ¡ˆBï¼ˆä¼˜åŒ–ï¼‰ï¼š
â€¢ Precision@5: 0.85 â†‘ 13%
â€¢ å“åº”æ—¶é—´: 3.5ç§’ â†‘ 25%
â€¢ æˆæœ¬: $0.008/æ¬¡ â†‘ 60%

ç»“è®ºï¼š
æ–¹æ¡ˆBæ£€ç´¢æ›´å‡†ä½†æ›´æ…¢æ›´è´µ
å»ºè®®ï¼šæ··åˆæ–¹æ¡ˆ
- ç®€å•é—®é¢˜ç”¨æ–¹æ¡ˆA
- å¤æ‚é—®é¢˜ç”¨æ–¹æ¡ˆB
é¢„æœŸï¼šå‡†ç¡®ç‡æå‡8%ï¼Œæˆæœ¬åªå¢åŠ 20%
```

**çœ‹åˆ°äº†å—ï¼Ÿ**

æœ‰äº†è¯„ä¼°æŠ¥å‘Šï¼š
âœ… å†³ç­–æœ‰ä¾æ®
âœ… ä¼˜åŒ–æœ‰æ–¹å‘
âœ… æ±‡æŠ¥æœ‰åº•æ°”
âœ… ä»·å€¼èƒ½é‡åŒ–

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦å¸¦ä½ ï¼š**

**ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯„ä¼°æµç¨‹è®¾è®¡**
- è¯„ä¼°è®¡åˆ’
- æ•°æ®å‡†å¤‡
- æ‰§è¡Œæµç¨‹

**ç¬¬äºŒéƒ¨åˆ†ï¼šæŠ¥å‘Šç»“æ„è®¾è®¡**
- æ‰§è¡Œæ‘˜è¦
- è¯¦ç»†æŒ‡æ ‡
- å¯è§†åŒ–
- ä¼˜åŒ–å»ºè®®

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šè‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ**
- æ•°æ®æ”¶é›†
- æŠ¥å‘Šæ¨¡æ¿
- è‡ªåŠ¨ç”Ÿæˆ

**ç¬¬å››éƒ¨åˆ†ï¼šå®Œæ•´å®ç°**
- è¯„ä¼°ç³»ç»Ÿ
- æŠ¥å‘Šç”Ÿæˆå™¨
- å¯¼å‡ºPDF/HTML

**ç¬¬äº”éƒ¨åˆ†ï¼šæœ€ä½³å®è·µ**
- æŠ¥å‘Šæ¨¡æ¿
- æˆåŠŸæ¡ˆä¾‹
- é¿å‘æŒ‡å—

å­¦å®Œè¿™ä¸€è¯¾ï¼Œä½ å°†èƒ½ç”Ÿæˆä¸“ä¸šçš„RAGè¯„ä¼°æŠ¥å‘Šï¼

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ï¼"

---

### ğŸ’¡ æ ¸å¿ƒç†å¿µ

```
ã€å¥½æŠ¥å‘Šçš„æ ‡å‡†ã€‘

1. æ¸…æ™°ï¼ˆClearï¼‰
   ä¸€ç›®äº†ç„¶ï¼Œé‡ç‚¹çªå‡º

2. å‡†ç¡®ï¼ˆAccurateï¼‰
   æ•°æ®çœŸå®ï¼Œåˆ†æå®¢è§‚

3. å¯è¡Œï¼ˆActionableï¼‰
   ç»™å‡ºå»ºè®®ï¼Œå¯ä»¥æ‰§è¡Œ

4. æœ‰ä»·å€¼ï¼ˆValuableï¼‰
   æ”¯æŒå†³ç­–ï¼Œæ¨åŠ¨æ”¹è¿›
```

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯„ä¼°æµç¨‹è®¾è®¡

### ä¸€ã€è¯„ä¼°è®¡åˆ’

```python
from dataclasses import dataclass
from datetime import datetime
from typing import List, Dict
from enum import Enum

class EvaluationType(Enum):
    """è¯„ä¼°ç±»å‹"""
    BASELINE = "åŸºçº¿è¯„ä¼°"
    PERIODIC = "å®šæœŸè¯„ä¼°"
    AB_TEST = "A/Bå¯¹æ¯”"
    POST_OPTIMIZATION = "ä¼˜åŒ–åè¯„ä¼°"

@dataclass
class EvaluationPlan:
    """è¯„ä¼°è®¡åˆ’"""
    eval_id: str
    eval_type: EvaluationType
    description: str
    start_date: datetime
    test_set_size: int
    metrics_to_evaluate: List[str]
    comparison_baseline: str = None  # ç”¨äºå¯¹æ¯”çš„åŸºçº¿
    
class EvaluationPlanner:
    """è¯„ä¼°è§„åˆ’å™¨"""
    
    def create_plan(
        self,
        eval_type: EvaluationType,
        description: str,
        test_set_size: int = 100
    ) -> EvaluationPlan:
        """åˆ›å»ºè¯„ä¼°è®¡åˆ’"""
        
        # æ ¹æ®è¯„ä¼°ç±»å‹ç¡®å®šéœ€è¦è¯„ä¼°çš„æŒ‡æ ‡
        if eval_type == EvaluationType.BASELINE:
            metrics = [
                'precision@5', 'recall@5', 'ndcg@5',
                'faithfulness', 'relevancy',
                'response_time', 'cost_per_query'
            ]
        elif eval_type == EvaluationType.AB_TEST:
            metrics = [
                'precision@5', 'response_time',
                'user_satisfaction', 'cost_per_query'
            ]
        else:
            metrics = [
                'precision@5', 'faithfulness',
                'response_time'
            ]
        
        plan = EvaluationPlan(
            eval_id=f"eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            eval_type=eval_type,
            description=description,
            start_date=datetime.now(),
            test_set_size=test_set_size,
            metrics_to_evaluate=metrics
        )
        
        return plan
    
    def print_plan(self, plan: EvaluationPlan):
        """æ‰“å°è¯„ä¼°è®¡åˆ’"""
        print("="*60)
        print("è¯„ä¼°è®¡åˆ’")
        print("="*60)
        print(f"\nè¯„ä¼°ID: {plan.eval_id}")
        print(f"ç±»å‹: {plan.eval_type.value}")
        print(f"æè¿°: {plan.description}")
        print(f"å¼€å§‹æ—¶é—´: {plan.start_date.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æµ‹è¯•é›†å¤§å°: {plan.test_set_size}")
        print(f"\nè¯„ä¼°æŒ‡æ ‡:")
        for metric in plan.metrics_to_evaluate:
            print(f"  â€¢ {metric}")

# æ¼”ç¤º
def demo_evaluation_planner():
    """æ¼”ç¤ºè¯„ä¼°è§„åˆ’"""
    
    planner = EvaluationPlanner()
    
    # åˆ›å»ºåŸºçº¿è¯„ä¼°è®¡åˆ’
    plan = planner.create_plan(
        eval_type=EvaluationType.BASELINE,
        description="RAGç³»ç»ŸåŸºçº¿æ€§èƒ½è¯„ä¼°",
        test_set_size=200
    )
    
    planner.print_plan(plan)

demo_evaluation_planner()
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šæŠ¥å‘Šç”Ÿæˆå™¨

### ä¸€ã€æŠ¥å‘Šç»“æ„

```python
from typing import Any
import json

@dataclass
class ExecutiveSummary:
    """æ‰§è¡Œæ‘˜è¦"""
    overall_score: float  # ç»¼åˆå¾—åˆ†
    grade: str  # è¯„çº§
    key_findings: List[str]  # å…³é”®å‘ç°
    top_issues: List[Dict]  # ä¸»è¦é—®é¢˜
    recommendations: List[Dict]  # æ”¹è¿›å»ºè®®

@dataclass
class DetailedMetrics:
    """è¯¦ç»†æŒ‡æ ‡"""
    retrieval_metrics: Dict
    generation_metrics: Dict
    performance_metrics: Dict
    cost_metrics: Dict

@dataclass
class EvaluationReport:
    """è¯„ä¼°æŠ¥å‘Š"""
    report_id: str
    eval_plan: EvaluationPlan
    executive_summary: ExecutiveSummary
    detailed_metrics: DetailedMetrics
    failure_cases: List[Dict]
    recommendations: List[Dict]
    generated_at: datetime

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        pass
    
    def generate_executive_summary(
        self,
        eval_results: Dict
    ) -> ExecutiveSummary:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        overall_score = eval_results.get('overall_score', 0.75)
        
        # è¯„çº§
        if overall_score >= 0.9:
            grade = "A+ å“è¶Š"
        elif overall_score >= 0.8:
            grade = "A ä¼˜ç§€"
        elif overall_score >= 0.7:
            grade = "B è‰¯å¥½"
        elif overall_score >= 0.6:
            grade = "C åŠæ ¼"
        else:
            grade = "D éœ€æ”¹è¿›"
        
        # å…³é”®å‘ç°
        key_findings = []
        
        # æ£€ç´¢è´¨é‡
        precision = eval_results.get('precision@5', 0)
        if precision >= 0.8:
            key_findings.append(f"âœ… æ£€ç´¢å‡†ç¡®ç‡ä¼˜ç§€({precision:.1%})")
        elif precision < 0.6:
            key_findings.append(f"âš ï¸ æ£€ç´¢å‡†ç¡®ç‡åä½({precision:.1%})")
        
        # å“åº”æ—¶é—´
        response_time = eval_results.get('avg_response_time', 0)
        if response_time <= 2.0:
            key_findings.append(f"âœ… å“åº”é€Ÿåº¦ä¼˜ç§€({response_time:.1f}ç§’)")
        elif response_time > 5.0:
            key_findings.append(f"âš ï¸ å“åº”æ—¶é—´è¿‡é•¿({response_time:.1f}ç§’)")
        
        # æˆæœ¬
        cost = eval_results.get('cost_per_query', 0)
        if cost <= 0.005:
            key_findings.append(f"âœ… æˆæœ¬æ§åˆ¶è‰¯å¥½(${cost:.4f}/æ¬¡)")
        elif cost > 0.01:
            key_findings.append(f"âš ï¸ å•æ¬¡æˆæœ¬åé«˜(${cost:.4f}/æ¬¡)")
        
        # ä¸»è¦é—®é¢˜
        top_issues = []
        if precision < 0.7:
            top_issues.append({
                'issue': 'æ£€ç´¢å‡†ç¡®ç‡ä¸è¶³',
                'severity': 'high',
                'impact': 'ç›´æ¥å½±å“ç­”æ¡ˆè´¨é‡'
            })
        
        if response_time > 5.0:
            top_issues.append({
                'issue': 'å“åº”æ—¶é—´è¿‡é•¿',
                'severity': 'high',
                'impact': 'ç”¨æˆ·ä½“éªŒå·®ï¼Œæ”¾å¼ƒç‡é«˜'
            })
        
        # æ”¹è¿›å»ºè®®
        recommendations = []
        if precision < 0.7:
            recommendations.append({
                'priority': 'high',
                'action': 'å®æ–½Reranké‡æ’åº',
                'expected_improvement': 'æ£€ç´¢å‡†ç¡®ç‡æå‡15-20%',
                'effort': 'medium'
            })
        
        if response_time > 5.0:
            recommendations.append({
                'priority': 'high',
                'action': 'æ·»åŠ ç»“æœç¼“å­˜',
                'expected_improvement': 'å“åº”æ—¶é—´é™ä½60%',
                'effort': 'low'
            })
        
        return ExecutiveSummary(
            overall_score=overall_score,
            grade=grade,
            key_findings=key_findings,
            top_issues=top_issues,
            recommendations=recommendations
        )
    
    def generate_report(
        self,
        eval_plan: EvaluationPlan,
        eval_results: Dict
    ) -> EvaluationReport:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        
        # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
        executive_summary = self.generate_executive_summary(eval_results)
        
        # ç»„ç»‡è¯¦ç»†æŒ‡æ ‡
        detailed_metrics = DetailedMetrics(
            retrieval_metrics={
                'precision@5': eval_results.get('precision@5', 0),
                'recall@5': eval_results.get('recall@5', 0),
                'ndcg@5': eval_results.get('ndcg@5', 0),
                'mrr': eval_results.get('mrr', 0)
            },
            generation_metrics={
                'faithfulness': eval_results.get('faithfulness', 0),
                'relevancy': eval_results.get('relevancy', 0),
                'correctness': eval_results.get('correctness', 0)
            },
            performance_metrics={
                'avg_response_time': eval_results.get('avg_response_time', 0),
                'p95_response_time': eval_results.get('p95_response_time', 0),
                'error_rate': eval_results.get('error_rate', 0)
            },
            cost_metrics={
                'cost_per_query': eval_results.get('cost_per_query', 0),
                'monthly_cost': eval_results.get('monthly_cost', 0)
            }
        )
        
        report = EvaluationReport(
            report_id=f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            eval_plan=eval_plan,
            executive_summary=executive_summary,
            detailed_metrics=detailed_metrics,
            failure_cases=eval_results.get('failure_cases', []),
            recommendations=executive_summary.recommendations,
            generated_at=datetime.now()
        )
        
        return report
    
    def print_report(self, report: EvaluationReport):
        """æ‰“å°æ–‡æœ¬æ ¼å¼æŠ¥å‘Š"""
        
        print("\n" + "="*70)
        print("RAGç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š".center(70))
        print("="*70)
        
        print(f"\næŠ¥å‘ŠID: {report.report_id}")
        print(f"ç”Ÿæˆæ—¶é—´: {report.generated_at.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"è¯„ä¼°ç±»å‹: {report.eval_plan.eval_type.value}")
        
        # ===== æ‰§è¡Œæ‘˜è¦ =====
        print("\n" + "â”€"*70)
        print("ğŸ“Š æ‰§è¡Œæ‘˜è¦")
        print("â”€"*70)
        
        summary = report.executive_summary
        print(f"\nç»¼åˆå¾—åˆ†: {summary.overall_score:.2f} / 1.00")
        print(f"è¯„çº§: {summary.grade}")
        
        print(f"\nå…³é”®å‘ç°:")
        for finding in summary.key_findings:
            print(f"  {finding}")
        
        if summary.top_issues:
            print(f"\nä¸»è¦é—®é¢˜:")
            for issue in summary.top_issues:
                severity_icon = "ğŸ”´" if issue['severity'] == 'high' else "ğŸŸ¡"
                print(f"  {severity_icon} {issue['issue']}")
                print(f"     å½±å“: {issue['impact']}")
        
        # ===== è¯¦ç»†æŒ‡æ ‡ =====
        print("\n" + "â”€"*70)
        print("ğŸ“ˆ è¯¦ç»†æŒ‡æ ‡")
        print("â”€"*70)
        
        metrics = report.detailed_metrics
        
        print(f"\nã€æ£€ç´¢è´¨é‡ã€‘")
        for metric, value in metrics.retrieval_metrics.items():
            status = "âœ…" if value >= 0.7 else "âš ï¸"
            print(f"  {status} {metric}: {value:.3f}")
        
        print(f"\nã€ç”Ÿæˆè´¨é‡ã€‘")
        for metric, value in metrics.generation_metrics.items():
            if value > 0:
                status = "âœ…" if value >= 0.7 else "âš ï¸"
                print(f"  {status} {metric}: {value:.3f}")
        
        print(f"\nã€ç³»ç»Ÿæ€§èƒ½ã€‘")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {metrics.performance_metrics['avg_response_time']:.2f}ç§’")
        print(f"  P95å“åº”æ—¶é—´: {metrics.performance_metrics['p95_response_time']:.2f}ç§’")
        print(f"  é”™è¯¯ç‡: {metrics.performance_metrics['error_rate']:.2%}")
        
        print(f"\nã€æˆæœ¬åˆ†æã€‘")
        print(f"  å•æ¬¡æŸ¥è¯¢æˆæœ¬: ${metrics.cost_metrics['cost_per_query']:.6f}")
        if metrics.cost_metrics['monthly_cost'] > 0:
            print(f"  æœˆåº¦æ€»æˆæœ¬: ${metrics.cost_metrics['monthly_cost']:.2f}")
        
        # ===== æ”¹è¿›å»ºè®® =====
        if report.recommendations:
            print("\n" + "â”€"*70)
            print("ğŸ’¡ æ”¹è¿›å»ºè®®")
            print("â”€"*70)
            
            for i, rec in enumerate(report.recommendations, 1):
                priority_icon = "ğŸ”´" if rec['priority'] == 'high' else "ğŸŸ¡"
                print(f"\n{i}. {priority_icon} {rec['action']}")
                print(f"   é¢„æœŸæ•ˆæœ: {rec['expected_improvement']}")
                print(f"   å®æ–½éš¾åº¦: {rec['effort']}")
        
        print("\n" + "="*70)
        print("æŠ¥å‘Šç»“æŸ".center(70))
        print("="*70 + "\n")
    
    def export_to_html(self, report: EvaluationReport, filepath: str):
        """å¯¼å‡ºä¸ºHTMLæ ¼å¼"""
        
        html_template = """
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>RAGç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .report-container {
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 3px solid #4CAF50;
            padding-bottom: 10px;
        }
        h2 {
            color: #555;
            margin-top: 30px;
            border-left: 4px solid #4CAF50;
            padding-left: 10px;
        }
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 20px;
            margin: 20px 0;
        }
        .metric-card {
            background: #f9f9f9;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #2196F3;
        }
        .metric-label {
            font-size: 14px;
            color: #666;
        }
        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #333;
            margin-top: 5px;
        }
        .grade {
            display: inline-block;
            padding: 10px 20px;
            background: #4CAF50;
            color: white;
            border-radius: 5px;
            font-size: 20px;
            font-weight: bold;
        }
        .issue {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 10px;
            margin: 10px 0;
        }
        .recommendation {
            background: #d4edda;
            border-left: 4px solid #28a745;
            padding: 10px;
            margin: 10px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background: #4CAF50;
            color: white;
        }
        .status-good { color: #4CAF50; }
        .status-warning { color: #ff9800; }
        .status-bad { color: #f44336; }
    </style>
</head>
<body>
    <div class="report-container">
        <h1>RAGç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š</h1>
        
        <p><strong>æŠ¥å‘ŠID:</strong> {report_id}</p>
        <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {generated_at}</p>
        <p><strong>è¯„ä¼°ç±»å‹:</strong> {eval_type}</p>
        
        <h2>ğŸ“Š æ‰§è¡Œæ‘˜è¦</h2>
        
        <div style="margin: 20px 0;">
            <span class="metric-label">ç»¼åˆå¾—åˆ†</span>
            <div class="metric-value">{overall_score:.2f}</div>
            <div class="grade">{grade}</div>
        </div>
        
        <h3>å…³é”®å‘ç°</h3>
        <ul>
        {key_findings}
        </ul>
        
        <h3>ä¸»è¦é—®é¢˜</h3>
        {top_issues}
        
        <h2>ğŸ“ˆ è¯¦ç»†æŒ‡æ ‡</h2>
        
        <h3>æ£€ç´¢è´¨é‡</h3>
        <table>
            <tr>
                <th>æŒ‡æ ‡</th>
                <th>å€¼</th>
                <th>çŠ¶æ€</th>
            </tr>
            {retrieval_metrics}
        </table>
        
        <h3>ç”Ÿæˆè´¨é‡</h3>
        <table>
            <tr>
                <th>æŒ‡æ ‡</th>
                <th>å€¼</th>
                <th>çŠ¶æ€</th>
            </tr>
            {generation_metrics}
        </table>
        
        <h3>ç³»ç»Ÿæ€§èƒ½</h3>
        <div class="metric-grid">
            {performance_metrics}
        </div>
        
        <h3>æˆæœ¬åˆ†æ</h3>
        <div class="metric-grid">
            {cost_metrics}
        </div>
        
        <h2>ğŸ’¡ æ”¹è¿›å»ºè®®</h2>
        {recommendations}
        
    </div>
</body>
</html>
        """
        
        # å¡«å……æ•°æ®
        summary = report.executive_summary
        metrics = report.detailed_metrics
        
        # å…³é”®å‘ç°
        key_findings_html = "\n".join([
            f"<li>{finding}</li>"
            for finding in summary.key_findings
        ])
        
        # ä¸»è¦é—®é¢˜
        top_issues_html = "\n".join([
            f'<div class="issue"><strong>{issue["issue"]}</strong><br>å½±å“: {issue["impact"]}</div>'
            for issue in summary.top_issues
        ])
        
        # æ£€ç´¢æŒ‡æ ‡
        retrieval_metrics_html = ""
        for metric, value in metrics.retrieval_metrics.items():
            status_class = "status-good" if value >= 0.7 else "status-warning"
            status = "âœ… ä¼˜ç§€" if value >= 0.7 else "âš ï¸ éœ€æ”¹è¿›"
            retrieval_metrics_html += f"""
            <tr>
                <td>{metric}</td>
                <td>{value:.3f}</td>
                <td class="{status_class}">{status}</td>
            </tr>
            """
        
        # ç”ŸæˆæŒ‡æ ‡
        generation_metrics_html = ""
        for metric, value in metrics.generation_metrics.items():
            if value > 0:
                status_class = "status-good" if value >= 0.7 else "status-warning"
                status = "âœ… ä¼˜ç§€" if value >= 0.7 else "âš ï¸ éœ€æ”¹è¿›"
                generation_metrics_html += f"""
                <tr>
                    <td>{metric}</td>
                    <td>{value:.3f}</td>
                    <td class="{status_class}">{status}</td>
                </tr>
                """
        
        # æ€§èƒ½æŒ‡æ ‡
        performance_metrics_html = f"""
        <div class="metric-card">
            <div class="metric-label">å¹³å‡å“åº”æ—¶é—´</div>
            <div class="metric-value">{metrics.performance_metrics['avg_response_time']:.2f}ç§’</div>
        </div>
        <div class="metric-card">
            <div class="metric-label">P95å“åº”æ—¶é—´</div>
            <div class="metric-value">{metrics.performance_metrics['p95_response_time']:.2f}ç§’</div>
        </div>
        """
        
        # æˆæœ¬æŒ‡æ ‡
        cost_metrics_html = f"""
        <div class="metric-card">
            <div class="metric-label">å•æ¬¡æŸ¥è¯¢æˆæœ¬</div>
            <div class="metric-value">${metrics.cost_metrics['cost_per_query']:.6f}</div>
        </div>
        <div class="metric-card">
            <div class="metric-label">æœˆåº¦æ€»æˆæœ¬</div>
            <div class="metric-value">${metrics.cost_metrics['monthly_cost']:.2f}</div>
        </div>
        """
        
        # æ”¹è¿›å»ºè®®
        recommendations_html = "\n".join([
            f'''<div class="recommendation">
                <strong>{rec["action"]}</strong><br>
                é¢„æœŸæ•ˆæœ: {rec["expected_improvement"]}<br>
                å®æ–½éš¾åº¦: {rec["effort"]}
            </div>'''
            for rec in report.recommendations
        ])
        
        # å¡«å……æ¨¡æ¿
        html_content = html_template.format(
            report_id=report.report_id,
            generated_at=report.generated_at.strftime('%Y-%m-%d %H:%M:%S'),
            eval_type=report.eval_plan.eval_type.value,
            overall_score=summary.overall_score,
            grade=summary.grade,
            key_findings=key_findings_html,
            top_issues=top_issues_html,
            retrieval_metrics=retrieval_metrics_html,
            generation_metrics=generation_metrics_html,
            performance_metrics=performance_metrics_html,
            cost_metrics=cost_metrics_html,
            recommendations=recommendations_html
        )
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… HTMLæŠ¥å‘Šå·²ä¿å­˜è‡³: {filepath}")

# å®Œæ•´æ¼”ç¤º
def demo_report_generator():
    """æ¼”ç¤ºæŠ¥å‘Šç”Ÿæˆ"""
    
    # 1. åˆ›å»ºè¯„ä¼°è®¡åˆ’
    planner = EvaluationPlanner()
    plan = planner.create_plan(
        eval_type=EvaluationType.BASELINE,
        description="RAGç³»ç»ŸåŸºçº¿æ€§èƒ½è¯„ä¼°",
        test_set_size=200
    )
    
    # 2. æ¨¡æ‹Ÿè¯„ä¼°ç»“æœ
    eval_results = {
        'overall_score': 0.78,
        'precision@5': 0.75,
        'recall@5': 0.68,
        'ndcg@5': 0.72,
        'mrr': 0.80,
        'faithfulness': 0.85,
        'relevancy': 0.82,
        'correctness': 0.78,
        'avg_response_time': 4.2,
        'p95_response_time': 6.5,
        'error_rate': 0.02,
        'cost_per_query': 0.008,
        'monthly_cost': 8500
    }
    
    # 3. ç”ŸæˆæŠ¥å‘Š
    generator = ReportGenerator()
    report = generator.generate_report(plan, eval_results)
    
    # 4. æ‰“å°æŠ¥å‘Š
    generator.print_report(report)
    
    # 5. å¯¼å‡ºHTML
    # generator.export_to_html(report, "rag_evaluation_report.html")

demo_report_generator()
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šPDFå¯¼å‡º
å®ç°PDFæ ¼å¼æŠ¥å‘Šå¯¼å‡º

### ç»ƒä¹ 2ï¼šæŠ¥å‘Šå¯¹æ¯”
ç”Ÿæˆå¤šç‰ˆæœ¬å¯¹æ¯”æŠ¥å‘Š

### ç»ƒä¹ 3ï¼šè‡ªåŠ¨åŒ–æµç¨‹
å®ç°å®šæœŸè‡ªåŠ¨è¯„ä¼°å’ŒæŠ¥å‘Šç”Ÿæˆ

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### ç¬¬12ç« å®Œæ•´å›é¡¾

é€šè¿‡5èŠ‚è¯¾ï¼Œæˆ‘ä»¬æŒæ¡äº†RAGè¯„ä¼°çš„å®Œæ•´ä½“ç³»ï¼š

1. **ç¬¬66è¯¾ï¼šè¯„ä¼°æŒ‡æ ‡ä½“ç³»**
   - æ£€ç´¢æŒ‡æ ‡
   - ç”ŸæˆæŒ‡æ ‡
   - Ground Truthæ„å»º

2. **ç¬¬67è¯¾ï¼šæ£€ç´¢è´¨é‡è¯„ä¼°**
   - ç¦»çº¿è¯„ä¼°
   - åœ¨çº¿è¯„ä¼°
   - å¤±è´¥æ¡ˆä¾‹åˆ†æ

3. **ç¬¬68è¯¾ï¼šç”Ÿæˆè´¨é‡è¯„ä¼°**
   - Faithfulnessè¯„ä¼°
   - Relevancyè¯„ä¼°
   - LLMä½œä¸ºè¯„ä¼°å™¨

4. **ç¬¬69è¯¾ï¼šç«¯åˆ°ç«¯è¯„ä¼°**
   - äº”å¤§è¯„ä¼°ç»´åº¦
   - ç”¨æˆ·ä½“éªŒè¯„ä¼°
   - æˆæœ¬æ•ˆç›Šåˆ†æ

5. **ç¬¬70è¯¾ï¼šè¯„ä¼°æŠ¥å‘Š**
   - æŠ¥å‘Šç»“æ„è®¾è®¡
   - è‡ªåŠ¨åŒ–ç”Ÿæˆ
   - å¯è§†åŒ–å±•ç¤º

### æœ€ä½³å®è·µ

âœ… **å®šæœŸè¯„ä¼°**
   - æ¯æœˆåŸºçº¿è¯„ä¼°
   - ä¼˜åŒ–å‰åå¯¹æ¯”
   - æŒç»­ç›‘æ§

âœ… **æ•°æ®é©±åŠ¨**
   - ç”¨æ•°æ®è¯´è¯
   - é‡åŒ–ä¼˜åŒ–æ•ˆæœ
   - æ”¯æŒå†³ç­–

âœ… **å…¨é¢è¯„ä¼°**
   - ä¸åªçœ‹æŠ€æœ¯æŒ‡æ ‡
   - å…³æ³¨ç”¨æˆ·ä½“éªŒ
   - é‡è§†æˆæœ¬æ•ˆç›Š

âœ… **å¯è§†åŒ–å‘ˆç°**
   - å›¾è¡¨ç›´è§‚
   - é‡ç‚¹çªå‡º
   - æ˜“äºç†è§£

---

## ğŸ‰ ç¬¬ä¸‰æ¨¡å—å®Œæˆï¼

### æ¨¡å—å›é¡¾

**æ¨¡å—3ï¼šå‘é‡æ•°æ®åº“ä¸RAGç³»ç»Ÿï¼ˆ30è¯¾ï¼Œå·²å®Œæˆ70è¯¾ï¼‰**

```
ç¬¬8ç« ï¼šå‘é‡æ•°æ®åº“åŸºç¡€ï¼ˆ6è¯¾ï¼‰âœ…
â”œâ”€ EmbeddingæŠ€æœ¯
â”œâ”€ å‘é‡æ•°æ®åº“åŸç†
â”œâ”€ Chromaå®æˆ˜
â””â”€ å¤šç§å‘é‡åº“å¯¹æ¯”

ç¬¬9ç« ï¼šæ–‡æ¡£å¤„ç†å·¥ç¨‹åŒ–ï¼ˆ7è¯¾ï¼‰âœ…
â”œâ”€ æ–‡æ¡£åŠ è½½
â”œâ”€ æ–‡æ¡£åˆ†å—ç­–ç•¥
â”œâ”€ å…ƒæ•°æ®è®¾è®¡
â”œâ”€ OCRå¤„ç†
â””â”€ çŸ¥è¯†åº“æ„å»º

ç¬¬10ç« ï¼šRAGç³»ç»Ÿæ·±åº¦å¼€å‘ï¼ˆ7è¯¾ï¼‰âœ…
â”œâ”€ RAGæ¶æ„è®¾è®¡
â”œâ”€ åŸºç¡€RAGå®ç°
â”œâ”€ æ··åˆæ£€ç´¢
â”œâ”€ Queryä¼˜åŒ–
â”œâ”€ RerankæŠ€æœ¯
â””â”€ ç”Ÿäº§çº§RAG

ç¬¬11ç« ï¼šé«˜çº§RAGæŠ€æœ¯ï¼ˆ5è¯¾ï¼‰âœ…
â”œâ”€ HyDE
â”œâ”€ è‡ªæŸ¥è¯¢
â”œâ”€ ä¸Šä¸‹æ–‡å‹ç¼©
â”œâ”€ Parent Document
â””â”€ å¤šç­–ç•¥RAG

ç¬¬12ç« ï¼šRAGè¯„ä¼°ä¸ä¼˜åŒ–ï¼ˆ5è¯¾ï¼‰âœ…
â”œâ”€ è¯„ä¼°æŒ‡æ ‡ä½“ç³»
â”œâ”€ æ£€ç´¢è´¨é‡è¯„ä¼°
â”œâ”€ ç”Ÿæˆè´¨é‡è¯„ä¼°
â”œâ”€ ç«¯åˆ°ç«¯è¯„ä¼°
â””â”€ è¯„ä¼°æŠ¥å‘Š
```

**ä½ å·²æŒæ¡ï¼š**
- âœ… å‘é‡æ•°æ®åº“æŠ€æœ¯
- âœ… æ–‡æ¡£å¤„ç†å·¥ç¨‹åŒ–
- âœ… RAGç³»ç»Ÿè®¾è®¡ä¸å®ç°
- âœ… é«˜çº§RAGæŠ€æœ¯
- âœ… å®Œæ•´è¯„ä¼°ä½“ç³»

---

## ğŸš€ ä¸‹ä¸€æ¨¡å—é¢„å‘Š

**ç¬¬å››æ¨¡å—ï¼šAgentæ™ºèƒ½ä½“å¼€å‘ï¼ˆ20è¯¾ï¼‰**

- AgentåŸºç¡€åŸç†
- ReActèŒƒå¼
- å·¥å…·è°ƒç”¨
- å¤šAgentåä½œ
- å¤æ‚ä»»åŠ¡è§„åˆ’
- ç”Ÿäº§çº§Agent

**ä»RAGåˆ°Agentï¼Œè¿ˆå‘æ›´é«˜é˜¶ï¼** ğŸ¯

---

**ğŸ’ª æ­å–œï¼ç¬¬ä¸‰æ¨¡å—åœ†æ»¡å®Œæˆï¼**

**ä½ å·²ç»æŒæ¡äº†RAGç³»ç»Ÿçš„å…¨éƒ¨æ ¸å¿ƒæŠ€èƒ½ï¼** ğŸ‰

**å‡†å¤‡å¥½å­¦ä¹ Agentäº†å—ï¼Ÿä¸‹ä¸€æ¨¡å—è§ï¼** ğŸš€
