![å‘é‡æ•°æ®åº“æ¶æ„](./images/vector_db.svg)
*å›¾ï¼šå‘é‡æ•°æ®åº“æ¶æ„*

# ç¬¬43è¯¾ï¼šæœ¬åœ°Embeddingæ¨¡å‹éƒ¨ç½² - å®Œå…¨ç¦»çº¿çš„å‘é‡ç”Ÿæˆ

> ğŸ“š **è¯¾ç¨‹ä¿¡æ¯**
> - æ‰€å±æ¨¡å—ï¼šç¬¬ä¸‰æ¨¡å— - å‘é‡æ•°æ®åº“ä¸RAGç³»ç»Ÿ  
> - ç« èŠ‚ï¼šç¬¬8ç«  - å‘é‡æ•°æ®åº“åŸºç¡€ï¼ˆç¬¬3/6è¯¾ï¼‰
> - å­¦ä¹ ç›®æ ‡ï¼šæŒæ¡æœ¬åœ°Embeddingæ¨¡å‹éƒ¨ç½²çš„å¤šç§æ–¹æ¡ˆ
> - é¢„è®¡æ—¶é—´ï¼š100-110åˆ†é’Ÿ
> - å‰ç½®çŸ¥è¯†ï¼šç¬¬41-42è¯¾

---

## ğŸ“¢ è¯¾ç¨‹å¯¼å…¥

### å‰è¨€

å‰ä¸¤è¯¾æˆ‘ä»¬å­¦äº†å‘é‡æ•°æ®åº“å’ŒEmbeddingæŠ€æœ¯ï¼Œä½†æœ‰ä¸ªé—®é¢˜ï¼š**æ¯æ¬¡ç”Ÿæˆå‘é‡éƒ½è¦è°ƒç”¨OpenAI APIï¼Œæˆæœ¬é«˜ã€é€Ÿåº¦æ…¢ã€è¿˜è¦è”ç½‘ï¼**

ä¼ä¸šåœºæ™¯æ›´éº»çƒ¦ï¼š
- æ•æ„Ÿæ•°æ®ä¸èƒ½å‘åˆ°äº‘ç«¯ âŒ
- APIè°ƒç”¨è´¹ç”¨å¤ªé«˜ï¼ˆç™¾ä¸‡æ–‡æ¡£ï¼Ÿç ´äº§ï¼ï¼‰âŒ
- ç½‘ç»œå»¶è¿Ÿå½±å“ç”¨æˆ·ä½“éªŒ âŒ

**æœ¬åœ°éƒ¨ç½²Embeddingæ¨¡å‹**å°±èƒ½å®Œç¾è§£å†³ï¼š
- âœ… å®Œå…¨å…è´¹ï¼Œæ— é™æ¬¡è°ƒç”¨
- âœ… æ•°æ®ä¸å‡ºæœ¬åœ°ï¼Œå®‰å…¨æœ‰ä¿éšœ
- âœ… æ¯«ç§’çº§å“åº”ï¼Œæé€Ÿä½“éªŒ

ä»Šå¤©è¿™è¯¾ï¼Œæˆ‘è¦æ•™ä½ 3ç§æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆï¼Œè®©ä½ çš„EmbeddingæœåŠ¡å®Œå…¨è‡ªä¸»å¯æ§ï¼

---

### æ ¸å¿ƒä»·å€¼ç‚¹

**ç¬¬ä¸€ï¼Œæœ¬åœ°éƒ¨ç½²æ˜¯ä¼ä¸šçº§åº”ç”¨çš„å¿…é€‰é¡¹ã€‚**

çœ‹çœ‹æˆæœ¬å¯¹æ¯”ï¼š
```
OpenAI Embeddingsï¼ˆtext-embedding-3-smallï¼‰ï¼š
- ä»·æ ¼ï¼š$0.02 / 1M tokens
- 100ä¸‡ç¯‡æ–‡æ¡£ï¼ˆå¹³å‡500 tokensï¼‰ï¼š$10,000ï¼
- æ¯æœˆæŒç»­å¢é•¿...

æœ¬åœ°æ¨¡å‹ï¼š
- åˆå§‹ï¼šå…è´¹ä¸‹è½½ï¼ˆ0å…ƒï¼‰
- è¿è¡Œï¼šåªéœ€GPU/CPUç”µè´¹
- 100ä¸‡æ–‡æ¡£ï¼šå‡ ä¹å…è´¹ï¼
```

**å¯¹äºå¤§è§„æ¨¡åº”ç”¨ï¼Œæœ¬åœ°éƒ¨ç½²èƒ½çœå‡ åä¸‡ï¼**

**ç¬¬äºŒï¼Œæœ¬åœ°éƒ¨ç½²æŠ€æœ¯å·²ç»éå¸¸æˆç†Ÿã€‚**

ä»¥å‰è§‰å¾—éƒ¨ç½²å›°éš¾ï¼Ÿç°åœ¨æœ‰å¤šç§ç®€å•æ–¹æ¡ˆï¼š
- **Sentence-Transformers**ï¼š3è¡Œä»£ç æå®š
- **LM Studio**ï¼šå›¾å½¢ç•Œé¢ï¼Œç‚¹ç‚¹é¼ æ ‡
- **Ollama**ï¼šä¸€è¡Œå‘½ä»¤éƒ¨ç½²
- **FastAPIåŒ…è£…**ï¼š10åˆ†é’Ÿä¸Šçº¿APIæœåŠ¡

**é›¶åŸºç¡€ä¹Ÿèƒ½å¿«é€Ÿä¸Šæ‰‹ï¼**

**ç¬¬ä¸‰ï¼Œæœ¬åœ°æ¨¡å‹è´¨é‡ä¸è¾“äº‘ç«¯ã€‚**

è¯¯åŒºï¼šæœ¬åœ°æ¨¡å‹æ•ˆæœå·®ï¼Ÿ
çœŸç›¸ï¼š**å¼€æºæ¨¡å‹è´¨é‡å·²ç»éå¸¸æ¥è¿‘å•†ä¸šæ¨¡å‹ï¼**

å¯¹æ¯”ï¼ˆä¸­æ–‡æ£€ç´¢ä»»åŠ¡ï¼‰ï¼š
- OpenAI text-embedding-3-smallï¼š92%å‡†ç¡®ç‡
- BGE-base-zh-v1.5ï¼ˆæœ¬åœ°ï¼‰ï¼š90%å‡†ç¡®ç‡
- å·®è·å¾ˆå°ï¼Œä½†å®Œå…¨å…è´¹ï¼

**è€Œä¸”ä½ å¯ä»¥é’ˆå¯¹è‡ªå·±çš„æ•°æ®fine-tuneï¼Œæ•ˆæœæ›´å¥½ï¼**

**ç¬¬å››ï¼Œè¿™æ˜¯æ„å»ºç§æœ‰åŒ–RAGç³»ç»Ÿçš„åŸºç¡€ã€‚**

ä¼ä¸šç§æœ‰åŒ–éƒ¨ç½²æµç¨‹ï¼š
1. **æœ¬åœ°EmbeddingæœåŠ¡**ï¼ˆæœ¬è¯¾ï¼‰
2. æœ¬åœ°å‘é‡æ•°æ®åº“
3. æœ¬åœ°å¤§æ¨¡å‹
4. å®Œæ•´çš„ç§æœ‰åŒ–RAGç³»ç»Ÿ

**ç¬¬ä¸€æ­¥åšå¥½ï¼Œåé¢å°±é¡ºäº†ï¼**

---

### è¡ŒåŠ¨å·å¬

ä»Šå¤©è¿™ä¸€è¯¾ä¼šæ•™ä½ ï¼š
- Sentence-Transformersæœ¬åœ°éƒ¨ç½²
- LM Studio Embeddingsä½¿ç”¨
- Ollama Embeddingsé…ç½®
- æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- éƒ¨ç½²APIæœåŠ¡

**å­¦å®Œè¿™è¯¾ï¼Œä½ å°±èƒ½æ­å»ºè‡ªå·±çš„EmbeddingæœåŠ¡ï¼**

---

## ğŸ“– çŸ¥è¯†è®²è§£

![æœ¬åœ°Embeddingæ¨¡å‹](./images/embedding.svg)
*å›¾ï¼šæœ¬åœ°Embeddingæ¨¡å‹*


### 1. éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”

#### 1.1 ä¸»æµæ–¹æ¡ˆ

```
æ–¹æ¡ˆ1ï¼šSentence-Transformersï¼ˆæ¨èï¼‰
  ä¼˜ç‚¹ï¼šæœ€ç®€å•ã€æœ€æˆç†Ÿã€PythonåŸç”Ÿ
  ç¼ºç‚¹ï¼šéœ€è¦Pythonç¯å¢ƒ
  é€‚åˆï¼šå¼€å‘ç¯å¢ƒã€Pythoné¡¹ç›®
  
æ–¹æ¡ˆ2ï¼šLM Studio
  ä¼˜ç‚¹ï¼šå›¾å½¢ç•Œé¢ã€æ˜“ç”¨
  ç¼ºç‚¹ï¼šåŠŸèƒ½ç›¸å¯¹åŸºç¡€
  é€‚åˆï¼šåˆå­¦è€…ã€å¿«é€ŸåŸå‹
  
æ–¹æ¡ˆ3ï¼šOllama
  ä¼˜ç‚¹ï¼šå‘½ä»¤è¡Œç®€å•ã€æ€§èƒ½å¥½
  ç¼ºç‚¹ï¼šæ¨¡å‹é€‰æ‹©å°‘ï¼ˆEmbeddingï¼‰
  é€‚åˆï¼šç³»ç»Ÿé›†æˆã€è½»é‡éƒ¨ç½²
  
æ–¹æ¡ˆ4ï¼šè‡ªå»ºAPIæœåŠ¡
  ä¼˜ç‚¹ï¼šçµæ´»ã€å¯æ§ã€å¯æ‰©å±•
  ç¼ºç‚¹ï¼šéœ€è¦ä¸€å®šå¼€å‘èƒ½åŠ›
  é€‚åˆï¼šç”Ÿäº§ç¯å¢ƒã€å›¢é˜Ÿä½¿ç”¨
```

---

### 2. Sentence-Transformerséƒ¨ç½²

#### 2.1 åŸºç¡€å®‰è£…

```bash
# 1. å®‰è£…
pip install sentence-transformers

# 2. å¯é€‰ï¼šå®‰è£…åŠ é€Ÿåº“
pip install torch  # GPUåŠ é€Ÿï¼ˆå¦‚æœæœ‰NVIDIA GPUï¼‰

# 3. éªŒè¯å®‰è£…
python -c "from sentence_transformers import SentenceTransformer; print('å®‰è£…æˆåŠŸ')"
```

#### 2.2 åŸºç¡€ä½¿ç”¨

```python
from sentence_transformers import SentenceTransformer

# ç¬¬ä¸€æ¬¡ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦1GBï¼‰
model = SentenceTransformer('all-MiniLM-L6-v2')

# ç”Ÿæˆå‘é‡
texts = [
    "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
    "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯"
]

embeddings = model.encode(texts)

print(f"å‘é‡å½¢çŠ¶ï¼š{embeddings.shape}")  # (2, 384)
print(f"ç¬¬ä¸€ä¸ªå‘é‡ï¼š{embeddings[0][:5]}...")
```

#### 2.3 æ¨¡å‹ä¸‹è½½å’Œç®¡ç†

```python
# æ–¹å¼1ï¼šè‡ªåŠ¨ä¸‹è½½ï¼ˆé»˜è®¤ï¼‰
model = SentenceTransformer('all-MiniLM-L6-v2')

# æ–¹å¼2ï¼šæŒ‡å®šç¼“å­˜ç›®å½•
model = SentenceTransformer(
    'all-MiniLM-L6-v2',
    cache_folder='/path/to/models'
)

# æ–¹å¼3ï¼šä»æœ¬åœ°åŠ è½½
# 1. å…ˆä¸‹è½½åˆ°æœ¬åœ°
# 2. ç„¶ååŠ è½½
model = SentenceTransformer('/path/to/local/model')

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
print(f"æœ€å¤§åºåˆ—é•¿åº¦ï¼š{model.max_seq_length}")
print(f"å‘é‡ç»´åº¦ï¼š{model.get_sentence_embedding_dimension()}")
```

#### 2.4 æ‰¹é‡å¤„ç†ä¼˜åŒ–

```python
from sentence_transformers import SentenceTransformer
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')

# å¤§é‡æ–‡æœ¬
texts = ["æ–‡æœ¬" + str(i) for i in range(10000)]

# âœ… æ‰¹é‡å¤„ç†ï¼ˆå¿«ï¼‰
embeddings = model.encode(
    texts,
    batch_size=32,  # æ‰¹æ¬¡å¤§å°
    show_progress_bar=True,  # æ˜¾ç¤ºè¿›åº¦
    convert_to_numpy=True  # è½¬numpyæ•°ç»„
)

# âŒ é€æ¡å¤„ç†ï¼ˆæ…¢ï¼‰
# embeddings = [model.encode([t])[0] for t in texts]

print(f"ç”Ÿæˆäº† {len(embeddings)} ä¸ªå‘é‡")
```

---

### 3. LM Studio Embeddings

#### 3.1 é…ç½®æ­¥éª¤

```
1. æ‰“å¼€LM Studio

2. ä¸‹è½½Embeddingæ¨¡å‹ï¼š
   - æœç´¢ï¼š"nomic-embed-text"
   - ä¸‹è½½ï¼šnomic-ai/nomic-embed-text-v1.5-GGUF
   
3. åŠ è½½æ¨¡å‹ï¼ˆLocal Serveré€‰é¡¹å¡ï¼‰

4. ä½¿ç”¨OpenAIå…¼å®¹API
```

#### 3.2 Pythonè°ƒç”¨

```python
from openai import OpenAI

# LM Studioæœ¬åœ°æœåŠ¡
client = OpenAI(
    base_url="http://localhost:1234/v1",
    api_key="lm-studio"  # éšæ„ï¼ŒLM Studioä¸éªŒè¯
)

def get_local_embedding(text):
    """ä½¿ç”¨LM Studioè·å–å‘é‡"""
    response = client.embeddings.create(
        input=text,
        model="nomic-embed-text"  # æ¨¡å‹åç§°
    )
    return response.data[0].embedding

# ä½¿ç”¨
text = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ"
embedding = get_local_embedding(text)

print(f"ç»´åº¦ï¼š{len(embedding)}")
print(f"å‰5ä¸ªå€¼ï¼š{embedding[:5]}")
```

#### 3.3 LangChainé›†æˆ

```python
from langchain.embeddings import OpenAIEmbeddings

# é…ç½®æœ¬åœ°Embeddings
embeddings = OpenAIEmbeddings(
    openai_api_base="http://localhost:1234/v1",
    openai_api_key="lm-studio",
    model="nomic-embed-text"
)

# ä½¿ç”¨
text = "æµ‹è¯•æ–‡æœ¬"
vector = embeddings.embed_query(text)

print(f"å‘é‡ç»´åº¦ï¼š{len(vector)}")

# æ‰¹é‡
texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
vectors = embeddings.embed_documents(texts)
print(f"ç”Ÿæˆäº† {len(vectors)} ä¸ªå‘é‡")
```

---

### 4. Ollama Embeddings

#### 4.1 å®‰è£…å’Œé…ç½®

```bash
# 1. å®‰è£…Ollamaï¼ˆmacOS/Linuxï¼‰
curl -fsSL https://ollama.com/install.sh | sh

# Windowsï¼šä¸‹è½½å®‰è£…åŒ…
# https://ollama.com/download

# 2. æ‹‰å–Embeddingæ¨¡å‹
ollama pull nomic-embed-text

# 3. æµ‹è¯•
ollama run nomic-embed-text "æµ‹è¯•æ–‡æœ¬"
```

#### 4.2 Pythonè°ƒç”¨

```python
import requests
import json

def get_ollama_embedding(text):
    """ä½¿ç”¨Ollamaè·å–å‘é‡"""
    
    url = "http://localhost:11434/api/embeddings"
    
    payload = {
        "model": "nomic-embed-text",
        "prompt": text
    }
    
    response = requests.post(url, json=payload)
    data = response.json()
    
    return data["embedding"]

# ä½¿ç”¨
text = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ"
embedding = get_ollama_embedding(text)

print(f"ç»´åº¦ï¼š{len(embedding)}")
print(f"å‰5ä¸ªå€¼ï¼š{embedding[:5]}")
```

#### 4.3 LangChainé›†æˆ

```python
from langchain.embeddings import OllamaEmbeddings

# åˆå§‹åŒ–
embeddings = OllamaEmbeddings(
    model="nomic-embed-text",
    base_url="http://localhost:11434"
)

# å•ä¸ªæ–‡æœ¬
text = "æµ‹è¯•æ–‡æœ¬"
vector = embeddings.embed_query(text)
print(f"ç»´åº¦ï¼š{len(vector)}")

# æ‰¹é‡
texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
vectors = embeddings.embed_documents(texts)
print(f"ç”Ÿæˆ {len(vectors)} ä¸ªå‘é‡")
```

---

### 5. è‡ªå»ºEmbedding APIæœåŠ¡

#### 5.1 FastAPIå®ç°

```python
# embedding_service.py

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
from typing import List
import uvicorn

# åˆå§‹åŒ–
app = FastAPI(title="Local Embedding Service")

# åŠ è½½æ¨¡å‹ï¼ˆå¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡ï¼‰
print("åŠ è½½Embeddingæ¨¡å‹...")
model = SentenceTransformer('all-MiniLM-L6-v2')
print("æ¨¡å‹åŠ è½½å®Œæˆï¼")


# è¯·æ±‚æ¨¡å‹
class EmbeddingRequest(BaseModel):
    texts: List[str]
    model: str = "all-MiniLM-L6-v2"


class EmbeddingResponse(BaseModel):
    embeddings: List[List[float]]
    model: str
    dimensions: int


# APIç«¯ç‚¹
@app.post("/embeddings", response_model=EmbeddingResponse)
async def create_embeddings(request: EmbeddingRequest):
    """ç”Ÿæˆå‘é‡"""
    
    try:
        # ç”Ÿæˆå‘é‡
        embeddings = model.encode(
            request.texts,
            batch_size=32,
            convert_to_numpy=True
        )
        
        # è½¬ä¸ºåˆ—è¡¨
        embeddings_list = embeddings.tolist()
        
        return EmbeddingResponse(
            embeddings=embeddings_list,
            model=request.model,
            dimensions=len(embeddings_list[0])
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "model": "all-MiniLM-L6-v2"}


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "Local Embedding Service",
        "version": "1.0",
        "model": "all-MiniLM-L6-v2",
        "dimensions": model.get_sentence_embedding_dimension()
    }


if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### 5.2 å®¢æˆ·ç«¯è°ƒç”¨

```python
# client.py

import requests
import json

def get_embeddings(texts, api_url="http://localhost:8000"):
    """è°ƒç”¨æœ¬åœ°EmbeddingæœåŠ¡"""
    
    response = requests.post(
        f"{api_url}/embeddings",
        json={"texts": texts}
    )
    
    if response.status_code == 200:
        data = response.json()
        return data["embeddings"]
    else:
        raise Exception(f"APIé”™è¯¯ï¼š{response.text}")


# ä½¿ç”¨
texts = [
    "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
    "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯"
]

embeddings = get_embeddings(texts)

print(f"ç”Ÿæˆäº† {len(embeddings)} ä¸ªå‘é‡")
print(f"ç»´åº¦ï¼š{len(embeddings[0])}")
```

#### 5.3 å¯åŠ¨å’Œä½¿ç”¨

```bash
# 1. å®‰è£…ä¾èµ–
pip install fastapi uvicorn sentence-transformers

# 2. å¯åŠ¨æœåŠ¡
python embedding_service.py

# æœåŠ¡è¿è¡Œåœ¨ http://localhost:8000

# 3. æµ‹è¯•
curl http://localhost:8000/health

# 4. è°ƒç”¨API
python client.py
```

---

### 6. æ€§èƒ½ä¼˜åŒ–

#### 6.1 GPUåŠ é€Ÿ

```python
from sentence_transformers import SentenceTransformer
import torch

# æ£€æŸ¥GPU
if torch.cuda.is_available():
    device = 'cuda'
    print(f"ä½¿ç”¨GPUï¼š{torch.cuda.get_device_name(0)}")
else:
    device = 'cpu'
    print("ä½¿ç”¨CPU")

# åŠ è½½åˆ°GPU
model = SentenceTransformer('all-MiniLM-L6-v2', device=device)

# ä½¿ç”¨ï¼ˆè‡ªåŠ¨åœ¨GPUä¸Šè¿è¡Œï¼‰
texts = ["æ–‡æœ¬" + str(i) for i in range(1000)]
embeddings = model.encode(texts, batch_size=64)

print("å®Œæˆï¼")
```

#### 6.2 å¤šè¿›ç¨‹åŠ é€Ÿ

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

texts = ["æ–‡æœ¬" + str(i) for i in range(10000)]

# ä½¿ç”¨å¤šè¿›ç¨‹æ± 
embeddings = model.encode_multi_process(
    texts,
    pool_size=4,  # è¿›ç¨‹æ•°
    batch_size=32
)

print(f"ç”Ÿæˆ {len(embeddings)} ä¸ªå‘é‡")
```

#### 6.3 é‡åŒ–æ¨¡å‹

```python
# ä½¿ç”¨é‡åŒ–æ¨¡å‹ï¼ˆå‡å°ä½“ç§¯ã€æå‡é€Ÿåº¦ï¼‰

from sentence_transformers import SentenceTransformer
import torch

model = SentenceTransformer('all-MiniLM-L6-v2')

# åŠ¨æ€é‡åŒ–
model = torch.quantization.quantize_dynamic(
    model, 
    {torch.nn.Linear}, 
    dtype=torch.qint8
)

# ä½¿ç”¨ï¼ˆé€Ÿåº¦æ›´å¿«ï¼Œç²¾åº¦ç•¥é™ï¼‰
texts = ["æµ‹è¯•æ–‡æœ¬"]
embeddings = model.encode(texts)
```

---

## ğŸ’» Demoæ¡ˆä¾‹ï¼šå®Œæ•´éƒ¨ç½²æ–¹æ¡ˆ

åˆ›å»º`local_embedding_deployment_demo.py`ï¼š

```python
"""
æœ¬åœ°Embeddingéƒ¨ç½²å®Œæ•´æ¼”ç¤º
å¯¹æ¯”ä¸åŒæ–¹æ¡ˆçš„æ€§èƒ½å’Œä½¿ç”¨ä½“éªŒ
"""

from sentence_transformers import SentenceTransformer
import time
import numpy as np


# ============= æ–¹æ¡ˆ1ï¼šSentence-Transformers =============

def demo_1_sentence_transformers():
    """æ–¹æ¡ˆ1ï¼šSentence-Transformers"""
    
    print("\n" + "="*60)
    print("æ–¹æ¡ˆ1ï¼šSentence-Transformers")
    print("="*60 + "\n")
    
    print("1. åŠ è½½æ¨¡å‹...")
    start = time.time()
    model = SentenceTransformer('all-MiniLM-L6-v2')
    load_time = time.time() - start
    print(f"   åŠ è½½è€—æ—¶ï¼š{load_time:.2f}ç§’\n")
    
    print("2. ç”Ÿæˆå‘é‡...")
    texts = [
        "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
        "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯",
        "æ·±åº¦å­¦ä¹ åŸºäºç¥ç»ç½‘ç»œ"
    ]
    
    start = time.time()
    embeddings = model.encode(texts)
    encode_time = time.time() - start
    
    print(f"   ç”Ÿæˆ3ä¸ªå‘é‡è€—æ—¶ï¼š{encode_time:.3f}ç§’")
    print(f"   å‘é‡ç»´åº¦ï¼š{embeddings.shape}\n")
    
    print("3. æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•...")
    large_texts = ["æµ‹è¯•æ–‡æœ¬" + str(i) for i in range(1000)]
    
    start = time.time()
    large_embeddings = model.encode(large_texts, batch_size=32, show_progress_bar=False)
    batch_time = time.time() - start
    
    print(f"   ç”Ÿæˆ1000ä¸ªå‘é‡è€—æ—¶ï¼š{batch_time:.2f}ç§’")
    print(f"   é€Ÿåº¦ï¼š{len(large_texts)/batch_time:.0f} docs/sec\n")
    
    return {
        "æ–¹æ¡ˆ": "Sentence-Transformers",
        "åŠ è½½æ—¶é—´": f"{load_time:.2f}s",
        "å•æ¬¡é€Ÿåº¦": f"{encode_time:.3f}s",
        "æ‰¹é‡é€Ÿåº¦": f"{len(large_texts)/batch_time:.0f} docs/s",
        "ç»´åº¦": embeddings.shape[1]
    }


# ============= æ–¹æ¡ˆ2ï¼šæ¨¡æ‹ŸLM Studio =============

def demo_2_lm_studio_style():
    """æ–¹æ¡ˆ2ï¼šLM Studioé£æ ¼ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    
    print("\n" + "="*60)
    print("æ–¹æ¡ˆ2ï¼šLM Studio APIé£æ ¼")
    print("="*60 + "\n")
    
    print("è¯´æ˜ï¼šLM Studioæä¾›OpenAIå…¼å®¹API")
    print("é…ç½®ï¼š")
    print("  base_url: http://localhost:1234/v1")
    print("  api_key: lm-studio")
    print("  model: nomic-embed-text\n")
    
    print("ç¤ºä¾‹ä»£ç ï¼š")
    code = """
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:1234/v1",
    api_key="lm-studio"
)

response = client.embeddings.create(
    input="ä½ çš„æ–‡æœ¬",
    model="nomic-embed-text"
)

embedding = response.data[0].embedding
"""
    print(code)
    
    print("ä¼˜ç‚¹ï¼š")
    print("  âœ“ å›¾å½¢ç•Œé¢ï¼Œæ˜“ç”¨")
    print("  âœ“ OpenAIå…¼å®¹API")
    print("  âœ“ é€‚åˆå¿«é€ŸåŸå‹\n")


# ============= æ–¹æ¡ˆ3ï¼šæ¨¡æ‹ŸOllama =============

def demo_3_ollama_style():
    """æ–¹æ¡ˆ3ï¼šOllamaé£æ ¼ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    
    print("\n" + "="*60)
    print("æ–¹æ¡ˆ3ï¼šOllama")
    print("="*60 + "\n")
    
    print("å®‰è£…å’Œä½¿ç”¨ï¼š")
    commands = """
# å®‰è£…
curl -fsSL https://ollama.com/install.sh | sh

# æ‹‰å–æ¨¡å‹
ollama pull nomic-embed-text

# Pythonè°ƒç”¨
import requests

url = "http://localhost:11434/api/embeddings"
response = requests.post(url, json={
    "model": "nomic-embed-text",
    "prompt": "ä½ çš„æ–‡æœ¬"
})

embedding = response.json()["embedding"]
"""
    print(commands)
    
    print("ä¼˜ç‚¹ï¼š")
    print("  âœ“ å‘½ä»¤è¡Œç®€å•")
    print("  âœ“ è½»é‡çº§")
    print("  âœ“ æ˜“äºé›†æˆ\n")


# ============= æ–¹æ¡ˆå¯¹æ¯” =============

def print_comparison():
    """æ‰“å°æ–¹æ¡ˆå¯¹æ¯”"""
    
    print("\n" + "="*60)
    print("æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“")
    print("="*60 + "\n")
    
    comparison = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç‰¹æ€§          â”‚  Sentence-Trans    â”‚  LM Studio         â”‚  Ollama            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ˜“ç”¨æ€§         â”‚  â˜…â˜…â˜…â˜…â˜†           â”‚  â˜…â˜…â˜…â˜…â˜…           â”‚  â˜…â˜…â˜…â˜…â˜†           â”‚
â”‚ æ€§èƒ½           â”‚  â˜…â˜…â˜…â˜…â˜…           â”‚  â˜…â˜…â˜…â˜†â˜†           â”‚  â˜…â˜…â˜…â˜…â˜†           â”‚
â”‚ æ¨¡å‹é€‰æ‹©       â”‚  â˜…â˜…â˜…â˜…â˜…ï¼ˆæœ€å¤šï¼‰   â”‚  â˜…â˜…â˜†â˜†â˜†           â”‚  â˜…â˜…â˜…â˜†â˜†           â”‚
â”‚ è‡ªå®šä¹‰èƒ½åŠ›     â”‚  â˜…â˜…â˜…â˜…â˜…           â”‚  â˜…â˜…â˜†â˜†â˜†           â”‚  â˜…â˜…â˜…â˜†â˜†           â”‚
â”‚ APIæ”¯æŒ        â”‚  â˜…â˜…â˜…â˜†â˜†           â”‚  â˜…â˜…â˜…â˜…â˜…ï¼ˆOpenAIï¼‰â”‚  â˜…â˜…â˜…â˜…â˜†           â”‚
â”‚ é€‚åˆåœºæ™¯       â”‚  å¼€å‘ã€ç”Ÿäº§        â”‚  å¿«é€ŸåŸå‹          â”‚  ç³»ç»Ÿé›†æˆ          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ¨èé€‰æ‹©ï¼š
1. Pythoné¡¹ç›®ï¼šSentence-Transformersï¼ˆæœ€çµæ´»ï¼‰
2. å¿«é€Ÿå¼€å§‹ï¼šLM Studioï¼ˆæœ€ç®€å•ï¼‰
3. ç³»ç»Ÿé›†æˆï¼šOllamaï¼ˆæœ€è½»é‡ï¼‰
4. ç”Ÿäº§ç¯å¢ƒï¼šè‡ªå»ºAPIæœåŠ¡ï¼ˆæœ€å¯æ§ï¼‰
"""
    
    print(comparison)


# ============= ä¸»å‡½æ•° =============

def main():
    """ä¸»å‡½æ•°"""
    
    print("\n" + "="*60)
    print("ğŸ¯ æœ¬åœ°Embeddingéƒ¨ç½²æ–¹æ¡ˆæ¼”ç¤º")
    print("="*60)
    
    # è¿è¡Œæ¼”ç¤º
    result = demo_1_sentence_transformers()
    demo_2_lm_studio_style()
    demo_3_ollama_style()
    print_comparison()
    
    print("\n" + "="*60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("="*60)
    print("\nğŸ’¡ æ ¸å¿ƒè¦ç‚¹ï¼š")
    print("  1. æœ¬åœ°éƒ¨ç½²å®Œå…¨å…è´¹ï¼Œæ— é™æ¬¡è°ƒç”¨")
    print("  2. æ•°æ®ä¸å‡ºæœ¬åœ°ï¼Œå®‰å…¨æœ‰ä¿éšœ")
    print("  3. å¤šç§æ–¹æ¡ˆå¯é€‰ï¼Œæ ¹æ®åœºæ™¯é€‰æ‹©")
    print("  4. æ€§èƒ½å’Œè´¨é‡éƒ½ä¸è¾“äº‘ç«¯API")
    print("\nğŸš€ ä¸‹ä¸€è¯¾ï¼šChromaå‘é‡æ•°æ®åº“ç²¾é€š")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### éƒ¨ç½²å»ºè®®

```
å¼€å‘é˜¶æ®µï¼š
âœ“ ä½¿ç”¨Sentence-Transformers
âœ“ å¿«é€Ÿè¿­ä»£å’Œæµ‹è¯•
âœ“ çµæ´»åˆ‡æ¢æ¨¡å‹

æµ‹è¯•é˜¶æ®µï¼š
âœ“ æ­å»ºAPIæœåŠ¡
âœ“ è´Ÿè½½æµ‹è¯•
âœ“ æ€§èƒ½è°ƒä¼˜

ç”Ÿäº§é˜¶æ®µï¼š
âœ“ Dockerå®¹å™¨åŒ–
âœ“ è´Ÿè½½å‡è¡¡
âœ“ ç›‘æ§å‘Šè­¦
âœ“ å®šæœŸæ›´æ–°æ¨¡å‹
```

---

## âœ… è¯¾åæ£€éªŒ

å®Œæˆæœ¬è¯¾åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] ä½¿ç”¨Sentence-Transformerséƒ¨ç½²æ¨¡å‹
- [ ] é…ç½®LM Studio Embeddings
- [ ] ä½¿ç”¨Ollamaç”Ÿæˆå‘é‡
- [ ] æ­å»ºè‡ªå®šä¹‰APIæœåŠ¡
- [ ] ä¼˜åŒ–Embeddingæ€§èƒ½

---

## ğŸ“ ä¸‹ä¸€è¯¾é¢„å‘Š

**ç¬¬44è¯¾ï¼šChromaå‘é‡æ•°æ®åº“ç²¾é€š**

ä¸‹ä¸€è¯¾æˆ‘ä»¬å°†å­¦ä¹ ï¼š
- Chromaæ•°æ®åº“å®Œæ•´æ•™ç¨‹
- é›†åˆç®¡ç†å’Œé…ç½®
- é«˜çº§æ£€ç´¢æŠ€å·§
- æŒä¹…åŒ–å’Œå¤‡ä»½
- ä¸LangChainé›†æˆ

**å¼€å§‹æ„å»ºå®Œæ•´çš„å‘é‡æ£€ç´¢ç³»ç»Ÿï¼**

---

**ğŸ‰ æ­å–œä½ å®Œæˆç¬¬43è¯¾ï¼**

**ä½ å·²ç»æŒæ¡äº†æœ¬åœ°Embeddingéƒ¨ç½²ï¼**

**è¿›åº¦ï¼š43/165è¯¾ï¼ˆ26.1%å®Œæˆï¼‰** ğŸš€