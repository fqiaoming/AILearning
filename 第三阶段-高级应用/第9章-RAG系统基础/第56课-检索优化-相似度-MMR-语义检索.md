![RAGç³»ç»Ÿæ¶æ„](./images/rag_flow.svg)
*å›¾ï¼šRAGç³»ç»Ÿæ¶æ„*

# ç¬¬56è¯¾ï¼šæ£€ç´¢ä¼˜åŒ–ï¼šç›¸ä¼¼åº¦ vs MMR vs è¯­ä¹‰æ£€ç´¢

> **æœ¬è¯¾ç›®æ ‡**ï¼šæ·±å…¥ç†è§£ä¸åŒæ£€ç´¢ç®—æ³•ï¼ŒæŒæ¡å¦‚ä½•é€‰æ‹©å’Œä¼˜åŒ–æ£€ç´¢ç­–ç•¥
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šç›¸ä¼¼åº¦æ£€ç´¢ã€MMRç®—æ³•ã€è¯­ä¹‰æ£€ç´¢ã€æ£€ç´¢è¯„ä¼°
> 
> **å®æˆ˜æ¡ˆä¾‹**ï¼šå¯¹æ¯”ä¸åŒæ£€ç´¢ç­–ç•¥çš„æ•ˆæœï¼Œé€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š75åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ3åˆ†é’Ÿï¼‰

### ğŸ¯ å‰è¨€

"ä¸ŠèŠ‚è¯¾æˆ‘ä»¬å®ç°äº†ä¸€ä¸ªåŸºç¡€çš„RAGç³»ç»Ÿï¼Œç”¨çš„æ˜¯æœ€ç®€å•çš„å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ã€‚

ä½†å¾ˆå¤šåŒå­¦åé¦ˆï¼š'æ£€ç´¢æ•ˆæœä¸ç†æƒ³ï¼Œç»å¸¸è¿”å›é‡å¤çš„å†…å®¹ï¼Œæˆ–è€…æ£€ç´¢ä¸åˆ°çœŸæ­£ç›¸å…³çš„æ–‡æ¡£'

**ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæ£€ç´¢ç®—æ³•æ²¡é€‰å¯¹ï¼**

æˆ‘è§è¿‡å¤ªå¤šRAGç³»ç»Ÿï¼Œæ˜æ˜çŸ¥è¯†åº“é‡Œæœ‰ç­”æ¡ˆï¼Œä½†å°±æ˜¯æ£€ç´¢ä¸å‡ºæ¥ï¼æˆ–è€…æ£€ç´¢å‡ºæ¥çš„éƒ½æ˜¯é‡å¤ä¿¡æ¯ï¼Œæ²¡æœ‰å¤šæ ·æ€§ï¼

ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘ä¼šç”¨75åˆ†é’Ÿï¼Œæ·±å…¥è®²è§£ä¸‰ç§æ ¸å¿ƒæ£€ç´¢ç®—æ³•ï¼š

**1. ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆSimilarity Searchï¼‰**
- æœ€å¸¸ç”¨ï¼Œä½†å®¹æ˜“è¿”å›é‡å¤å†…å®¹
- é€‚åˆç²¾ç¡®åŒ¹é…åœºæ™¯

**2. MMRæ£€ç´¢ï¼ˆMaximum Marginal Relevanceï¼‰**
- å¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
- é¿å…é‡å¤ï¼Œè¿”å›æ›´ä¸°å¯Œçš„ä¿¡æ¯

**3. è¯­ä¹‰æ£€ç´¢ï¼ˆSemantic Searchï¼‰**
- ç†è§£è¯­ä¹‰è€Œä¸æ˜¯å­—é¢æ„æ€
- èƒ½æ‰¾åˆ°ç›¸å…³ä½†ä¸å®Œå…¨ç›¸åŒçš„å†…å®¹

å­¦å®Œè¿™ä¸€è¯¾ï¼Œä½ ä¼šçŸ¥é“ï¼š
- âœ… æ¯ç§ç®—æ³•çš„åŸç†å’Œé€‚ç”¨åœºæ™¯
- âœ… å¦‚ä½•å®ç°å’Œä¼˜åŒ–æ¯ç§ç®—æ³•
- âœ… å¦‚ä½•è¯„ä¼°æ£€ç´¢æ•ˆæœ
- âœ… å¦‚ä½•æ ¹æ®åœºæ™¯é€‰æ‹©æœ€ä¼˜ç­–ç•¥

è¿™ä¸æ˜¯ç†è®ºè¯¾ï¼Œæ¯ä¸ªç®—æ³•æˆ‘éƒ½ä¼šå¸¦ä½ ä»é›¶å®ç°ï¼

è®©æˆ‘ä»¬å¼€å§‹ï¼"

---

### ğŸ’¡ æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### æ£€ç´¢çš„æ ¸å¿ƒç›®æ ‡

```
1. ç›¸å…³æ€§ï¼ˆRelevanceï¼‰
   - è¿”å›çš„æ–‡æ¡£ä¸æŸ¥è¯¢ç›¸å…³

2. å¤šæ ·æ€§ï¼ˆDiversityï¼‰
   - è¿”å›çš„æ–‡æ¡£ä¹‹é—´ä¸é‡å¤ï¼Œä¿¡æ¯äº’è¡¥

3. å®Œæ•´æ€§ï¼ˆCoverageï¼‰
   - è¦†ç›–æŸ¥è¯¢çš„ä¸åŒæ–¹é¢
```

#### ä¸‰ç§æ£€ç´¢ç®—æ³•å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç®—æ³•å¯¹æ¯”                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆSimilarityï¼‰                      â”‚
â”‚  â€¢ åŸç†ï¼šä½™å¼¦ç›¸ä¼¼åº¦                            â”‚
â”‚  â€¢ ä¼˜ç‚¹ï¼šç®€å•å¿«é€Ÿ                              â”‚
â”‚  â€¢ ç¼ºç‚¹ï¼šå®¹æ˜“è¿”å›é‡å¤å†…å®¹                      â”‚
â”‚  â€¢ é€‚ç”¨ï¼šç²¾ç¡®åŒ¹é…æŸ¥è¯¢                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MMRæ£€ç´¢ï¼ˆMaximum Marginal Relevanceï¼‰         â”‚
â”‚  â€¢ åŸç†ï¼šå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§                    â”‚
â”‚  â€¢ ä¼˜ç‚¹ï¼šç»“æœå¤šæ ·ï¼Œä¿¡æ¯ä¸°å¯Œ                    â”‚
â”‚  â€¢ ç¼ºç‚¹ï¼šè®¡ç®—ç¨æ…¢                              â”‚
â”‚  â€¢ é€‚ç”¨ï¼šéœ€è¦å…¨é¢ä¿¡æ¯çš„æŸ¥è¯¢                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¯­ä¹‰æ£€ç´¢ï¼ˆSemantic Searchï¼‰                   â”‚
â”‚  â€¢ åŸç†ï¼šç†è§£è¯­ä¹‰è€Œéå­—é¢                      â”‚
â”‚  â€¢ ä¼˜ç‚¹ï¼šèƒ½æ‰¾åˆ°è¯­ä¹‰ç›¸å…³å†…å®¹                    â”‚
â”‚  â€¢ ç¼ºç‚¹ï¼šå¯èƒ½åç¦»åŸæ„                          â”‚
â”‚  â€¢ é€‚ç”¨ï¼šéœ€è¦æ‰©å±•ç†è§£çš„æŸ¥è¯¢                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š çŸ¥è¯†è®²è§£

### ä¸€ã€ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆSimilarity Searchï¼‰

#
![æ£€ç´¢ä¼˜åŒ–](./images/retrieval.svg)
*å›¾ï¼šæ£€ç´¢ä¼˜åŒ–*

### 1.1 åŸç†è¯¦è§£

```
ç›¸ä¼¼åº¦æ£€ç´¢çš„æ ¸å¿ƒï¼šä½™å¼¦ç›¸ä¼¼åº¦

å‘é‡A: [0.2, 0.5, 0.8]
å‘é‡B: [0.3, 0.4, 0.7]

ä½™å¼¦ç›¸ä¼¼åº¦ = (AÂ·B) / (||A|| Ã— ||B||)

å…¶ä¸­ï¼š
- AÂ·Bï¼šå‘é‡ç‚¹ç§¯
- ||A||ï¼šå‘é‡Açš„æ¨¡é•¿
- ||B||ï¼šå‘é‡Bçš„æ¨¡é•¿

ç›¸ä¼¼åº¦èŒƒå›´ï¼š-1 åˆ° 1
- 1ï¼šå®Œå…¨ç›¸åŒ
- 0ï¼šæ­£äº¤ï¼ˆæ— å…³ï¼‰
- -1ï¼šå®Œå…¨ç›¸å
```

#### 1.2 å®ç°ç›¸ä¼¼åº¦æ£€ç´¢

```python
import numpy as np
from typing import List, Tuple
from dataclasses import dataclass

@dataclass
class Document:
    """æ–‡æ¡£å¯¹è±¡"""
    content: str
    embedding: np.ndarray
    metadata: dict = None

class SimilarityRetriever:
    """ç›¸ä¼¼åº¦æ£€ç´¢å™¨"""
    
    def __init__(self):
        self.documents: List[Document] = []
    
    def add_documents(self, documents: List[Document]):
        """æ·»åŠ æ–‡æ¡£"""
        self.documents.extend(documents)
    
    def cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        # ç‚¹ç§¯
        dot_product = np.dot(vec1, vec2)
        
        # æ¨¡é•¿
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = dot_product / (norm1 * norm2)
        
        return similarity
    
    def search(self, query_embedding: np.ndarray, k: int = 5) -> List[Tuple[Document, float]]:
        """ç›¸ä¼¼åº¦æ£€ç´¢"""
        # è®¡ç®—æŸ¥è¯¢ä¸æ‰€æœ‰æ–‡æ¡£çš„ç›¸ä¼¼åº¦
        similarities = []
        
        for doc in self.documents:
            sim = self.cosine_similarity(query_embedding, doc.embedding)
            similarities.append((doc, sim))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›top-k
        return similarities[:k]

# ä½¿ç”¨ç¤ºä¾‹
def demo_similarity_search():
    """æ¼”ç¤ºç›¸ä¼¼åº¦æ£€ç´¢"""
    
    # 1. å‡†å¤‡æ–‡æ¡£ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼Œå®é™…åº”è¯¥ç”¨embeddingæ¨¡å‹ï¼‰
    documents = [
        Document(
            content="äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯",
            embedding=np.array([0.8, 0.6, 0.2, 0.1]),
            metadata={"source": "doc1.txt"}
        ),
        Document(
            content="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯",
            embedding=np.array([0.7, 0.7, 0.3, 0.1]),
            metadata={"source": "doc2.txt"}
        ),
        Document(
            content="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯",
            embedding=np.array([0.75, 0.65, 0.25, 0.15]),
            metadata={"source": "doc3.txt"}
        ),
        Document(
            content="ä»Šå¤©å¤©æ°”çœŸå¥½",
            embedding=np.array([0.1, 0.2, 0.8, 0.9]),
            metadata={"source": "doc4.txt"}
        ),
    ]
    
    # 2. åˆ›å»ºæ£€ç´¢å™¨
    retriever = SimilarityRetriever()
    retriever.add_documents(documents)
    
    # 3. æŸ¥è¯¢
    query_embedding = np.array([0.8, 0.6, 0.2, 0.1])  # ä¸doc1ç›¸ä¼¼
    
    results = retriever.search(query_embedding, k=3)
    
    # 4. æ˜¾ç¤ºç»“æœ
    print("ç›¸ä¼¼åº¦æ£€ç´¢ç»“æœï¼š")
    for i, (doc, score) in enumerate(results):
        print(f"\n{i+1}. ç›¸ä¼¼åº¦: {score:.4f}")
        print(f"   å†…å®¹: {doc.content}")
        print(f"   æ¥æº: {doc.metadata['source']}")

demo_similarity_search()
```

#### 1.3 ç›¸ä¼¼åº¦æ£€ç´¢çš„é—®é¢˜

```python
# é—®é¢˜æ¼”ç¤º
documents = [
    "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯",
    "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºæŠ€æœ¯çš„ä¸€ä¸ªåˆ†æ”¯",  # å‡ ä¹ç›¸åŒ
    "AIæ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦é¢†åŸŸ",     # å‡ ä¹ç›¸åŒ
    "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯",            # ç›¸å…³ä½†ä¸åŒ
]

query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"

# ç›¸ä¼¼åº¦æ£€ç´¢è¿”å›ï¼š
# 1. "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯"      - ç›¸å…³ âœ…
# 2. "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºæŠ€æœ¯çš„ä¸€ä¸ªåˆ†æ”¯"      - é‡å¤ âŒ
# 3. "AIæ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦é¢†åŸŸ"        - é‡å¤ âŒ

# é—®é¢˜ï¼šå‰ä¸‰ä¸ªç»“æœå‡ ä¹ç›¸åŒï¼Œç¼ºä¹å¤šæ ·æ€§ï¼
# ç¬¬4ä¸ªç»“æœ"æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯"æ›´æœ‰ä»·å€¼ï¼Œä½†è¢«æ’é™¤äº†
```

---

### äºŒã€MMRæ£€ç´¢ï¼ˆMaximum Marginal Relevanceï¼‰

#### 2.1 MMRåŸç†

```
MMRçš„ç›®æ ‡ï¼šå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§

å…¬å¼ï¼š
MMR = argmax[Î» Ã— Sim(Di, Q) - (1-Î») Ã— max Sim(Di, Dj)]
           DiâˆˆR\S              DjâˆˆS

å…¶ä¸­ï¼š
- Diï¼šå€™é€‰æ–‡æ¡£
- Qï¼šæŸ¥è¯¢
- Sï¼šå·²é€‰æ‹©çš„æ–‡æ¡£é›†åˆ
- Rï¼šæ‰€æœ‰æ–‡æ¡£
- Î»ï¼šå¹³è¡¡å‚æ•°ï¼ˆ0-1ï¼‰
  - Î»=1ï¼šåªè€ƒè™‘ç›¸å…³æ€§ï¼ˆé€€åŒ–ä¸ºç›¸ä¼¼åº¦æ£€ç´¢ï¼‰
  - Î»=0ï¼šåªè€ƒè™‘å¤šæ ·æ€§
  - Î»=0.5ï¼šå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§ï¼ˆå¸¸ç”¨ï¼‰

ç›´è§‚ç†è§£ï¼š
- ç¬¬ä¸€é¡¹ Sim(Di, Q)ï¼šä¸æŸ¥è¯¢çš„ç›¸å…³æ€§ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
- ç¬¬äºŒé¡¹ max Sim(Di, Dj)ï¼šä¸å·²é€‰æ–‡æ¡£çš„ç›¸ä¼¼æ€§ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
- é€šè¿‡å¹³è¡¡ä¸¤é¡¹ï¼Œé€‰æ‹©"ç›¸å…³ä½†ä¸é‡å¤"çš„æ–‡æ¡£
```

#### 2.2 MMRå®ç°

```python
class MMRRetriever:
    """MMRæ£€ç´¢å™¨"""
    
    def __init__(self, lambda_param: float = 0.5):
        """
        Args:
            lambda_param: å¹³è¡¡å‚æ•°
                - 1.0: åªè€ƒè™‘ç›¸å…³æ€§
                - 0.0: åªè€ƒè™‘å¤šæ ·æ€§
                - 0.5: å¹³è¡¡ï¼ˆæ¨èï¼‰
        """
        self.documents: List[Document] = []
        self.lambda_param = lambda_param
    
    def add_documents(self, documents: List[Document]):
        """æ·»åŠ æ–‡æ¡£"""
        self.documents.extend(documents)
    
    def cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        return dot_product / (norm1 * norm2)
    
    def search(self, query_embedding: np.ndarray, k: int = 5) -> List[Tuple[Document, float]]:
        """MMRæ£€ç´¢"""
        # 1. è®¡ç®—æ‰€æœ‰æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸ä¼¼åº¦
        query_similarities = []
        for doc in self.documents:
            sim = self.cosine_similarity(query_embedding, doc.embedding)
            query_similarities.append((doc, sim))
        
        # 2. æŒ‰ç›¸ä¼¼åº¦æ’åº
        query_similarities.sort(key=lambda x: x[1], reverse=True)
        
        # 3. MMRé€‰æ‹©
        selected = []  # å·²é€‰æ‹©çš„æ–‡æ¡£
        candidates = query_similarities.copy()  # å€™é€‰æ–‡æ¡£
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆä¸æŸ¥è¯¢æœ€ç›¸ä¼¼çš„ï¼‰
        if candidates:
            first_doc, first_sim = candidates.pop(0)
            selected.append((first_doc, first_sim))
        
        # è¿­ä»£é€‰æ‹©å‰©ä½™æ–‡æ¡£
        while len(selected) < k and candidates:
            best_score = -float('inf')
            best_idx = -1
            
            # éå†å€™é€‰æ–‡æ¡£
            for idx, (candidate_doc, query_sim) in enumerate(candidates):
                # è®¡ç®—ä¸å·²é€‰æ–‡æ¡£çš„æœ€å¤§ç›¸ä¼¼åº¦
                max_sim_to_selected = 0
                for selected_doc, _ in selected:
                    sim = self.cosine_similarity(
                        candidate_doc.embedding,
                        selected_doc.embedding
                    )
                    max_sim_to_selected = max(max_sim_to_selected, sim)
                
                # è®¡ç®—MMRåˆ†æ•°
                mmr_score = (
                    self.lambda_param * query_sim - 
                    (1 - self.lambda_param) * max_sim_to_selected
                )
                
                # é€‰æ‹©MMRåˆ†æ•°æœ€é«˜çš„
                if mmr_score > best_score:
                    best_score = mmr_score
                    best_idx = idx
            
            # æ·»åŠ åˆ°å·²é€‰æ‹©åˆ—è¡¨
            if best_idx >= 0:
                selected.append(candidates.pop(best_idx))
        
        return selected

# ä½¿ç”¨ç¤ºä¾‹
def demo_mmr_search():
    """æ¼”ç¤ºMMRæ£€ç´¢"""
    
    # 1. å‡†å¤‡æ–‡æ¡£
    documents = [
        Document(
            content="äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯",
            embedding=np.array([0.8, 0.6, 0.2, 0.1]),
            metadata={"id": 1}
        ),
        Document(
            content="äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºæŠ€æœ¯çš„ä¸€ä¸ªåˆ†æ”¯",  # ä¸ä¸Šé¢å‡ ä¹ç›¸åŒ
            embedding=np.array([0.81, 0.59, 0.21, 0.11]),
            metadata={"id": 2}
        ),
        Document(
            content="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯",
            embedding=np.array([0.7, 0.7, 0.3, 0.1]),
            metadata={"id": 3}
        ),
        Document(
            content="æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ",
            embedding=np.array([0.6, 0.5, 0.4, 0.2]),
            metadata={"id": 4}
        ),
    ]
    
    # 2. å¯¹æ¯”ç›¸ä¼¼åº¦æ£€ç´¢å’ŒMMRæ£€ç´¢
    query_embedding = np.array([0.8, 0.6, 0.2, 0.1])
    
    # ç›¸ä¼¼åº¦æ£€ç´¢
    print("ã€ç›¸ä¼¼åº¦æ£€ç´¢ã€‘")
    sim_retriever = SimilarityRetriever()
    sim_retriever.add_documents(documents)
    sim_results = sim_retriever.search(query_embedding, k=3)
    
    for i, (doc, score) in enumerate(sim_results):
        print(f"{i+1}. ID={doc.metadata['id']}, ç›¸ä¼¼åº¦={score:.4f}")
        print(f"   {doc.content}")
    
    # MMRæ£€ç´¢
    print("\nã€MMRæ£€ç´¢ã€‘(Î»=0.5)")
    mmr_retriever = MMRRetriever(lambda_param=0.5)
    mmr_retriever.add_documents(documents)
    mmr_results = mmr_retriever.search(query_embedding, k=3)
    
    for i, (doc, score) in enumerate(mmr_results):
        print(f"{i+1}. ID={doc.metadata['id']}, åˆ†æ•°={score:.4f}")
        print(f"   {doc.content}")
    
    print("\nè§‚å¯Ÿï¼š")
    print("- ç›¸ä¼¼åº¦æ£€ç´¢ï¼šID=1å’ŒID=2å‡ ä¹ç›¸åŒï¼ˆé‡å¤ï¼‰")
    print("- MMRæ£€ç´¢ï¼šé€‰æ‹©äº†ID=1ã€ID=3ã€ID=4ï¼ˆå¤šæ ·æ€§æ›´å¥½ï¼‰")

demo_mmr_search()
```

#### 2.3 è°ƒæ•´Lambdaå‚æ•°

```python
def demo_lambda_effect():
    """æ¼”ç¤ºlambdaå‚æ•°çš„å½±å“"""
    
    # å‡†å¤‡æ–‡æ¡£ï¼ˆåŒä¸Šï¼‰
    documents = [...]
    query_embedding = np.array([0.8, 0.6, 0.2, 0.1])
    
    # æµ‹è¯•ä¸åŒçš„lambdaå€¼
    lambdas = [0.0, 0.3, 0.5, 0.7, 1.0]
    
    for lambda_val in lambdas:
        print(f"\nã€Lambda = {lambda_val}ã€‘")
        
        retriever = MMRRetriever(lambda_param=lambda_val)
        retriever.add_documents(documents)
        results = retriever.search(query_embedding, k=3)
        
        for i, (doc, score) in enumerate(results):
            print(f"{i+1}. ID={doc.metadata['id']}")
    
    print("\nåˆ†æï¼š")
    print("- Î»=0.0: æœ€å¤§å¤šæ ·æ€§ï¼Œå¯èƒ½ä¸ç›¸å…³")
    print("- Î»=0.5: å¹³è¡¡ï¼Œæ¨è")
    print("- Î»=1.0: æœ€å¤§ç›¸å…³æ€§ï¼Œç­‰åŒäºç›¸ä¼¼åº¦æ£€ç´¢")
```

---

### ä¸‰ã€è¯­ä¹‰æ£€ç´¢ï¼ˆSemantic Searchï¼‰

#### 3.1 è¯­ä¹‰æ£€ç´¢åŸç†

```
è¯­ä¹‰æ£€ç´¢ vs å­—é¢æ£€ç´¢

å­—é¢æ£€ç´¢ï¼š
æŸ¥è¯¢ï¼š"è‹¹æœæ‰‹æœºæ€ä¹ˆæ ·ï¼Ÿ"
åŒ¹é…ï¼š"è‹¹æœæ‰‹æœº"ã€"iPhone"
ä¸åŒ¹é…ï¼š"æ°´æœ"ï¼ˆè™½ç„¶ä¹Ÿå«è‹¹æœï¼‰

è¯­ä¹‰æ£€ç´¢ï¼š
æŸ¥è¯¢ï¼š"è‹¹æœæ‰‹æœºæ€ä¹ˆæ ·ï¼Ÿ"
ç†è§£ï¼šç”¨æˆ·æƒ³äº†è§£iPhoneçš„è¯„ä»·
åŒ¹é…ï¼š
  - "iPhoneæ€§èƒ½ä¸é”™"  âœ…
  - "iOSç³»ç»Ÿå¾ˆæµç•…"   âœ…
  - "è‹¹æœçš„äº§å“è´¨é‡å¥½" âœ…
  - "è‹¹æœå¾ˆç”œ"        âŒ (ä¸åŒè¯­ä¹‰)

æ ¸å¿ƒï¼šç†è§£è¯­ä¹‰ï¼Œè€Œä¸æ˜¯åŒ¹é…å…³é”®è¯
```

#### 3.2 è¯­ä¹‰æ£€ç´¢å®ç°

```python
from sentence_transformers import SentenceTransformer

class SemanticRetriever:
    """è¯­ä¹‰æ£€ç´¢å™¨"""
    
    def __init__(self, model_name: str = "moka-ai/m3e-base"):
        """
        åˆå§‹åŒ–è¯­ä¹‰æ£€ç´¢å™¨
        
        ä½¿ç”¨é¢„è®­ç»ƒçš„Sentence-BERTæ¨¡å‹
        è¿™ç§æ¨¡å‹ä¸“é—¨ä¸ºè¯­ä¹‰ç›¸ä¼¼åº¦ä¼˜åŒ–
        """
        print(f"åŠ è½½è¯­ä¹‰æ¨¡å‹: {model_name}")
        self.model = SentenceTransformer(model_name)
        self.documents = []
        self.embeddings = None
    
    def add_documents(self, documents: List[str]):
        """æ·»åŠ æ–‡æ¡£å¹¶ç¼–ç """
        self.documents = documents
        
        # æ‰¹é‡ç¼–ç ï¼ˆæ›´é«˜æ•ˆï¼‰
        print(f"ç¼–ç  {len(documents)} ä¸ªæ–‡æ¡£...")
        self.embeddings = self.model.encode(
            documents,
            convert_to_numpy=True,
            show_progress_bar=True
        )
    
    def search(self, query: str, k: int = 5) -> List[Tuple[str, float]]:
        """è¯­ä¹‰æ£€ç´¢"""
        # 1. ç¼–ç æŸ¥è¯¢
        query_embedding = self.model.encode([query], convert_to_numpy=True)[0]
        
        # 2. è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for i, doc_embedding in enumerate(self.embeddings):
            sim = self._cosine_similarity(query_embedding, doc_embedding)
            similarities.append((self.documents[i], sim))
        
        # 3. æ’åºè¿”å›
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:k]
    
    def _cosine_similarity(self, vec1, vec2):
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# ä½¿ç”¨ç¤ºä¾‹
def demo_semantic_search():
    """æ¼”ç¤ºè¯­ä¹‰æ£€ç´¢"""
    
    # 1. å‡†å¤‡æ–‡æ¡£
    documents = [
        "iPhone 15æ€§èƒ½éå¸¸å‡ºè‰²ï¼Œå¤„ç†é€Ÿåº¦å¿«",
        "è‹¹æœæ‰‹æœºçš„iOSç³»ç»Ÿéå¸¸æµç•…",
        "è‹¹æœå…¬å¸çš„äº§å“è´¨é‡ä¸€ç›´å¾ˆå¥½",
        "è¿™ä¸ªè‹¹æœå¾ˆç”œï¼Œå¾ˆå¥½åƒ",
        "æ°´æœåº—çš„è‹¹æœæ–°é²œåˆä¾¿å®œ",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯",
    ]
    
    # 2. åˆ›å»ºæ£€ç´¢å™¨
    retriever = SemanticRetriever()
    retriever.add_documents(documents)
    
    # 3. è¯­ä¹‰æŸ¥è¯¢
    queries = [
        "è‹¹æœæ‰‹æœºæ€ä¹ˆæ ·ï¼Ÿ",
        "AIæŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ",
    ]
    
    for query in queries:
        print(f"\næŸ¥è¯¢: {query}")
        print("="*60)
        
        results = retriever.search(query, k=3)
        
        for i, (doc, score) in enumerate(results):
            print(f"{i+1}. ç›¸ä¼¼åº¦: {score:.4f}")
            print(f"   {doc}")
    
    print("\nè§‚å¯Ÿï¼š")
    print("- æŸ¥è¯¢'è‹¹æœæ‰‹æœº'æ—¶ï¼Œæ­£ç¡®ç†è§£ä¸ºiPhoneï¼Œä¸æ˜¯æ°´æœ")
    print("- è¿”å›çš„éƒ½æ˜¯å…³äºiPhoneçš„å†…å®¹ï¼Œè¯­ä¹‰ç›¸å…³")

demo_semantic_search()
```

#### 3.3 è¯­ä¹‰æ£€ç´¢çš„ä¼˜åŠ¿

```python
def compare_search_methods():
    """å¯¹æ¯”ä¸åŒæ£€ç´¢æ–¹æ³•"""
    
    documents = [
        "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½ï¼Œäººå£è¶…è¿‡2000ä¸‡",
        "ä¸Šæµ·æ˜¯ä¸­å›½æœ€å¤§çš„åŸå¸‚ï¼Œç»æµå‘è¾¾",
        "æ·±åœ³æ˜¯ä¸­å›½çš„ç§‘æŠ€ä¸­å¿ƒï¼Œåˆ›æ–°ä¼ä¸šä¼—å¤š",
        "çŒ«æ˜¯ä¸€ç§å¯çˆ±çš„å® ç‰©",
        "ç‹—æ˜¯äººç±»æœ€å¿ è¯šçš„æœ‹å‹",
    ]
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "ä¸­å›½æœ‰å“ªäº›å¤§åŸå¸‚ï¼Ÿ"
    
    print(f"æŸ¥è¯¢: {query}\n")
    
    # 1. å…³é”®è¯æ£€ç´¢ï¼ˆç®€å•å®ç°ï¼‰
    print("ã€å…³é”®è¯æ£€ç´¢ã€‘")
    keyword_results = []
    for doc in documents:
        # ç®€å•è®¡ç®—å…³é”®è¯åŒ¹é…
        keywords = ["ä¸­å›½", "åŸå¸‚"]
        score = sum(1 for kw in keywords if kw in doc)
        if score > 0:
            keyword_results.append((doc, score))
    
    keyword_results.sort(key=lambda x: x[1], reverse=True)
    for i, (doc, score) in enumerate(keyword_results[:3]):
        print(f"{i+1}. åŒ¹é…åº¦={score}: {doc}")
    
    # 2. è¯­ä¹‰æ£€ç´¢
    print("\nã€è¯­ä¹‰æ£€ç´¢ã€‘")
    retriever = SemanticRetriever()
    retriever.add_documents(documents)
    semantic_results = retriever.search(query, k=3)
    
    for i, (doc, score) in enumerate(semantic_results):
        print(f"{i+1}. ç›¸ä¼¼åº¦={score:.4f}: {doc}")
    
    print("\nå¯¹æ¯”ï¼š")
    print("- å…³é”®è¯ï¼šåªåŒ¹é…åŒ…å«'ä¸­å›½'å’Œ'åŸå¸‚'çš„æ–‡æ¡£")
    print("- è¯­ä¹‰ï¼šç†è§£æŸ¥è¯¢æ„å›¾ï¼Œè¿”å›ç›¸å…³åŸå¸‚ä¿¡æ¯")
    print("- è¯­ä¹‰æ£€ç´¢èƒ½æ‰¾åˆ°'ä¸Šæµ·'ã€'æ·±åœ³'ï¼ˆè™½ç„¶æ–‡æ¡£ä¸­æ²¡æœ‰'åŸå¸‚'äºŒå­—ï¼‰")
```

---

### å››ã€æ£€ç´¢ç­–ç•¥å¯¹æ¯”ä¸é€‰æ‹©

#### 4.1 ä¸‰ç§ç­–ç•¥å…¨é¢å¯¹æ¯”

```python
class ComprehensiveRetriever:
    """ç»¼åˆæ£€ç´¢å™¨ï¼ˆæ”¯æŒä¸‰ç§ç­–ç•¥ï¼‰"""
    
    def __init__(self, model_name: str = "moka-ai/m3e-base"):
        self.model = SentenceTransformer(model_name)
        self.documents = []
        self.embeddings = None
    
    def add_documents(self, documents: List[str]):
        """æ·»åŠ æ–‡æ¡£"""
        self.documents = documents
        self.embeddings = self.model.encode(documents, convert_to_numpy=True)
    
    def search_similarity(self, query: str, k: int = 5):
        """ç›¸ä¼¼åº¦æ£€ç´¢"""
        query_emb = self.model.encode([query])[0]
        
        similarities = []
        for i, doc_emb in enumerate(self.embeddings):
            sim = np.dot(query_emb, doc_emb) / (
                np.linalg.norm(query_emb) * np.linalg.norm(doc_emb)
            )
            similarities.append((self.documents[i], sim, i))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:k]
    
    def search_mmr(self, query: str, k: int = 5, lambda_param: float = 0.5):
        """MMRæ£€ç´¢"""
        query_emb = self.model.encode([query])[0]
        
        # è®¡ç®—æ‰€æœ‰ç›¸ä¼¼åº¦
        query_sims = []
        for i, doc_emb in enumerate(self.embeddings):
            sim = np.dot(query_emb, doc_emb) / (
                np.linalg.norm(query_emb) * np.linalg.norm(doc_emb)
            )
            query_sims.append((i, sim))
        
        query_sims.sort(key=lambda x: x[1], reverse=True)
        
        # MMRé€‰æ‹©
        selected_indices = []
        candidates = [idx for idx, _ in query_sims]
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ª
        if candidates:
            selected_indices.append(candidates.pop(0))
        
        # è¿­ä»£é€‰æ‹©
        while len(selected_indices) < k and candidates:
            best_score = -float('inf')
            best_idx = -1
            best_cand_idx = -1
            
            for cand_idx, doc_idx in enumerate(candidates):
                # æŸ¥è¯¢ç›¸ä¼¼åº¦
                query_sim = query_sims[doc_idx][1]
                
                # ä¸å·²é€‰æ–‡æ¡£çš„æœ€å¤§ç›¸ä¼¼åº¦
                max_sim = 0
                for sel_idx in selected_indices:
                    sim = np.dot(
                        self.embeddings[doc_idx],
                        self.embeddings[sel_idx]
                    ) / (
                        np.linalg.norm(self.embeddings[doc_idx]) *
                        np.linalg.norm(self.embeddings[sel_idx])
                    )
                    max_sim = max(max_sim, sim)
                
                # MMRåˆ†æ•°
                score = lambda_param * query_sim - (1 - lambda_param) * max_sim
                
                if score > best_score:
                    best_score = score
                    best_idx = doc_idx
                    best_cand_idx = cand_idx
            
            if best_idx >= 0:
                selected_indices.append(candidates.pop(best_cand_idx))
        
        # æ„å»ºç»“æœ
        results = []
        for idx in selected_indices:
            results.append((self.documents[idx], query_sims[idx][1], idx))
        
        return results
    
    def compare_all(self, query: str, k: int = 3):
        """å¯¹æ¯”æ‰€æœ‰æ£€ç´¢ç­–ç•¥"""
        print(f"æŸ¥è¯¢: {query}")
        print("="*80)
        
        # 1. ç›¸ä¼¼åº¦æ£€ç´¢
        print("\nã€1. ç›¸ä¼¼åº¦æ£€ç´¢ã€‘")
        sim_results = self.search_similarity(query, k)
        for i, (doc, score, idx) in enumerate(sim_results):
            print(f"{i+1}. [ID={idx}] ç›¸ä¼¼åº¦={score:.4f}")
            print(f"   {doc[:80]}...")
        
        # 2. MMRæ£€ç´¢ (Î»=0.5)
        print("\nã€2. MMRæ£€ç´¢ (Î»=0.5)ã€‘")
        mmr_results = self.search_mmr(query, k, lambda_param=0.5)
        for i, (doc, score, idx) in enumerate(mmr_results):
            print(f"{i+1}. [ID={idx}] åˆ†æ•°={score:.4f}")
            print(f"   {doc[:80]}...")
        
        # 3. MMRæ£€ç´¢ (Î»=0.7 - æ›´é‡è§†ç›¸å…³æ€§)
        print("\nã€3. MMRæ£€ç´¢ (Î»=0.7 - åé‡ç›¸å…³æ€§)ã€‘")
        mmr_results_07 = self.search_mmr(query, k, lambda_param=0.7)
        for i, (doc, score, idx) in enumerate(mmr_results_07):
            print(f"{i+1}. [ID={idx}] åˆ†æ•°={score:.4f}")
            print(f"   {doc[:80]}...")
        
        # 4. åˆ†æ
        print("\nã€åˆ†æã€‘")
        sim_ids = [idx for _, _, idx in sim_results]
        mmr_ids = [idx for _, _, idx in mmr_results]
        
        print(f"- ç›¸ä¼¼åº¦æ£€ç´¢è¿”å›çš„æ–‡æ¡£ID: {sim_ids}")
        print(f"- MMRæ£€ç´¢è¿”å›çš„æ–‡æ¡£ID: {mmr_ids}")
        
        if sim_ids == mmr_ids:
            print("- ä¸¤ç§æ–¹æ³•è¿”å›ç›¸åŒç»“æœï¼ˆæ–‡æ¡£å·®å¼‚è¾ƒå¤§ï¼‰")
        else:
            print("- MMRæ£€ç´¢ç»“æœæ›´å¤šæ ·åŒ–")

# å®Œæ•´æ¼”ç¤º
def full_demo():
    """å®Œæ•´æ¼”ç¤º"""
    
    # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
    documents = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œç ”ç©¶å¦‚ä½•è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½",
        "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨ç°ä»£ç¤¾ä¼šä¸­æ‰®æ¼”ç€è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²",
        "AIæ˜¯Artificial Intelligenceçš„ç¼©å†™ï¼ŒæŒ‡çš„æ˜¯äººå·¥æ™ºèƒ½æŠ€æœ¯",
        "æœºå™¨å­¦ä¹ æ˜¯å®ç°äººå·¥æ™ºèƒ½çš„ä¸€ç§é‡è¦æ–¹æ³•ï¼Œé€šè¿‡æ•°æ®è®­ç»ƒæ¨¡å‹",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œ",
        "ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€ï¼Œæ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒçš„å·¥ä½œæ–¹å¼",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯AIçš„ä¸€ä¸ªé‡è¦åº”ç”¨é¢†åŸŸ",
        "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿç†è§£å’Œåˆ†æå›¾åƒ",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»æ•£æ­¥",
        "æˆ‘å–œæ¬¢åƒè‹¹æœï¼Œå®ƒå¾ˆç”œå¾ˆæœ‰è¥å…»",
    ]
    
    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = ComprehensiveRetriever()
    retriever.add_documents(documents)
    
    # æµ‹è¯•æŸ¥è¯¢
    queries = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "æœºå™¨å­¦ä¹ çš„æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ",
    ]
    
    for query in queries:
        retriever.compare_all(query, k=3)
        print("\n" + "="*80 + "\n")

full_demo()
```

#### 4.2 é€‰æ‹©æ£€ç´¢ç­–ç•¥çš„åŸåˆ™

```python
def choose_strategy_guide():
    """æ£€ç´¢ç­–ç•¥é€‰æ‹©æŒ‡å—"""
    
    guide = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  æ£€ç´¢ç­–ç•¥é€‰æ‹©æŒ‡å—                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ã€åœºæ™¯1ï¼šFAQé—®ç­”ã€‘
    â€¢ ç‰¹ç‚¹ï¼šé—®é¢˜æ˜ç¡®ï¼Œç­”æ¡ˆå”¯ä¸€
    â€¢ æ¨èï¼šç›¸ä¼¼åº¦æ£€ç´¢
    â€¢ åŸå› ï¼šéœ€è¦ç²¾ç¡®åŒ¹é…ï¼Œä¸éœ€è¦å¤šæ ·æ€§
    â€¢ ç¤ºä¾‹ï¼š"å¯†ç å¿˜è®°äº†æ€ä¹ˆåŠï¼Ÿ"
    
    ã€åœºæ™¯2ï¼šç ”ç©¶è°ƒç ”ã€‘
    â€¢ ç‰¹ç‚¹ï¼šéœ€è¦å…¨é¢äº†è§£æŸä¸ªä¸»é¢˜
    â€¢ æ¨èï¼šMMRæ£€ç´¢ (Î»=0.5)
    â€¢ åŸå› ï¼šéœ€è¦å¤šè§’åº¦ä¿¡æ¯ï¼Œé¿å…é‡å¤
    â€¢ ç¤ºä¾‹ï¼š"äººå·¥æ™ºèƒ½çš„å‘å±•å†å²"
    
    ã€åœºæ™¯3ï¼šåˆ›æ„å†™ä½œã€‘
    â€¢ ç‰¹ç‚¹ï¼šéœ€è¦ä¸åŒè§†è§’çš„ç´ æ
    â€¢ æ¨èï¼šMMRæ£€ç´¢ (Î»=0.3, åé‡å¤šæ ·æ€§)
    â€¢ åŸå› ï¼šæ¿€å‘åˆ›æ„ï¼Œæä¾›å¤šæ ·åŒ–å†…å®¹
    â€¢ ç¤ºä¾‹ï¼š"å†™ä¸€ç¯‡å…³äºæœªæ¥ç§‘æŠ€çš„æ–‡ç« "
    
    ã€åœºæ™¯4ï¼šè¯­ä¹‰ç†è§£ã€‘
    â€¢ ç‰¹ç‚¹ï¼šæŸ¥è¯¢è¡¨è¾¾æ¨¡ç³Šï¼Œéœ€è¦ç†è§£æ„å›¾
    â€¢ æ¨èï¼šè¯­ä¹‰æ£€ç´¢
    â€¢ åŸå› ï¼šèƒ½ç†è§£åŒä¹‰è¯ã€ç›¸å…³æ¦‚å¿µ
    â€¢ ç¤ºä¾‹ï¼š"æ€ä¹ˆè®©ç”µè„‘å˜èªæ˜ï¼Ÿ"ï¼ˆæ„å›¾ï¼šAIï¼‰
    
    ã€åœºæ™¯5ï¼šæŠ€æœ¯æ–‡æ¡£æŸ¥è¯¢ã€‘
    â€¢ ç‰¹ç‚¹ï¼šéœ€è¦å‡†ç¡®çš„æŠ€æœ¯ä¿¡æ¯
    â€¢ æ¨èï¼šç›¸ä¼¼åº¦æ£€ç´¢ + å…ƒæ•°æ®è¿‡æ»¤
    â€¢ åŸå› ï¼šç²¾ç¡®åº¦ä¼˜å…ˆ
    â€¢ ç¤ºä¾‹ï¼š"å¦‚ä½•é…ç½®nginxåå‘ä»£ç†ï¼Ÿ"
    
    ã€åœºæ™¯6ï¼šæ–°é—»æ£€ç´¢ã€‘
    â€¢ ç‰¹ç‚¹ï¼šéœ€è¦å¤šä¸ªæ¥æºçš„æŠ¥é“
    â€¢ æ¨èï¼šMMRæ£€ç´¢ (Î»=0.6)
    â€¢ åŸå› ï¼šç›¸å…³ä½†ä¸é‡å¤çš„æ–°é—»
    â€¢ ç¤ºä¾‹ï¼š"æœ€æ–°çš„AIæŠ€æœ¯çªç ´"
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  å¿«é€Ÿå†³ç­–æ ‘                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    é—®é¢˜1ï¼šæ˜¯å¦éœ€è¦å¤šæ ·æ€§ï¼Ÿ
    â”œâ”€ å¦ â†’ ä½¿ç”¨ç›¸ä¼¼åº¦æ£€ç´¢
    â””â”€ æ˜¯ â†’ é—®é¢˜2
    
    é—®é¢˜2ï¼šæŸ¥è¯¢è¡¨è¾¾æ˜¯å¦æ˜ç¡®ï¼Ÿ
    â”œâ”€ æ˜¯ â†’ ä½¿ç”¨MMRæ£€ç´¢
    â””â”€ å¦ â†’ ä½¿ç”¨è¯­ä¹‰æ£€ç´¢
    
    é—®é¢˜3ï¼šç›¸å…³æ€§ vs å¤šæ ·æ€§ï¼Ÿ
    â”œâ”€ åé‡ç›¸å…³æ€§ â†’ MMR (Î»=0.7)
    â”œâ”€ å¹³è¡¡ â†’ MMR (Î»=0.5)
    â””â”€ åé‡å¤šæ ·æ€§ â†’ MMR (Î»=0.3)
    """
    
    print(guide)

choose_strategy_guide()
```

---

### äº”ã€æ£€ç´¢æ•ˆæœè¯„ä¼°

#### 5.1 è¯„ä¼°æŒ‡æ ‡

```python
from typing import Set

class RetrievalEvaluator:
    """æ£€ç´¢æ•ˆæœè¯„ä¼°å™¨"""
    
    def precision_at_k(
        self,
        retrieved: List[int],
        relevant: Set[int],
        k: int
    ) -> float:
        """
        Precision@Kï¼šå‰Kä¸ªç»“æœä¸­ç›¸å…³çš„æ¯”ä¾‹
        
        P@K = (æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£æ•°) / K
        """
        retrieved_k = set(retrieved[:k])
        relevant_retrieved = retrieved_k & relevant
        return len(relevant_retrieved) / k if k > 0 else 0
    
    def recall_at_k(
        self,
        retrieved: List[int],
        relevant: Set[int],
        k: int
    ) -> float:
        """
        Recall@Kï¼šç›¸å…³æ–‡æ¡£è¢«æ£€ç´¢åˆ°çš„æ¯”ä¾‹
        
        R@K = (æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£æ•°) / (æ€»ç›¸å…³æ–‡æ¡£æ•°)
        """
        retrieved_k = set(retrieved[:k])
        relevant_retrieved = retrieved_k & relevant
        return len(relevant_retrieved) / len(relevant) if relevant else 0
    
    def f1_at_k(
        self,
        retrieved: List[int],
        relevant: Set[int],
        k: int
    ) -> float:
        """
        F1@Kï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
        
        F1 = 2 * (P * R) / (P + R)
        """
        p = self.precision_at_k(retrieved, relevant, k)
        r = self.recall_at_k(retrieved, relevant, k)
        
        if p + r == 0:
            return 0
        
        return 2 * (p * r) / (p + r)
    
    def mrr(self, retrieved: List[int], relevant: Set[int]) -> float:
        """
        MRR (Mean Reciprocal Rank)ï¼šç¬¬ä¸€ä¸ªç›¸å…³ç»“æœçš„å€’æ•°æ’å
        
        MRR = 1 / (ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ’å)
        """
        for i, doc_id in enumerate(retrieved):
            if doc_id in relevant:
                return 1.0 / (i + 1)
        return 0.0
    
    def ndcg_at_k(
        self,
        retrieved: List[int],
        relevance_scores: dict,
        k: int
    ) -> float:
        """
        NDCG@K (Normalized Discounted Cumulative Gain)
        è€ƒè™‘æ’åä½ç½®çš„è¯„ä¼°æŒ‡æ ‡
        """
        # DCG (Discounted Cumulative Gain)
        dcg = 0
        for i, doc_id in enumerate(retrieved[:k]):
            rel = relevance_scores.get(doc_id, 0)
            dcg += rel / np.log2(i + 2)  # i+2å› ä¸ºlog2(1)=0
        
        # IDCG (Ideal DCG)
        sorted_rels = sorted(relevance_scores.values(), reverse=True)
        idcg = 0
        for i, rel in enumerate(sorted_rels[:k]):
            idcg += rel / np.log2(i + 2)
        
        # NDCG
        return dcg / idcg if idcg > 0 else 0

# ä½¿ç”¨ç¤ºä¾‹
def demo_evaluation():
    """æ¼”ç¤ºè¯„ä¼°"""
    
    evaluator = RetrievalEvaluator()
    
    # å‡è®¾æ£€ç´¢ç»“æœï¼ˆæ–‡æ¡£IDï¼‰
    retrieved = [1, 3, 5, 2, 8, 10, 4]
    
    # çœŸå®ç›¸å…³çš„æ–‡æ¡£ID
    relevant = {1, 2, 4, 6, 7}
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    k = 5
    
    print(f"æ£€ç´¢ç»“æœ: {retrieved[:k]}")
    print(f"ç›¸å…³æ–‡æ¡£: {relevant}")
    print("\nè¯„ä¼°æŒ‡æ ‡:")
    
    precision = evaluator.precision_at_k(retrieved, relevant, k)
    print(f"- Precision@{k}: {precision:.4f}")
    print(f"  å«ä¹‰: å‰{k}ä¸ªç»“æœä¸­ï¼Œ{precision*100:.1f}%æ˜¯ç›¸å…³çš„")
    
    recall = evaluator.recall_at_k(retrieved, relevant, k)
    print(f"\n- Recall@{k}: {recall:.4f}")
    print(f"  å«ä¹‰: {len(relevant)}ä¸ªç›¸å…³æ–‡æ¡£ä¸­ï¼Œæ£€ç´¢åˆ°äº†{recall*100:.1f}%")
    
    f1 = evaluator.f1_at_k(retrieved, relevant, k)
    print(f"\n- F1@{k}: {f1:.4f}")
    print(f"  å«ä¹‰: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„å¹³è¡¡")
    
    mrr = evaluator.mrr(retrieved, relevant)
    print(f"\n- MRR: {mrr:.4f}")
    print(f"  å«ä¹‰: ç¬¬ä¸€ä¸ªç›¸å…³ç»“æœåœ¨ç¬¬{int(1/mrr)}ä½")
    
    # å¸¦ç›¸å…³æ€§åˆ†æ•°çš„è¯„ä¼°
    relevance_scores = {1: 3, 2: 2, 4: 2, 6: 1, 7: 1, 3: 0, 5: 0, 8: 0, 10: 0}
    ndcg = evaluator.ndcg_at_k(retrieved, relevance_scores, k)
    print(f"\n- NDCG@{k}: {ndcg:.4f}")
    print(f"  å«ä¹‰: è€ƒè™‘æ’åä½ç½®çš„ç»¼åˆæŒ‡æ ‡")

demo_evaluation()
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šå®ç°æ··åˆæ£€ç´¢

ç»“åˆç›¸ä¼¼åº¦å’ŒMMRï¼Œè®¾è®¡ä¸€ä¸ªè‡ªé€‚åº”æ£€ç´¢ç­–ç•¥

### ç»ƒä¹ 2ï¼šä¼˜åŒ–MMRæ€§èƒ½

MMRè®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¼˜åŒ–ç®—æ³•æå‡é€Ÿåº¦

### ç»ƒä¹ 3ï¼šA/Bæµ‹è¯•

åœ¨å®é™…åœºæ™¯ä¸­å¯¹æ¯”ä¸åŒç­–ç•¥çš„æ•ˆæœ

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **ä¸‰ç§æ£€ç´¢ç®—æ³•**
   - ç›¸ä¼¼åº¦ï¼šç®€å•å¿«é€Ÿï¼Œä½†æ˜“é‡å¤
   - MMRï¼šå¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
   - è¯­ä¹‰ï¼šç†è§£æ„å›¾ï¼Œä¸æ‹˜æ³¥å­—é¢

2. **é€‰æ‹©åŸåˆ™**
   - FAQï¼šç›¸ä¼¼åº¦æ£€ç´¢
   - ç ”ç©¶ï¼šMMRæ£€ç´¢
   - æ¨¡ç³ŠæŸ¥è¯¢ï¼šè¯­ä¹‰æ£€ç´¢

3. **è¯„ä¼°æŒ‡æ ‡**
   - Precision@Kï¼šç²¾ç¡®ç‡
   - Recall@Kï¼šå¬å›ç‡
   - F1@Kï¼šç»¼åˆæŒ‡æ ‡
   - NDCGï¼šè€ƒè™‘æ’å

### æœ€ä½³å®è·µ

âœ… æ ¹æ®åœºæ™¯é€‰æ‹©ç­–ç•¥
âœ… è°ƒæ•´MMRçš„Î»å‚æ•°
âœ… ä½¿ç”¨è¯„ä¼°æŒ‡æ ‡éªŒè¯
âœ… A/Bæµ‹è¯•å¯¹æ¯”æ•ˆæœ
âœ… æŒç»­ä¼˜åŒ–è¿­ä»£

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬57è¯¾ï¼šæ··åˆæ£€ç´¢ï¼šå‘é‡+å…³é”®è¯+å…ƒæ•°æ®**

- å¦‚ä½•ç»“åˆå¤šç§æ£€ç´¢æ–¹å¼
- BM25å…³é”®è¯æ£€ç´¢
- å…ƒæ•°æ®è¿‡æ»¤
- å®Œæ•´çš„æ··åˆæ£€ç´¢ç³»ç»Ÿ

**è®©æ£€ç´¢æ›´ç²¾å‡†ã€æ›´å…¨é¢ï¼** ğŸ¯

---

**ğŸ’ª è®°ä½ï¼šé€‰å¯¹æ£€ç´¢ç­–ç•¥ï¼ŒRAGæ•ˆæœæå‡ä¸€åŠï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
