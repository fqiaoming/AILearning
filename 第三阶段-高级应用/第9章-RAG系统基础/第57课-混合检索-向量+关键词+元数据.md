![RAGç³»ç»Ÿæ¶æ„](./images/rag_flow.svg)
*å›¾ï¼šRAGç³»ç»Ÿæ¶æ„*

# ç¬¬57è¯¾ï¼šæ··åˆæ£€ç´¢ï¼šå‘é‡+å…³é”®è¯+å…ƒæ•°æ®

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŒæ¡æ··åˆæ£€ç´¢æŠ€æœ¯ï¼Œç»“åˆå‘é‡ã€å…³é”®è¯å’Œå…ƒæ•°æ®ï¼Œæ„å»ºæ›´å¼ºå¤§çš„æ£€ç´¢ç³»ç»Ÿ
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šBM25ç®—æ³•ã€å‘é‡æ£€ç´¢ã€å…ƒæ•°æ®è¿‡æ»¤ã€ç»“æœèåˆ
> 
> **å®æˆ˜æ¡ˆä¾‹**ï¼šå®ç°ä¼ä¸šçº§æ··åˆæ£€ç´¢å¼•æ“
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š85åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ3åˆ†é’Ÿï¼‰

### ğŸ¯ å‰è¨€

"ä¸ŠèŠ‚è¯¾æˆ‘ä»¬å­¦äº†ä¸‰ç§æ£€ç´¢ç®—æ³•ï¼Œä½†æœ‰ä¸ªé—®é¢˜ï¼š**å•ä¸€æ£€ç´¢æ–¹å¼éƒ½æœ‰å±€é™æ€§ï¼**

ä¸¾ä¸ªä¾‹å­ï¼š

ç”¨æˆ·é—®ï¼š'2023å¹´å…³äºäººå·¥æ™ºèƒ½çš„æ”¿ç­–æ–‡ä»¶'

- **çº¯å‘é‡æ£€ç´¢**ï¼šå¯èƒ½æ‰¾åˆ°AIç›¸å…³å†…å®¹ï¼Œä½†æ—¶é—´ä¸å¯¹
- **çº¯å…³é”®è¯æ£€ç´¢**ï¼šèƒ½åŒ¹é…'2023'å’Œ'AI'ï¼Œä½†è¯­ä¹‰ç†è§£å·®
- **çº¯å…ƒæ•°æ®è¿‡æ»¤**ï¼šèƒ½æŒ‰æ—¶é—´ç­›é€‰ï¼Œä½†ä¸çŸ¥é“å“ªä¸ªæœ€ç›¸å…³

**æ€ä¹ˆåŠï¼Ÿæ··åˆæ£€ç´¢ï¼**

æŠŠä¸‰ç§æ–¹å¼ç»“åˆèµ·æ¥ï¼š
1. å‘é‡æ£€ç´¢ï¼šç†è§£è¯­ä¹‰
2. å…³é”®è¯æ£€ç´¢ï¼šç²¾ç¡®åŒ¹é…
3. å…ƒæ•°æ®è¿‡æ»¤ï¼šé™å®šèŒƒå›´

ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘ä¼šç”¨85åˆ†é’Ÿï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ ï¼š

âœ… **BM25ç®—æ³•**ï¼šç»å…¸çš„å…³é”®è¯æ£€ç´¢ç®—æ³•
âœ… **å‘é‡æ£€ç´¢**ï¼šè¯­ä¹‰ç†è§£
âœ… **å…ƒæ•°æ®è¿‡æ»¤**ï¼šæ¡ä»¶ç­›é€‰
âœ… **ç»“æœèåˆ**ï¼šå¦‚ä½•åˆå¹¶å¤šç§æ£€ç´¢ç»“æœ
âœ… **æ··åˆæ£€ç´¢ç³»ç»Ÿ**ï¼šå®Œæ•´çš„ä¼ä¸šçº§å®ç°

å­¦å®Œè¿™ä¸€è¯¾ï¼Œä½ çš„RAGç³»ç»Ÿæ£€ç´¢èƒ½åŠ›å°†æå‡ä¸€ä¸ªæ¡£æ¬¡ï¼

è¿™æ˜¯RAGç³»ç»Ÿçš„æ ¸å¿ƒç«äº‰åŠ›ï¼Œå‡†å¤‡å¥½äº†å—ï¼Ÿ

è®©æˆ‘ä»¬å¼€å§‹ï¼"

---

### ğŸ’¡ æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### ä¸ºä»€ä¹ˆéœ€è¦æ··åˆæ£€ç´¢ï¼Ÿ

```
ã€å•ä¸€æ£€ç´¢çš„å±€é™ã€‘

1. çº¯å‘é‡æ£€ç´¢
   âœ… ä¼˜ç‚¹ï¼šè¯­ä¹‰ç†è§£å¥½
   âŒ ç¼ºç‚¹ï¼šå¯¹ä¸“æœ‰åè¯ã€æ•°å­—ä¸æ•æ„Ÿ
   
   ä¾‹å­ï¼šæŸ¥è¯¢"Python 3.11æ–°ç‰¹æ€§"
   å¯èƒ½åŒ¹é…åˆ°"Python 3.10"ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼‰
   è€Œä¸æ˜¯ç²¾ç¡®çš„"3.11"

2. çº¯å…³é”®è¯æ£€ç´¢
   âœ… ä¼˜ç‚¹ï¼šç²¾ç¡®åŒ¹é…
   âŒ ç¼ºç‚¹ï¼šæ— æ³•ç†è§£åŒä¹‰è¯ã€ç›¸å…³æ¦‚å¿µ
   
   ä¾‹å­ï¼šæŸ¥è¯¢"å¦‚ä½•å­¦ä¹ AI"
   æ— æ³•åŒ¹é…"äººå·¥æ™ºèƒ½å­¦ä¹ æŒ‡å—"
   ï¼ˆè™½ç„¶AI=äººå·¥æ™ºèƒ½ï¼‰

3. çº¯å…ƒæ•°æ®è¿‡æ»¤
   âœ… ä¼˜ç‚¹ï¼šç²¾ç¡®ç­›é€‰æ¡ä»¶
   âŒ ç¼ºç‚¹ï¼šæ— æ³•è¯„ä¼°å†…å®¹ç›¸å…³æ€§
   
   ä¾‹å­ï¼šç­›é€‰"2023å¹´çš„æ–‡æ¡£"
   ä½†ä¸çŸ¥é“å“ªä¸ªå†…å®¹æœ€ç›¸å…³

ã€æ··åˆæ£€ç´¢çš„ä¼˜åŠ¿ã€‘

ç»“åˆä¸‰è€…ä¼˜åŠ¿ï¼š
â€¢ å‘é‡æ£€ç´¢ï¼šæ‰¾åˆ°è¯­ä¹‰ç›¸å…³çš„å€™é€‰é›†
â€¢ å…³é”®è¯æ£€ç´¢ï¼šç¡®ä¿å…³é”®è¯ç²¾ç¡®åŒ¹é…
â€¢ å…ƒæ•°æ®è¿‡æ»¤ï¼šæ»¡è¶³ç‰¹å®šæ¡ä»¶
â€¢ ç»“æœèåˆï¼šç»¼åˆè¯„åˆ†ï¼Œæœ€ä¼˜æ’åº
```

#### æ··åˆæ£€ç´¢æ¶æ„

```
ç”¨æˆ·æŸ¥è¯¢
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æŸ¥è¯¢åˆ†æ                      â”‚
â”‚  â€¢ æå–å…³é”®è¯                  â”‚
â”‚  â€¢ æå–å…ƒæ•°æ®æ¡ä»¶              â”‚
â”‚  â€¢ ç”Ÿæˆå‘é‡                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‘é‡æ£€ç´¢     â”‚  å…³é”®è¯æ£€ç´¢   â”‚  å…ƒæ•°æ®è¿‡æ»¤   â”‚
â”‚  (è¯­ä¹‰ç›¸ä¼¼)   â”‚  (BM25)       â”‚  (æ¡ä»¶ç­›é€‰)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“               â†“               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç»“æœèåˆ (Reciprocal Rank Fusion)            â”‚
â”‚  â€¢ åˆå¹¶å¤šä¸ªæ’åºåˆ—è¡¨                           â”‚
â”‚  â€¢ è®¡ç®—ç»¼åˆå¾—åˆ†                               â”‚
â”‚  â€¢ é‡æ–°æ’åº                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æœ€ç»ˆç»“æœ
```

---

## ğŸ“š çŸ¥è¯†è®²è§£

### ä¸€ã€BM25å…³é”®è¯æ£€ç´¢

#
![æ··åˆæ£€ç´¢](./images/hybrid.svg)
*å›¾ï¼šæ··åˆæ£€ç´¢*

### 1.1 BM25ç®—æ³•åŸç†

```
BM25 (Best Matching 25) æ˜¯ä¸€ç§ç»å…¸çš„å…³é”®è¯æ£€ç´¢ç®—æ³•

æ ¸å¿ƒæ€æƒ³ï¼š
1. è¯é¢‘ï¼ˆTFï¼‰ï¼šè¯åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„é¢‘ç‡
2. é€†æ–‡æ¡£é¢‘ç‡ï¼ˆIDFï¼‰ï¼šè¯çš„ç¨€æœ‰ç¨‹åº¦
3. æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–

å…¬å¼ï¼š
BM25(Q, D) = Î£ IDF(qi) Ã— (f(qi,D) Ã— (k1+1)) / (f(qi,D) + k1 Ã— (1-b+bÃ—|D|/avgdl))

å…¶ä¸­ï¼š
- Q: æŸ¥è¯¢
- D: æ–‡æ¡£
- qi: æŸ¥è¯¢ä¸­çš„ç¬¬iä¸ªè¯
- f(qi,D): qiåœ¨æ–‡æ¡£Dä¸­çš„å‡ºç°æ¬¡æ•°
- |D|: æ–‡æ¡£Dçš„é•¿åº¦
- avgdl: æ‰€æœ‰æ–‡æ¡£çš„å¹³å‡é•¿åº¦
- k1: æ§åˆ¶è¯é¢‘é¥±å’Œåº¦ï¼ˆé€šå¸¸1.2-2.0ï¼‰
- b: æ§åˆ¶é•¿åº¦å½’ä¸€åŒ–ï¼ˆé€šå¸¸0.75ï¼‰

IDF(qi) = log((N - n(qi) + 0.5) / (n(qi) + 0.5) + 1)
- N: æ€»æ–‡æ¡£æ•°
- n(qi): åŒ…å«qiçš„æ–‡æ¡£æ•°

ç›´è§‚ç†è§£ï¼š
â€¢ ä¸€ä¸ªè¯åœ¨æ–‡æ¡£ä¸­å‡ºç°è¶Šå¤šï¼Œå¾—åˆ†è¶Šé«˜ï¼ˆä½†æœ‰é¥±å’Œï¼‰
â€¢ ä¸€ä¸ªè¯è¶Šç¨€æœ‰ï¼Œå¾—åˆ†è¶Šé«˜
â€¢ è¾ƒé•¿çš„æ–‡æ¡£ä¼šè¢«é€‚å½“æƒ©ç½š
```

#### 1.2 BM25å®ç°

```python
import math
import re
from typing import List, Dict, Tuple
from collections import Counter, defaultdict

class BM25Retriever:
    """BM25æ£€ç´¢å™¨"""
    
    def __init__(self, k1: float = 1.5, b: float = 0.75):
        """
        Args:
            k1: è¯é¢‘é¥±å’Œåº¦å‚æ•°ï¼ˆ1.2-2.0ï¼‰
            b: é•¿åº¦å½’ä¸€åŒ–å‚æ•°ï¼ˆ0.75æ¨èï¼‰
        """
        self.k1 = k1
        self.b = b
        
        self.documents = []
        self.doc_freqs = []  # æ¯ä¸ªæ–‡æ¡£çš„è¯é¢‘
        self.idf = {}  # æ¯ä¸ªè¯çš„IDFå€¼
        self.avg_doc_len = 0  # å¹³å‡æ–‡æ¡£é•¿åº¦
    
    def tokenize(self, text: str) -> List[str]:
        """åˆ†è¯ï¼ˆç®€å•å®ç°ï¼‰"""
        # è½¬å°å†™
        text = text.lower()
        
        # åˆ†è¯ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        tokens = re.findall(r'\w+', text)
        
        return tokens
    
    def build_index(self, documents: List[str]):
        """æ„å»ºç´¢å¼•"""
        print(f"ğŸ“š æ„å»ºBM25ç´¢å¼•...")
        
        self.documents = documents
        num_docs = len(documents)
        
        # 1. è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„è¯é¢‘
        self.doc_freqs = []
        doc_lens = []
        
        for doc in documents:
            tokens = self.tokenize(doc)
            doc_lens.append(len(tokens))
            freq = Counter(tokens)
            self.doc_freqs.append(freq)
        
        # 2. è®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦
        self.avg_doc_len = sum(doc_lens) / num_docs if num_docs > 0 else 0
        
        # 3. è®¡ç®—IDF
        # ç»Ÿè®¡æ¯ä¸ªè¯å‡ºç°åœ¨å¤šå°‘ä¸ªæ–‡æ¡£ä¸­
        doc_count = defaultdict(int)
        for freq in self.doc_freqs:
            for word in freq.keys():
                doc_count[word] += 1
        
        # è®¡ç®—IDFå€¼
        self.idf = {}
        for word, count in doc_count.items():
            # BM25çš„IDFå…¬å¼
            self.idf[word] = math.log(
                (num_docs - count + 0.5) / (count + 0.5) + 1
            )
        
        print(f"  âœ… ç´¢å¼•æ„å»ºå®Œæˆ")
        print(f"  ğŸ“„ æ–‡æ¡£æ•°: {num_docs}")
        print(f"  ğŸ“ å¹³å‡æ–‡æ¡£é•¿åº¦: {self.avg_doc_len:.2f}")
        print(f"  ğŸ“– è¯æ±‡è¡¨å¤§å°: {len(self.idf)}")
    
    def get_score(self, query: str, doc_idx: int) -> float:
        """è®¡ç®—BM25å¾—åˆ†"""
        # æŸ¥è¯¢åˆ†è¯
        query_tokens = self.tokenize(query)
        
        # æ–‡æ¡£è¯é¢‘
        doc_freq = self.doc_freqs[doc_idx]
        
        # æ–‡æ¡£é•¿åº¦
        doc_len = sum(doc_freq.values())
        
        # è®¡ç®—å¾—åˆ†
        score = 0.0
        
        for token in query_tokens:
            if token not in doc_freq:
                continue
            
            # è¯é¢‘
            freq = doc_freq[token]
            
            # IDF
            idf = self.idf.get(token, 0)
            
            # BM25å…¬å¼
            numerator = freq * (self.k1 + 1)
            denominator = freq + self.k1 * (
                1 - self.b + self.b * doc_len / self.avg_doc_len
            )
            
            score += idf * (numerator / denominator)
        
        return score
    
    def search(self, query: str, k: int = 5) -> List[Tuple[str, float, int]]:
        """æ£€ç´¢"""
        # è®¡ç®—æ‰€æœ‰æ–‡æ¡£çš„å¾—åˆ†
        scores = []
        for i, doc in enumerate(self.documents):
            score = self.get_score(query, i)
            scores.append((doc, score, i))
        
        # æŒ‰å¾—åˆ†æ’åº
        scores.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›top-k
        return scores[:k]

# ä½¿ç”¨ç¤ºä¾‹
def demo_bm25():
    """æ¼”ç¤ºBM25"""
    
    # 1. å‡†å¤‡æ–‡æ¡£
    documents = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åº”ç”¨",
        "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿç†è§£å›¾åƒ",
        "Pythonæ˜¯äººå·¥æ™ºèƒ½å¼€å‘çš„ä¸»æµç¼–ç¨‹è¯­è¨€",
        "TensorFlowå’ŒPyTorchæ˜¯æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶",
        "ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€",
    ]
    
    # 2. æ„å»ºç´¢å¼•
    bm25 = BM25Retriever()
    bm25.build_index(documents)
    
    # 3. æŸ¥è¯¢
    query = "äººå·¥æ™ºèƒ½æŠ€æœ¯"
    
    print(f"\nğŸ” æŸ¥è¯¢: {query}")
    print("="*60)
    
    results = bm25.search(query, k=5)
    
    for i, (doc, score, idx) in enumerate(results):
        print(f"\n{i+1}. [ID={idx}] BM25å¾—åˆ†={score:.4f}")
        print(f"   {doc}")
    
    # 4. å¯¹æ¯”ä¸åŒæŸ¥è¯¢
    queries = [
        "æ·±åº¦å­¦ä¹ ",
        "Pythonç¼–ç¨‹",
        "æœºå™¨å­¦ä¹ ç®—æ³•",
    ]
    
    print("\n\n" + "="*60)
    print("ğŸ“Š å¤šæŸ¥è¯¢å¯¹æ¯”")
    print("="*60)
    
    for query in queries:
        print(f"\næŸ¥è¯¢: {query}")
        results = bm25.search(query, k=3)
        for i, (doc, score, idx) in enumerate(results):
            print(f"  {i+1}. [{score:.2f}] {doc[:40]}...")

demo_bm25()
```

#### 1.3 BM25çš„ç‰¹ç‚¹

```python
def analyze_bm25_features():
    """åˆ†æBM25ç‰¹æ€§"""
    
    documents = [
        "äººå·¥æ™ºèƒ½",  # çŸ­æ–‡æ¡£
        "äººå·¥æ™ºèƒ½ äººå·¥æ™ºèƒ½ äººå·¥æ™ºèƒ½",  # é«˜é¢‘ä½†çŸ­
        "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨ç°ä»£ç¤¾ä¼šä¸­è¶Šæ¥è¶Šé‡è¦ï¼Œäººå·¥æ™ºèƒ½åº”ç”¨å¹¿æ³›",  # é•¿æ–‡æ¡£
    ]
    
    bm25 = BM25Retriever()
    bm25.build_index(documents)
    
    query = "äººå·¥æ™ºèƒ½"
    
    print("ğŸ”¬ BM25ç‰¹æ€§åˆ†æ")
    print("="*60)
    
    for i, doc in enumerate(documents):
        score = bm25.get_score(query, i)
        freq = bm25.doc_freqs[i][query]
        doc_len = sum(bm25.doc_freqs[i].values())
        
        print(f"\næ–‡æ¡£{i+1}:")
        print(f"  å†…å®¹: {doc[:50]}...")
        print(f"  è¯é¢‘: {freq}")
        print(f"  é•¿åº¦: {doc_len}")
        print(f"  BM25å¾—åˆ†: {score:.4f}")
    
    print("\nè§‚å¯Ÿ:")
    print("1. è¯é¢‘å¢åŠ ï¼Œå¾—åˆ†ä¸Šå‡ï¼ˆä½†æœ‰é¥±å’Œæ•ˆåº”ï¼‰")
    print("2. æ–‡æ¡£è¶Šé•¿ï¼Œå¾—åˆ†æœ‰é€‚å½“æƒ©ç½š")
    print("3. å¹³è¡¡äº†è¯é¢‘å’Œæ–‡æ¡£é•¿åº¦")

analyze_bm25_features()
```

---

### äºŒã€å‘é‡æ£€ç´¢

#### 2.1 å‘é‡æ£€ç´¢å®ç°

```python
from sentence_transformers import SentenceTransformer
import numpy as np

class VectorRetriever:
    """å‘é‡æ£€ç´¢å™¨"""
    
    def __init__(self, model_name: str = "moka-ai/m3e-base"):
        print(f"ğŸ”¢ åŠ è½½å‘é‡æ¨¡å‹: {model_name}")
        self.model = SentenceTransformer(model_name)
        self.documents = []
        self.embeddings = None
    
    def build_index(self, documents: List[str]):
        """æ„å»ºå‘é‡ç´¢å¼•"""
        print(f"ğŸ“š æ„å»ºå‘é‡ç´¢å¼•...")
        
        self.documents = documents
        
        # æ‰¹é‡ç¼–ç 
        self.embeddings = self.model.encode(
            documents,
            convert_to_numpy=True,
            show_progress_bar=True
        )
        
        print(f"  âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ")
        print(f"  ğŸ“„ æ–‡æ¡£æ•°: {len(documents)}")
        print(f"  ğŸ“ å‘é‡ç»´åº¦: {self.embeddings.shape[1]}")
    
    def search(self, query: str, k: int = 5) -> List[Tuple[str, float, int]]:
        """å‘é‡æ£€ç´¢"""
        # ç¼–ç æŸ¥è¯¢
        query_embedding = self.model.encode([query], convert_to_numpy=True)[0]
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for i, doc_embedding in enumerate(self.embeddings):
            sim = np.dot(query_embedding, doc_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
            )
            similarities.append((self.documents[i], sim, i))
        
        # æ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:k]

# ä½¿ç”¨ç¤ºä¾‹
def demo_vector_retrieval():
    """æ¼”ç¤ºå‘é‡æ£€ç´¢"""
    
    documents = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åº”ç”¨",
        "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿç†è§£å›¾åƒ",
        "Pythonæ˜¯äººå·¥æ™ºèƒ½å¼€å‘çš„ä¸»æµç¼–ç¨‹è¯­è¨€",
        "TensorFlowå’ŒPyTorchæ˜¯æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶",
        "ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€",
    ]
    
    vector_retriever = VectorRetriever()
    vector_retriever.build_index(documents)
    
    query = "AIæŠ€æœ¯"  # æ³¨æ„ï¼šæ²¡æœ‰ç›´æ¥åŒ…å«"äººå·¥æ™ºèƒ½"
    
    print(f"\nğŸ” æŸ¥è¯¢: {query}")
    print("="*60)
    
    results = vector_retriever.search(query, k=5)
    
    for i, (doc, score, idx) in enumerate(results):
        print(f"\n{i+1}. [ID={idx}] ç›¸ä¼¼åº¦={score:.4f}")
        print(f"   {doc}")

demo_vector_retrieval()
```

---

### ä¸‰ã€å…ƒæ•°æ®è¿‡æ»¤

#### 3.1 å…ƒæ•°æ®è¿‡æ»¤å™¨

```python
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Optional, Callable

@dataclass
class DocumentWithMetadata:
    """å¸¦å…ƒæ•°æ®çš„æ–‡æ¡£"""
    content: str
    metadata: Dict[str, Any]
    doc_id: int

class MetadataFilter:
    """å…ƒæ•°æ®è¿‡æ»¤å™¨"""
    
    def __init__(self):
        self.documents: List[DocumentWithMetadata] = []
    
    def add_documents(self, documents: List[DocumentWithMetadata]):
        """æ·»åŠ æ–‡æ¡£"""
        self.documents = documents
    
    def filter_by_field(
        self,
        field: str,
        value: Any,
        operator: str = "eq"
    ) -> List[DocumentWithMetadata]:
        """æŒ‰å­—æ®µè¿‡æ»¤"""
        filtered = []
        
        for doc in self.documents:
            if field not in doc.metadata:
                continue
            
            meta_value = doc.metadata[field]
            
            # æ ¹æ®æ“ä½œç¬¦åˆ¤æ–­
            match = False
            if operator == "eq":  # ç­‰äº
                match = meta_value == value
            elif operator == "ne":  # ä¸ç­‰äº
                match = meta_value != value
            elif operator == "gt":  # å¤§äº
                match = meta_value > value
            elif operator == "gte":  # å¤§äºç­‰äº
                match = meta_value >= value
            elif operator == "lt":  # å°äº
                match = meta_value < value
            elif operator == "lte":  # å°äºç­‰äº
                match = meta_value <= value
            elif operator == "in":  # åŒ…å«
                match = meta_value in value
            elif operator == "contains":  # å­—ç¬¦ä¸²åŒ…å«
                match = value in str(meta_value)
            
            if match:
                filtered.append(doc)
        
        return filtered
    
    def filter_by_conditions(
        self,
        conditions: List[Dict[str, Any]],
        logic: str = "and"
    ) -> List[DocumentWithMetadata]:
        """æŒ‰å¤šä¸ªæ¡ä»¶è¿‡æ»¤"""
        if not conditions:
            return self.documents
        
        # å¯¹æ¯ä¸ªæ¡ä»¶åˆ†åˆ«è¿‡æ»¤
        results = []
        for condition in conditions:
            field = condition.get("field")
            value = condition.get("value")
            operator = condition.get("operator", "eq")
            
            filtered = self.filter_by_field(field, value, operator)
            results.append(set(doc.doc_id for doc in filtered))
        
        # æ ¹æ®é€»è¾‘ç»„åˆç»“æœ
        if logic == "and":
            # äº¤é›†
            final_ids = set.intersection(*results) if results else set()
        else:  # "or"
            # å¹¶é›†
            final_ids = set.union(*results) if results else set()
        
        # è¿”å›æ–‡æ¡£
        return [doc for doc in self.documents if doc.doc_id in final_ids]

# ä½¿ç”¨ç¤ºä¾‹
def demo_metadata_filter():
    """æ¼”ç¤ºå…ƒæ•°æ®è¿‡æ»¤"""
    
    # 1. å‡†å¤‡å¸¦å…ƒæ•°æ®çš„æ–‡æ¡£
    documents = [
        DocumentWithMetadata(
            content="äººå·¥æ™ºèƒ½æŠ€æœ¯æŠ¥å‘Š2023",
            metadata={
                "year": 2023,
                "category": "æŠ€æœ¯",
                "author": "å¼ ä¸‰",
                "tags": ["AI", "æœºå™¨å­¦ä¹ "]
            },
            doc_id=0
        ),
        DocumentWithMetadata(
            content="æœºå™¨å­¦ä¹ å®æˆ˜æŒ‡å—",
            metadata={
                "year": 2022,
                "category": "æ•™ç¨‹",
                "author": "æå››",
                "tags": ["æœºå™¨å­¦ä¹ ", "å®æˆ˜"]
            },
            doc_id=1
        ),
        DocumentWithMetadata(
            content="æ·±åº¦å­¦ä¹ å‰æ²¿ç ”ç©¶2023",
            metadata={
                "year": 2023,
                "category": "ç ”ç©¶",
                "author": "ç‹äº”",
                "tags": ["æ·±åº¦å­¦ä¹ ", "å‰æ²¿"]
            },
            doc_id=2
        ),
        DocumentWithMetadata(
            content="Pythonç¼–ç¨‹å…¥é—¨",
            metadata={
                "year": 2021,
                "category": "æ•™ç¨‹",
                "author": "èµµå…­",
                "tags": ["Python", "ç¼–ç¨‹"]
            },
            doc_id=3
        ),
    ]
    
    # 2. åˆ›å»ºè¿‡æ»¤å™¨
    filter = MetadataFilter()
    filter.add_documents(documents)
    
    # 3. å•æ¡ä»¶è¿‡æ»¤
    print("ã€ç¤ºä¾‹1ï¼šå¹´ä»½ = 2023ã€‘")
    results = filter.filter_by_field("year", 2023, "eq")
    for doc in results:
        print(f"  â€¢ {doc.content} (year={doc.metadata['year']})")
    
    # 4. å¤šæ¡ä»¶è¿‡æ»¤ï¼ˆANDï¼‰
    print("\nã€ç¤ºä¾‹2ï¼šå¹´ä»½=2023 AND ç±»åˆ«=æŠ€æœ¯ã€‘")
    results = filter.filter_by_conditions([
        {"field": "year", "value": 2023, "operator": "eq"},
        {"field": "category", "value": "æŠ€æœ¯", "operator": "eq"}
    ], logic="and")
    for doc in results:
        print(f"  â€¢ {doc.content}")
    
    # 5. å¤šæ¡ä»¶è¿‡æ»¤ï¼ˆORï¼‰
    print("\nã€ç¤ºä¾‹3ï¼šå¹´ä»½=2023 OR ç±»åˆ«=æ•™ç¨‹ã€‘")
    results = filter.filter_by_conditions([
        {"field": "year", "value": 2023, "operator": "eq"},
        {"field": "category", "value": "æ•™ç¨‹", "operator": "eq"}
    ], logic="or")
    for doc in results:
        print(f"  â€¢ {doc.content}")
    
    # 6. èŒƒå›´è¿‡æ»¤
    print("\nã€ç¤ºä¾‹4ï¼šå¹´ä»½ >= 2022ã€‘")
    results = filter.filter_by_field("year", 2022, "gte")
    for doc in results:
        print(f"  â€¢ {doc.content} (year={doc.metadata['year']})")

demo_metadata_filter()
```

---

### å››ã€ç»“æœèåˆ

#### 4.1 Reciprocal Rank Fusion (RRF)

```
RRFæ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„ç»“æœèåˆç®—æ³•

åŸç†ï¼š
å¯¹äºæ¯ä¸ªæ£€ç´¢ç»“æœåˆ—è¡¨ï¼Œæ ¹æ®æ’åè®¡ç®—åˆ†æ•°ï¼š
RRF_score = Î£ 1 / (k + rank_i)

å…¶ä¸­ï¼š
- rank_i: æ–‡æ¡£åœ¨ç¬¬iä¸ªåˆ—è¡¨ä¸­çš„æ’å
- k: å¸¸æ•°ï¼ˆé€šå¸¸60ï¼‰

ä¼˜ç‚¹ï¼š
1. ä¸éœ€è¦å½’ä¸€åŒ–åˆ†æ•°
2. å¤„ç†ä¸åŒé‡çº§çš„åˆ†æ•°
3. é²æ£’æ€§å¥½

ç¤ºä¾‹ï¼š
æ–‡æ¡£A:
  - åœ¨å‘é‡æ£€ç´¢ä¸­æ’åç¬¬1 â†’ 1/(60+1) = 0.0164
  - åœ¨BM25æ£€ç´¢ä¸­æ’åç¬¬3 â†’ 1/(60+3) = 0.0159
  - RRFæ€»åˆ†: 0.0323

æ–‡æ¡£B:
  - åœ¨å‘é‡æ£€ç´¢ä¸­æ’åç¬¬2 â†’ 1/(60+2) = 0.0161
  - åœ¨BM25æ£€ç´¢ä¸­æœªå‡ºç° â†’ 0
  - RRFæ€»åˆ†: 0.0161

æ–‡æ¡£Aå¾—åˆ†æ›´é«˜ï¼ˆåœ¨ä¸¤ä¸ªåˆ—è¡¨ä¸­éƒ½å‡ºç°ï¼‰
```

#### 4.2 RRFå®ç°

```python
from collections import defaultdict

class ResultFusion:
    """ç»“æœèåˆå™¨"""
    
    @staticmethod
    def reciprocal_rank_fusion(
        result_lists: List[List[Tuple[str, float, int]]],
        k: int = 60
    ) -> List[Tuple[str, float, int]]:
        """
        Reciprocal Rank Fusion
        
        Args:
            result_lists: å¤šä¸ªæ£€ç´¢ç»“æœåˆ—è¡¨
            k: RRFå¸¸æ•°ï¼ˆé€šå¸¸60ï¼‰
        
        Returns:
            èåˆåçš„ç»“æœåˆ—è¡¨
        """
        # å­˜å‚¨æ¯ä¸ªæ–‡æ¡£çš„RRFåˆ†æ•°
        rrf_scores = defaultdict(float)
        
        # å­˜å‚¨æ–‡æ¡£å†…å®¹å’ŒIDçš„æ˜ å°„
        doc_map = {}
        
        # éå†æ¯ä¸ªç»“æœåˆ—è¡¨
        for result_list in result_lists:
            for rank, (content, score, doc_id) in enumerate(result_list):
                # è®¡ç®—RRFåˆ†æ•°
                rrf_score = 1.0 / (k + rank + 1)
                rrf_scores[doc_id] += rrf_score
                
                # ä¿å­˜æ–‡æ¡£ä¿¡æ¯
                if doc_id not in doc_map:
                    doc_map[doc_id] = content
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_results = []
        for doc_id, score in rrf_scores.items():
            final_results.append((doc_map[doc_id], score, doc_id))
        
        # æŒ‰åˆ†æ•°æ’åº
        final_results.sort(key=lambda x: x[1], reverse=True)
        
        return final_results
    
    @staticmethod
    def weighted_fusion(
        result_lists: List[List[Tuple[str, float, int]]],
        weights: List[float]
    ) -> List[Tuple[str, float, int]]:
        """
        åŠ æƒèåˆ
        
        Args:
            result_lists: å¤šä¸ªæ£€ç´¢ç»“æœåˆ—è¡¨
            weights: æ¯ä¸ªåˆ—è¡¨çš„æƒé‡
        """
        if len(result_lists) != len(weights):
            raise ValueError("ç»“æœåˆ—è¡¨æ•°é‡ä¸æƒé‡æ•°é‡ä¸åŒ¹é…")
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(weights)
        weights = [w / total_weight for w in weights]
        
        # å­˜å‚¨åŠ æƒåˆ†æ•°
        weighted_scores = defaultdict(float)
        doc_map = {}
        
        # éå†æ¯ä¸ªç»“æœåˆ—è¡¨
        for result_list, weight in zip(result_lists, weights):
            # å¯¹è¯¥åˆ—è¡¨ä¸­çš„åˆ†æ•°è¿›è¡Œå½’ä¸€åŒ–
            if not result_list:
                continue
            
            max_score = max(score for _, score, _ in result_list)
            min_score = min(score for _, score, _ in result_list)
            score_range = max_score - min_score if max_score != min_score else 1
            
            for content, score, doc_id in result_list:
                # å½’ä¸€åŒ–åˆ°0-1
                normalized_score = (score - min_score) / score_range
                
                # åŠ æƒ
                weighted_scores[doc_id] += normalized_score * weight
                
                if doc_id not in doc_map:
                    doc_map[doc_id] = content
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_results = []
        for doc_id, score in weighted_scores.items():
            final_results.append((doc_map[doc_id], score, doc_id))
        
        # æ’åº
        final_results.sort(key=lambda x: x[1], reverse=True)
        
        return final_results

# ä½¿ç”¨ç¤ºä¾‹
def demo_fusion():
    """æ¼”ç¤ºç»“æœèåˆ"""
    
    # 1. å‡†å¤‡ä¸¤ä¸ªæ£€ç´¢ç»“æœåˆ—è¡¨
    
    # å‘é‡æ£€ç´¢ç»“æœ
    vector_results = [
        ("æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ", 0.95, 2),
        ("æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯", 0.88, 1),
        ("Pythonæ˜¯AIå¼€å‘çš„ä¸»æµè¯­è¨€", 0.75, 5),
        ("ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€", 0.70, 7),
    ]
    
    # BM25æ£€ç´¢ç»“æœ
    bm25_results = [
        ("æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯", 5.2, 1),
        ("äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯", 4.8, 0),
        ("æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸ", 4.5, 2),
        ("è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯AIçš„åº”ç”¨", 3.9, 3),
    ]
    
    print("ã€å‘é‡æ£€ç´¢ç»“æœã€‘")
    for i, (content, score, doc_id) in enumerate(vector_results):
        print(f"{i+1}. [ID={doc_id}] åˆ†æ•°={score:.2f}")
        print(f"   {content}")
    
    print("\nã€BM25æ£€ç´¢ç»“æœã€‘")
    for i, (content, score, doc_id) in enumerate(bm25_results):
        print(f"{i+1}. [ID={doc_id}] åˆ†æ•°={score:.2f}")
        print(f"   {content}")
    
    # 2. RRFèåˆ
    print("\nã€RRFèåˆç»“æœã€‘")
    rrf_results = ResultFusion.reciprocal_rank_fusion([
        vector_results,
        bm25_results
    ])
    
    for i, (content, score, doc_id) in enumerate(rrf_results[:5]):
        print(f"{i+1}. [ID={doc_id}] RRFåˆ†æ•°={score:.4f}")
        print(f"   {content}")
    
    # 3. åŠ æƒèåˆ
    print("\nã€åŠ æƒèåˆç»“æœã€‘(å‘é‡:0.6, BM25:0.4)")
    weighted_results = ResultFusion.weighted_fusion(
        [vector_results, bm25_results],
        [0.6, 0.4]
    )
    
    for i, (content, score, doc_id) in enumerate(weighted_results[:5]):
        print(f"{i+1}. [ID={doc_id}] åŠ æƒåˆ†æ•°={score:.4f}")
        print(f"   {content}")
    
    print("\nè§‚å¯Ÿ:")
    print("- ID=1å’ŒID=2åœ¨ä¸¤ä¸ªåˆ—è¡¨ä¸­éƒ½å‡ºç°ï¼Œèåˆåæ’åé å‰")
    print("- RRFä¸éœ€è¦å½’ä¸€åŒ–åˆ†æ•°ï¼Œæ›´é²æ£’")
    print("- åŠ æƒèåˆå¯ä»¥æ§åˆ¶ä¸åŒæ£€ç´¢æ–¹å¼çš„é‡è¦æ€§")

demo_fusion()
```

---

### äº”ã€å®Œæ•´çš„æ··åˆæ£€ç´¢ç³»ç»Ÿ

#### 5.1 æ··åˆæ£€ç´¢å¼•æ“

```python
class HybridRetriever:
    """æ··åˆæ£€ç´¢å¼•æ“"""
    
    def __init__(
        self,
        embedding_model: str = "moka-ai/m3e-base",
        bm25_k1: float = 1.5,
        bm25_b: float = 0.75
    ):
        """åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨"""
        print("="*60)
        print("ğŸš€ åˆå§‹åŒ–æ··åˆæ£€ç´¢å¼•æ“")
        print("="*60)
        
        # åˆå§‹åŒ–å„ä¸ªæ£€ç´¢å™¨
        self.vector_retriever = VectorRetriever(embedding_model)
        self.bm25_retriever = BM25Retriever(bm25_k1, bm25_b)
        self.metadata_filter = MetadataFilter()
        
        self.documents = []
        
        print("\nâœ… åˆå§‹åŒ–å®Œæˆ\n")
    
    def build_index(self, documents: List[DocumentWithMetadata]):
        """æ„å»ºç´¢å¼•"""
        print("="*60)
        print("ğŸ“š æ„å»ºæ··åˆç´¢å¼•")
        print("="*60)
        
        self.documents = documents
        
        # æå–å†…å®¹
        contents = [doc.content for doc in documents]
        
        # 1. æ„å»ºå‘é‡ç´¢å¼•
        print("\nã€1/3ã€‘å‘é‡ç´¢å¼•")
        self.vector_retriever.build_index(contents)
        
        # 2. æ„å»ºBM25ç´¢å¼•
        print("\nã€2/3ã€‘BM25ç´¢å¼•")
        self.bm25_retriever.build_index(contents)
        
        # 3. æ·»åŠ åˆ°å…ƒæ•°æ®è¿‡æ»¤å™¨
        print("\nã€3/3ã€‘å…ƒæ•°æ®ç´¢å¼•")
        self.metadata_filter.add_documents(documents)
        print(f"  âœ… å…ƒæ•°æ®ç´¢å¼•å®Œæˆ")
        
        print("\n" + "="*60)
        print("âœ… æ··åˆç´¢å¼•æ„å»ºå®Œæˆ")
        print("="*60 + "\n")
    
    def search(
        self,
        query: str,
        k: int = 5,
        metadata_conditions: Optional[List[Dict]] = None,
        use_vector: bool = True,
        use_bm25: bool = True,
        fusion_method: str = "rrf",
        vector_weight: float = 0.6,
        bm25_weight: float = 0.4,
        verbose: bool = True
    ) -> List[Tuple[DocumentWithMetadata, float]]:
        """
        æ··åˆæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›ç»“æœæ•°
            metadata_conditions: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            use_vector: æ˜¯å¦ä½¿ç”¨å‘é‡æ£€ç´¢
            use_bm25: æ˜¯å¦ä½¿ç”¨BM25æ£€ç´¢
            fusion_method: èåˆæ–¹æ³• ("rrf" æˆ– "weighted")
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
            bm25_weight: BM25æ£€ç´¢æƒé‡
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        if verbose:
            print("\n" + "="*60)
            print("ğŸ” æ··åˆæ£€ç´¢")
            print("="*60)
            print(f"æŸ¥è¯¢: {query}")
            print(f"æ¨¡å¼: {'å‘é‡' if use_vector else ''}{'+'if use_vector and use_bm25 else ''}{'BM25' if use_bm25 else ''}")
            print(f"èåˆæ–¹æ³•: {fusion_method}")
        
        # 1. å…ƒæ•°æ®è¿‡æ»¤ï¼ˆå¦‚æœæœ‰ï¼‰
        candidate_docs = self.documents
        if metadata_conditions:
            if verbose:
                print(f"\nã€æ­¥éª¤1ã€‘å…ƒæ•°æ®è¿‡æ»¤")
                print(f"  æ¡ä»¶: {metadata_conditions}")
            
            candidate_docs = self.metadata_filter.filter_by_conditions(
                metadata_conditions, logic="and"
            )
            
            if verbose:
                print(f"  âœ… è¿‡æ»¤åå‰©ä½™: {len(candidate_docs)} ä¸ªæ–‡æ¡£")
            
            if not candidate_docs:
                if verbose:
                    print("  âš ï¸  æ²¡æœ‰æ–‡æ¡£æ»¡è¶³æ¡ä»¶")
                return []
        else:
            if verbose:
                print(f"\nã€æ­¥éª¤1ã€‘æ— å…ƒæ•°æ®è¿‡æ»¤ï¼Œå€™é€‰æ–‡æ¡£: {len(candidate_docs)}")
        
        # è·å–å€™é€‰æ–‡æ¡£çš„IDé›†åˆ
        candidate_ids = set(doc.doc_id for doc in candidate_docs)
        
        # 2. æ‰§è¡Œæ£€ç´¢
        result_lists = []
        
        if use_vector:
            if verbose:
                print(f"\nã€æ­¥éª¤2-1ã€‘å‘é‡æ£€ç´¢")
            
            vector_results = self.vector_retriever.search(query, k=k*2)
            # è¿‡æ»¤å€™é€‰é›†
            vector_results = [
                (content, score, idx)
                for content, score, idx in vector_results
                if idx in candidate_ids
            ]
            result_lists.append(vector_results)
            
            if verbose:
                print(f"  âœ… æ‰¾åˆ° {len(vector_results)} ä¸ªç»“æœ")
                for i, (content, score, idx) in enumerate(vector_results[:3]):
                    print(f"    {i+1}. [ID={idx}] {score:.4f} {content[:40]}...")
        
        if use_bm25:
            if verbose:
                print(f"\nã€æ­¥éª¤2-2ã€‘BM25æ£€ç´¢")
            
            bm25_results = self.bm25_retriever.search(query, k=k*2)
            # è¿‡æ»¤å€™é€‰é›†
            bm25_results = [
                (content, score, idx)
                for content, score, idx in bm25_results
                if idx in candidate_ids
            ]
            result_lists.append(bm25_results)
            
            if verbose:
                print(f"  âœ… æ‰¾åˆ° {len(bm25_results)} ä¸ªç»“æœ")
                for i, (content, score, idx) in enumerate(bm25_results[:3]):
                    print(f"    {i+1}. [ID={idx}] {score:.4f} {content[:40]}...")
        
        # 3. èåˆç»“æœ
        if verbose:
            print(f"\nã€æ­¥éª¤3ã€‘ç»“æœèåˆ ({fusion_method})")
        
        if len(result_lists) == 0:
            return []
        elif len(result_lists) == 1:
            # åªæœ‰ä¸€ç§æ£€ç´¢æ–¹å¼
            fused_results = result_lists[0]
        else:
            # å¤šç§æ£€ç´¢æ–¹å¼ï¼Œéœ€è¦èåˆ
            if fusion_method == "rrf":
                fused_results = ResultFusion.reciprocal_rank_fusion(result_lists)
            else:  # weighted
                fused_results = ResultFusion.weighted_fusion(
                    result_lists,
                    [vector_weight, bm25_weight]
                )
        
        # 4. æ„å»ºæœ€ç»ˆç»“æœ
        final_results = []
        for content, score, doc_id in fused_results[:k]:
            doc = self.documents[doc_id]
            final_results.append((doc, score))
        
        if verbose:
            print(f"  âœ… èåˆå®Œæˆï¼Œè¿”å›Top-{len(final_results)}ç»“æœ")
            print("\n" + "="*60)
            print("ğŸ“‹ æœ€ç»ˆç»“æœ")
            print("="*60)
            
            for i, (doc, score) in enumerate(final_results):
                print(f"\n{i+1}. [ID={doc.doc_id}] å¾—åˆ†={score:.4f}")
                print(f"   å†…å®¹: {doc.content}")
                print(f"   å…ƒæ•°æ®: {doc.metadata}")
        
        return final_results
```

#### 5.2 å®Œæ•´ç¤ºä¾‹

```python
def full_hybrid_demo():
    """å®Œæ•´çš„æ··åˆæ£€ç´¢æ¼”ç¤º"""
    
    # 1. å‡†å¤‡æ–‡æ¡£
    documents = [
        DocumentWithMetadata(
            content="äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•æŠ¥å‘Š2023ï¼šæ·±åº¦å­¦ä¹ å–å¾—é‡å¤§çªç ´",
            metadata={
                "year": 2023,
                "category": "æŠ€æœ¯æŠ¥å‘Š",
                "author": "AIç ”ç©¶é™¢",
                "tags": ["AI", "æ·±åº¦å­¦ä¹ "]
            },
            doc_id=0
        ),
        DocumentWithMetadata(
            content="æœºå™¨å­¦ä¹ å®æˆ˜æŒ‡å—ï¼šä»å…¥é—¨åˆ°ç²¾é€š",
            metadata={
                "year": 2022,
                "category": "æ•™ç¨‹",
                "author": "å¼ ä¸‰",
                "tags": ["æœºå™¨å­¦ä¹ ", "æ•™ç¨‹"]
            },
            doc_id=1
        ),
        DocumentWithMetadata(
            content="è‡ªç„¶è¯­è¨€å¤„ç†æœ€æ–°è¿›å±•2023",
            metadata={
                "year": 2023,
                "category": "ç ”ç©¶è®ºæ–‡",
                "author": "æå››",
                "tags": ["NLP", "ç ”ç©¶"]
            },
            doc_id=2
        ),
        DocumentWithMetadata(
            content="è®¡ç®—æœºè§†è§‰åº”ç”¨æ¡ˆä¾‹é›†2022",
            metadata={
                "year": 2022,
                "category": "æ¡ˆä¾‹",
                "author": "ç‹äº”",
                "tags": ["è®¡ç®—æœºè§†è§‰", "åº”ç”¨"]
            },
            doc_id=3
        ),
        DocumentWithMetadata(
            content="Pythonæ·±åº¦å­¦ä¹ æ¡†æ¶å¯¹æ¯”2023",
            metadata={
                "year": 2023,
                "category": "æŠ€æœ¯å¯¹æ¯”",
                "author": "èµµå…­",
                "tags": ["Python", "æ·±åº¦å­¦ä¹ "]
            },
            doc_id=4
        ),
        DocumentWithMetadata(
            content="å¼ºåŒ–å­¦ä¹ ç†è®ºä¸å®è·µ",
            metadata={
                "year": 2021,
                "category": "æ•™ç¨‹",
                "author": "å­™ä¸ƒ",
                "tags": ["å¼ºåŒ–å­¦ä¹ ", "ç†è®º"]
            },
            doc_id=5
        ),
    ]
    
    # 2. åˆ›å»ºæ··åˆæ£€ç´¢å™¨
    hybrid = HybridRetriever()
    hybrid.build_index(documents)
    
    # 3. æµ‹è¯•ä¸åŒçš„æ£€ç´¢åœºæ™¯
    
    print("\n\n" + "ğŸ¯"*30)
    print("åœºæ™¯1ï¼šçº¯å‘é‡æ£€ç´¢")
    print("ğŸ¯"*30)
    results = hybrid.search(
        query="æ·±åº¦å­¦ä¹ æŠ€æœ¯",
        k=3,
        use_vector=True,
        use_bm25=False
    )
    
    print("\n\n" + "ğŸ¯"*30)
    print("åœºæ™¯2ï¼šçº¯BM25æ£€ç´¢")
    print("ğŸ¯"*30)
    results = hybrid.search(
        query="æ·±åº¦å­¦ä¹ æŠ€æœ¯",
        k=3,
        use_vector=False,
        use_bm25=True
    )
    
    print("\n\n" + "ğŸ¯"*30)
    print("åœºæ™¯3ï¼šæ··åˆæ£€ç´¢ï¼ˆRRFèåˆï¼‰")
    print("ğŸ¯"*30)
    results = hybrid.search(
        query="æ·±åº¦å­¦ä¹ æŠ€æœ¯",
        k=3,
        use_vector=True,
        use_bm25=True,
        fusion_method="rrf"
    )
    
    print("\n\n" + "ğŸ¯"*30)
    print("åœºæ™¯4ï¼šæ··åˆæ£€ç´¢ + å…ƒæ•°æ®è¿‡æ»¤")
    print("ğŸ¯"*30)
    results = hybrid.search(
        query="æ·±åº¦å­¦ä¹ ",
        k=3,
        metadata_conditions=[
            {"field": "year", "value": 2023, "operator": "eq"}
        ],
        use_vector=True,
        use_bm25=True,
        fusion_method="rrf"
    )
    
    print("\n\n" + "ğŸ¯"*30)
    print("åœºæ™¯5ï¼šåŠ æƒèåˆï¼ˆåé‡å‘é‡ï¼‰")
    print("ğŸ¯"*30)
    results = hybrid.search(
        query="AIåº”ç”¨",
        k=3,
        use_vector=True,
        use_bm25=True,
        fusion_method="weighted",
        vector_weight=0.8,
        bm25_weight=0.2
    )

# è¿è¡Œæ¼”ç¤º
full_hybrid_demo()
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šä¼˜åŒ–BM25å‚æ•°

è°ƒæ•´k1å’Œbå‚æ•°ï¼Œè§‚å¯Ÿå¯¹æ£€ç´¢æ•ˆæœçš„å½±å“

### ç»ƒä¹ 2ï¼šå®ç°è‡ªå®šä¹‰èåˆç®—æ³•

è®¾è®¡ä¸€ä¸ªæ ¹æ®æŸ¥è¯¢ç±»å‹è‡ªé€‚åº”è°ƒæ•´æƒé‡çš„èåˆç®—æ³•

### ç»ƒä¹ 3ï¼šæ·»åŠ ç¼“å­˜

ä¸ºæ··åˆæ£€ç´¢æ·»åŠ ç¼“å­˜æœºåˆ¶ï¼Œæå‡æ€§èƒ½

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **æ··åˆæ£€ç´¢çš„ä¸‰å¤§ç»„ä»¶**
   - å‘é‡æ£€ç´¢ï¼šè¯­ä¹‰ç†è§£
   - BM25æ£€ç´¢ï¼šç²¾ç¡®åŒ¹é…
   - å…ƒæ•°æ®è¿‡æ»¤ï¼šæ¡ä»¶ç­›é€‰

2. **BM25ç®—æ³•**
   - è€ƒè™‘è¯é¢‘ã€IDFã€æ–‡æ¡£é•¿åº¦
   - k1æ§åˆ¶è¯é¢‘é¥±å’Œ
   - bæ§åˆ¶é•¿åº¦å½’ä¸€åŒ–

3. **ç»“æœèåˆ**
   - RRFï¼šé²æ£’ï¼Œæ— éœ€å½’ä¸€åŒ–
   - åŠ æƒï¼šå¯æ§ï¼Œéœ€è¦è°ƒå‚

4. **åº”ç”¨åœºæ™¯**
   - ä¼ä¸šæœç´¢ï¼šæ··åˆæ£€ç´¢+å…ƒæ•°æ®
   - FAQç³»ç»Ÿï¼šBM25ä¸ºä¸»
   - è¯­ä¹‰æœç´¢ï¼šå‘é‡ä¸ºä¸»

### æœ€ä½³å®è·µ

âœ… æ ¹æ®åœºæ™¯é€‰æ‹©æ£€ç´¢ç»„åˆ
âœ… RRFä½œä¸ºé»˜è®¤èåˆæ–¹å¼
âœ… å…ƒæ•°æ®è¿‡æ»¤å‡å°‘å€™é€‰é›†
âœ… ç›‘æ§å„æ£€ç´¢å™¨çš„è´¡çŒ®
âœ… A/Bæµ‹è¯•éªŒè¯æ•ˆæœ

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬58è¯¾ï¼šQueryç†è§£ä¸æ”¹å†™**

- Queryæ„å›¾è¯†åˆ«
- Queryæ‰©å±•ä¸æ”¹å†™
- åŒä¹‰è¯å¤„ç†
- å®æˆ˜ï¼šæ™ºèƒ½Queryä¼˜åŒ–ç³»ç»Ÿ

**è®©RAGç†è§£ç”¨æˆ·çš„çœŸå®æ„å›¾ï¼** ğŸ¯

---

**ğŸ’ª è®°ä½ï¼šæ··åˆæ£€ç´¢æ˜¯ä¼ä¸šçº§RAGçš„æ ‡é…ï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
