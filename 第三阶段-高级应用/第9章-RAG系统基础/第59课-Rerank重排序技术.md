![RAGç³»ç»Ÿæž¶æž„](./images/rag_flow.svg)
*å›¾ï¼šRAGç³»ç»Ÿæž¶æž„*

# ç¬¬59è¯¾ï¼šReranké‡æŽ’åºæŠ€æœ¯

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŽŒæ¡Reranké‡æŽ’åºæŠ€æœ¯ï¼Œå¤§å¹…æå‡æ£€ç´¢ç»“æžœçš„å‡†ç¡®æ€§
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šCross-Encoderã€é‡æŽ’åºç­–ç•¥ã€æ€§èƒ½ä¼˜åŒ–
> 
> **å®žæˆ˜æ¡ˆä¾‹**ï¼šæž„å»ºé«˜ç²¾åº¦é‡æŽ’åºç³»ç»Ÿ
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š75åˆ†é’Ÿ

---

## ðŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ3åˆ†é’Ÿï¼‰

### ðŸŽ¯ å‰è¨€

"ä½ æœ‰æ²¡æœ‰å‘çŽ°ä¸€ä¸ªé—®é¢˜ï¼š

å‘é‡æ£€ç´¢è¿”å›žçš„Top-10ç»“æžœä¸­ï¼Œæœ€ç›¸å…³çš„å†…å®¹ç»å¸¸ä¸åœ¨ç¬¬ä¸€ä½ï¼

æ¯”å¦‚ï¼š
ç”¨æˆ·é—®ï¼š'Pythonå’ŒJavaå“ªä¸ªæ›´é€‚åˆAIå¼€å‘ï¼Ÿ'

æ£€ç´¢ç»“æžœï¼š
1. Pythonè¯­æ³•åŸºç¡€ âŒï¼ˆä¸ç›¸å…³ï¼‰
2. Javaé¢å‘å¯¹è±¡ç¼–ç¨‹ âŒï¼ˆä¸ç›¸å…³ï¼‰
3. Pythonåœ¨AIé¢†åŸŸçš„åº”ç”¨ âœ…ï¼ˆç›¸å…³ï¼ï¼‰
4. AIå¼€å‘è¯­è¨€å¯¹æ¯” âœ…âœ…ï¼ˆæœ€ç›¸å…³ï¼ï¼‰

**é—®é¢˜æ˜¯ï¼šç¬¬4ä¸ªæ‰æ˜¯æœ€ä½³ç­”æ¡ˆï¼Œä½†å®ƒæŽ’åœ¨åŽé¢ï¼**

ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ

å› ä¸ºå‘é‡æ£€ç´¢åªçœ‹'è¯­ä¹‰ç›¸ä¼¼åº¦'ï¼Œä¸çœ‹'çœŸæ­£çš„ç›¸å…³æ€§'ï¼

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦æ•™ä½ Rerankï¼ˆé‡æŽ’åºï¼‰æŠ€æœ¯ï¼**

å®ƒçš„ä½œç”¨æ˜¯ï¼š
- å¯¹åˆç­›ç»“æžœè¿›è¡Œç²¾ç»†åŒ–æŽ’åº
- ç”¨æ›´å¼ºå¤§çš„æ¨¡åž‹é‡æ–°è¯„åˆ†
- æŠŠæœ€ç›¸å…³çš„ç»“æžœæ”¾åœ¨æœ€å‰é¢

å­¦å®Œè¿™ä¸€è¯¾ï¼Œä½ ä¼šæŽŒæ¡ï¼š

âœ… **Bi-Encoder vs Cross-Encoder**ï¼šä¸¤ç§ç¼–ç å™¨çš„åŒºåˆ«
âœ… **é‡æŽ’åºåŽŸç†**ï¼šå¦‚ä½•é‡æ–°è¯„åˆ†
âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šå¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦
âœ… **å®Œæ•´å®žçŽ°**ï¼šå¯ç”¨äºŽç”Ÿäº§çš„é‡æŽ’åºç³»ç»Ÿ

è¿™æ˜¯RAGç³»ç»Ÿä»Ž'80åˆ†'åˆ°'95åˆ†'çš„å…³é”®æŠ€æœ¯ï¼

å¾ˆå¤šä¼ä¸šçº§RAGç³»ç»Ÿçš„ç§˜å¯†æ­¦å™¨å°±æ˜¯Rerankï¼

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ï¼"

---

### ðŸ’¡ æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### ä¸ºä»€ä¹ˆéœ€è¦é‡æŽ’åºï¼Ÿ

```
ã€æ£€ç´¢çš„ä¸¤é˜¶æ®µç­–ç•¥ã€‘

ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿå¬å›žï¼ˆRetrievalï¼‰
â€¢ ç›®æ ‡ï¼šä»Žæµ·é‡æ–‡æ¡£ä¸­å¿«é€Ÿæ‰¾å‡ºå€™é€‰é›†
â€¢ æ–¹æ³•ï¼šå‘é‡æ£€ç´¢ï¼ˆBi-Encoderï¼‰
â€¢ ç‰¹ç‚¹ï¼šé€Ÿåº¦å¿«ï¼Œä½†ä¸å¤Ÿç²¾å‡†
â€¢ ç»“æžœï¼šTop-100 ~ Top-1000å€™é€‰

ç¬¬äºŒé˜¶æ®µï¼šç²¾å‡†æŽ’åºï¼ˆRerankï¼‰
â€¢ ç›®æ ‡ï¼šä»Žå€™é€‰é›†ä¸­æ‰¾å‡ºæœ€ç›¸å…³çš„
â€¢ æ–¹æ³•ï¼šCross-Encoderé‡æŽ’åº
â€¢ ç‰¹ç‚¹ï¼šç²¾å‡†ï¼Œä½†è¾ƒæ…¢
â€¢ ç»“æžœï¼šTop-5 ~ Top-10æœ€ç»ˆç»“æžœ

ç±»æ¯”ï¼š
å°±åƒæ‹›è˜ï¼š
1. ç®€åŽ†ç­›é€‰ï¼ˆå¿«é€Ÿï¼‰ â†’ Retrieval
2. é¢è¯•è¯„ä¼°ï¼ˆç²¾å‡†ï¼‰ â†’ Rerank
```

#### Bi-Encoder vs Cross-Encoder

```
ã€Bi-Encoderï¼ˆåŒå¡”æ¨¡åž‹ï¼‰ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query  â”‚         â”‚Document â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                   â”‚
     â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Encoder â”‚         â”‚ Encoder â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                   â”‚
     â†“                   â†“
  Vectorâ‚             Vectorâ‚‚
     â”‚                   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
       Cosine Similarity

ä¼˜ç‚¹ï¼š
â€¢ å¯ä»¥é¢„å…ˆè®¡ç®—æ–‡æ¡£å‘é‡
â€¢ æ£€ç´¢é€Ÿåº¦å¿«ï¼ˆå‘é‡ç›¸ä¼¼åº¦è®¡ç®—ï¼‰
â€¢ é€‚åˆå¤§è§„æ¨¡æ£€ç´¢

ç¼ºç‚¹ï¼š
â€¢ Queryå’ŒDocumentåˆ†å¼€ç¼–ç 
â€¢ æ— æ³•æ•æ‰ç»†ç²’åº¦äº¤äº’
â€¢ å‡†ç¡®æ€§æœ‰é™

ã€Cross-Encoderï¼ˆäº¤å‰ç¼–ç å™¨ï¼‰ã€‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query + Document       â”‚
â”‚  (æ‹¼æŽ¥åœ¨ä¸€èµ·)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Encoder â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚Classifierâ”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â†“
    Relevance Score
    (0-1ä¹‹é—´çš„ç›¸å…³æ€§åˆ†æ•°)

ä¼˜ç‚¹ï¼š
â€¢ Queryå’ŒDocumentè”åˆç¼–ç 
â€¢ æ•æ‰ç»†ç²’åº¦äº¤äº’
â€¢ å‡†ç¡®æ€§é«˜

ç¼ºç‚¹ï¼š
â€¢ æ— æ³•é¢„å…ˆè®¡ç®—
â€¢ æ¯ä¸ªQuery-Documentå¯¹éƒ½è¦é‡æ–°è®¡ç®—
â€¢ é€Ÿåº¦æ…¢ï¼Œä¸é€‚åˆå¤§è§„æ¨¡æ£€ç´¢

ã€æœ€ä½³å®žè·µã€‘
Bi-Encoderå¬å›ž â†’ Cross-Encoderé‡æŽ’åº
  (å¿«é€Ÿç­›é€‰)      (ç²¾å‡†æŽ’åº)
```

---

## ðŸ“š çŸ¥è¯†è®²è§£

### ä¸€ã€Cross-EncoderåŽŸç†

#
![Generation](./images/generation.svg)
*å›¾ï¼šGeneration*

### 1.1 Cross-Encoderæž¶æž„

```python
from sentence_transformers import CrossEncoder
from typing import List, Tuple
import numpy as np

class CrossEncoderReranker:
    """Cross-Encoderé‡æŽ’åºå™¨"""
    
    def __init__(self, model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"):
        """
        åˆå§‹åŒ–Cross-Encoder
        
        å¸¸ç”¨æ¨¡åž‹ï¼š
        â€¢ cross-encoder/ms-marco-MiniLM-L-6-v2 (è‹±æ–‡)
        â€¢ BAAI/bge-reranker-base (ä¸­æ–‡)
        â€¢ maidalun1020/bce-reranker-base_v1 (ä¸­æ–‡)
        """
        print(f"ðŸ¤– åŠ è½½Cross-Encoderæ¨¡åž‹: {model_name}")
        self.model = CrossEncoder(model_name)
        print("âœ… æ¨¡åž‹åŠ è½½å®Œæˆ")
    
    def rerank(
        self,
        query: str,
        documents: List[str],
        top_k: int = 5
    ) -> List[Tuple[str, float, int]]:
        """
        é‡æŽ’åºæ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢
            documents: æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›žtop-kä¸ªç»“æžœ
        
        Returns:
            List of (document, score, original_index)
        """
        print(f"\nðŸ”„ é‡æŽ’åº {len(documents)} ä¸ªæ–‡æ¡£...")
        
        # 1. æž„å»ºQuery-Documentå¯¹
        pairs = [[query, doc] for doc in documents]
        
        # 2. è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        scores = self.model.predict(pairs)
        
        # 3. æŽ’åº
        doc_score_indices = [
            (documents[i], scores[i], i)
            for i in range(len(documents))
        ]
        doc_score_indices.sort(key=lambda x: x[1], reverse=True)
        
        print(f"âœ… é‡æŽ’åºå®Œæˆ")
        
        # 4. è¿”å›žtop-k
        return doc_score_indices[:top_k]
    
    def rerank_with_threshold(
        self,
        query: str,
        documents: List[str],
        threshold: float = 0.5,
        top_k: int = 10
    ) -> List[Tuple[str, float, int]]:
        """
        é‡æŽ’åºå¹¶è¿‡æ»¤ä½Žåˆ†æ–‡æ¡£
        
        Args:
            threshold: åˆ†æ•°é˜ˆå€¼ï¼Œä½ŽäºŽæ­¤å€¼çš„æ–‡æ¡£è¢«è¿‡æ»¤
        """
        # é‡æŽ’åº
        results = self.rerank(query, documents, top_k=len(documents))
        
        # è¿‡æ»¤
        filtered = [
            (doc, score, idx)
            for doc, score, idx in results
            if score >= threshold
        ]
        
        return filtered[:top_k]

# ä½¿ç”¨ç¤ºä¾‹
def demo_cross_encoder():
    """æ¼”ç¤ºCross-Encoder"""
    
    # å‡†å¤‡æ•°æ®
    query = "Pythonå’ŒJavaå“ªä¸ªæ›´é€‚åˆAIå¼€å‘ï¼Ÿ"
    
    documents = [
        "Pythonæ˜¯ä¸€ç§ç®€å•æ˜“å­¦çš„ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•æ¸…æ™°",
        "Javaæ˜¯ä¸€ç§é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ï¼Œåº”ç”¨å¹¿æ³›",
        "Pythonåœ¨äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ é¢†åŸŸåº”ç”¨æœ€å¹¿æ³›",
        "Javaåœ¨ä¼ä¸šçº§åº”ç”¨å¼€å‘ä¸­å æ®é‡è¦åœ°ä½",
        "AIå¼€å‘ä¸»è¦ä½¿ç”¨Pythonï¼Œå› ä¸ºæœ‰ä¸°å¯Œçš„åº“å¦‚TensorFlowå’ŒPyTorch",
        "Pythonå’ŒJavaéƒ½å¯ä»¥ç”¨äºŽAIå¼€å‘ï¼Œä½†Pythonç”Ÿæ€æ›´æˆç†Ÿ",
        "æ·±åº¦å­¦ä¹ æ¡†æž¶å¤§å¤šåŸºäºŽPythonå¼€å‘",
        "Javaä¹Ÿæœ‰DeepLearning4jç­‰AIæ¡†æž¶",
    ]
    
    print("="*60)
    print("Cross-Encoderé‡æŽ’åºæ¼”ç¤º")
    print("="*60)
    print(f"æŸ¥è¯¢: {query}\n")
    
    # æ˜¾ç¤ºåŽŸå§‹é¡ºåº
    print("ã€åŽŸå§‹æ–‡æ¡£é¡ºåºã€‘")
    for i, doc in enumerate(documents):
        print(f"{i+1}. {doc}")
    
    # åˆ›å»ºé‡æŽ’åºå™¨
    reranker = CrossEncoderReranker()
    
    # é‡æŽ’åº
    results = reranker.rerank(query, documents, top_k=5)
    
    # æ˜¾ç¤ºé‡æŽ’åºç»“æžœ
    print("\nã€é‡æŽ’åºåŽï¼ˆTop-5ï¼‰ã€‘")
    for i, (doc, score, idx) in enumerate(results):
        print(f"{i+1}. [åŽŸåºå·={idx+1}] åˆ†æ•°={score:.4f}")
        print(f"   {doc}")

demo_cross_encoder()
```

#### 1.2 å¯¹æ¯”Bi-Encoderå’ŒCross-Encoder

```python
from sentence_transformers import SentenceTransformer
import time

def compare_encoders():
    """å¯¹æ¯”ä¸¤ç§ç¼–ç å™¨"""
    
    query = "Pythonåœ¨AIå¼€å‘ä¸­çš„ä¼˜åŠ¿"
    
    documents = [
        "Pythonè¯­æ³•ç®€å•æ˜“å­¦ï¼Œé€‚åˆåˆå­¦è€…",
        "Pythonæœ‰ä¸°å¯Œçš„AIåº“ï¼Œå¦‚TensorFlowã€PyTorch",
        "Pythonåœ¨æ•°æ®ç§‘å­¦é¢†åŸŸåº”ç”¨å¹¿æ³›",
        "Javaæ€§èƒ½ä¼˜ç§€ï¼Œé€‚åˆå¤§åž‹ç³»ç»Ÿ",
        "AIå¼€å‘é¦–é€‰Pythonï¼Œç¤¾åŒºæ”¯æŒå¥½",
    ]
    
    print("="*60)
    print("Bi-Encoder vs Cross-Encoder å¯¹æ¯”")
    print("="*60)
    
    # 1. Bi-Encoder
    print("\nã€Bi-Encoderã€‘")
    bi_model = SentenceTransformer('moka-ai/m3e-base')
    
    start = time.time()
    
    # ç¼–ç queryå’Œdocuments
    query_emb = bi_model.encode([query])[0]
    doc_embs = bi_model.encode(documents)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    similarities = []
    for i, doc_emb in enumerate(doc_embs):
        sim = np.dot(query_emb, doc_emb) / (
            np.linalg.norm(query_emb) * np.linalg.norm(doc_emb)
        )
        similarities.append((documents[i], sim, i))
    
    similarities.sort(key=lambda x: x[1], reverse=True)
    
    bi_time = time.time() - start
    
    print(f"è€—æ—¶: {bi_time:.4f}ç§’")
    print("Top-3ç»“æžœ:")
    for i, (doc, score, idx) in enumerate(similarities[:3]):
        print(f"  {i+1}. [#{idx+1}] {score:.4f} - {doc[:40]}...")
    
    # 2. Cross-Encoder
    print("\nã€Cross-Encoderã€‘")
    cross_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    start = time.time()
    
    pairs = [[query, doc] for doc in documents]
    scores = cross_model.predict(pairs)
    
    results = [(documents[i], scores[i], i) for i in range(len(documents))]
    results.sort(key=lambda x: x[1], reverse=True)
    
    cross_time = time.time() - start
    
    print(f"è€—æ—¶: {cross_time:.4f}ç§’")
    print("Top-3ç»“æžœ:")
    for i, (doc, score, idx) in enumerate(results[:3]):
        print(f"  {i+1}. [#{idx+1}] {score:.4f} - {doc[:40]}...")
    
    # 3. å¯¹æ¯”åˆ†æž
    print("\nã€å¯¹æ¯”åˆ†æžã€‘")
    print(f"é€Ÿåº¦å¯¹æ¯”: Bi-Encoder {bi_time:.4f}s vs Cross-Encoder {cross_time:.4f}s")
    print(f"é€Ÿåº¦æ¯”: Cross-Encoderæ˜¯Bi-Encoderçš„ {cross_time/bi_time:.2f}å€")
    print("\næŽ’åºå·®å¼‚:")
    bi_top3 = [idx for _, _, idx in similarities[:3]]
    cross_top3 = [idx for _, _, idx in results[:3]]
    print(f"  Bi-Encoder Top-3: {[i+1 for i in bi_top3]}")
    print(f"  Cross-Encoder Top-3: {[i+1 for i in cross_top3]}")

compare_encoders()
```

---

### äºŒã€ä¸¤é˜¶æ®µæ£€ç´¢+é‡æŽ’åº

#### 2.1 å®Œæ•´æµç¨‹å®žçŽ°

```python
class TwoStageRetriever:
    """ä¸¤é˜¶æ®µæ£€ç´¢å™¨ï¼ˆæ£€ç´¢+é‡æŽ’åºï¼‰"""
    
    def __init__(
        self,
        embedding_model: str = "moka-ai/m3e-base",
        rerank_model: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"
    ):
        print("ðŸš€ åˆå§‹åŒ–ä¸¤é˜¶æ®µæ£€ç´¢ç³»ç»Ÿ")
        print("="*60)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šBi-Encoderï¼ˆå¿«é€Ÿå¬å›žï¼‰
        print("åŠ è½½Bi-Encoder...")
        self.bi_encoder = SentenceTransformer(embedding_model)
        
        # ç¬¬äºŒé˜¶æ®µï¼šCross-Encoderï¼ˆç²¾å‡†é‡æŽ’ï¼‰
        print("åŠ è½½Cross-Encoder...")
        self.cross_encoder = CrossEncoder(rerank_model)
        
        self.documents = []
        self.embeddings = None
        
        print("âœ… åˆå§‹åŒ–å®Œæˆ\n")
    
    def index_documents(self, documents: List[str]):
        """ç´¢å¼•æ–‡æ¡£"""
        print(f"ðŸ“š ç´¢å¼• {len(documents)} ä¸ªæ–‡æ¡£...")
        
        self.documents = documents
        self.embeddings = self.bi_encoder.encode(
            documents,
            show_progress_bar=True
        )
        
        print("âœ… ç´¢å¼•å®Œæˆ\n")
    
    def search(
        self,
        query: str,
        retrieval_k: int = 20,
        rerank_k: int = 5,
        enable_rerank: bool = True,
        verbose: bool = True
    ) -> List[Tuple[str, float, int]]:
        """
        ä¸¤é˜¶æ®µæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢
            retrieval_k: ç¬¬ä¸€é˜¶æ®µå¬å›žæ•°é‡
            rerank_k: ç¬¬äºŒé˜¶æ®µè¿”å›žæ•°é‡
            enable_rerank: æ˜¯å¦å¯ç”¨é‡æŽ’åº
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        if verbose:
            print("="*60)
            print("ðŸ” ä¸¤é˜¶æ®µæ£€ç´¢")
            print("="*60)
            print(f"æŸ¥è¯¢: {query}\n")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šå‘é‡æ£€ç´¢ï¼ˆå¿«é€Ÿå¬å›žï¼‰
        if verbose:
            print(f"ã€é˜¶æ®µ1ã€‘å‘é‡æ£€ç´¢ (å¬å›žTop-{retrieval_k})")
        
        start = time.time()
        
        query_emb = self.bi_encoder.encode([query])[0]
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for i, doc_emb in enumerate(self.embeddings):
            sim = np.dot(query_emb, doc_emb) / (
                np.linalg.norm(query_emb) * np.linalg.norm(doc_emb)
            )
            similarities.append((self.documents[i], sim, i))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        retrieved = similarities[:retrieval_k]
        
        retrieval_time = time.time() - start
        
        if verbose:
            print(f"  âœ… å¬å›žå®Œæˆï¼Œè€—æ—¶ {retrieval_time:.3f}ç§’")
            print(f"  Top-3é¢„è§ˆ:")
            for i, (doc, score, idx) in enumerate(retrieved[:3]):
                print(f"    {i+1}. [ID={idx}] {score:.4f} - {doc[:50]}...")
        
        # ç¬¬äºŒé˜¶æ®µï¼šCross-Encoderé‡æŽ’åº
        if enable_rerank:
            if verbose:
                print(f"\nã€é˜¶æ®µ2ã€‘Cross-Encoderé‡æŽ’åº (ç²¾é€‰Top-{rerank_k})")
            
            start = time.time()
            
            # æå–æ–‡æ¡£
            candidate_docs = [doc for doc, _, _ in retrieved]
            candidate_indices = [idx for _, _, idx in retrieved]
            
            # é‡æŽ’åº
            pairs = [[query, doc] for doc in candidate_docs]
            scores = self.cross_encoder.predict(pairs)
            
            # é‡æ–°æŽ’åº
            reranked = [
                (candidate_docs[i], scores[i], candidate_indices[i])
                for i in range(len(candidate_docs))
            ]
            reranked.sort(key=lambda x: x[1], reverse=True)
            
            final_results = reranked[:rerank_k]
            
            rerank_time = time.time() - start
            
            if verbose:
                print(f"  âœ… é‡æŽ’åºå®Œæˆï¼Œè€—æ—¶ {rerank_time:.3f}ç§’")
                print(f"  æ€»è€—æ—¶: {retrieval_time + rerank_time:.3f}ç§’")
        else:
            final_results = retrieved[:rerank_k]
            rerank_time = 0
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æžœ
        if verbose:
            print(f"\nã€æœ€ç»ˆç»“æžœã€‘Top-{len(final_results)}")
            for i, (doc, score, idx) in enumerate(final_results):
                print(f"  {i+1}. [ID={idx}] åˆ†æ•°={score:.4f}")
                print(f"     {doc}")
        
        return final_results
    
    def compare_with_without_rerank(self, query: str, k: int = 5):
        """å¯¹æ¯”æœ‰æ— é‡æŽ’åºçš„æ•ˆæžœ"""
        print("\n" + "ðŸ”¬"*30)
        print("å¯¹æ¯”å®žéªŒï¼šæœ‰æ— é‡æŽ’åº")
        print("ðŸ”¬"*30)
        
        # æ— é‡æŽ’åº
        print("\nã€æ–¹æ¡ˆAï¼šä»…å‘é‡æ£€ç´¢ã€‘")
        results_without = self.search(
            query,
            retrieval_k=20,
            rerank_k=k,
            enable_rerank=False,
            verbose=False
        )
        
        print(f"Top-{k}ç»“æžœ:")
        for i, (doc, score, idx) in enumerate(results_without):
            print(f"  {i+1}. [ID={idx}] {score:.4f}")
            print(f"     {doc[:60]}...")
        
        # æœ‰é‡æŽ’åº
        print("\nã€æ–¹æ¡ˆBï¼šå‘é‡æ£€ç´¢ + é‡æŽ’åºã€‘")
        results_with = self.search(
            query,
            retrieval_k=20,
            rerank_k=k,
            enable_rerank=True,
            verbose=False
        )
        
        print(f"Top-{k}ç»“æžœ:")
        for i, (doc, score, idx) in enumerate(results_with):
            print(f"  {i+1}. [ID={idx}] {score:.4f}")
            print(f"     {doc[:60]}...")
        
        # å¯¹æ¯”
        print("\nã€å¯¹æ¯”åˆ†æžã€‘")
        without_ids = [idx for _, _, idx in results_without]
        with_ids = [idx for _, _, idx in results_with]
        
        print(f"  æ— é‡æŽ’åºçš„æ–‡æ¡£ID: {without_ids}")
        print(f"  æœ‰é‡æŽ’åºçš„æ–‡æ¡£ID: {with_ids}")
        
        # è®¡ç®—æŽ’åºå˜åŒ–
        changes = sum(1 for i in range(min(len(without_ids), len(with_ids)))
                     if without_ids[i] != with_ids[i])
        print(f"  æŽ’åºå˜åŒ–: Top-{k}ä¸­æœ‰ {changes} ä¸ªä½ç½®å‘ç”Ÿå˜åŒ–")

# å®Œæ•´ç¤ºä¾‹
def full_demo():
    """å®Œæ•´æ¼”ç¤º"""
    
    # 1. å‡†å¤‡æ–‡æ¡£
    documents = [
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´æ˜“è¯»",
        "Javaæ˜¯é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºŽä¼ä¸šå¼€å‘",
        "Pythonåœ¨äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ é¢†åŸŸå æ®ä¸»å¯¼åœ°ä½",
        "TensorFlowå’ŒPyTorchæ˜¯Pythonçš„ä¸»æµæ·±åº¦å­¦ä¹ æ¡†æž¶",
        "Javaæœ‰DeepLearning4jç­‰AIæ¡†æž¶ï¼Œä½†ä¸å¦‚Pythonç”Ÿæ€ä¸°å¯Œ",
        "Pythonçš„NumPyã€Pandasç­‰åº“ä½¿æ•°æ®å¤„ç†éžå¸¸ä¾¿æ·",
        "AIç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆé¦–é€‰Pythonä½œä¸ºå¼€å‘è¯­è¨€",
        "Pythonç¤¾åŒºæ´»è·ƒï¼ŒAIç›¸å…³çš„å¼€æºé¡¹ç›®ä¼—å¤š",
        "Javaåœ¨å¤§æ•°æ®é¢†åŸŸæœ‰Hadoopã€Sparkç­‰æˆç†Ÿæ¡†æž¶",
        "æœºå™¨å­¦ä¹ ç®—æ³•å®žçŽ°æ—¶ï¼ŒPythonä»£ç æ›´ç®€æ´ç›´è§‚",
    ]
    
    # 2. åˆ›å»ºä¸¤é˜¶æ®µæ£€ç´¢å™¨
    retriever = TwoStageRetriever()
    retriever.index_documents(documents)
    
    # 3. æŸ¥è¯¢
    query = "ä¸ºä»€ä¹ˆPythonæ˜¯AIå¼€å‘çš„é¦–é€‰è¯­è¨€ï¼Ÿ"
    
    # 4. å¯¹æ¯”æœ‰æ— é‡æŽ’åº
    retriever.compare_with_without_rerank(query, k=5)

full_demo()
```

---

### ä¸‰ã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 3.1 æ‰¹é‡é‡æŽ’åºä¼˜åŒ–

```python
class OptimizedReranker:
    """ä¼˜åŒ–çš„é‡æŽ’åºå™¨"""
    
    def __init__(self, model_name: str):
        self.model = CrossEncoder(model_name)
    
    def rerank_batch(
        self,
        queries: List[str],
        documents_list: List[List[str]],
        batch_size: int = 32
    ) -> List[List[Tuple[str, float]]]:
        """
        æ‰¹é‡é‡æŽ’åºï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
        
        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            documents_list: æ¯ä¸ªæŸ¥è¯¢å¯¹åº”çš„æ–‡æ¡£åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        all_results = []
        
        for query, documents in zip(queries, documents_list):
            # æž„å»ºpairs
            pairs = [[query, doc] for doc in documents]
            
            # æ‰¹é‡é¢„æµ‹ï¼ˆæé«˜æ•ˆçŽ‡ï¼‰
            scores = self.model.predict(
                pairs,
                batch_size=batch_size,
                show_progress_bar=False
            )
            
            # æŽ’åº
            results = [
                (documents[i], scores[i])
                for i in range(len(documents))
            ]
            results.sort(key=lambda x: x[1], reverse=True)
            
            all_results.append(results)
        
        return all_results
    
    def rerank_with_cache(
        self,
        query: str,
        documents: List[str],
        cache: dict
    ) -> List[Tuple[str, float]]:
        """
        å¸¦ç¼“å­˜çš„é‡æŽ’åº
        """
        import hashlib
        
        # ç”Ÿæˆç¼“å­˜key
        cache_key = hashlib.md5(
            f"{query}{''.join(documents)}".encode()
        ).hexdigest()
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in cache:
            return cache[cache_key]
        
        # è®¡ç®—
        pairs = [[query, doc] for doc in documents]
        scores = self.model.predict(pairs)
        
        results = [
            (documents[i], scores[i])
            for i in range(len(documents))
        ]
        results.sort(key=lambda x: x[1], reverse=True)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        cache[cache_key] = results
        
        return results
```

#### 3.2 è‡ªé€‚åº”é‡æŽ’åº

```python
class AdaptiveReranker:
    """è‡ªé€‚åº”é‡æŽ’åºå™¨"""
    
    def __init__(self, model_name: str):
        self.model = CrossEncoder(model_name)
    
    def adaptive_rerank(
        self,
        query: str,
        documents: List[str],
        retrieval_scores: List[float],
        score_threshold: float = 0.7,
        max_rerank: int = 50
    ) -> List[Tuple[str, float, int]]:
        """
        è‡ªé€‚åº”é‡æŽ’åº
        
        ç­–ç•¥ï¼š
        1. å¦‚æžœå¬å›žåˆ†æ•°éƒ½å¾ˆé«˜ï¼Œåªé‡æŽ’å°‘é‡æ–‡æ¡£
        2. å¦‚æžœå¬å›žåˆ†æ•°ä¸ç¨³å®šï¼Œé‡æŽ’æ›´å¤šæ–‡æ¡£
        """
        # åˆ†æžå¬å›žåˆ†æ•°
        avg_score = np.mean(retrieval_scores)
        std_score = np.std(retrieval_scores)
        
        # å†³å®šé‡æŽ’åºæ•°é‡
        if avg_score > score_threshold and std_score < 0.1:
            # åˆ†æ•°é«˜ä¸”ç¨³å®šï¼Œåªé‡æŽ’å‰é¢çš„
            rerank_count = min(10, len(documents))
        else:
            # åˆ†æ•°ä¸ç¨³å®šï¼Œé‡æŽ’æ›´å¤š
            rerank_count = min(max_rerank, len(documents))
        
        print(f"ðŸ“Š å¬å›žåˆ†æ•°åˆ†æž:")
        print(f"  å¹³å‡: {avg_score:.4f}, æ ‡å‡†å·®: {std_score:.4f}")
        print(f"  å†³å®šé‡æŽ’åºå‰ {rerank_count} ä¸ªæ–‡æ¡£")
        
        # é‡æŽ’åº
        pairs = [[query, doc] for doc in documents[:rerank_count]]
        scores = self.model.predict(pairs)
        
        # æž„å»ºç»“æžœ
        results = []
        for i in range(rerank_count):
            results.append((documents[i], scores[i], i))
        
        # æ·»åŠ æœªé‡æŽ’çš„æ–‡æ¡£ï¼ˆä¿æŒåŽŸé¡ºåºï¼‰
        for i in range(rerank_count, len(documents)):
            results.append((documents[i], retrieval_scores[i], i))
        
        # æŽ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        
        return results
```

---

### å››ã€è¯„ä¼°é‡æŽ’åºæ•ˆæžœ

#### 4.1 è¯„ä¼°æŒ‡æ ‡

```python
class RerankEvaluator:
    """é‡æŽ’åºæ•ˆæžœè¯„ä¼°å™¨"""
    
    def mrr(
        self,
        rankings: List[List[int]],
        relevant: List[int]
    ) -> float:
        """
        MRR (Mean Reciprocal Rank)
        ç¬¬ä¸€ä¸ªç›¸å…³ç»“æžœçš„å¹³å‡å€’æ•°æŽ’å
        """
        reciprocal_ranks = []
        
        for ranking in rankings:
            for i, doc_id in enumerate(ranking):
                if doc_id in relevant:
                    reciprocal_ranks.append(1.0 / (i + 1))
                    break
            else:
                reciprocal_ranks.append(0.0)
        
        return np.mean(reciprocal_ranks)
    
    def ndcg_at_k(
        self,
        ranking: List[int],
        relevance: dict,
        k: int
    ) -> float:
        """NDCG@K"""
        # DCG
        dcg = 0
        for i, doc_id in enumerate(ranking[:k]):
            rel = relevance.get(doc_id, 0)
            dcg += rel / np.log2(i + 2)
        
        # IDCG
        ideal_ranking = sorted(
            relevance.items(),
            key=lambda x: x[1],
            reverse=True
        )
        idcg = 0
        for i, (_, rel) in enumerate(ideal_ranking[:k]):
            idcg += rel / np.log2(i + 2)
        
        return dcg / idcg if idcg > 0 else 0
    
    def compare_rankings(
        self,
        before: List[int],
        after: List[int],
        relevance: dict,
        k: int = 5
    ):
        """å¯¹æ¯”é‡æŽ’åºå‰åŽçš„æ•ˆæžœ"""
        print("\n" + "="*60)
        print("é‡æŽ’åºæ•ˆæžœå¯¹æ¯”")
        print("="*60)
        
        # è®¡ç®—NDCG
        ndcg_before = self.ndcg_at_k(before, relevance, k)
        ndcg_after = self.ndcg_at_k(after, relevance, k)
        
        print(f"\nNDCG@{k}:")
        print(f"  é‡æŽ’åºå‰: {ndcg_before:.4f}")
        print(f"  é‡æŽ’åºåŽ: {ndcg_after:.4f}")
        print(f"  æå‡: {(ndcg_after - ndcg_before):.4f} ({(ndcg_after/ndcg_before-1)*100:.1f}%)")
        
        # æŸ¥çœ‹æŽ’åå˜åŒ–
        print(f"\nTop-{k}æŽ’åå¯¹æ¯”:")
        print(f"  é‡æŽ’åºå‰: {before[:k]}")
        print(f"  é‡æŽ’åºåŽ: {after[:k]}")
        
        # ç›¸å…³æ–‡æ¡£çš„æŽ’åå˜åŒ–
        print(f"\nç›¸å…³æ–‡æ¡£æŽ’åå˜åŒ–:")
        for doc_id, rel in sorted(relevance.items(), key=lambda x: x[1], reverse=True):
            if rel > 0:
                pos_before = before.index(doc_id) + 1 if doc_id in before else -1
                pos_after = after.index(doc_id) + 1 if doc_id in after else -1
                
                if pos_before > 0 and pos_after > 0:
                    change = pos_before - pos_after
                    arrow = "â†‘" if change > 0 else ("â†“" if change < 0 else "â†’")
                    print(f"  æ–‡æ¡£{doc_id} (ç›¸å…³åº¦={rel}): {pos_before} {arrow} {pos_after}")

# ä½¿ç”¨ç¤ºä¾‹
def demo_evaluation():
    """æ¼”ç¤ºè¯„ä¼°"""
    
    # æ¨¡æ‹Ÿé‡æŽ’åºå‰åŽçš„æŽ’å
    before_ranking = [1, 3, 5, 2, 4, 7, 6, 8, 9, 0]
    after_ranking = [2, 4, 1, 7, 3, 5, 6, 8, 9, 0]
    
    # ç›¸å…³æ€§æ ‡æ³¨ï¼ˆ0-3åˆ†ï¼‰
    relevance = {
        0: 0,  # ä¸ç›¸å…³
        1: 1,  # å¼±ç›¸å…³
        2: 3,  # å¼ºç›¸å…³
        3: 1,
        4: 3,  # å¼ºç›¸å…³
        5: 1,
        6: 0,
        7: 2,  # ä¸­ç­‰ç›¸å…³
        8: 0,
        9: 0,
    }
    
    evaluator = RerankEvaluator()
    evaluator.compare_rankings(before_ranking, after_ranking, relevance, k=5)

demo_evaluation()
```

---

## ðŸ“ è¯¾åŽç»ƒä¹ 

### ç»ƒä¹ 1ï¼šè®­ç»ƒè‡ªå·±çš„Cross-Encoder

ä½¿ç”¨è‡ªå·±çš„æ•°æ®fine-tune Cross-Encoderæ¨¡åž‹

### ç»ƒä¹ 2ï¼šå¤šæ¨¡åž‹é›†æˆ

ç»“åˆå¤šä¸ªé‡æŽ’åºæ¨¡åž‹ï¼ŒæŠ•ç¥¨å†³ç­–

### ç»ƒä¹ 3ï¼šå®žæ—¶æ€§ä¼˜åŒ–

ä¼˜åŒ–é‡æŽ’åºæ€§èƒ½ï¼Œæ»¡è¶³å®žæ—¶æŸ¥è¯¢éœ€æ±‚

---

## ðŸŽ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **ä¸¤é˜¶æ®µæ£€ç´¢**
   - å¬å›žï¼šBi-Encoderå¿«é€Ÿç­›é€‰
   - é‡æŽ’ï¼šCross-Encoderç²¾å‡†æŽ’åº
   - å¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦

2. **Cross-Encoderä¼˜åŠ¿**
   - è”åˆç¼–ç Queryå’ŒDocument
   - æ•æ‰ç»†ç²’åº¦äº¤äº’
   - æ˜¾è‘—æå‡å‡†ç¡®æ€§

3. **æ€§èƒ½ä¼˜åŒ–**
   - æ‰¹é‡å¤„ç†
   - ç¼“å­˜ç»“æžœ
   - è‡ªé€‚åº”ç­–ç•¥

4. **åº”ç”¨åœºæ™¯**
   - ä¼ä¸šæœç´¢
   - é—®ç­”ç³»ç»Ÿ
   - æŽ¨èç³»ç»Ÿ

### æœ€ä½³å®žè·µ

âœ… å¬å›žç”¨Bi-Encoderï¼ˆå¿«ï¼‰
âœ… é‡æŽ’ç”¨Cross-Encoderï¼ˆå‡†ï¼‰
âœ… å¬å›ž20-100ï¼Œé‡æŽ’åˆ°5-10
âœ… ç›‘æŽ§é‡æŽ’åºæ•ˆæžœ
âœ… æ ¹æ®åœºæ™¯è°ƒæ•´ç­–ç•¥

---

## ðŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬60è¯¾ï¼šå®žæˆ˜ï¼šæž„å»ºç”Ÿäº§çº§RAGç³»ç»Ÿ**

- å®Œæ•´ç³»ç»Ÿæž¶æž„
- æ€§èƒ½ä¼˜åŒ–
- é”™è¯¯å¤„ç†
- ç›‘æŽ§å’Œæ—¥å¿—
- éƒ¨ç½²æ–¹æ¡ˆ

**æŠŠæ‰€æœ‰æŠ€æœ¯æ•´åˆåˆ°ä¸€èµ·ï¼** ðŸŽ¯

---

**ðŸ’ª è®°ä½ï¼šRerankæ˜¯æå‡RAGå‡†ç¡®æ€§çš„æ€æ‰‹é”ï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ðŸŽ‰
