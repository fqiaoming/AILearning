![RAGç³»ç»Ÿæ¶æ„](./images/rag_flow.svg)
*å›¾ï¼šRAGç³»ç»Ÿæ¶æ„*

# ç¬¬60è¯¾ï¼šå®æˆ˜ï¼šæ„å»ºç”Ÿäº§çº§RAGç³»ç»Ÿ

> **æœ¬è¯¾ç›®æ ‡**ï¼šæ•´åˆæ‰€æœ‰æŠ€æœ¯ï¼Œæ„å»ºå®Œæ•´çš„ç”Ÿäº§çº§RAGç³»ç»Ÿ
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šç³»ç»Ÿæ¶æ„ã€æ€§èƒ½ä¼˜åŒ–ã€é”™è¯¯å¤„ç†ã€ç›‘æ§éƒ¨ç½²
> 
> **å®æˆ˜æ¡ˆä¾‹**ï¼šä¼ä¸šçº§RAGå®Œæ•´å®ç°
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š90åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ5åˆ†é’Ÿï¼‰
![Generation](./images/generation.svg)
*å›¾ï¼šGeneration*


### ğŸ¯ å‰è¨€

"æˆ‘è§è¿‡å¤ªå¤šè¿™æ ·çš„åœºæ™¯ï¼š

å°ç‹èŠ±äº†ä¸€ä¸ªæœˆï¼Œå­¦å®Œäº†RAGçš„æ‰€æœ‰æŠ€æœ¯ï¼š
- âœ… å‘é‡æ£€ç´¢å­¦ä¼šäº†
- âœ… æ··åˆæ£€ç´¢ææ‡‚äº†
- âœ… Queryä¼˜åŒ–ä¹Ÿä¼šäº†
- âœ… Rerankä¹Ÿå®ç°äº†

ç„¶åä¿¡å¿ƒæ»¡æ»¡åœ°å¼€å§‹åšé¡¹ç›®ï¼Œç»“æœï¼š

**ç¬¬ä¸€å¤©**ï¼šå†™äº†ä¸ªdemoï¼Œæœ¬åœ°è·‘å¾—æŒºå¥½
**ç¬¬äºŒå¤©**ï¼šåŠ äº†å‡ åƒä¸ªæ–‡æ¡£ï¼ŒæŸ¥è¯¢é€Ÿåº¦å˜æˆ10ç§’
**ç¬¬ä¸‰å¤©**ï¼šå‡ºç°ä¸€ä¸ªé”™è¯¯ï¼Œæ•´ä¸ªç³»ç»Ÿå´©æºƒï¼Œä¸çŸ¥é“å“ªé‡Œå‡ºé—®é¢˜
**ç¬¬å››å¤©**ï¼šè€æ¿é—®æ•ˆæœæ€ä¹ˆæ ·ï¼Œä»–è¯´'ä¸çŸ¥é“ï¼Œæ²¡ç›‘æ§'
**ç¬¬äº”å¤©**ï¼šæƒ³æ”¹ä¸ªå‚æ•°ï¼Œå‘ç°ä»£ç å¤ªä¹±ï¼Œä¸æ•¢åŠ¨

**ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿå› ä¸ºdemoå’Œç”Ÿäº§ç³»ç»Ÿå·®è·å¤ªå¤§äº†ï¼**

æˆ‘è‡ªå·±åœ¨åšRAGé¡¹ç›®æ—¶ä¹Ÿè¸©è¿‡æ— æ•°å‘ï¼š

**æ€§èƒ½å‘**ï¼š
- åˆç‰ˆç³»ç»ŸæŸ¥è¯¢è¦15ç§’ï¼Œç”¨æˆ·å®Œå…¨æ— æ³•æ¥å—
- ä¼˜åŒ–åé™åˆ°2ç§’ä»¥å†…ï¼Œæ‰ç®—èƒ½ç”¨

**ç¨³å®šæ€§å‘**ï¼š
- æŸä¸ªæ–‡æ¡£æ ¼å¼ä¸å¯¹ï¼Œæ•´ä¸ªç³»ç»Ÿå°±å´©äº†
- å‘é‡åº“å¶å°”è¿æ¥å¤±è´¥ï¼Œæ²¡æœ‰é‡è¯•æœºåˆ¶

**ç»´æŠ¤æ€§å‘**ï¼š
- ä»£ç å†™å¾—å¤ªéšæ„ï¼Œ3ä¸ªæœˆåè‡ªå·±éƒ½çœ‹ä¸æ‡‚
- æƒ³åŠ ä¸ªæ–°åŠŸèƒ½ï¼Œå‘ç°è¦æ”¹ä¸€å †åœ°æ–¹

**ç›‘æ§ç›²åŒº**ï¼š
- ç”¨æˆ·è¯´"ä½ è¿™ä¸ªç³»ç»Ÿä¸è¡Œå•Š"ï¼Œæˆ‘é—®å“ªé‡Œä¸è¡Œï¼Œä»–è¯´ä¸çŸ¥é“
- æŸ¥äº†åŠå¤©æ—¥å¿—ï¼Œå‘ç°æ ¹æœ¬æ²¡è®°å½•å…³é”®ä¿¡æ¯

è¿™äº›å‘ï¼ŒèŠ±äº†æˆ‘å¤§åŠå¹´æ—¶é—´æ‰å¡«å®Œï¼

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦æŠŠè¿™äº›è¡€æ³ªæ•™è®­å…¨éƒ¨åˆ†äº«ç»™ä½ ï¼**

æˆ‘ä»¬è¦æ„å»ºçš„ä¸æ˜¯ä¸€ä¸ªdemoï¼Œè€Œæ˜¯ä¸€ä¸ªï¼š

âœ… **é«˜æ€§èƒ½**çš„ç³»ç»Ÿ
   - æŸ¥è¯¢å“åº” < 2ç§’
   - æ”¯æŒå¹¶å‘æŸ¥è¯¢
   - èµ„æºåˆ©ç”¨ç‡é«˜

âœ… **é«˜å¯é **çš„ç³»ç»Ÿ
   - å®Œå–„çš„é”™è¯¯å¤„ç†
   - è‡ªåŠ¨é‡è¯•æœºåˆ¶
   - é™çº§ç­–ç•¥

âœ… **å¯è§‚æµ‹**çš„ç³»ç»Ÿ
   - è¯¦ç»†çš„æ—¥å¿—è®°å½•
   - å®æ—¶æ€§èƒ½ç›‘æ§
   - é—®é¢˜å¿«é€Ÿå®šä½

âœ… **æ˜“ç»´æŠ¤**çš„ç³»ç»Ÿ
   - ä»£ç ç»“æ„æ¸…æ™°
   - é…ç½®çµæ´»å¯è°ƒ
   - æ–‡æ¡£å®Œå–„

âœ… **å¯æ‰©å±•**çš„ç³»ç»Ÿ
   - æ¨¡å—åŒ–è®¾è®¡
   - æ’ä»¶åŒ–æ¶æ„
   - æ˜“äºæ·»åŠ æ–°åŠŸèƒ½

è¿™ä¸€è¯¾æˆ‘ä¼šæ•™ä½ ï¼š

**ç¬¬ä¸€éƒ¨åˆ†ï¼šå®Œæ•´æ¶æ„è®¾è®¡**
- åˆ†å±‚æ¶æ„çš„è®¾è®¡åŸåˆ™
- å„æ¨¡å—çš„èŒè´£åˆ’åˆ†
- æ¥å£è®¾è®¡çš„æœ€ä½³å®è·µ

**ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒä»£ç å®ç°**
- é…ç½®ç®¡ç†ç³»ç»Ÿ
- å®Œæ•´çš„RAG Pipeline
- é”™è¯¯å¤„ç†æœºåˆ¶
- ç¼“å­˜ç­–ç•¥

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ–**
- æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–
- å†…å­˜ä¼˜åŒ–
- æ‰¹å¤„ç†ä¼˜åŒ–
- å¼‚æ­¥å¤„ç†

**ç¬¬å››éƒ¨åˆ†ï¼šç›‘æ§å’Œæ—¥å¿—**
- ç»“æ„åŒ–æ—¥å¿—
- æ€§èƒ½æŒ‡æ ‡é‡‡é›†
- ç›‘æ§å¤§ç›˜
- å‘Šè­¦æœºåˆ¶

**ç¬¬äº”éƒ¨åˆ†ï¼šéƒ¨ç½²æ–¹æ¡ˆ**
- Dockerå®¹å™¨åŒ–
- APIæœåŠ¡éƒ¨ç½²
- è´Ÿè½½å‡è¡¡
- é«˜å¯ç”¨æ–¹æ¡ˆ

**è¿™æ˜¯ä½ ä»å…¥é—¨åˆ°ç²¾é€šçš„æœ€åä¸€è¯¾ï¼Œä¹Ÿæ˜¯æœ€é‡è¦çš„ä¸€è¯¾ï¼**

å­¦å®Œè¿™ä¸€è¯¾ï¼Œä½ å°±èƒ½ç‹¬ç«‹æ„å»ºä¸€ä¸ªçœŸæ­£èƒ½ä¸Šçº¿çš„RAGç³»ç»Ÿï¼

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ï¼"

---

### ğŸ’¡ è¯¾ç¨‹æ ¸å¿ƒä»·å€¼

```
ã€Demoç³»ç»Ÿ vs ç”Ÿäº§ç³»ç»Ÿã€‘

Demoç³»ç»Ÿï¼š
â€¢ åŠŸèƒ½èƒ½è·‘å°±è¡Œ
â€¢ æ€§èƒ½æ…¢ç‚¹æ— æ‰€è°“
â€¢ å‡ºé”™äº†é‡å¯
â€¢ ä»£ç éšä¾¿å†™
â€¢ æ²¡æœ‰ç›‘æ§

ç”Ÿäº§ç³»ç»Ÿï¼š
â€¢ åŠŸèƒ½ç¨³å®šå¯é  âœ…
â€¢ æ€§èƒ½è¾¾æ ‡ < 2ç§’ âœ…
â€¢ é”™è¯¯è‡ªåŠ¨å¤„ç† âœ…
â€¢ ä»£ç è§„èŒƒæ˜“ç»´æŠ¤ âœ…
â€¢ ç›‘æ§å‘Šè­¦å®Œå–„ âœ…

è¿™ä¸€è¯¾æ•™ä½ å¦‚ä½•ä»å·¦è¾¹åˆ°å³è¾¹ï¼
```

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šç³»ç»Ÿæ¶æ„è®¾è®¡

### ä¸€ã€æ¶æ„è®¾è®¡åŸåˆ™

```
ã€ä¼˜ç§€æ¶æ„çš„å…­å¤§åŸåˆ™ã€‘

1. å•ä¸€èŒè´£åŸåˆ™
   æ¯ä¸ªæ¨¡å—åªåšä¸€ä»¶äº‹ï¼Œåšå¥½ä¸€ä»¶äº‹

2. å¼€é—­åŸåˆ™
   å¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å°é—­

3. ä¾èµ–å€’ç½®åŸåˆ™
   ä¾èµ–æŠ½è±¡ï¼Œä¸ä¾èµ–å…·ä½“å®ç°

4. æ¥å£éš”ç¦»åŸåˆ™
   æ¥å£å°è€Œä¸“ï¼Œä¸è¦è‡ƒè‚¿

5. é«˜å†…èšä½è€¦åˆ
   æ¨¡å—å†…éƒ¨ç´§å¯†ï¼Œæ¨¡å—ä¹‹é—´æ¾æ•£

6. å¯æµ‹è¯•æ€§
   æ¯ä¸ªæ¨¡å—éƒ½å¯ä»¥ç‹¬ç«‹æµ‹è¯•
```

### äºŒã€æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  å®¢æˆ·ç«¯å±‚                        â”‚
â”‚  Web UI / API / å‘½ä»¤è¡Œ                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  æ¥å£å±‚                          â”‚
â”‚  â€¢ è¯·æ±‚éªŒè¯                                      â”‚
â”‚  â€¢ é™æµæ§åˆ¶                                      â”‚
â”‚  â€¢ ç»“æœç¼“å­˜                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               æ ¸å¿ƒå¤„ç†å±‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  1. Queryä¼˜åŒ–æ¨¡å—                  â”‚          â”‚
â”‚  â”‚     â€¢ é¢„å¤„ç†                       â”‚          â”‚
â”‚  â”‚     â€¢ çº é”™                         â”‚          â”‚
â”‚  â”‚     â€¢ æ‰©å±•                         â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚               â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  2. æ£€ç´¢æ¨¡å—                       â”‚          â”‚
â”‚  â”‚     â€¢ å‘é‡æ£€ç´¢                     â”‚          â”‚
â”‚  â”‚     â€¢ BM25æ£€ç´¢                     â”‚          â”‚
â”‚  â”‚     â€¢ å…ƒæ•°æ®è¿‡æ»¤                   â”‚          â”‚
â”‚  â”‚     â€¢ ç»“æœèåˆ                     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚               â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  3. é‡æ’åºæ¨¡å—                     â”‚          â”‚
â”‚  â”‚     â€¢ Cross-Encoder                â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚               â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  4. ç”Ÿæˆæ¨¡å—                       â”‚          â”‚
â”‚  â”‚     â€¢ Promptæ„å»º                   â”‚          â”‚
â”‚  â”‚     â€¢ LLMè°ƒç”¨                      â”‚          â”‚
â”‚  â”‚     â€¢ ç­”æ¡ˆåå¤„ç†                   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 æ•°æ®å±‚                           â”‚
â”‚  â€¢ å‘é‡æ•°æ®åº“ (Chroma)                          â”‚
â”‚  â€¢ æ–‡æ¡£å­˜å‚¨                                      â”‚
â”‚  â€¢ ç¼“å­˜ (Redis)                                 â”‚
â”‚  â€¢ æ—¥å¿—å­˜å‚¨                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒä»£ç å®ç°

### ä¸€ã€é¡¹ç›®ç»“æ„

```
production_rag/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py          # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ prompts.py           # Promptæ¨¡æ¿
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ query_optimizer.py   # Queryä¼˜åŒ–
â”‚   â”œâ”€â”€ retriever.py         # æ£€ç´¢å™¨
â”‚   â”œâ”€â”€ reranker.py          # é‡æ’åº
â”‚   â””â”€â”€ generator.py         # ç­”æ¡ˆç”Ÿæˆ
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py            # æ—¥å¿—å·¥å…·
â”‚   â”œâ”€â”€ cache.py             # ç¼“å­˜å·¥å…·
â”‚   â””â”€â”€ metrics.py           # æŒ‡æ ‡æ”¶é›†
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py               # FastAPIåº”ç”¨
â”‚   â””â”€â”€ models.py            # APIæ¨¡å‹
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_retriever.py
â”‚   â”œâ”€â”€ test_reranker.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### äºŒã€é…ç½®ç®¡ç†ç³»ç»Ÿ

```python
# config/settings.py
from pydantic import BaseSettings
from typing import Optional
import os

class Settings(BaseSettings):
    """ç³»ç»Ÿé…ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡ï¼‰"""
    
    # ========== åŸºç¡€é…ç½® ==========
    app_name: str = "Production RAG System"
    version: str = "1.0.0"
    debug: bool = False
    
    # ========== æ¨¡å‹é…ç½® ==========
    embedding_model: str = "moka-ai/m3e-base"
    embedding_device: str = "cpu"
    embedding_batch_size: int = 32
    
    rerank_model: str = "BAAI/bge-reranker-base"
    rerank_enabled: bool = True
    rerank_batch_size: int = 16
    
    # ========== LLMé…ç½® ==========
    llm_base_url: str = "http://localhost:1234/v1"
    llm_api_key: str = "lm-studio"
    llm_model: str = "local-model"
    llm_temperature: float = 0.0
    llm_max_tokens: int = 500
    llm_timeout: int = 30
    
    # ========== æ£€ç´¢é…ç½® ==========
    retrieval_k: int = 20
    retrieval_timeout: int = 10
    rerank_k: int = 5
    
    # ========== å‘é‡åº“é…ç½® ==========
    vector_db_path: str = "./data/chroma_db"
    vector_db_collection: str = "documents"
    
    # ========== ç¼“å­˜é…ç½® ==========
    cache_enabled: bool = True
    cache_ttl: int = 3600
    cache_max_size: int = 1000
    
    # ========== æ€§èƒ½é…ç½® ==========
    max_concurrent_queries: int = 10
    query_timeout: int = 60
    
    # ========== æ—¥å¿—é…ç½® ==========
    log_level: str = "INFO"
    log_file: str = "./logs/rag_system.log"
    log_rotation: str = "1 day"
    log_retention: str = "30 days"
    
    # ========== ç›‘æ§é…ç½® ==========
    metrics_enabled: bool = True
    metrics_port: int = 9090
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# å…¨å±€é…ç½®å®ä¾‹
settings = Settings()

# config/prompts.py
class PromptTemplates:
    """Promptæ¨¡æ¿ç®¡ç†"""
    
    QA_TEMPLATE = """è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{query}

è¦æ±‚ï¼š
1. å¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·åŸºäºä¸Šä¸‹æ–‡å‡†ç¡®å›ç­”
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´"æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜"
3. ä¸è¦ç¼–é€ ä¿¡æ¯
4. å›ç­”è¦ç®€æ´æ˜äº†
5. å¦‚æœå¯èƒ½ï¼Œè¯·å¼•ç”¨å…·ä½“çš„ä¸Šä¸‹æ–‡ç‰‡æ®µ

ç­”æ¡ˆï¼š"""
    
    SUMMARY_TEMPLATE = """è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š

{content}

æ€»ç»“ï¼š"""
    
    @staticmethod
    def format_qa_prompt(query: str, context: str) -> str:
        """æ ¼å¼åŒ–QA Prompt"""
        return PromptTemplates.QA_TEMPLATE.format(
            query=query,
            context=context
        )
```

### ä¸‰ã€æ ¸å¿ƒç³»ç»Ÿç±»

```python
# core/rag_system.py
import logging
import time
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

@dataclass
class RAGConfig:
    """RAGç³»ç»Ÿé…ç½®"""
    # å‘é‡æ¨¡å‹
    embedding_model: str = "moka-ai/m3e-base"
    rerank_model: str = "BAAI/bge-reranker-base"
    
    # LLMé…ç½®
    llm_base_url: str = "http://localhost:1234/v1"
    llm_api_key: str = "lm-studio"
    llm_model: str = "local-model"
    llm_temperature: float = 0
    
    # æ£€ç´¢é…ç½®
    retrieval_k: int = 20
    rerank_k: int = 5
    
    # æ€§èƒ½é…ç½®
    enable_cache: bool = True
    enable_rerank: bool = True
    cache_ttl: int = 3600
    
    # è¶…æ—¶é…ç½®
    retrieval_timeout: int = 10
    generation_timeout: int = 30

@dataclass
class QueryResult:
    """æŸ¥è¯¢ç»“æœ"""
    query: str
    answer: str
    sources: List[Dict]
    metadata: Dict
    timing: Dict
    
    def to_dict(self):
        return asdict(self)

class ProductionRAGSystem:
    """ç”Ÿäº§çº§RAGç³»ç»Ÿ"""
    
    def __init__(self, config: RAGConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()
        
        # æ€§èƒ½æŒ‡æ ‡
        self.metrics = {
            'total_queries': 0,
            'cache_hits': 0,
            'errors': 0
        }
    
    def _init_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            self.logger.info("åˆå§‹åŒ–RAGç³»ç»Ÿç»„ä»¶...")
            
            # 1. Queryä¼˜åŒ–å™¨
            from query_optimizer import QueryOptimizer
            self.query_optimizer = QueryOptimizer()
            
            # 2. æ£€ç´¢å™¨
            from hybrid_retriever import HybridRetriever
            self.retriever = HybridRetriever(
                embedding_model=self.config.embedding_model
            )
            
            # 3. é‡æ’åºå™¨
            if self.config.enable_rerank:
                from reranker import CrossEncoderReranker
                self.reranker = CrossEncoderReranker(
                    model_name=self.config.rerank_model
                )
            
            # 4. LLMå®¢æˆ·ç«¯
            from langchain.chat_models import ChatOpenAI
            self.llm = ChatOpenAI(
                base_url=self.config.llm_base_url,
                api_key=self.config.llm_api_key,
                model=self.config.llm_model,
                temperature=self.config.llm_temperature
            )
            
            # 5. ç¼“å­˜
            if self.config.enable_cache:
                self.cache = {}
            
            self.logger.info("âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def query(
        self,
        query: str,
        metadata_filters: Optional[Dict] = None,
        verbose: bool = False
    ) -> QueryResult:
        """
        æ‰§è¡ŒæŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            metadata_filters: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        start_time = time.time()
        timing = {}
        
        try:
            self.metrics['total_queries'] += 1
            
            if verbose:
                self.logger.info(f"æ”¶åˆ°æŸ¥è¯¢: {query}")
            
            # 1. æ£€æŸ¥ç¼“å­˜
            if self.config.enable_cache:
                cache_key = self._get_cache_key(query, metadata_filters)
                cached = self._get_from_cache(cache_key)
                if cached:
                    self.metrics['cache_hits'] += 1
                    if verbose:
                        self.logger.info("âœ… ç¼“å­˜å‘½ä¸­")
                    return cached
            
            # 2. Queryä¼˜åŒ–
            t0 = time.time()
            optimized = self.query_optimizer.optimize(query, verbose=False)
            timing['query_optimization'] = time.time() - t0
            
            if verbose:
                self.logger.info(f"Queryä¼˜åŒ–: {optimized['corrected']}")
            
            # 3. æ£€ç´¢
            t0 = time.time()
            retrieved = self.retriever.search(
                query=optimized['corrected'],
                k=self.config.retrieval_k,
                metadata_filters=metadata_filters
            )
            timing['retrieval'] = time.time() - t0
            
            if verbose:
                self.logger.info(f"æ£€ç´¢åˆ° {len(retrieved)} ä¸ªæ–‡æ¡£")
            
            # 4. é‡æ’åº
            if self.config.enable_rerank and retrieved:
                t0 = time.time()
                docs = [doc.content for doc, _ in retrieved]
                reranked = self.reranker.rerank(
                    query=optimized['corrected'],
                    documents=docs,
                    top_k=self.config.rerank_k
                )
                timing['rerank'] = time.time() - t0
                
                # é‡æ–°æ„å»ºç»“æœ
                retrieved = [(docs[idx], score) for _, score, idx in reranked]
                
                if verbose:
                    self.logger.info(f"é‡æ’åºå®Œæˆï¼Œä¿ç•™Top-{len(retrieved)}")
            
            # 5. ç”Ÿæˆç­”æ¡ˆ
            t0 = time.time()
            answer = self._generate_answer(
                query=query,
                context_docs=retrieved
            )
            timing['generation'] = time.time() - t0
            
            if verbose:
                self.logger.info("ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
            
            # 6. æ„å»ºç»“æœ
            total_time = time.time() - start_time
            timing['total'] = total_time
            
            result = QueryResult(
                query=query,
                answer=answer,
                sources=[
                    {
                        'content': doc[:200] + '...',
                        'score': float(score)
                    }
                    for doc, score in retrieved[:5]
                ],
                metadata={
                    'optimized_query': optimized['corrected'],
                    'intent': optimized.get('intent', {}).get('value', 'unknown'),
                    'num_retrieved': len(retrieved)
                },
                timing=timing
            )
            
            # 7. ç¼“å­˜ç»“æœ
            if self.config.enable_cache:
                self._save_to_cache(cache_key, result)
            
            if verbose:
                self.logger.info(f"âœ… æŸ¥è¯¢å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}ç§’")
            
            return result
            
        except Exception as e:
            self.metrics['errors'] += 1
            self.logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            
            # è¿”å›é”™è¯¯ç»“æœ
            return QueryResult(
                query=query,
                answer=f"æŠ±æ­‰ï¼ŒæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                sources=[],
                metadata={'error': str(e)},
                timing={'total': time.time() - start_time}
            )
    
    def _generate_answer(
        self,
        query: str,
        context_docs: List[tuple]
    ) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([
            f"ã€æ–‡æ¡£{i+1}ã€‘\n{doc}"
            for i, (doc, _) in enumerate(context_docs)
        ])
        
        # æ„å»ºPrompt
        prompt = f"""è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{query}

è¦æ±‚ï¼š
1. å¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·å‡†ç¡®å›ç­”
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. ä¸è¦ç¼–é€ ä¿¡æ¯
4. å›ç­”è¦ç®€æ´æ˜äº†

ç­”æ¡ˆï¼š"""
        
        # è°ƒç”¨LLM
        response = self.llm.invoke(prompt)
        return response.content
    
    def _get_cache_key(self, query: str, metadata_filters: Optional[Dict]) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        import hashlib
        key_str = f"{query}_{json.dumps(metadata_filters, sort_keys=True)}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _get_from_cache(self, key: str) -> Optional[QueryResult]:
        """ä»ç¼“å­˜è·å–"""
        return self.cache.get(key)
    
    def _save_to_cache(self, key: str, result: QueryResult):
        """ä¿å­˜åˆ°ç¼“å­˜"""
        self.cache[key] = result
    
    def get_metrics(self) -> Dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        return {
            **self.metrics,
            'cache_hit_rate': (
                self.metrics['cache_hits'] / self.metrics['total_queries']
                if self.metrics['total_queries'] > 0 else 0
            )
        }
    
    def health_check(self) -> Dict:
        """å¥åº·æ£€æŸ¥"""
        return {
            'status': 'healthy',
            'components': {
                'retriever': 'ok',
                'reranker': 'ok' if self.config.enable_rerank else 'disabled',
                'llm': 'ok',
                'cache': 'ok' if self.config.enable_cache else 'disabled'
            },
            'metrics': self.get_metrics()
        }
```

---

---

## ğŸ”§ ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ–

### ä¸€ã€æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

```python
# utils/performance.py
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Callable, Any

class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self, max_workers: int = 4):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    async def parallel_execute(
        self,
        tasks: List[Callable],
        *args, **kwargs
    ) -> List[Any]:
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡"""
        loop = asyncio.get_event_loop()
        futures = [
            loop.run_in_executor(self.executor, task, *args, **kwargs)
            for task in tasks
        ]
        return await asyncio.gather(*futures)

# åœ¨RAGç³»ç»Ÿä¸­ä½¿ç”¨
class OptimizedRAGSystem(ProductionRAGSystem):
    """æ€§èƒ½ä¼˜åŒ–ç‰ˆRAGç³»ç»Ÿ"""
    
    async def query_async(
        self,
        query: str,
        **kwargs
    ) -> QueryResult:
        """å¼‚æ­¥æŸ¥è¯¢ï¼ˆæå‡å¹¶å‘æ€§èƒ½ï¼‰"""
        
        # 1. Queryä¼˜åŒ–ï¼ˆå¯å¹¶è¡Œï¼‰
        optimized_task = asyncio.create_task(
            self._optimize_query_async(query)
        )
        
        # 2. ç­‰å¾…ä¼˜åŒ–å®Œæˆ
        optimized = await optimized_task
        
        # 3. æ£€ç´¢ï¼ˆå¯èƒ½éœ€è¦å¤šä¸ªæºï¼‰
        retrieval_tasks = [
            self._vector_search_async(optimized['corrected']),
            self._bm25_search_async(optimized['corrected'])
        ]
        
        results = await asyncio.gather(*retrieval_tasks)
        
        # 4. èåˆå’Œé‡æ’åº
        fused = self._fuse_results(results)
        
        if self.config.enable_rerank:
            reranked = await self._rerank_async(query, fused)
        else:
            reranked = fused
        
        # 5. ç”Ÿæˆç­”æ¡ˆ
        answer = await self._generate_async(query, reranked)
        
        return self._build_result(query, answer, reranked)
```

### äºŒã€ç¼“å­˜ç­–ç•¥

```python
# utils/cache.py
from functools import lru_cache
import hashlib
import time
from typing import Optional, Any
import redis

class SmartCache:
    """æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ"""
    
    def __init__(
        self,
        use_redis: bool = False,
        redis_host: str = "localhost",
        redis_port: int = 6379,
        ttl: int = 3600,
        max_size: int = 1000
    ):
        self.ttl = ttl
        self.use_redis = use_redis
        
        if use_redis:
            self.redis_client = redis.Redis(
                host=redis_host,
                port=redis_port,
                decode_responses=True
            )
        else:
            # ä½¿ç”¨å†…å­˜ç¼“å­˜
            self.memory_cache = {}
            self.cache_times = {}
            self.max_size = max_size
    
    def _get_key(self, query: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        key_str = f"{query}_{str(sorted(kwargs.items()))}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, query: str, **kwargs) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        key = self._get_key(query, **kwargs)
        
        if self.use_redis:
            return self._get_from_redis(key)
        else:
            return self._get_from_memory(key)
    
    def set(self, query: str, value: Any, **kwargs):
        """è®¾ç½®ç¼“å­˜"""
        key = self._get_key(query, **kwargs)
        
        if self.use_redis:
            self._set_to_redis(key, value)
        else:
            self._set_to_memory(key, value)
    
    def _get_from_memory(self, key: str) -> Optional[Any]:
        """ä»å†…å­˜è·å–"""
        if key not in self.memory_cache:
            return None
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if time.time() - self.cache_times[key] > self.ttl:
            del self.memory_cache[key]
            del self.cache_times[key]
            return None
        
        return self.memory_cache[key]
    
    def _set_to_memory(self, key: str, value: Any):
        """è®¾ç½®åˆ°å†…å­˜"""
        # LRUæ·˜æ±°
        if len(self.memory_cache) >= self.max_size:
            oldest_key = min(self.cache_times, key=self.cache_times.get)
            del self.memory_cache[oldest_key]
            del self.cache_times[oldest_key]
        
        self.memory_cache[key] = value
        self.cache_times[key] = time.time()
    
    def _get_from_redis(self, key: str) -> Optional[Any]:
        """ä»Redisè·å–"""
        import json
        value = self.redis_client.get(key)
        return json.loads(value) if value else None
    
    def _set_to_redis(self, key: str, value: Any):
        """è®¾ç½®åˆ°Redis"""
        import json
        self.redis_client.setex(
            key,
            self.ttl,
            json.dumps(value)
        )
```

### ä¸‰ã€æ‰¹å¤„ç†ä¼˜åŒ–

```python
class BatchProcessor:
    """æ‰¹å¤„ç†ä¼˜åŒ–å™¨"""
    
    def __init__(self, batch_size: int = 32):
        self.batch_size = batch_size
    
    def batch_embed(
        self,
        texts: List[str],
        model
    ) -> np.ndarray:
        """æ‰¹é‡å‘é‡åŒ–ï¼ˆå‡å°‘æ¨¡å‹è°ƒç”¨æ¬¡æ•°ï¼‰"""
        embeddings = []
        
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i:i + self.batch_size]
            batch_emb = model.encode(batch)
            embeddings.append(batch_emb)
        
        return np.vstack(embeddings)
    
    def batch_rerank(
        self,
        query: str,
        documents: List[str],
        model,
        batch_size: int = 16
    ) -> List[float]:
        """æ‰¹é‡é‡æ’åº"""
        scores = []
        
        for i in range(0, len(documents), batch_size):
            batch_docs = documents[i:i + batch_size]
            pairs = [[query, doc] for doc in batch_docs]
            batch_scores = model.predict(pairs)
            scores.extend(batch_scores)
        
        return scores
```

---

## ğŸ“Š ç¬¬å››éƒ¨åˆ†ï¼šç›‘æ§å’Œæ—¥å¿—

### ä¸€ã€ç»“æ„åŒ–æ—¥å¿—

```python
# utils/logger.py
import logging
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—å™¨"""
    
    def __init__(
        self,
        name: str,
        log_file: str = "./logs/rag_system.log",
        level: str = "INFO"
    ):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(getattr(logging, level))
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
        
        # æ–‡ä»¶å¤„ç†å™¨
        fh = logging.FileHandler(log_file, encoding='utf-8')
        fh.setLevel(getattr(logging, level))
        
        # æ§åˆ¶å°å¤„ç†å™¨
        ch = logging.StreamHandler()
        ch.setLevel(getattr(logging, level))
        
        # æ ¼å¼åŒ–
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        fh.setFormatter(formatter)
        ch.setFormatter(formatter)
        
        self.logger.addHandler(fh)
        self.logger.addHandler(ch)
    
    def log_query(
        self,
        query: str,
        result: QueryResult,
        user_id: Optional[str] = None,
        **extra
    ):
        """è®°å½•æŸ¥è¯¢æ—¥å¿—"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'event': 'query',
            'user_id': user_id,
            'query': query,
            'query_length': len(query),
            'answer_length': len(result.answer),
            'num_sources': len(result.sources),
            'timing': result.timing,
            'metadata': result.metadata,
            **extra
        }
        
        self.logger.info(json.dumps(log_data, ensure_ascii=False))
    
    def log_error(
        self,
        error: Exception,
        context: Dict[str, Any]
    ):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'event': 'error',
            'error_type': type(error).__name__,
            'error_message': str(error),
            'context': context
        }
        
        self.logger.error(json.dumps(log_data, ensure_ascii=False))
    
    def log_performance(
        self,
        operation: str,
        duration: float,
        **metrics
    ):
        """è®°å½•æ€§èƒ½æ—¥å¿—"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'event': 'performance',
            'operation': operation,
            'duration': duration,
            **metrics
        }
        
        self.logger.info(json.dumps(log_data, ensure_ascii=False))
```

### äºŒã€æ€§èƒ½æŒ‡æ ‡é‡‡é›†

```python
# utils/metrics.py
from dataclasses import dataclass, field
from typing import Dict, List
import time
from collections import defaultdict
import numpy as np

@dataclass
class MetricsCollector:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""
    
    total_queries: int = 0
    successful_queries: int = 0
    failed_queries: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    
    query_times: List[float] = field(default_factory=list)
    retrieval_times: List[float] = field(default_factory=list)
    rerank_times: List[float] = field(default_factory=list)
    generation_times: List[float] = field(default_factory=list)
    
    error_counts: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    
    def record_query(
        self,
        success: bool,
        timing: Dict[str, float],
        cache_hit: bool = False
    ):
        """è®°å½•æŸ¥è¯¢æŒ‡æ ‡"""
        self.total_queries += 1
        
        if success:
            self.successful_queries += 1
        else:
            self.failed_queries += 1
        
        if cache_hit:
            self.cache_hits += 1
        else:
            self.cache_misses += 1
        
        # è®°å½•æ—¶é—´
        if 'total' in timing:
            self.query_times.append(timing['total'])
        if 'retrieval' in timing:
            self.retrieval_times.append(timing['retrieval'])
        if 'rerank' in timing:
            self.rerank_times.append(timing['rerank'])
        if 'generation' in timing:
            self.generation_times.append(timing['generation'])
    
    def record_error(self, error_type: str):
        """è®°å½•é”™è¯¯"""
        self.error_counts[error_type] += 1
    
    def get_summary(self) -> Dict:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        return {
            'total_queries': self.total_queries,
            'successful_queries': self.successful_queries,
            'failed_queries': self.failed_queries,
            'success_rate': (
                self.successful_queries / self.total_queries
                if self.total_queries > 0 else 0
            ),
            'cache_hit_rate': (
                self.cache_hits / (self.cache_hits + self.cache_misses)
                if (self.cache_hits + self.cache_misses) > 0 else 0
            ),
            'avg_query_time': np.mean(self.query_times) if self.query_times else 0,
            'p50_query_time': np.percentile(self.query_times, 50) if self.query_times else 0,
            'p95_query_time': np.percentile(self.query_times, 95) if self.query_times else 0,
            'p99_query_time': np.percentile(self.query_times, 99) if self.query_times else 0,
            'avg_retrieval_time': np.mean(self.retrieval_times) if self.retrieval_times else 0,
            'avg_rerank_time': np.mean(self.rerank_times) if self.rerank_times else 0,
            'avg_generation_time': np.mean(self.generation_times) if self.generation_times else 0,
            'error_counts': dict(self.error_counts)
        }
```

---

## ğŸš€ ç¬¬äº”éƒ¨åˆ†ï¼šAPIæœåŠ¡ä¸éƒ¨ç½²

### ä¸€ã€FastAPIå®Œæ•´å®ç°

```python
# api/app.py
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
import time

app = FastAPI(
    title="Production RAG API",
    version="1.0.0",
    description="ä¼ä¸šçº§RAGç³»ç»ŸAPI"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–RAGç³»ç»Ÿï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
rag_system = None

def get_rag_system():
    """è·å–RAGç³»ç»Ÿå®ä¾‹"""
    global rag_system
    if rag_system is None:
        from config.settings import settings
        rag_system = ProductionRAGSystem(settings)
    return rag_system

# APIæ¨¡å‹å®šä¹‰
class QueryRequest(BaseModel):
    query: str
    metadata_filters: Optional[Dict] = None
    user_id: Optional[str] = None
    verbose: bool = False
    
    class Config:
        schema_extra = {
            "example": {
                "query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                "metadata_filters": {"category": "æŠ€æœ¯"},
                "user_id": "user123",
                "verbose": False
            }
        }

class QueryResponse(BaseModel):
    query: str
    answer: str
    sources: List[Dict]
    metadata: Dict
    timing: Dict
    request_id: str

class HealthResponse(BaseModel):
    status: str
    version: str
    components: Dict
    timestamp: str

@app.post("/v1/query", response_model=QueryResponse, tags=["Query"])
async def query(
    request: QueryRequest,
    background_tasks: BackgroundTasks,
    rag: ProductionRAGSystem = Depends(get_rag_system)
):
    """
    æŸ¥è¯¢æ¥å£
    
    - **query**: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
    - **metadata_filters**: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ï¼ˆå¯é€‰ï¼‰
    - **user_id**: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œç”¨äºæ—¥å¿—ï¼‰
    - **verbose**: æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯
    """
    import uuid
    request_id = str(uuid.uuid4())
    
    try:
        start_time = time.time()
        
        result = rag.query(
            query=request.query,
            metadata_filters=request.metadata_filters,
            verbose=request.verbose
        )
        
        # åå°ä»»åŠ¡ï¼šè®°å½•æ—¥å¿—
        background_tasks.add_task(
            rag.logger.log_query,
            query=request.query,
            result=result,
            user_id=request.user_id,
            request_id=request_id
        )
        
        response = result.to_dict()
        response['request_id'] = request_id
        
        return response
        
    except Exception as e:
        rag.logger.log_error(e, {
            'query': request.query,
            'request_id': request_id
        })
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health", response_model=HealthResponse, tags=["System"])
async def health(rag: ProductionRAGSystem = Depends(get_rag_system)):
    """å¥åº·æ£€æŸ¥"""
    from datetime import datetime
    
    health_status = rag.health_check()
    health_status['timestamp'] = datetime.now().isoformat()
    
    return health_status

@app.get("/metrics", tags=["System"])
async def metrics(rag: ProductionRAGSystem = Depends(get_rag_system)):
    """æ€§èƒ½æŒ‡æ ‡"""
    return rag.metrics_collector.get_summary()

@app.post("/v1/index", tags=["Management"])
async def index_documents(
    documents: List[str],
    rag: ProductionRAGSystem = Depends(get_rag_system)
):
    """ç´¢å¼•æ–‡æ¡£"""
    try:
        rag.index_documents(documents)
        return {"status": "success", "count": len(documents)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
```

### äºŒã€Dockeréƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p logs data

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "api.app:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  rag-api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      - LOG_LEVEL=INFO
      - CACHE_ENABLED=true
      - RERANK_ENABLED=true
    restart: unless-stopped
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped
```

### ä¸‰ã€éƒ¨ç½²è„šæœ¬

```bash
# deploy.sh
#!/bin/bash

echo "ğŸš€ å¼€å§‹éƒ¨ç½²RAGç³»ç»Ÿ..."

# 1. æ„å»ºDockeré•œåƒ
echo "ğŸ“¦ æ„å»ºDockeré•œåƒ..."
docker-compose build

# 2. å¯åŠ¨æœåŠ¡
echo "ğŸ”„ å¯åŠ¨æœåŠ¡..."
docker-compose up -d

# 3. ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 10

# 4. å¥åº·æ£€æŸ¥
echo "ğŸ¥ å¥åº·æ£€æŸ¥..."
curl -f http://localhost:8000/health || exit 1

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "ğŸ“ APIåœ°å€: http://localhost:8000"
echo "ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs"
```

---

## ğŸ¯ ç¬¬å…­éƒ¨åˆ†ï¼šæµ‹è¯•ä¸è´¨é‡ä¿è¯

### ä¸€ã€å•å…ƒæµ‹è¯•

```python
# tests/test_retriever.py
import pytest
from core.retriever import HybridRetriever

class TestRetriever:
    """æµ‹è¯•æ£€ç´¢å™¨"""
    
    @pytest.fixture
    def retriever(self):
        """æµ‹è¯•å¤¹å…·"""
        return HybridRetriever()
    
    @pytest.fixture
    def sample_documents(self):
        """ç¤ºä¾‹æ–‡æ¡£"""
        return [
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯",
            "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ"
        ]
    
    def test_index_documents(self, retriever, sample_documents):
        """æµ‹è¯•æ–‡æ¡£ç´¢å¼•"""
        retriever.index_documents(sample_documents)
        assert len(retriever.documents) == 3
    
    def test_search(self, retriever, sample_documents):
        """æµ‹è¯•æ£€ç´¢åŠŸèƒ½"""
        retriever.index_documents(sample_documents)
        results = retriever.search("ä»€ä¹ˆæ˜¯AI", k=2)
        assert len(results) <= 2
        assert all(isinstance(r, tuple) for r in results)
    
    def test_empty_query(self, retriever, sample_documents):
        """æµ‹è¯•ç©ºæŸ¥è¯¢"""
        retriever.index_documents(sample_documents)
        results = retriever.search("", k=5)
        assert len(results) == 0

# tests/test_api.py
from fastapi.testclient import TestClient
from api.app import app

client = TestClient(app)

def test_health_check():
    """æµ‹è¯•å¥åº·æ£€æŸ¥"""
    response = client.get("/health")
    assert response.status_code == 200
    assert "status" in response.json()

def test_query():
    """æµ‹è¯•æŸ¥è¯¢æ¥å£"""
    response = client.post(
        "/v1/query",
        json={"query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"}
    )
    assert response.status_code == 200
    data = response.json()
    assert "answer" in data
    assert "sources" in data
```

### äºŒã€æ€§èƒ½æµ‹è¯•

```python
# tests/performance_test.py
import time
import statistics
from concurrent.futures import ThreadPoolExecutor

def performance_test(rag_system, num_queries: int = 100):
    """æ€§èƒ½æµ‹è¯•"""
    
    test_queries = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "æœºå™¨å­¦ä¹ çš„åº”ç”¨åœºæ™¯",
        "æ·±åº¦å­¦ä¹ vsä¼ ç»Ÿæœºå™¨å­¦ä¹ "
    ] * (num_queries // 3)
    
    print(f"ğŸ§ª å¼€å§‹æ€§èƒ½æµ‹è¯• ({num_queries}æ¬¡æŸ¥è¯¢)...")
    
    # å•çº¿ç¨‹æµ‹è¯•
    print("\nã€å•çº¿ç¨‹æµ‹è¯•ã€‘")
    single_times = []
    start = time.time()
    
    for query in test_queries:
        t0 = time.time()
        rag_system.query(query, verbose=False)
        single_times.append(time.time() - t0)
    
    single_total = time.time() - start
    
    print(f"æ€»è€—æ—¶: {single_total:.2f}ç§’")
    print(f"å¹³å‡è€—æ—¶: {statistics.mean(single_times):.3f}ç§’")
    print(f"QPS: {num_queries / single_total:.2f}")
    
    # å¹¶å‘æµ‹è¯•
    print("\nã€å¹¶å‘æµ‹è¯•ã€‘(10çº¿ç¨‹)")
    concurrent_times = []
    
    def query_task(query):
        t0 = time.time()
        rag_system.query(query, verbose=False)
        return time.time() - t0
    
    start = time.time()
    with ThreadPoolExecutor(max_workers=10) as executor:
        concurrent_times = list(executor.map(query_task, test_queries))
    
    concurrent_total = time.time() - start
    
    print(f"æ€»è€—æ—¶: {concurrent_total:.2f}ç§’")
    print(f"å¹³å‡è€—æ—¶: {statistics.mean(concurrent_times):.3f}ç§’")
    print(f"QPS: {num_queries / concurrent_total:.2f}")
    
    # æ€§èƒ½åˆ†æ
    print("\nã€æ€§èƒ½åˆ†æã€‘")
    print(f"P50: {statistics.median(single_times):.3f}ç§’")
    print(f"P95: {sorted(single_times)[int(0.95*len(single_times))]:.3f}ç§’")
    print(f"P99: {sorted(single_times)[int(0.99*len(single_times))]:.3f}ç§’")
```

---

## ğŸ“‹ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæœ€ä½³å®è·µä¸ç»éªŒæ€»ç»“

### ä¸€ã€æ€§èƒ½ä¼˜åŒ–æ¸…å•

```
âœ… ã€å¿…åšã€‘ç¼“å­˜çƒ­é—¨æŸ¥è¯¢
   â†’ å¯æå‡30-50%å“åº”é€Ÿåº¦

âœ… ã€å¿…åšã€‘æ‰¹é‡å¤„ç†embedding
   â†’ å‡å°‘æ¨¡å‹è°ƒç”¨æ¬¡æ•°ï¼Œæå‡2-3å€é€Ÿåº¦

âœ… ã€å¿…åšã€‘å¼‚æ­¥å¤„ç†éå…³é”®ä»»åŠ¡
   â†’ æ—¥å¿—è®°å½•ã€æŒ‡æ ‡ä¸ŠæŠ¥ç­‰

âœ… ã€æ¨èã€‘ä½¿ç”¨è¿æ¥æ± 
   â†’ æ•°æ®åº“ã€Redisè¿æ¥å¤ç”¨

âœ… ã€æ¨èã€‘é™åˆ¶æ£€ç´¢å€™é€‰æ•°
   â†’ retrieval_k=20-50å³å¯ï¼Œä¸è¦å¤ªå¤§

âœ… ã€æ¨èã€‘å¼€å¯é‡æ’åº
   â†’ æ˜¾è‘—æå‡å‡†ç¡®æ€§ï¼Œæˆæœ¬å¯æ§

âœ… ã€å¯é€‰ã€‘ä½¿ç”¨GPUåŠ é€Ÿ
   â†’ embeddingå’Œrerankå¯ä»¥GPUåŠ é€Ÿ
```

### äºŒã€ç¨³å®šæ€§ä¿éšœæ¸…å•

```
âœ… ã€å¿…åšã€‘å®Œå–„çš„é”™è¯¯å¤„ç†
   â€¢ try-catchåŒ…è£¹æ‰€æœ‰å¤–éƒ¨è°ƒç”¨
   â€¢ è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
   â€¢ è®°å½•è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

âœ… ã€å¿…åšã€‘è¶…æ—¶æ§åˆ¶
   â€¢ è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
   â€¢ é¿å…é•¿æ—¶é—´é˜»å¡

âœ… ã€å¿…åšã€‘é‡è¯•æœºåˆ¶
   â€¢ ç½‘ç»œè¯·æ±‚å¤±è´¥è‡ªåŠ¨é‡è¯•
   â€¢ æŒ‡æ•°é€€é¿ç­–ç•¥

âœ… ã€å¿…åšã€‘é™çº§ç­–ç•¥
   â€¢ å‘é‡æ£€ç´¢å¤±è´¥â†’é™çº§åˆ°BM25
   â€¢ Rerankå¤±è´¥â†’è¿”å›åŸå§‹æ£€ç´¢ç»“æœ
   â€¢ LLMå¤±è´¥â†’è¿”å›æ£€ç´¢åˆ°çš„åŸæ–‡

âœ… ã€æ¨èã€‘ç†”æ–­æœºåˆ¶
   â€¢ è¿ç»­å¤±è´¥è¾¾åˆ°é˜ˆå€¼â†’æš‚åœè°ƒç”¨
   â€¢ è‡ªåŠ¨æ¢å¤æœºåˆ¶

âœ… ã€æ¨èã€‘é™æµä¿æŠ¤
   â€¢ APIé™æµï¼šé˜²æ­¢è¿‡è½½
   â€¢ ç”¨æˆ·é™æµï¼šé˜²æ­¢æ»¥ç”¨
```

### ä¸‰ã€å¯è§‚æµ‹æ€§æ¸…å•

```
âœ… ã€å¿…åšã€‘ç»“æ„åŒ–æ—¥å¿—
   â€¢ JSONæ ¼å¼
   â€¢ åŒ…å«å…³é”®ä¿¡æ¯ï¼ˆqueryã€timingã€ç»“æœç­‰ï¼‰
   â€¢ ä¾¿äºæŸ¥è¯¢å’Œåˆ†æ

âœ… ã€å¿…åšã€‘æ€§èƒ½æŒ‡æ ‡
   â€¢ æŸ¥è¯¢è€—æ—¶ï¼ˆP50ã€P95ã€P99ï¼‰
   â€¢ QPSï¼ˆæ¯ç§’æŸ¥è¯¢æ•°ï¼‰
   â€¢ é”™è¯¯ç‡
   â€¢ ç¼“å­˜å‘½ä¸­ç‡

âœ… ã€å¿…åšã€‘å¥åº·æ£€æŸ¥
   â€¢ /health æ¥å£
   â€¢ æ£€æŸ¥å„ç»„ä»¶çŠ¶æ€
   â€¢ ç”¨äºè´Ÿè½½å‡è¡¡æ¢æ´»

âœ… ã€æ¨èã€‘åˆ†å¸ƒå¼è¿½è¸ª
   â€¢ ä½¿ç”¨Trace IDä¸²è”è¯·æ±‚
   â€¢ æŸ¥çœ‹å®Œæ•´è°ƒç”¨é“¾

âœ… ã€æ¨èã€‘å‘Šè­¦æœºåˆ¶
   â€¢ é”™è¯¯ç‡è¶…é˜ˆå€¼â†’å‘Šè­¦
   â€¢ å“åº”æ—¶é—´è¶…é˜ˆå€¼â†’å‘Šè­¦
   â€¢ æœåŠ¡ä¸å¯ç”¨â†’å‘Šè­¦
```

### å››ã€å®‰å…¨æ€§æ¸…å•

```
âœ… ã€å¿…åšã€‘è¾“å…¥éªŒè¯
   â€¢ Queryé•¿åº¦é™åˆ¶
   â€¢ ç‰¹æ®Šå­—ç¬¦è¿‡æ»¤
   â€¢ SQLæ³¨å…¥é˜²æŠ¤

âœ… ã€å¿…åšã€‘APIè®¤è¯
   â€¢ API KeyéªŒè¯
   â€¢ Tokenæœºåˆ¶
   â€¢ æƒé™æ§åˆ¶

âœ… ã€å¿…åšã€‘æ•°æ®è„±æ•
   â€¢ æ—¥å¿—ä¸­æ•æ„Ÿä¿¡æ¯è„±æ•
   â€¢ PIIæ•°æ®ä¿æŠ¤

âœ… ã€æ¨èã€‘HTTPS
   â€¢ ç”Ÿäº§ç¯å¢ƒä½¿ç”¨HTTPS
   â€¢ è¯ä¹¦ç®¡ç†

âœ… ã€æ¨èã€‘å®¡è®¡æ—¥å¿—
   â€¢ è®°å½•æ•æ„Ÿæ“ä½œ
   â€¢ æ•°æ®è®¿é—®å®¡è®¡
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šæ·»åŠ æµå¼è¾“å‡º
ä¸ºAPIæ·»åŠ æµå¼è¾“å‡ºåŠŸèƒ½ï¼Œè®©ç”¨æˆ·å¯ä»¥å®æ—¶çœ‹åˆ°ç­”æ¡ˆç”Ÿæˆè¿‡ç¨‹

### ç»ƒä¹ 2ï¼šå®ç°å¤šç§Ÿæˆ·
æ”¯æŒå¤šä¸ªç§Ÿæˆ·å…±ç”¨ä¸€ä¸ªç³»ç»Ÿï¼Œæ¯ä¸ªç§Ÿæˆ·æœ‰ç‹¬ç«‹çš„æ•°æ®å’Œé…ç½®

### ç»ƒä¹ 3ï¼šæ·»åŠ åé¦ˆæœºåˆ¶
è®©ç”¨æˆ·å¯ä»¥å¯¹ç­”æ¡ˆç‚¹èµ/ç‚¹è¸©ï¼Œç”¨äºæŒç»­ä¼˜åŒ–

### ç»ƒä¹ 4ï¼šå®ç°A/Bæµ‹è¯•
æ”¯æŒåŒæ—¶è¿è¡Œå¤šä¸ªç‰ˆæœ¬çš„æ¨¡å‹ï¼Œå¯¹æ¯”æ•ˆæœ

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **æ¶æ„è®¾è®¡**
   - åˆ†å±‚æ¶æ„ï¼šæ¥å£å±‚ã€æ ¸å¿ƒå±‚ã€æ•°æ®å±‚
   - æ¨¡å—åŒ–ï¼šæ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€
   - å¯æ‰©å±•ï¼šæ˜“äºæ·»åŠ æ–°åŠŸèƒ½

2. **æ€§èƒ½ä¼˜åŒ–**
   - ç¼“å­˜ï¼šå‡å°‘é‡å¤è®¡ç®—
   - æ‰¹å¤„ç†ï¼šæå‡ååé‡
   - å¼‚æ­¥ï¼šæé«˜å¹¶å‘æ€§èƒ½

3. **ç›‘æ§æ—¥å¿—**
   - ç»“æ„åŒ–æ—¥å¿—ï¼šä¾¿äºåˆ†æ
   - æ€§èƒ½æŒ‡æ ‡ï¼šåŠæ—¶å‘ç°é—®é¢˜
   - å‘Šè­¦æœºåˆ¶ï¼šå¿«é€Ÿå“åº”

4. **è´¨é‡ä¿è¯**
   - å•å…ƒæµ‹è¯•ï¼šä¿è¯åŠŸèƒ½æ­£ç¡®
   - æ€§èƒ½æµ‹è¯•ï¼šéªŒè¯æ€§èƒ½æŒ‡æ ‡
   - é”™è¯¯å¤„ç†ï¼šæå‡ç¨³å®šæ€§

### ç”Ÿäº§çº§ç³»ç»Ÿçš„æ ¸å¿ƒç‰¹å¾

```
Demoç³»ç»Ÿ                  ç”Ÿäº§ç³»ç»Ÿ
â”œâ”€ åŠŸèƒ½èƒ½è·‘       â†’      â”œâ”€ åŠŸèƒ½ç¨³å®šå¯é 
â”œâ”€ æ€§èƒ½ä¸å…³æ³¨     â†’      â”œâ”€ æ€§èƒ½ä¼˜åŒ–åˆ°ä½
â”œâ”€ é”™è¯¯å°±å´©æºƒ     â†’      â”œâ”€ é”™è¯¯ä¼˜é›…å¤„ç†
â”œâ”€ ä»£ç éšæ„å†™     â†’      â”œâ”€ ä»£ç è§„èŒƒæ¸…æ™°
â””â”€ æ²¡æœ‰ç›‘æ§       â†’      â””â”€ ç›‘æ§å‘Šè­¦å®Œå–„
```

### å…³é”®æŒ‡æ ‡

```
æ€§èƒ½æŒ‡æ ‡ï¼š
â€¢ æŸ¥è¯¢å“åº”æ—¶é—´ < 2ç§’ (P95)
â€¢ QPS > 10 (å•æœº)
â€¢ ç¼“å­˜å‘½ä¸­ç‡ > 30%

è´¨é‡æŒ‡æ ‡ï¼š
â€¢ é”™è¯¯ç‡ < 1%
â€¢ å¯ç”¨æ€§ > 99.9%
â€¢ å‡†ç¡®ç‡ > 85%
```

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

**ç¬¬10ç« å®Œæˆï¼æ­å–œä½ å®ŒæˆRAGç³»ç»Ÿçš„å®Œæ•´å­¦ä¹ ï¼**

ä¸‹ä¸€ç« ï¼š**ç¬¬å››æ¨¡å—ï¼šAgentæ™ºèƒ½ä½“å¼€å‘**

- Agentæ¶æ„è®¾è®¡
- å·¥å…·è°ƒç”¨æœºåˆ¶
- ReActæ¨¡å¼å®ç°
- å¤šAgentåä½œ

**ä»RAGåˆ°Agentï¼Œå¼€å¯æ–°çš„ç¯‡ç« ï¼** ğŸ¯

---

## ğŸ’ª æœ€åçš„è¯

"ä»ç¬¬41è¯¾åˆ°ç¬¬60è¯¾ï¼Œæˆ‘ä»¬å®Œæ•´å­¦ä¹ äº†RAGç³»ç»Ÿçš„æ–¹æ–¹é¢é¢ï¼š

- ä»å‘é‡æ•°æ®åº“çš„åŸºç¡€åŸç†
- åˆ°æ–‡æ¡£å¤„ç†çš„å·¥ç¨‹åŒ–å®è·µ
- ä»åŸºç¡€æ£€ç´¢åˆ°æ··åˆæ£€ç´¢
- ä»Queryä¼˜åŒ–åˆ°Reranké‡æ’åº
- æœ€ååˆ°å®Œæ•´çš„ç”Ÿäº§çº§ç³»ç»Ÿ

è¿™20è¯¾çš„å†…å®¹ï¼Œæ˜¯æˆ‘åœ¨å®é™…é¡¹ç›®ä¸­è¸©è¿‡æ— æ•°å‘ã€èŠ±äº†å¤§é‡æ—¶é—´æ€»ç»“å‡ºæ¥çš„ç²¾åï¼

å¦‚æœä½ èƒ½å®Œæ•´å­¦å®Œå¹¶å®è·µè¿™äº›å†…å®¹ï¼Œä½ å·²ç»å…·å¤‡äº†ï¼š
âœ… æ„å»ºä¼ä¸šçº§RAGç³»ç»Ÿçš„èƒ½åŠ›
âœ… è§£å†³å®é™…é—®é¢˜çš„èƒ½åŠ›
âœ… æŒç»­ä¼˜åŒ–ç³»ç»Ÿçš„èƒ½åŠ›

è®°ä½ï¼š
- å¥½çš„ç³»ç»Ÿä¸æ˜¯ä¸€è¹´è€Œå°±çš„ï¼Œéœ€è¦æŒç»­è¿­ä»£
- ç›‘æ§å’Œæ—¥å¿—æ˜¯ä½ æœ€å¥½çš„æœ‹å‹
- ç”¨æˆ·åé¦ˆæ¯”ä»»ä½•æŒ‡æ ‡éƒ½é‡è¦

æ¥ä¸‹æ¥ï¼Œç»§ç»­å­¦ä¹ Agentæ™ºèƒ½ä½“å¼€å‘ï¼Œè®©ä½ çš„AIåº”ç”¨æ›´åŠ æ™ºèƒ½ï¼

åŠ æ²¹ï¼ğŸ’ª"

---

**ğŸ‰ RAGç³»ç»Ÿå®Œæ•´ç« èŠ‚å­¦ä¹ å®Œæˆï¼**

**ğŸ‘ ä¸ºè‡ªå·±é¼“æŒï¼ä½ å·²ç»æŒæ¡äº†RAGçš„å…¨éƒ¨æ ¸å¿ƒæŠ€æœ¯ï¼**
