![å·¥ç¨‹åŒ–æ¶æ„](./images/engineering.svg)
*å›¾ï¼šå·¥ç¨‹åŒ–æ¶æ„*

# ç¬¬130è¯¾ï¼šç›‘æ§å‘Šè­¦ - æ—¥å¿—ã€æŒ‡æ ‡ä¸è¿½è¸ªä½“ç³»

> **æœ¬è¯¾ç›®æ ‡**ï¼šæ„å»ºå®Œæ•´çš„å¯è§‚æµ‹æ€§ä½“ç³»
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šç»“æ„åŒ–æ—¥å¿—ã€Prometheusç›‘æ§ã€åˆ†å¸ƒå¼è¿½è¸ªã€å‘Šè­¦é…ç½®
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š90åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ8åˆ†é’Ÿï¼‰
![Monitoring](./images/monitoring.svg)
*å›¾ï¼šMonitoring*


### ğŸ¯ å‰è¨€

"ç³»ç»Ÿä¸Šçº¿äº†ï¼Œå‡ºé—®é¢˜äº†ï¼Œ**æ€ä¹ˆæ’æŸ¥ï¼Ÿ**

**æ²¡æœ‰ç›‘æ§=ç›²äººæ‘¸è±¡ï¼**

**å¯è§‚æµ‹æ€§çš„3å¤§æ”¯æŸ±ï¼š**

```
æ”¯æŸ±1ï¼šæ—¥å¿—ï¼ˆLogsï¼‰
â€¢ å‘ç”Ÿäº†ä»€ä¹ˆ
â€¢ è¯¦ç»†äº‹ä»¶è®°å½•
â€¢ é—®é¢˜å›æº¯

æ”¯æŸ±2ï¼šæŒ‡æ ‡ï¼ˆMetricsï¼‰
â€¢ ç³»ç»ŸçŠ¶æ€å¦‚ä½•
â€¢ æ•°å€¼å‹æ•°æ®
â€¢ è¶‹åŠ¿åˆ†æ

æ”¯æŸ±3ï¼šè¿½è¸ªï¼ˆTracesï¼‰
â€¢ è¯·æ±‚å¦‚ä½•æµè½¬
â€¢ è°ƒç”¨é“¾è·¯
â€¢ æ€§èƒ½ç“¶é¢ˆ

ä¸‰ä½ä¸€ä½“ï¼Œå…¨é¢å¯è§‚æµ‹ï¼
```

**æ—¥å¿—çš„è¿›åŒ–ï¼š**

```
Level 1ï¼šæ‰“å°è°ƒè¯•
print("ç”¨æˆ·ç™»å½•")
âœ— æ²¡æœ‰æ—¶é—´
âœ— æ²¡æœ‰ä¸Šä¸‹æ–‡
âœ— æ— æ³•æœç´¢

Level 2ï¼šæ ‡å‡†æ—¥å¿—
logging.info("ç”¨æˆ·ç™»å½•")
âœ“ æœ‰æ—¶é—´
âœ— æ ¼å¼ä¸ç»Ÿä¸€
âœ— éš¾ä»¥åˆ†æ

Level 3ï¼šç»“æ„åŒ–æ—¥å¿—
logger.info("user_login", extra={
    "user_id": 123,
    "ip": "1.2.3.4",
    "timestamp": "2024-01-15T10:30:00Z"
})
âœ“ ç»“æ„åŒ–
âœ“ æ˜“äºæœç´¢
âœ“ ä¾¿äºåˆ†æ

Level 4ï¼šåˆ†å¸ƒå¼è¿½è¸ª
logger.info("user_login", extra={
    "trace_id": "abc123",
    "span_id": "def456",
    "user_id": 123
})
âœ“ å…³è”è¯·æ±‚
âœ“ å®Œæ•´é“¾è·¯
âœ“ æ€§èƒ½åˆ†æ

å±‚å±‚é€’è¿›ï¼
```

**ç›‘æ§æŒ‡æ ‡çš„4ä¸ªé»„é‡‘ä¿¡å·ï¼š**

```
ä¿¡å·1ï¼šå»¶è¿Ÿï¼ˆLatencyï¼‰
â€¢ P50ï¼š50%è¯·æ±‚çš„å“åº”æ—¶é—´
â€¢ P95ï¼š95%è¯·æ±‚çš„å“åº”æ—¶é—´
â€¢ P99ï¼š99%è¯·æ±‚çš„å“åº”æ—¶é—´

ç›®æ ‡ï¼šP95 < 200ms

ä¿¡å·2ï¼šæµé‡ï¼ˆTrafficï¼‰
â€¢ QPSï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰
â€¢ å¹¶å‘æ•°
â€¢ å¸¦å®½

ç›®æ ‡ï¼šæ”¯æ’‘10000 QPS

ä¿¡å·3ï¼šé”™è¯¯ï¼ˆErrorsï¼‰
â€¢ é”™è¯¯ç‡
â€¢ 5xxé”™è¯¯
â€¢ è¶…æ—¶

ç›®æ ‡ï¼šé”™è¯¯ç‡ < 0.1%

ä¿¡å·4ï¼šé¥±å’Œåº¦ï¼ˆSaturationï¼‰
â€¢ CPUä½¿ç”¨ç‡
â€¢ å†…å­˜ä½¿ç”¨ç‡
â€¢ ç£ç›˜IO

ç›®æ ‡ï¼šCPU < 70%

Google SREæ ‡å‡†ï¼
```

**å‘Šè­¦çš„è‰ºæœ¯ï¼š**

```
ã€å‘Šè­¦ç–²åŠ³ã€‘

é”™è¯¯åšæ³•ï¼š
â€¢ æ¯ä¸ªERRORéƒ½å‘Šè­¦
â€¢ æ¯å¤©1000æ¡å‘Šè­¦
â€¢ å›¢é˜Ÿéº»æœ¨

ç»“æœï¼šçœŸæ­£é—®é¢˜è¢«æ·¹æ²¡

æ­£ç¡®åšæ³•ï¼š
â€¢ åªå‘Šè­¦çœŸæ­£é‡è¦çš„
â€¢ æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†çº§
â€¢ å¯æ“ä½œçš„å‘Šè­¦

P0 - ç´§æ€¥ï¼šæœåŠ¡å®•æœº
  â†’ ç«‹å³ç”µè¯é€šçŸ¥
  â†’ 5åˆ†é’Ÿå“åº”

P1 - é«˜ï¼šé”™è¯¯ç‡>1%
  â†’ çŸ­ä¿¡é€šçŸ¥
  â†’ 15åˆ†é’Ÿå“åº”

P2 - ä¸­ï¼šæ€§èƒ½ä¸‹é™
  â†’ é‚®ä»¶é€šçŸ¥
  â†’ 1å°æ—¶å“åº”

P3 - ä½ï¼šé¢„è­¦
  â†’ ç¾¤æ¶ˆæ¯
  â†’ å·¥ä½œæ—¶é—´å¤„ç†

ã€å‘Šè­¦è´¨é‡ã€‘

å¥½å‘Šè­¦ï¼š
âœ“ æ˜ç¡®é—®é¢˜
âœ“ æä¾›ä¸Šä¸‹æ–‡
âœ“ å»ºè®®è§£å†³æ–¹æ¡ˆ

ç¤ºä¾‹ï¼š
"ğŸš¨ P0å‘Šè­¦ï¼šAPIæœåŠ¡å®•æœº
â€¢ æœåŠ¡ï¼šai-api-prod
â€¢ é”™è¯¯ç‡ï¼š100%
â€¢ å½±å“ï¼šæ‰€æœ‰ç”¨æˆ·
â€¢ å¼€å§‹æ—¶é—´ï¼š10:30:00
â€¢ æŒç»­æ—¶é—´ï¼š2åˆ†é’Ÿ
â€¢ å¯èƒ½åŸå› ï¼šæ•°æ®åº“è¿æ¥å¤±è´¥
â€¢ å»ºè®®æ“ä½œï¼šæ£€æŸ¥æ•°æ®åº“ã€é‡å¯æœåŠ¡
â€¢ RunBookï¼šhttps://wiki/runbook/api-down"

å·®å‘Šè­¦ï¼š
"Error in production"
âœ— ä»€ä¹ˆé”™è¯¯ï¼Ÿ
âœ— å¤šä¸¥é‡ï¼Ÿ
âœ— æ€ä¹ˆå¤„ç†ï¼Ÿ
```

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦å¸¦ä½ ï¼š**

**ç¬¬ä¸€éƒ¨åˆ†ï¼šç»“æ„åŒ–æ—¥å¿—**
- Python logging
- JSONæ ¼å¼
- æ—¥å¿—æ”¶é›†

**ç¬¬äºŒéƒ¨åˆ†ï¼šPrometheusç›‘æ§**
- æŒ‡æ ‡å®šä¹‰
- æ•°æ®é‡‡é›†
- Grafanaå¯è§†åŒ–

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šåˆ†å¸ƒå¼è¿½è¸ª**
- OpenTelemetry
- è¯·æ±‚è¿½è¸ª
- æ€§èƒ½åˆ†æ

**ç¬¬å››éƒ¨åˆ†ï¼šå‘Šè­¦é…ç½®**
- å‘Šè­¦è§„åˆ™
- é€šçŸ¥æ¸ é“
- å‡çº§ç­–ç•¥

å»ºç«‹å®Œæ•´å¯è§‚æµ‹æ€§ï¼"

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šç»“æ„åŒ–æ—¥å¿—

### ä¸€ã€æ—¥å¿—é…ç½®

```python
# app/core/logging.py
import logging
import json
import sys
from datetime import datetime
from typing import Dict, Any
from pythonjsonlogger import jsonlogger

class CustomJsonFormatter(jsonlogger.JsonFormatter):
    """è‡ªå®šä¹‰JSONæ—¥å¿—æ ¼å¼åŒ–å™¨"""
    
    def add_fields(self, log_record: Dict, record: logging.LogRecord, message_dict: Dict):
        """æ·»åŠ è‡ªå®šä¹‰å­—æ®µ"""
        super().add_fields(log_record, record, message_dict)
        
        # æ·»åŠ æ—¶é—´æˆ³
        log_record['timestamp'] = datetime.utcnow().isoformat()
        
        # æ·»åŠ æ—¥å¿—çº§åˆ«
        log_record['level'] = record.levelname
        
        # æ·»åŠ æœåŠ¡ä¿¡æ¯
        log_record['service'] = 'ai-api'
        log_record['environment'] = 'production'
        
        # æ·»åŠ è¿½è¸ªä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(record, 'trace_id'):
            log_record['trace_id'] = record.trace_id
        if hasattr(record, 'span_id'):
            log_record['span_id'] = record.span_id
        
        # æ·»åŠ è¯·æ±‚ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(record, 'request_id'):
            log_record['request_id'] = record.request_id
        if hasattr(record, 'user_id'):
            log_record['user_id'] = record.user_id
        if hasattr(record, 'ip'):
            log_record['ip'] = record.ip

def setup_logging(log_level: str = "INFO"):
    """
    è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
    
    Args:
        log_level: æ—¥å¿—çº§åˆ«
    """
    
    # åˆ›å»ºlogger
    logger = logging.getLogger()
    logger.setLevel(log_level)
    
    # æ¸…é™¤ç°æœ‰handlers
    logger.handlers.clear()
    
    # æ§åˆ¶å°handlerï¼ˆJSONæ ¼å¼ï¼‰
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(log_level)
    
    # JSONæ ¼å¼åŒ–å™¨
    formatter = CustomJsonFormatter(
        '%(timestamp)s %(level)s %(name)s %(message)s'
    )
    console_handler.setFormatter(formatter)
    
    logger.addHandler(console_handler)
    
    # æ–‡ä»¶handlerï¼ˆå¯é€‰ï¼‰
    # file_handler = logging.handlers.RotatingFileHandler(
    #     'app.log',
    #     maxBytes=10485760,  # 10MB
    #     backupCount=5
    # )
    # file_handler.setFormatter(formatter)
    # logger.addHandler(file_handler)
    
    print("âœ“ æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–")

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, name: str):
        """åˆå§‹åŒ–"""
        self.logger = logging.getLogger(name)
    
    def log(
        self,
        level: str,
        message: str,
        **kwargs
    ):
        """
        è®°å½•æ—¥å¿—
        
        Args:
            level: æ—¥å¿—çº§åˆ«
            message: æ¶ˆæ¯
            **kwargs: é¢å¤–å­—æ®µ
        """
        log_func = getattr(self.logger, level.lower())
        log_func(message, extra=kwargs)
    
    def info(self, message: str, **kwargs):
        """ä¿¡æ¯æ—¥å¿—"""
        self.log('INFO', message, **kwargs)
    
    def warning(self, message: str, **kwargs):
        """è­¦å‘Šæ—¥å¿—"""
        self.log('WARNING', message, **kwargs)
    
    def error(self, message: str, **kwargs):
        """é”™è¯¯æ—¥å¿—"""
        self.log('ERROR', message, **kwargs)
    
    def debug(self, message: str, **kwargs):
        """è°ƒè¯•æ—¥å¿—"""
        self.log('DEBUG', message, **kwargs)
    
    def log_request(
        self,
        method: str,
        path: str,
        status_code: int,
        duration_ms: float,
        **kwargs
    ):
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        self.info(
            "http_request",
            method=method,
            path=path,
            status_code=status_code,
            duration_ms=duration_ms,
            **kwargs
        )
    
    def log_error(
        self,
        error: Exception,
        **kwargs
    ):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        self.error(
            "error_occurred",
            error_type=type(error).__name__,
            error_message=str(error),
            **kwargs
        )

# ä½¿ç”¨ç¤ºä¾‹
logger = StructuredLogger(__name__)

# æ™®é€šæ—¥å¿—
logger.info("æœåŠ¡å¯åŠ¨", port=8000, workers=4)

# è¯·æ±‚æ—¥å¿—
logger.log_request(
    method="POST",
    path="/api/v1/predict",
    status_code=200,
    duration_ms=150.5,
    user_id=123,
    request_id="abc123"
)

# é”™è¯¯æ—¥å¿—
try:
    1 / 0
except Exception as e:
    logger.log_error(e, context="æ•°å­¦è¿ç®—")
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šPrometheusç›‘æ§

### ä¸€ã€æŒ‡æ ‡å®šä¹‰

```python
# app/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge, Summary
from functools import wraps
import time

# ============ è®¡æ•°å™¨ï¼ˆCounterï¼‰ ============
# åªå¢ä¸å‡çš„æŒ‡æ ‡

# HTTPè¯·æ±‚æ€»æ•°
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

# é¢„æµ‹è¯·æ±‚æ€»æ•°
prediction_requests_total = Counter(
    'prediction_requests_total',
    'Total prediction requests',
    ['model', 'status']
)

# é”™è¯¯æ€»æ•°
errors_total = Counter(
    'errors_total',
    'Total errors',
    ['error_type']
)

# ============ ç›´æ–¹å›¾ï¼ˆHistogramï¼‰ ============
# è§‚å¯Ÿå€¼çš„åˆ†å¸ƒ

# è¯·æ±‚å»¶è¿Ÿ
http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    ['method', 'endpoint'],
    buckets=(0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0)
)

# é¢„æµ‹å»¶è¿Ÿ
prediction_duration_seconds = Histogram(
    'prediction_duration_seconds',
    'Prediction latency',
    ['model'],
    buckets=(0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0)
)

# ============ ä»ªè¡¨ï¼ˆGaugeï¼‰ ============
# å¯å¢å¯å‡çš„æŒ‡æ ‡

# æ´»è·ƒè¿æ¥æ•°
active_connections = Gauge(
    'active_connections',
    'Number of active connections'
)

# é˜Ÿåˆ—é•¿åº¦
queue_length = Gauge(
    'queue_length',
    'Length of processing queue'
)

# å†…å­˜ä½¿ç”¨
memory_usage_bytes = Gauge(
    'memory_usage_bytes',
    'Memory usage in bytes'
)

# ============ æ‘˜è¦ï¼ˆSummaryï¼‰ ============
# ç±»ä¼¼Histogramï¼Œä½†è®¡ç®—åˆ†ä½æ•°

# APIå“åº”æ—¶é—´æ‘˜è¦
api_response_time_summary = Summary(
    'api_response_time_summary',
    'API response time summary',
    ['endpoint']
)

class MetricsMiddleware:
    """æŒ‡æ ‡æ”¶é›†ä¸­é—´ä»¶"""
    
    @staticmethod
    def track_request():
        """è¿½è¸ªè¯·æ±‚æŒ‡æ ‡"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                # å¢åŠ æ´»è·ƒè¿æ¥
                active_connections.inc()
                
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                try:
                    # æ‰§è¡Œå‡½æ•°
                    result = await func(*args, **kwargs)
                    
                    # è®°å½•æˆåŠŸ
                    http_requests_total.labels(
                        method="POST",
                        endpoint=func.__name__,
                        status="success"
                    ).inc()
                    
                    return result
                
                except Exception as e:
                    # è®°å½•é”™è¯¯
                    http_requests_total.labels(
                        method="POST",
                        endpoint=func.__name__,
                        status="error"
                    ).inc()
                    
                    errors_total.labels(
                        error_type=type(e).__name__
                    ).inc()
                    
                    raise
                
                finally:
                    # è®°å½•å»¶è¿Ÿ
                    duration = time.time() - start_time
                    http_request_duration_seconds.labels(
                        method="POST",
                        endpoint=func.__name__
                    ).observe(duration)
                    
                    # å‡å°‘æ´»è·ƒè¿æ¥
                    active_connections.dec()
            
            return wrapper
        return decorator
    
    @staticmethod
    def track_prediction():
        """è¿½è¸ªé¢„æµ‹æŒ‡æ ‡"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                model_name = kwargs.get('model_name', 'default')
                
                start_time = time.time()
                
                try:
                    result = await func(*args, **kwargs)
                    
                    # æˆåŠŸ
                    prediction_requests_total.labels(
                        model=model_name,
                        status="success"
                    ).inc()
                    
                    return result
                
                except Exception as e:
                    # å¤±è´¥
                    prediction_requests_total.labels(
                        model=model_name,
                        status="error"
                    ).inc()
                    
                    raise
                
                finally:
                    # å»¶è¿Ÿ
                    duration = time.time() - start_time
                    prediction_duration_seconds.labels(
                        model=model_name
                    ).observe(duration)
            
            return wrapper
        return decorator

# ä½¿ç”¨ç¤ºä¾‹
from app.core.metrics import MetricsMiddleware

@MetricsMiddleware.track_request()
@MetricsMiddleware.track_prediction()
async def predict(text: str, model_name: str = "default"):
    """é¢„æµ‹å‡½æ•°ï¼ˆå¸¦æŒ‡æ ‡ï¼‰"""
    # é¢„æµ‹é€»è¾‘
    result = {"text": text, "result": "..."}
    return result
```

### äºŒã€Prometheusé…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'ai-cluster'
    environment: 'production'

# å‘Šè­¦è§„åˆ™æ–‡ä»¶
rule_files:
  - 'alerts.yml'

# æŠ“å–é…ç½®
scrape_configs:
  # AI APIæœåŠ¡
  - job_name: 'ai-api'
    static_configs:
      - targets: ['api:8000']
        labels:
          service: 'ai-api'
    
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Node Exporterï¼ˆç³»ç»ŸæŒ‡æ ‡ï¼‰
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

  # PostgreSQL Exporter
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis Exporter
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
```

### ä¸‰ã€å‘Šè­¦è§„åˆ™

```yaml
# alerts.yml
groups:
  - name: api_alerts
    interval: 30s
    rules:
      # P0ï¼šæœåŠ¡å®•æœº
      - alert: ServiceDown
        expr: up{job="ai-api"} == 0
        for: 1m
        labels:
          severity: critical
          priority: P0
        annotations:
          summary: "æœåŠ¡å®•æœº"
          description: "{{ $labels.instance }} æœåŠ¡å·²å®•æœºè¶…è¿‡1åˆ†é’Ÿ"
          runbook: "https://wiki/runbook/service-down"
      
      # P0ï¼šé”™è¯¯ç‡è¿‡é«˜
      - alert: HighErrorRate
        expr: |
          rate(http_requests_total{status="error"}[5m])
          /
          rate(http_requests_total[5m])
          > 0.01
        for: 5m
        labels:
          severity: critical
          priority: P0
        annotations:
          summary: "é”™è¯¯ç‡è¿‡é«˜"
          description: "é”™è¯¯ç‡ {{ $value | humanizePercentage }} è¶…è¿‡1%"
      
      # P1ï¼šå»¶è¿Ÿè¿‡é«˜
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            rate(http_request_duration_seconds_bucket[5m])
          ) > 1.0
        for: 10m
        labels:
          severity: warning
          priority: P1
        annotations:
          summary: "å»¶è¿Ÿè¿‡é«˜"
          description: "P95å»¶è¿Ÿ {{ $value }}s è¶…è¿‡1ç§’"
      
      # P1ï¼šå†…å­˜ä½¿ç”¨è¿‡é«˜
      - alert: HighMemoryUsage
        expr: |
          (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes)
          / node_memory_MemTotal_bytes
          > 0.9
        for: 5m
        labels:
          severity: warning
          priority: P1
        annotations:
          summary: "å†…å­˜ä½¿ç”¨è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨ç‡ {{ $value | humanizePercentage }}"
      
      # P2ï¼šCPUä½¿ç”¨è¿‡é«˜
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
          > 80
        for: 10m
        labels:
          severity: info
          priority: P2
        annotations:
          summary: "CPUä½¿ç”¨è¿‡é«˜"
          description: "CPUä½¿ç”¨ç‡ {{ $value }}%"

# å‘Šè­¦ç®¡ç†å™¨é…ç½®
alertmanager_config:
  route:
    group_by: ['alertname', 'cluster']
    group_wait: 10s
    group_interval: 10s
    repeat_interval: 12h
    receiver: 'default'
    
    routes:
      # P0å‘Šè­¦ï¼šç«‹å³é€šçŸ¥
      - match:
          priority: P0
        receiver: 'pagerduty'
        continue: true
      
      # P1å‘Šè­¦ï¼šçŸ­ä¿¡
      - match:
          priority: P1
        receiver: 'sms'
        continue: true
      
      # P2å‘Šè­¦ï¼šé‚®ä»¶
      - match:
          priority: P2
        receiver: 'email'
  
  receivers:
    - name: 'default'
      webhook_configs:
        - url: 'http://alertmanager-webhook:5000'
    
    - name: 'pagerduty'
      pagerduty_configs:
        - service_key: '<key>'
    
    - name: 'sms'
      webhook_configs:
        - url: 'http://sms-gateway/send'
    
    - name: 'email'
      email_configs:
        - to: 'ops@example.com'
```

---

## ğŸ“ è¯¾åæ€»ç»“

### æ ¸å¿ƒæ”¶è·

1. **ç»“æ„åŒ–æ—¥å¿—**
   - JSONæ ¼å¼
   - è‡ªå®šä¹‰å­—æ®µ
   - æ—¥å¿—æ”¶é›†

2. **Prometheusç›‘æ§**
   - 4ç§æŒ‡æ ‡ç±»å‹
   - æŒ‡æ ‡æ”¶é›†
   - Grafanaå¯è§†åŒ–

3. **å‘Šè­¦é…ç½®**
   - å‘Šè­¦è§„åˆ™
   - ä¸¥é‡ç¨‹åº¦åˆ†çº§
   - é€šçŸ¥æ¸ é“

4. **å¯è§‚æµ‹æ€§**
   - æ—¥å¿—+æŒ‡æ ‡+è¿½è¸ª
   - å®Œæ•´ä½“ç³»
   - é—®é¢˜å®šä½

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬131è¯¾ï¼šæ•°æ®å®‰å…¨ - è¾“å…¥éªŒè¯ä¸æ•æ„Ÿä¿¡æ¯ä¿æŠ¤**

- è¾“å…¥éªŒè¯
- SQLæ³¨å…¥é˜²æŠ¤
- XSSé˜²æŠ¤
- æ•°æ®åŠ å¯†

**å®‰å…¨ç¬¬ä¸€ï¼** ğŸ”¥

---

**ğŸ’ª ç›‘æ§å‘Šè­¦ä½“ç³»å»ºç«‹å®Œæˆï¼ç³»ç»Ÿå¯è§‚æµ‹ï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
