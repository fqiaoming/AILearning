![å·¥ç¨‹åŒ–æ¶æ„](./images/engineering.svg)
*å›¾ï¼šå·¥ç¨‹åŒ–æ¶æ„*

# ç¬¬128è¯¾ï¼šDockerå®¹å™¨åŒ– - AIåº”ç”¨æ‰“åŒ…ä¸éƒ¨ç½²

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŒæ¡Dockerå®¹å™¨åŒ–å’ŒAIåº”ç”¨éƒ¨ç½²
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šDockerfileã€å¤šé˜¶æ®µæ„å»ºã€Docker Composeã€ä¼˜åŒ–æŠ€å·§
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š90åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ8åˆ†é’Ÿï¼‰
![Monitoring](./images/monitoring.svg)
*å›¾ï¼šMonitoring*


### ğŸ¯ å‰è¨€

"ä»£ç å†™å¥½äº†ï¼Œæµ‹è¯•é€šè¿‡äº†ï¼Œå¦‚ä½•éƒ¨ç½²ï¼Ÿ**Dockerï¼**

**ä¸ºä»€ä¹ˆå¿…é¡»ç”¨Dockerï¼Ÿ**

```
ä¼ ç»Ÿéƒ¨ç½²çš„å™©æ¢¦ï¼š

é—®é¢˜1ï¼š"åœ¨æˆ‘æœºå™¨ä¸Šèƒ½è·‘ï¼"
â€¢ å¼€å‘ç¯å¢ƒï¼šPython 3.9
â€¢ æµ‹è¯•ç¯å¢ƒï¼šPython 3.10
â€¢ ç”Ÿäº§ç¯å¢ƒï¼šPython 3.8
â†’ ä¾èµ–ä¸å…¼å®¹ï¼Œå´©æºƒï¼

é—®é¢˜2ï¼šç¯å¢ƒé…ç½®åœ°ç‹±
â€¢ å®‰è£…Python
â€¢ å®‰è£…CUDA/cuDNN
â€¢ å®‰è£…ç³»ç»Ÿä¾èµ–
â€¢ é…ç½®ç¯å¢ƒå˜é‡
â†’ 2å°æ—¶é…ç½®ï¼Œ5åˆ†é’Ÿéƒ¨ç½²

é—®é¢˜3ï¼šèµ„æºéš”ç¦»
â€¢ å¤šä¸ªåº”ç”¨å…±äº«æœåŠ¡å™¨
â€¢ ä¾èµ–å†²çª
â€¢ èµ„æºæŠ¢å 
â†’ Aåº”ç”¨å´©ï¼ŒBåº”ç”¨ä¹Ÿå´©

Dockerè§£å†³ï¼š
âœ“ ç¯å¢ƒä¸€è‡´ï¼ˆå¼€å‘=æµ‹è¯•=ç”Ÿäº§ï¼‰
âœ“ ç§’çº§éƒ¨ç½²ï¼ˆdocker runï¼‰
âœ“ èµ„æºéš”ç¦»ï¼ˆå®¹å™¨äº’ä¸å½±å“ï¼‰
âœ“ æ˜“äºæ‰©å±•ï¼ˆæ°´å¹³æ‰©å®¹ï¼‰

æ ‡å‡†åŒ–ï¼
```

**Docker vs è™šæ‹Ÿæœºï¼š**

```
è™šæ‹Ÿæœºï¼ˆVMï¼‰ï¼š

Host OS
â”œâ”€ Hypervisor
   â”œâ”€ Guest OS (2GB)
   â”‚  â””â”€ App
   â”œâ”€ Guest OS (2GB)
   â”‚  â””â”€ App
   â””â”€ Guest OS (2GB)
      â””â”€ App

â€¢ ç¬¨é‡ï¼ˆæ¯ä¸ªå‡ GBï¼‰
â€¢ å¯åŠ¨æ…¢ï¼ˆåˆ†é’Ÿçº§ï¼‰
â€¢ èµ„æºæ¶ˆè€—å¤§

Dockerå®¹å™¨ï¼š

Host OS
â”œâ”€ Docker Engine
   â”œâ”€ Container (100MB)
   â”‚  â””â”€ App
   â”œâ”€ Container (100MB)
   â”‚  â””â”€ App
   â””â”€ Container (100MB)
      â””â”€ App

â€¢ è½»é‡ï¼ˆå‡ ç™¾MBï¼‰
â€¢ å¯åŠ¨å¿«ï¼ˆç§’çº§ï¼‰
â€¢ èµ„æºåˆ©ç”¨é«˜

10-100å€å·®è·ï¼
```

**AIåº”ç”¨DockeråŒ–çš„æŒ‘æˆ˜ï¼š**

```
æŒ‘æˆ˜1ï¼šé•œåƒå¤§
â€¢ PythonåŸºç¡€é•œåƒï¼š~1GB
â€¢ PyTorchï¼š~2GB
â€¢ æ¨¡å‹æ–‡ä»¶ï¼š~5GB
â€¢ æ€»è®¡ï¼š>8GB

âœ— ä¸‹è½½æ…¢
âœ— å­˜å‚¨è´µ
âœ— éƒ¨ç½²æ…¢

è§£å†³ï¼š
âœ“ å¤šé˜¶æ®µæ„å»ºï¼ˆå»é™¤æ„å»ºä¾èµ–ï¼‰
âœ“ å±‚ç¼“å­˜ä¼˜åŒ–ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
âœ“ æ¨¡å‹å¤–ç½®ï¼ˆæŒ‚è½½å·ï¼‰
â†’ å‡å°åˆ°~2GB

æŒ‘æˆ˜2ï¼šGPUæ”¯æŒ
â€¢ éœ€è¦CUDAè¿è¡Œæ—¶
â€¢ éœ€è¦nvidia-docker
â€¢ æ˜¾å­˜ç®¡ç†

è§£å†³ï¼š
âœ“ ä½¿ç”¨nvidiaå®˜æ–¹é•œåƒ
âœ“ é…ç½®GPUèµ„æºé™åˆ¶
âœ“ å¤šå®¹å™¨å…±äº«GPU

æŒ‘æˆ˜3ï¼šæ€§èƒ½
â€¢ å®¹å™¨ç½‘ç»œå¼€é”€
â€¢ æ–‡ä»¶ç³»ç»Ÿå¼€é”€
â€¢ CPUäº²å’Œæ€§

è§£å†³ï¼š
âœ“ hostç½‘ç»œæ¨¡å¼
âœ“ tmpfså†…å­˜æ–‡ä»¶ç³»ç»Ÿ
âœ“ CPUç»‘å®š

ä¼˜åŒ–åæ¥è¿‘è£¸æœºæ€§èƒ½ï¼
```

**å¤šé˜¶æ®µæ„å»ºçš„å¨åŠ›ï¼š**

```
å•é˜¶æ®µï¼ˆè‡ƒè‚¿ï¼‰ï¼š

FROM python:3.9
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "app.py"]

é•œåƒå¤§å°ï¼š2.5GB
â€¢ åŒ…å«pipã€setuptools
â€¢ åŒ…å«æ‰€æœ‰æ„å»ºå·¥å…·
â€¢ åŒ…å«ä¸å¿…è¦çš„æ–‡ä»¶

å¤šé˜¶æ®µï¼ˆç²¾ç®€ï¼‰ï¼š

# æ„å»ºé˜¶æ®µ
FROM python:3.9 as builder
COPY requirements.txt .
RUN pip install --user -r requirements.txt

# è¿è¡Œé˜¶æ®µ
FROM python:3.9-slim
COPY --from=builder /root/.local /root/.local
COPY app.py .
CMD ["python", "app.py"]

é•œåƒå¤§å°ï¼š800MB
â€¢ åªåŒ…å«è¿è¡Œæ—¶ä¾èµ–
â€¢ å»é™¤æ„å»ºå·¥å…·
â€¢ ä½¿ç”¨slimé•œåƒ

3å€å‡å°ï¼
```

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦å¸¦ä½ ï¼š**

**ç¬¬ä¸€éƒ¨åˆ†ï¼šDockerfileç¼–å†™**
- åŸºç¡€é•œåƒé€‰æ‹©
- å±‚ä¼˜åŒ–
- å¤šé˜¶æ®µæ„å»º

**ç¬¬äºŒéƒ¨åˆ†ï¼šDocker Compose**
- å¤šå®¹å™¨ç¼–æ’
- ç½‘ç»œé…ç½®
- æ•°æ®å·ç®¡ç†

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šç”Ÿäº§ä¼˜åŒ–**
- é•œåƒç˜¦èº«
- æ€§èƒ½è°ƒä¼˜
- å®‰å…¨åŠ å›º

**ç¬¬å››éƒ¨åˆ†ï¼šéƒ¨ç½²å®æˆ˜**
- æœ¬åœ°éƒ¨ç½²
- äº‘ç«¯éƒ¨ç½²
- CI/CDé›†æˆ

å®¹å™¨åŒ–å…¨æµç¨‹ï¼"

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šDockerfileæœ€ä½³å®è·µ

### ä¸€ã€åŸºç¡€Dockerfile

```dockerfile
# Dockerfile
# åŸºç¡€é•œåƒé€‰æ‹©
FROM python:3.9-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY app/ ./app/

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### äºŒã€å¤šé˜¶æ®µæ„å»ºï¼ˆAIåº”ç”¨ï¼‰

```dockerfile
# Dockerfile.ai
# ============ æ„å»ºé˜¶æ®µ ============
FROM python:3.9 as builder

WORKDIR /build

# å¤åˆ¶ä¾èµ–
COPY requirements.txt .

# å®‰è£…åˆ°ç”¨æˆ·ç›®å½•
RUN pip install --user --no-cache-dir -r requirements.txt

# ============ è¿è¡Œé˜¶æ®µ ============
FROM python:3.9-slim

WORKDIR /app

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶å·²å®‰è£…çš„åŒ…
COPY --from=builder /root/.local /root/.local

# æ›´æ–°PATH
ENV PATH=/root/.local/bin:$PATH

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY app/ ./app/

# åˆ›å»ºæ¨¡å‹ç›®å½•
RUN mkdir -p /app/models

# érootç”¨æˆ·
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app
USER appuser

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ä¸‰ã€GPUæ”¯æŒDockerfile

```dockerfile
# Dockerfile.gpu
# ä½¿ç”¨NVIDIAå®˜æ–¹é•œåƒ
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# å®‰è£…Python
RUN apt-get update && apt-get install -y \
    python3.9 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# å®‰è£…PyTorchï¼ˆGPUç‰ˆæœ¬ï¼‰
RUN pip3 install --no-cache-dir \
    torch==2.0.0+cu118 \
    torchvision==0.15.0+cu118 \
    --extra-index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨
COPY app/ ./app/

# ç¯å¢ƒå˜é‡
ENV NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility

EXPOSE 8000

CMD ["python3", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0"]
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šDocker Composeç¼–æ’

### ä¸€ã€å®Œæ•´åº”ç”¨æ ˆ

```yaml
# docker-compose.yml
version: '3.8'

services:
  # APIæœåŠ¡
  api:
    build:
      context: .
      dockerfile: Dockerfile
    image: ai-api:latest
    container_name: ai-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/aidb
      - REDIS_URL=redis://redis:6379/0
      - MODEL_PATH=/models
    volumes:
      - ./models:/models:ro
      - ./logs:/app/logs
    depends_on:
      - postgres
      - redis
    networks:
      - ai-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: ai-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=aidb
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - ai-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: ai-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - ai-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: ai-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - api
    networks:
      - ai-network

  # Prometheusç›‘æ§
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - ai-network

  # Grafanaå¯è§†åŒ–
  grafana:
    image: grafana/grafana:latest
    container_name: ai-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - ai-network

networks:
  ai-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
  prometheus-data:
  grafana-data:
```

### äºŒã€GPUç‰ˆæœ¬Compose

```yaml
# docker-compose.gpu.yml
version: '3.8'

services:
  ai-gpu:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    image: ai-api-gpu:latest
    container_name: ai-api-gpu
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./models:/models:ro
    ports:
      - "8000:8000"
    networks:
      - ai-network

networks:
  ai-network:
    driver: bridge
```

### ä¸‰ã€å¼€å‘ç¯å¢ƒCompose

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  api-dev:
    build:
      context: .
      dockerfile: Dockerfile
      target: builder
    image: ai-api-dev:latest
    container_name: ai-api-dev
    volumes:
      - ./app:/app/app:delegated  # ä»£ç çƒ­é‡è½½
      - ./models:/models:ro
    ports:
      - "8000:8000"
      - "5678:5678"  # debugpyç«¯å£
    environment:
      - DEBUG=true
      - RELOAD=true
    command: >
      uvicorn app.main:app 
      --host 0.0.0.0 
      --reload 
      --reload-dir /app/app
    networks:
      - ai-network

networks:
  ai-network:
    driver: bridge
```

---

## ğŸ¯ ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¼˜åŒ–ä¸å®‰å…¨

### ä¸€ã€.dockerignore

```bash
# .dockerignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/

# æµ‹è¯•
.pytest_cache/
.coverage
htmlcov/
*.log

# IDE
.vscode/
.idea/
*.swp
*.swo

# Git
.git/
.gitignore

# Docker
Dockerfile*
docker-compose*.yml
.dockerignore

# æ–‡æ¡£
*.md
docs/

# æ¨¡å‹ï¼ˆå¤ªå¤§ï¼Œåº”æŒ‚è½½ï¼‰
models/
*.pth
*.bin
*.safetensors

# æ•°æ®
data/
datasets/
```

### äºŒã€é•œåƒä¼˜åŒ–

```bash
# build.sh
#!/bin/bash

# æ„å»ºä¼˜åŒ–åçš„é•œåƒ

echo "æ„å»ºAI APIé•œåƒ..."

# å¤šé˜¶æ®µæ„å»º
docker build \
  --tag ai-api:latest \
  --tag ai-api:v1.0.0 \
  --build-arg PYTHON_VERSION=3.9 \
  --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
  --file Dockerfile \
  --target production \
  .

echo "âœ“ æ„å»ºå®Œæˆ"

# æŸ¥çœ‹é•œåƒå¤§å°
docker images ai-api:latest

# æ‰«æå®‰å…¨æ¼æ´
echo "\næ‰«æå®‰å…¨æ¼æ´..."
docker scan ai-api:latest

# æ¨é€åˆ°ä»“åº“ï¼ˆå¯é€‰ï¼‰
if [ "$1" == "push" ]; then
    echo "\næ¨é€åˆ°Docker Hub..."
    docker push ai-api:latest
    docker push ai-api:v1.0.0
fi
```

### ä¸‰ã€è¿è¡Œè„šæœ¬

```bash
# run.sh
#!/bin/bash

# å¯åŠ¨åº”ç”¨æ ˆ

set -e

echo "å¯åŠ¨AIåº”ç”¨..."

# åœæ­¢æ—§å®¹å™¨
docker-compose down

# æ‹‰å–æœ€æ–°é•œåƒ
docker-compose pull

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# ç­‰å¾…æœåŠ¡å°±ç»ª
echo "ç­‰å¾…æœåŠ¡å°±ç»ª..."
sleep 10

# å¥åº·æ£€æŸ¥
echo "\nå¥åº·æ£€æŸ¥..."
curl -f http://localhost:8000/health || exit 1

echo "\nâœ“ åº”ç”¨å·²å¯åŠ¨"
echo "\nAPI: http://localhost:8000"
echo "æ–‡æ¡£: http://localhost:8000/docs"
echo "ç›‘æ§: http://localhost:9090"
echo "å¯è§†åŒ–: http://localhost:3000"

# æŸ¥çœ‹æ—¥å¿—
echo "\næŸ¥çœ‹æ—¥å¿—: docker-compose logs -f"
```

---

## ğŸ“ è¯¾åæ€»ç»“

### æ ¸å¿ƒæ”¶è·

1. **Dockerfileç¼–å†™**
   - åŸºç¡€é•œåƒé€‰æ‹©
   - å¤šé˜¶æ®µæ„å»º
   - å±‚ç¼“å­˜ä¼˜åŒ–

2. **Docker Compose**
   - å¤šå®¹å™¨ç¼–æ’
   - ç½‘ç»œé…ç½®
   - æ•°æ®æŒä¹…åŒ–

3. **ç”Ÿäº§ä¼˜åŒ–**
   - é•œåƒç˜¦èº«
   - GPUæ”¯æŒ
   - å®‰å…¨åŠ å›º

4. **éƒ¨ç½²å®æˆ˜**
   - æœ¬åœ°æµ‹è¯•
   - ç”Ÿäº§éƒ¨ç½²
   - ç›‘æ§é…ç½®

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬129è¯¾ï¼šæ€§èƒ½ä¼˜åŒ– - ç¼“å­˜ã€å¹¶å‘ã€è´Ÿè½½å‡è¡¡**

- ç¼“å­˜ç­–ç•¥
- å¼‚æ­¥ä¼˜åŒ–
- è´Ÿè½½å‡è¡¡
- æ€§èƒ½ç›‘æ§

**æ¦¨å¹²æ¯ä¸€æ»´æ€§èƒ½ï¼** ğŸ”¥

---

## ğŸ“Š **Dockerå‘½ä»¤é€ŸæŸ¥**

```bash
# æ„å»º
docker build -t image:tag .

# è¿è¡Œ
docker run -d -p 8000:8000 image:tag

# æŸ¥çœ‹å®¹å™¨
docker ps

# æŸ¥çœ‹æ—¥å¿—
docker logs container-name

# è¿›å…¥å®¹å™¨
docker exec -it container-name bash

# åœæ­¢å®¹å™¨
docker stop container-name

# åˆ é™¤å®¹å™¨
docker rm container-name

# Docker Compose
docker-compose up -d
docker-compose down
docker-compose logs -f
docker-compose ps
docker-compose exec service bash

# æ¸…ç†
docker system prune -a
```

---

**ğŸ’ª å®¹å™¨åŒ–éƒ¨ç½²å®Œæˆï¼åº”ç”¨å¯éšå¤„è¿è¡Œï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
