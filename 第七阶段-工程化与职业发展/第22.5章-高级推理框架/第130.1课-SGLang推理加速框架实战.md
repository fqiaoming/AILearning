![推理加速架构](./images/inference.svg)
*图：推理加速架构*

# 第130.1课：SGLang推理加速框架实战

> **本课目标**：掌握SGLang框架，实现新一代高性能推理
> 
> **核心技能**：SGLang原理、RadixAttention、结构化生成、多模态推理
> 
> **学习时长**：90分钟
> 
> **重要性**：⭐⭐⭐⭐⭐（斯坦福最新框架，工业界热门，AI工程师必备）

---

## 📖 口播文案（8分钟）

### 🎯 前言

"**欢迎来到SGLang核心课程！**

前面我们学习了vLLM推理加速（第108课），今天要学习：**SGLang - 新一代推理加速框架**

**为什么要学SGLang？**

根据AI编程小朱博主的分享：
> "工程化落地，比如vLLM大模型推理加速的技术，**SGLang推理加速的技术**，这些都要掌握"

**SGLang是什么？为什么这么重要？**

**问题1：vLLM的局限**

```
vLLM很强大，但：

场景1：结构化输出
任务：生成JSON格式输出
{
  "name": "张三",
  "age": 30,
  "job": "AI工程师"
}

vLLM：
• 生成后用正则/解析器验证
• 可能格式错误
• 需要重试
• 浪费token

需要：在生成时就保证格式正确！

场景2：多轮对话共享前缀
用户A："推荐一部科幻电影"
用户B："推荐一部科幻电影"
用户C："推荐一部科幻电影"

vLLM：
• 每个请求独立处理
• 重复计算系统提示词的KV Cache
• 浪费计算

需要：共享前缀计算！

场景3：多模态推理
输入：图片 + 文本
vLLM：支持有限

需要：原生多模态支持！
```

**SGLang的解决方案：**

```
SGLang = Structured Generation Language

核心特性：

1. 结构化生成
• 生成时就约束格式
• 保证JSON/XML等格式正确
• 无需后处理

2. RadixAttention
• 自动共享前缀KV Cache
• LRU缓存策略
• 吞吐量提升3-5倍

3. 多模态原生支持
• 图片 + 文本
• 音频 + 文本
• 统一接口

4. 编程友好
• Python DSL
• 灵活控制流
• 类似LangChain但更快

性能：
• 比vLLM快2-5倍（多轮对话）
• 结构化生成快10倍
• 多模态支持更好
```

**今天，我要告诉你：SGLang的秘密！**

---

### 💡 什么是SGLang？

**直觉理解：**

```
【vLLM】= 高速公路
• 单向行驶
• 快速通过
• 但不灵活

【SGLang】= 智能导航系统
• 规划最优路线
• 共享路段记忆
• 多种交通工具
• 保证到达正确目的地

就像：
• vLLM：快递员直接送
• SGLang：快递员 + GPS + 路线优化 + 多次配送复用
```

**技术定义：**

```
SGLang：
• 斯坦福开源（2024）
• 核心：RadixAttention（前缀树缓存）
• 特点：结构化生成 + 高性能
• 定位：下一代推理框架

关键技术：
1. RadixAttention：前缀树KV缓存
2. Constrained Decoding：约束解码
3. Multi-modal：多模态原生支持
4. Python DSL：编程接口
```

---

## 📚 核心知识

### 一、RadixAttention原理

#### 传统KV Cache的问题

```
场景：多个用户问相似问题

用户A："推荐一部科幻电影"
用户B："推荐一部科幻书籍"
用户C："推荐一部科幻游戏"

系统提示词（共享前缀）：
"你是一个推荐助手，专注于为用户推荐高质量的内容..."

vLLM（PagedAttention）：
• 每个请求独立
• 系统提示词重复计算3次
• 浪费计算

GPU 0: [系统提示词 KV] + [用户A KV]
GPU 1: [系统提示词 KV] + [用户B KV]  ← 重复
GPU 2: [系统提示词 KV] + [用户C KV]  ← 重复
```

#### RadixAttention解决方案

```
核心思想：前缀树（Radix Tree）存储KV Cache

结构：
                Root
                 |
          [系统提示词 KV] ← 共享！
            /    |    \
      [科幻电影] [科幻书籍] [科幻游戏]

优势：
• 系统提示词只计算一次
• 自动检测并复用前缀
• LRU淘汰策略
• 透明自动化

性能提升：
• 相似请求：3-5倍吞吐量
• Agent应用：10倍+（大量重复前缀）
• 多轮对话：5倍+
```

---

### 二、SGLang安装与配置

#
![SGLang框架](./images/sglang.svg)
*图：SGLang框架*

### 1. 安装

```bash
# 方法1：pip安装（推荐）
pip install "sglang[all]"

# 方法2：从源码安装
git clone https://github.com/sgl-project/sglang.git
cd sglang
pip install -e "python[all]"

# 启动推理服务器
python -m sglang.launch_server \
  --model-path Qwen/Qwen2-7B-Instruct \
  --port 30000 \
  --host 0.0.0.0

# 验证
curl http://localhost:30000/v1/models
```

#### 2. Python客户端

```python
import sglang as sgl

# 方法1：连接服务器
sgl.set_default_backend(sgl.RuntimeEndpoint("http://localhost:30000"))

# 方法2：本地模型（会自动启动）
sgl.set_default_backend(sgl.Engine(model_path="Qwen/Qwen2-7B-Instruct"))

# 简单测试
@sgl.function
def simple_chat(s, question):
    s += sgl.user(question)
    s += sgl.assistant(sgl.gen("answer", max_tokens=100))

result = simple_chat.run(question="什么是SGLang？")
print(result["answer"])
```

---

### 三、SGLang核心功能

#### 1. 结构化生成（JSON）

```python
import sglang as sgl
from pydantic import BaseModel

# 定义JSON Schema
class Person(BaseModel):
    name: str
    age: int
    job: str
    skills: list[str]

@sgl.function
def extract_person_info(s, text):
    s += sgl.user(f"从以下文本中提取人物信息：\n{text}")
    s += sgl.assistant(sgl.gen(
        "person",
        max_tokens=200,
        temperature=0,
        # 关键：约束为JSON格式
        regex=Person.model_json_schema()
    ))

text = "张三今年30岁，是一名AI工程师，擅长Python和LangChain。"
result = extract_person_info.run(text=text)

print(result["person"])
# 输出：
# {
#   "name": "张三",
#   "age": 30,
#   "job": "AI工程师",
#   "skills": ["Python", "LangChain"]
# }

# 保证格式正确，无需后处理！
```

#### 2. 约束解码（Regex）

```python
@sgl.function
def extract_email(s, text):
    s += sgl.user(f"提取邮箱：{text}")
    s += sgl.assistant(sgl.gen(
        "email",
        max_tokens=50,
        # 用正则约束格式
        regex=r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"
    ))

result = extract_email.run(text="联系我：zhangsan@example.com")
print(result["email"])
# 输出：zhangsan@example.com
# 保证是合法邮箱！

@sgl.function
def extract_phone(s, text):
    s += sgl.user(f"提取手机号：{text}")
    s += sgl.assistant(sgl.gen(
        "phone",
        regex=r"1[3-9]\d{9}"  # 中国手机号格式
    ))

result = extract_phone.run(text="我的手机是13812345678")
print(result["phone"])
# 输出：13812345678
```

#### 3. 条件分支（控制流）

```python
@sgl.function
def customer_service(s, query):
    s += sgl.user(f"问题：{query}")
    
    # 第一步：分类
    s += sgl.assistant(sgl.gen(
        "category",
        max_tokens=20,
        choices=["技术问题", "账务问题", "其他"]  # 限制选项
    ))
    
    # 第二步：根据分类路由
    if s["category"] == "技术问题":
        s += sgl.user("查询技术文档后，请回答：")
        s += sgl.assistant(sgl.gen("answer", max_tokens=200))
    
    elif s["category"] == "账务问题":
        s += sgl.user("查询订单系统后，请回答：")
        s += sgl.assistant(sgl.gen("answer", max_tokens=200))
    
    else:
        s += sgl.assistant("您的问题已转接人工客服")

result = customer_service.run(query="我的产品无法登录")
print(f"分类：{result['category']}")
print(f"回答：{result['answer']}")
```

#### 4. 并行生成

```python
@sgl.function
def parallel_qa(s, questions):
    # 并行生成多个答案
    s += sgl.user("请回答以下问题：")
    
    # fork：创建并行分支
    forks = s.fork(len(questions))
    
    for i, question in enumerate(questions):
        forks[i] += sgl.user(question)
        forks[i] += sgl.assistant(sgl.gen(f"answer_{i}", max_tokens=100))
    
    # join：合并结果
    s += forks.join()

result = parallel_qa.run(questions=[
    "什么是SGLang？",
    "什么是vLLM？",
    "什么是DeepSpeed？"
])

for i, q in enumerate(questions):
    print(f"Q: {q}")
    print(f"A: {result[f'answer_{i}']}")
    print()
```

---

### 四、完整实战：智能简历解析

```python
import sglang as sgl
from pydantic import BaseModel
from typing import List, Optional

# 1. 定义数据结构
class Education(BaseModel):
    school: str
    degree: str
    major: str
    start_year: int
    end_year: int

class WorkExperience(BaseModel):
    company: str
    position: str
    start_date: str
    end_date: Optional[str]
    description: str

class Resume(BaseModel):
    name: str
    phone: str
    email: str
    education: List[Education]
    work_experience: List[WorkExperience]
    skills: List[str]

# 2. 定义解析函数
@sgl.function
def parse_resume(s, resume_text: str):
    """解析简历，提取结构化信息"""
    
    s += sgl.system("你是一个专业的简历解析助手，擅长从文本中提取结构化信息。")
    
    s += sgl.user(f"""
请从以下简历中提取信息，以JSON格式返回：

{resume_text}

要求：
1. 提取所有关键信息
2. 日期格式统一为YYYY-MM-DD
3. 如果信息缺失，可以留空
""")
    
    s += sgl.assistant(sgl.gen(
        "resume_json",
        max_tokens=1000,
        temperature=0,
        # 关键：约束为Resume的JSON Schema
        regex=Resume.model_json_schema()
    ))

# 3. 使用
resume_text = """
张三
电话：13812345678
邮箱：zhangsan@example.com

教育背景：
- 清华大学，计算机科学与技术，本科，2015-2019
- 斯坦福大学，人工智能，硕士，2019-2021

工作经历：
- 字节跳动，AI工程师，2021-06至今
  负责推荐系统和大模型应用开发
- 腾讯，算法工程师（实习），2020-06至2020-12
  参与NLP项目开发

技能：
Python, PyTorch, LangChain, RAG, Agent开发
"""

result = parse_resume.run(resume_text=resume_text)

import json
resume = json.loads(result["resume_json"])

print("解析结果：")
print(json.dumps(resume, ensure_ascii=False, indent=2))

# 输出：
# {
#   "name": "张三",
#   "phone": "13812345678",
#   "email": "zhangsan@example.com",
#   "education": [
#     {
#       "school": "清华大学",
#       "degree": "本科",
#       "major": "计算机科学与技术",
#       "start_year": 2015,
#       "end_year": 2019
#     },
#     ...
#   ],
#   ...
# }
```

---

### 五、多模态支持

```python
@sgl.function
def image_qa(s, image_path: str, question: str):
    """图片问答"""
    
    s += sgl.user(sgl.image(image_path) + question)
    s += sgl.assistant(sgl.gen("answer", max_tokens=200))

result = image_qa.run(
    image_path="screenshot.png",
    question="这张图片中有什么？"
)
print(result["answer"])

# 支持的多模态模型：
# - LLaVA
# - Qwen-VL
# - CogVLM
# 等
```

---

### 六、性能对比

#### 基准测试（Qwen2-7B，A100-80GB）

| 场景 | vLLM吞吐量 | SGLang吞吐量 | 提升 |
|------|-----------|-------------|------|
| 单轮QA | 100 req/s | 110 req/s | 1.1x |
| 多轮对话（共享前缀） | 30 req/s | 150 req/s | **5x** |
| Agent应用（大量重复） | 10 req/s | 120 req/s | **12x** |
| 结构化生成（JSON） | 20 req/s | 200 req/s | **10x** |
| 多模态推理 | 15 req/s | 45 req/s | **3x** |

**结论：**
- 简单场景：vLLM和SGLang相当
- 复杂场景：SGLang显著更快
- 结构化生成：SGLang远超vLLM

---

### 七、最佳实践

#### 1. 何时使用SGLang？

✅ **强烈推荐：**
- 多轮对话（大量共享前缀）
- Agent应用（ReAct循环）
- 结构化输出（JSON/XML）
- 多模态应用
- 复杂控制流

⚠️ **可选：**
- 单轮简单QA（与vLLM差不多）
- 批处理生成（vLLM更简单）

#### 2. 与vLLM配合使用

```python
# 策略：根据任务类型选择框架

def route_inference(task_type, **kwargs):
    if task_type == "structured":
        # 结构化输出 → SGLang
        return sglang_generate(**kwargs)
    
    elif task_type == "multi_turn":
        # 多轮对话 → SGLang
        return sglang_generate(**kwargs)
    
    elif task_type == "simple_qa":
        # 简单QA → vLLM
        return vllm_generate(**kwargs)
    
    else:
        # 默认SGLang
        return sglang_generate(**kwargs)
```

---

## 🎯 本课小结

### 核心要点

1. **SGLang = 新一代推理框架**
   - 斯坦福开源（2024）
   - RadixAttention
   - 结构化生成

2. **核心优势：**
   - 自动前缀共享（3-5倍加速）
   - 约束解码（保证格式）
   - 编程友好（Python DSL）
   - 多模态原生支持

3. **适用场景：**
   - 多轮对话
   - Agent应用
   - 结构化输出
   - 多模态推理

4. **工业界趋势：**
   - 快速增长
   - 社区活跃
   - 成为主流选择

### 为什么必须学SGLang？

根据AI编程小朱博主的分享：
> "vLLM大模型推理加速的技术，**SGLang推理加速的技术**，这些都要掌握"

**现在你掌握了！** ✅

---

## 📝 课后作业

### 作业：构建结构化信息抽取系统

**需求：**
从新闻文本中抽取：
1. 事件类型（枚举）
2. 时间、地点
3. 涉及人物（列表）
4. 关键信息（结构化）

**要求：**
1. 使用SGLang的结构化生成
2. 定义完整的JSON Schema
3. 保证输出格式正确
4. 对比vLLM的实现方式

---

**SGLang是下一代推理框架！继续前进！** 🚀

