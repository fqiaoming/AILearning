# ç¬¬07è¯¾ï¼šæœ¬åœ°æ¨¡å‹ vs äº‘ç«¯API - å¦‚ä½•é€‰æ‹©

> ğŸ“š **è¯¾ç¨‹ä¿¡æ¯**
> - æ‰€å±æ¨¡å—ï¼šç¬¬ä¸€æ¨¡å— - AIåŸºç¡€ä¸ç¯å¢ƒæ­å»º
> - å­¦ä¹ ç›®æ ‡ï¼šç†è§£æœ¬åœ°å’Œäº‘ç«¯æ–¹æ¡ˆçš„å·®å¼‚ï¼Œå­¦ä¼šçµæ´»é€‰æ‹©å’Œåˆ‡æ¢
> - é¢„è®¡æ—¶é—´ï¼š40-50åˆ†é’Ÿ
> - å‰ç½®çŸ¥è¯†ï¼šç¬¬05-06è¯¾

---

## ğŸ“¢ è¯¾ç¨‹å¯¼å…¥

![ç³»ç»Ÿæ¶æ„å¯¹æ¯”](./images/system_arch.svg)
*å›¾ï¼šæœ¬åœ°éƒ¨ç½²vsäº‘ç«¯APIçš„ç³»ç»Ÿæ¶æ„å¯¹æ¯”*

### å‰è¨€

å­¦AIçš„æ—¶å€™ï¼Œä½ è‚¯å®šçº ç»“è¿‡è¿™ä¸ªé—®é¢˜ï¼šåˆ°åº•ç”¨æœ¬åœ°æ¨¡å‹è¿˜æ˜¯äº‘ç«¯APIï¼Ÿæœ¬åœ°æ¨¡å‹å…è´¹ä½†æ€§èƒ½æœ‰é™ï¼Œäº‘ç«¯APIå¼ºå¤§ä½†è¦èŠ±é’±ã€‚å¾ˆå¤šäººåœ¨è¿™ä¸ªé—®é¢˜ä¸Šæµªè´¹äº†å¤§é‡æ—¶é—´ï¼Œè¦ä¹ˆå…¨ç”¨æœ¬åœ°ç»“æœæ•ˆæœä¸è¡Œï¼Œè¦ä¹ˆå…¨ç”¨äº‘ç«¯ç»“æœæˆæœ¬å¤±æ§ã€‚

ä½†å…¶å®ï¼Œ**çœŸæ­£çš„é«˜æ‰‹ä»æ¥ä¸åšå•é€‰é¢˜ï¼**ä»–ä»¬çŸ¥é“ä»€ä¹ˆåœºæ™¯ç”¨ä»€ä¹ˆæ–¹æ¡ˆï¼Œç”šè‡³åœ¨åŒä¸€ä¸ªé¡¹ç›®é‡Œæ··åˆä½¿ç”¨ã€‚ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘å°±è¦æ•™ä½ è¿™ä¸ªæŠ€å·§ï¼Œè®©ä½ æ—¢èƒ½æ§åˆ¶æˆæœ¬ï¼Œåˆèƒ½ä¿è¯æ•ˆæœï¼

---

### æ ¸å¿ƒä»·å€¼ç‚¹

**ç¬¬ä¸€ï¼Œæœ¬åœ°å’Œäº‘ç«¯ä¸æ˜¯å¯¹ç«‹çš„ï¼Œè€Œæ˜¯äº’è¡¥çš„ã€‚**

å¾ˆå¤šäººä»¥ä¸ºé€‰äº†æœ¬åœ°å°±ä¸èƒ½ç”¨äº‘ç«¯ï¼Œé€‰äº†äº‘ç«¯å°±ä¸ç”¨æœ¬åœ°ã€‚å¤§é”™ç‰¹é”™ï¼ä¸“ä¸šçš„åšæ³•æ˜¯ï¼š
- å¼€å‘è°ƒè¯•ç”¨æœ¬åœ°ï¼ˆå…è´¹ï¼Œéšä¾¿æµ‹ï¼‰
- ç®€å•ä»»åŠ¡ç”¨æœ¬åœ°ï¼ˆçœé’±ï¼Œå¤Ÿç”¨ï¼‰
- å¤æ‚ä»»åŠ¡ç”¨äº‘ç«¯ï¼ˆæ•ˆæœå¥½ï¼Œå€¼å¾—ï¼‰
- ç”Ÿäº§ç¯å¢ƒçœ‹æƒ…å†µï¼ˆå¹³è¡¡æˆæœ¬å’Œæ•ˆæœï¼‰

è¿™æ‰æ˜¯æ€§ä»·æ¯”æœ€é«˜çš„æ–¹æ¡ˆï¼

**ç¬¬äºŒï¼Œä»£ç è®¾è®¡å¥½äº†ï¼Œåˆ‡æ¢æ¨¡å‹åªéœ€è¦æ”¹ä¸€è¡Œé…ç½®ã€‚**

å¦‚æœä½ çš„ä»£ç å†™å¾—å¥½ï¼Œåˆ‡æ¢æœ¬åœ°å’Œäº‘ç«¯åªéœ€è¦æ”¹ä¸€ä¸ªå‚æ•°ï¼æ¯”å¦‚å¼€å‘æ—¶ç”¨æœ¬åœ°æ¨¡å‹å…è´¹æµ‹è¯•ï¼Œä¸Šçº¿æ—¶åˆ‡æ¢åˆ°äº‘ç«¯APIï¼Œä»£ç å®Œå…¨ä¸ç”¨åŠ¨ã€‚è¿™å°±æ˜¯ä¸“ä¸šçš„æ¶æ„è®¾è®¡ï¼

è€Œä¸”è¿™ä¸ªæŠ€èƒ½åœ¨å·¥ä½œä¸­éå¸¸é‡è¦ï¼Œå› ä¸ºå…¬å¸å¯èƒ½ä¼šè¦æ±‚ä½ ï¼šé¢„ç®—ç´§å¼ æ—¶ç”¨æœ¬åœ°ï¼Œé‡è¦å®¢æˆ·ç”¨äº‘ç«¯ã€‚å¦‚æœä½ çš„ä»£ç å†™æ­»äº†ï¼Œé‚£å°±éº»çƒ¦å¤§äº†ï¼

**ç¬¬ä¸‰ï¼Œä¸åŒçš„AIæœåŠ¡å•†å„æœ‰ä¼˜åŠ¿ï¼Œå­¦ä¼šé€‰æ‹©èƒ½äº‹åŠåŠŸå€ã€‚**

ç°åœ¨AIæœåŠ¡å•†å¤ªå¤šäº†ï¼šOpenAIã€Claudeã€DeepSeekã€æ™ºè°±ã€ç™¾åº¦...æ¯å®¶éƒ½è¯´è‡ªå·±æœ€å¥½ã€‚ä½†å…¶å®ï¼š
- OpenAIï¼šç”Ÿæ€æœ€å¥½ï¼Œæœ€æˆç†Ÿ
- Claudeï¼šæ¨ç†èƒ½åŠ›å¼ºï¼Œé•¿æ–‡æœ¬å¥½
- DeepSeekï¼šæ€§ä»·æ¯”ç‹è€…ï¼Œä»£ç å¼º
- æœ¬åœ°æ¨¡å‹ï¼šå…è´¹ï¼Œæ•°æ®å®‰å…¨

å­¦ä¼šé€‰æ‹©ï¼Œä½ çš„é¡¹ç›®èƒ½çœ90%çš„æˆæœ¬ï¼

**ç¬¬å››ï¼Œæˆæœ¬æ§åˆ¶æ˜¯ä¸“ä¸šèƒ½åŠ›çš„ä¸€éƒ¨åˆ†ã€‚**

å¾ˆå¤šæ–°æ‰‹åªå…³æ³¨èƒ½ä¸èƒ½å®ç°åŠŸèƒ½ï¼Œä»ä¸è€ƒè™‘æˆæœ¬ã€‚ä½†åœ¨å…¬å¸é‡Œï¼Œæˆæœ¬æ§åˆ¶æ˜¯éå¸¸é‡è¦çš„èƒ½åŠ›ï¼å¦‚æœä½ èƒ½ç”¨æœ¬åœ°æ¨¡å‹å®ç°çš„æ•ˆæœï¼Œå´èŠ±å¤§ä»·é’±ç”¨GPT-4ï¼Œè€æ¿ä¼šæ€ä¹ˆçœ‹ä½ ï¼Ÿ

å­¦ä¼šæ ¹æ®åœºæ™¯é€‰æ‹©æ–¹æ¡ˆï¼Œåœ¨ä¿è¯æ•ˆæœçš„å‰æä¸‹æœ€å°åŒ–æˆæœ¬ï¼Œè¿™æ‰æ˜¯ä¸“ä¸šçš„AIå·¥ç¨‹å¸ˆï¼

---

### è¡ŒåŠ¨å·å¬

ä»Šå¤©è¿™ä¸€è¯¾ä¼šæ•™ä½ ï¼š
- æœ¬åœ°å’Œäº‘ç«¯çš„è¯¦ç»†å¯¹æ¯”
- ä¸åŒåœºæ™¯çš„é€‰æ‹©ç­–ç•¥
- å¦‚ä½•å†™å‡ºçµæ´»å¯åˆ‡æ¢çš„ä»£ç 
- å®é™…é¡¹ç›®çš„æˆæœ¬ä¼˜åŒ–æ–¹æ¡ˆ

**å­¦ä¼šäº†è¿™äº›ï¼Œä½ çš„AIé¡¹ç›®æˆæœ¬èƒ½é™ä½80%ä»¥ä¸Šï¼**

---

## ğŸ“– çŸ¥è¯†è®²è§£

### 1. æœ¬åœ°æ¨¡å‹ vs äº‘ç«¯API å…¨é¢å¯¹æ¯”

![æ•°æ®æµè½¬](./images/data_flow.svg)
*å›¾ï¼šæœ¬åœ°å’Œäº‘ç«¯çš„æ•°æ®æµè½¬æ–¹å¼å¯¹æ¯”*

#### 1.1 æ ¸å¿ƒå·®å¼‚

| ç»´åº¦ | æœ¬åœ°æ¨¡å‹ | äº‘ç«¯API |
|------|---------|--------|
| **æˆæœ¬** | 0å…ƒï¼ˆç”µè´¹å¿½ç•¥ä¸è®¡ï¼‰ | æŒ‰ä½¿ç”¨é‡ä»˜è´¹ |
| **æ€§èƒ½** | å–å†³äºæ¨¡å‹å¤§å°<br>7Bæ¨¡å‹ < GPT-3.5<br>70Bæ¨¡å‹ â‰ˆ GPT-3.5-4 | GPT-4æœ€å¼º<br>Claudeæ¨ç†å¥½<br>DeepSeekæ€§ä»·æ¯”é«˜ |
| **é€Ÿåº¦** | CPU: 3-10 tokens/s<br>GPU: 20-50 tokens/s | 10-100 tokens/s<br>å»¶è¿Ÿæ›´ä½ |
| **æ•°æ®å®‰å…¨** | âœ… å®Œå…¨æœ¬åœ°<br>ä¸ä¼šæ³„éœ² | âš ï¸ æ•°æ®ä¸Šä¼ äº‘ç«¯<br>éœ€è¦ä¿¡ä»»æœåŠ¡å•† |
| **å¯ç”¨æ€§** | âœ… ç¦»çº¿å¯ç”¨<br>ä¸ä¾èµ–ç½‘ç»œ | âŒ å¿…é¡»è”ç½‘<br>æœåŠ¡å•†å®•æœºå°±æŒ‚ |
| **æ‰©å±•æ€§** | âŒ å—é™äºæœ¬åœ°ç¡¬ä»¶ | âœ… æ— é™æ‰©å±• |
| **éƒ¨ç½²éš¾åº¦** | â­â­â­ ä¸­ç­‰<br>LM Studioç®€åŒ–äº† | â­ ç®€å•<br>æ³¨å†Œå³ç”¨ |
| **ç»´æŠ¤æˆæœ¬** | â­â­ éœ€è¦è‡ªå·±ç®¡ç† | â­â­â­â­ é›¶ç»´æŠ¤ |

---

#### 1.2 èƒ½åŠ›å¯¹æ¯”ï¼ˆå®æµ‹æ•°æ®ï¼‰

**æµ‹è¯•ä»»åŠ¡ï¼šä»£ç ç”Ÿæˆ**

| æ¨¡å‹ | ä»£ç æ­£ç¡®ç‡ | ç”Ÿæˆé€Ÿåº¦ | æˆæœ¬(1000æ¬¡) |
|------|----------|---------|------------|
| Qwen2.5-7B(æœ¬åœ°) | 75% | 5 tokens/s | 0å…ƒ |
| Qwen2.5-14B(æœ¬åœ°) | 82% | 3 tokens/s | 0å…ƒ |
| DeepSeek-Coder | 88% | 30 tokens/s | 10å…ƒ |
| GPT-3.5-Turbo | 85% | 50 tokens/s | 100å…ƒ |
| GPT-4-Turbo | 95% | 30 tokens/s | 1000å…ƒ |
| Claude-3.5 | 94% | 40 tokens/s | 1500å…ƒ |

**æµ‹è¯•ä»»åŠ¡ï¼šä¸­æ–‡å¯¹è¯**

| æ¨¡å‹ | è´¨é‡è¯„åˆ† | å“åº”é€Ÿåº¦ | æˆæœ¬(1000æ¬¡) |
|------|---------|---------|------------|
| Qwen2.5-7B(æœ¬åœ°) | 8.2/10 | 5 tokens/s | 0å…ƒ |
| Qwen2.5-14B(æœ¬åœ°) | 8.7/10 | 3 tokens/s | 0å…ƒ |
| DeepSeek-Chat | 8.9/10 | 35 tokens/s | 10å…ƒ |
| GPT-3.5-Turbo | 8.5/10 | 50 tokens/s | 100å…ƒ |
| GPT-4-Turbo | 9.5/10 | 30 tokens/s | 1000å…ƒ |
| Claude-3.5 | 9.3/10 | 40 tokens/s | 1500å…ƒ |

**ç»“è®ºï¼š**
- æœ¬åœ°7Bæ¨¡å‹ â‰ˆ 75-80%çš„GPT-3.5èƒ½åŠ›
- æœ¬åœ°14Bæ¨¡å‹ â‰ˆ 85-90%çš„GPT-3.5èƒ½åŠ›
- å¯¹äºå¤§éƒ¨åˆ†åœºæ™¯ï¼Œæœ¬åœ°æ¨¡å‹å¤Ÿç”¨äº†ï¼

---

### 2. ä¸åŒåœºæ™¯çš„é€‰æ‹©ç­–ç•¥

#### 2.1 å¼€å‘è°ƒè¯•é˜¶æ®µ

```
âœ… å¼ºçƒˆæ¨èï¼šæœ¬åœ°æ¨¡å‹

ç†ç”±ï¼š
1. å…è´¹ï¼Œå¯ä»¥æ— é™æ¬¡æµ‹è¯•
2. å“åº”å¤Ÿå¿«ï¼Œä¸å½±å“å¼€å‘
3. è°ƒè¯•æç¤ºè¯éœ€è¦åå¤å®éªŒ
4. ä»£ç å‡ºé”™é‡è·‘ä¸å¿ƒç–¼

åœºæ™¯ä¸¾ä¾‹ï¼š
- è°ƒè¯•æç¤ºè¯ï¼ˆå¯èƒ½æµ‹è¯•50+ æ¬¡ï¼‰
- æµ‹è¯•ä¸åŒå‚æ•°
- å¼€å‘æ–°åŠŸèƒ½
- å­¦ä¹ æ–°æŠ€æœ¯
```

#### 2.2 ç”Ÿäº§ç¯å¢ƒç®€å•ä»»åŠ¡

```
âœ… æ¨èï¼šæœ¬åœ°æ¨¡å‹æˆ–DeepSeek

ç†ç”±ï¼š
1. æˆæœ¬æ•æ„Ÿ
2. ä»»åŠ¡ç®€å•ï¼Œæœ¬åœ°å¤Ÿç”¨
3. é«˜å¹¶å‘æ—¶æœ¬åœ°æ›´ç¨³å®š

åœºæ™¯ä¸¾ä¾‹ï¼š
- ç®€å•æ–‡æœ¬åˆ†ç±»
- å…³é”®è¯æå–
- ç®€å•é—®ç­”
- æƒ…æ„Ÿåˆ†æ
- æ–‡æœ¬æ‘˜è¦ï¼ˆçŸ­æ–‡æœ¬ï¼‰
```

#### 2.3 ç”Ÿäº§ç¯å¢ƒå¤æ‚ä»»åŠ¡

```
âœ… æ¨èï¼šäº‘ç«¯APIï¼ˆGPT-4/Claudeï¼‰

ç†ç”±ï¼š
1. å‡†ç¡®æ€§è¦æ±‚é«˜
2. å¤æ‚æ¨ç†ä»»åŠ¡
3. ç”¨æˆ·ä½“éªŒä¼˜å…ˆ
4. å¤±è´¥æˆæœ¬é«˜

åœºæ™¯ä¸¾ä¾‹ï¼š
- æ³•å¾‹æ–‡ä¹¦åˆ†æ
- åŒ»ç–—è¯Šæ–­è¾…åŠ©
- é‡‘èé£æ§
- å¤æ‚ä»£ç ç”Ÿæˆ
- å¤šè½®å¤æ‚å¯¹è¯
```

#### 2.4 æ•°æ®æ•æ„Ÿåœºæ™¯

```
âœ… å¿…é¡»ï¼šæœ¬åœ°æ¨¡å‹

ç†ç”±ï¼š
1. æ•°æ®ä¸èƒ½å¤–ä¼ 
2. åˆè§„è¦æ±‚
3. å•†ä¸šæœºå¯†

åœºæ™¯ä¸¾ä¾‹ï¼š
- ä¼ä¸šå†…éƒ¨æ–‡æ¡£å¤„ç†
- ä¸ªäººéšç§æ•°æ®
- å•†ä¸šæœºå¯†åˆ†æ
- åŒ»ç–—æ•°æ®å¤„ç†
```

---

### 3. äº‘ç«¯APIæœåŠ¡å•†é€‰æ‹©æŒ‡å—

#### 3.1 OpenAI

```
ä¼˜åŠ¿ï¼š
âœ… ç”Ÿæ€æœ€å®Œå–„ï¼ˆæ–‡æ¡£ã€å·¥å…·ã€ç¤¾åŒºï¼‰
âœ… GPT-4èƒ½åŠ›æœ€å¼º
âœ… æœ€å¤šå¼€å‘è€…ä½¿ç”¨
âœ… å…¼å®¹æ€§æœ€å¥½

åŠ£åŠ¿ï¼š
âŒ ä»·æ ¼æœ€è´µ
âŒ å›½å†…è®¿é—®éœ€ä»£ç†
âŒ APIé™æµä¸¥æ ¼

é€‚åˆåœºæ™¯ï¼š
- å­¦ä¹ å’Œå‚è€ƒ
- é«˜è¦æ±‚ä»»åŠ¡
- éœ€è¦æœ€æ–°åŠŸèƒ½

ä»·æ ¼ï¼š
- GPT-3.5: ~$0.001/1K tokens
- GPT-4-Turbo: ~$0.01/1K tokens
```

#### 3.2 Anthropic Claude

```
ä¼˜åŠ¿ï¼š
âœ… æ¨ç†èƒ½åŠ›å¼º
âœ… é•¿æ–‡æœ¬å¤„ç†å¥½ï¼ˆ200K contextï¼‰
âœ… å®‰å…¨æ€§å¥½
âœ… ä»£ç è´¨é‡é«˜

åŠ£åŠ¿ï¼š
âŒ ä»·æ ¼è´µ
âŒ å›½å†…è®¿é—®å›°éš¾
âŒ ç”Ÿæ€ä¸å¦‚OpenAI

é€‚åˆåœºæ™¯ï¼š
- å¤æ‚æ¨ç†ä»»åŠ¡
- é•¿æ–‡æ¡£åˆ†æ
- éœ€è¦é«˜å®‰å…¨æ€§

ä»·æ ¼ï¼š
- Claude-3.5-Sonnet: ~$0.003/1K in, $0.015/1K out
- Claude-3-Haiku: ~$0.00025/1K in, $0.00125/1K out
```

#### 3.3 DeepSeekï¼ˆå¼ºçƒˆæ¨èï¼‰

```
ä¼˜åŠ¿ï¼š
âœ… æ€§ä»·æ¯”æé«˜ï¼ˆæœ€ä¾¿å®œï¼‰
âœ… ä»£ç èƒ½åŠ›å¼º
âœ… ä¸­æ–‡å‹å¥½
âœ… å›½å†…å¯ç›´æ¥è®¿é—®
âœ… APIç¨³å®š

åŠ£åŠ¿ï¼š
âŒ çŸ¥ååº¦ç›¸å¯¹è¾ƒä½
âŒ ç”Ÿæ€è¿˜åœ¨å»ºè®¾ä¸­

é€‚åˆåœºæ™¯ï¼š
- ğŸŒŸ æ€§ä»·æ¯”ä¼˜å…ˆ
- ä»£ç ç”Ÿæˆ
- ä¸­æ–‡ä»»åŠ¡
- å­¦ä¹ å’Œå¼€å‘

ä»·æ ¼ï¼šï¼ˆæœ€ä¾¿å®œï¼ï¼‰
- DeepSeek-Chat: Â¥1/ç™¾ä¸‡tokens
- DeepSeek-Coder: Â¥1/ç™¾ä¸‡tokens

æˆæœ¬å¯¹æ¯”ï¼š
- ç›¸åŒä»»åŠ¡
- OpenAI: Â¥100
- DeepSeek: Â¥1  ï¼ˆä¾¿å®œ100å€ï¼ï¼‰
```

---

### 4. æ··åˆä½¿ç”¨ç­–ç•¥ï¼ˆé«˜çº§ï¼‰

#### 4.1 åˆ†å±‚ç­–ç•¥

```
ç¬¬ä¸€å±‚ï¼šç®€å•è¿‡æ»¤ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
  â†“ è¯†åˆ«å‡ºç®€å•é—®é¢˜ï¼Œç›´æ¥å›ç­”
  â†“ è¯†åˆ«å‡ºå¤æ‚é—®é¢˜ï¼Œä¼ é€’åˆ°ä¸‹ä¸€å±‚

ç¬¬äºŒå±‚ï¼šæ·±åº¦å¤„ç†ï¼ˆäº‘ç«¯APIï¼‰
  â†“ å¤„ç†å¤æ‚é—®é¢˜
  â†“ ç”Ÿæˆé«˜è´¨é‡å›ç­”

æ•ˆæœï¼š
- 80%çš„ç®€å•é—®é¢˜ç”¨æœ¬åœ°ï¼ˆ0æˆæœ¬ï¼‰
- 20%çš„å¤æ‚é—®é¢˜ç”¨äº‘ç«¯ï¼ˆç²¾å‡†æŠ•å…¥ï¼‰
- æ€»æˆæœ¬é™ä½80%
```

#### 4.2 æ™ºèƒ½è·¯ç”±

```
é—®é¢˜ â†’ åˆ†ç±»å™¨ï¼ˆæœ¬åœ°å°æ¨¡å‹ï¼‰â†’ è·¯ç”±
                            â”œâ†’ ç®€å•ï¼šæœ¬åœ°å¤„ç†
                            â”œâ†’ ä¸­ç­‰ï¼šDeepSeek
                            â””â†’ å¤æ‚ï¼šGPT-4

å®ç°æˆæœ¬ï¼š
- åˆ†ç±»å™¨ï¼š0æˆæœ¬ï¼ˆæœ¬åœ°ï¼‰
- è·¯ç”±å†³ç­–ï¼šæ™ºèƒ½åˆ†é…
- æ€»æˆæœ¬ï¼šé™ä½60-80%
```

---

## ğŸ’» Demoæ¡ˆä¾‹ï¼šçµæ´»åˆ‡æ¢æ¨¡å‹

### æ¡ˆä¾‹è¯´æ˜

è®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„AIå®¢æˆ·ç«¯ï¼Œå¯ä»¥æ–¹ä¾¿åœ°åœ¨æœ¬åœ°å’Œäº‘ç«¯æ¨¡å‹ä¹‹é—´åˆ‡æ¢ã€‚

### ç¬¬ä¸€æ­¥ï¼šè®¾è®¡ç»Ÿä¸€æ¥å£

åˆ›å»º`ai_client.py`ï¼š

```python
"""
ç»Ÿä¸€çš„AIå®¢æˆ·ç«¯
æ”¯æŒçµæ´»åˆ‡æ¢æœ¬åœ°æ¨¡å‹å’Œäº‘ç«¯API
"""

from openai import OpenAI
from anthropic import Anthropic
from dotenv import load_dotenv
import os
from enum import Enum
from typing import Optional, List, Dict

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class ModelProvider(Enum):
    """æ¨¡å‹æä¾›å•†æšä¸¾"""
    LOCAL = "local"              # æœ¬åœ°LM Studio
    OPENAI = "openai"            # OpenAI
    DEEPSEEK = "deepseek"        # DeepSeek
    CLAUDE = "claude"            # Anthropic Claude


class AIClient:
    """ç»Ÿä¸€çš„AIå®¢æˆ·ç«¯"""
    
    def __init__(self, provider: ModelProvider = ModelProvider.LOCAL):
        """
        åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        
        Args:
            provider: æ¨¡å‹æä¾›å•†
        """
        self.provider = provider
        self._init_client()
    
    def _init_client(self):
        """æ ¹æ®provideråˆå§‹åŒ–å¯¹åº”çš„å®¢æˆ·ç«¯"""
        if self.provider == ModelProvider.LOCAL:
            self.client = OpenAI(
                base_url=os.getenv("LOCAL_LLM_BASE_URL"),
                api_key=os.getenv("LOCAL_LLM_API_KEY")
            )
            self.model = os.getenv("LOCAL_LLM_MODEL")
            
        elif self.provider == ModelProvider.OPENAI:
            self.client = OpenAI(
                api_key=os.getenv("OPENAI_API_KEY")
            )
            self.model = "gpt-3.5-turbo"
            
        elif self.provider == ModelProvider.DEEPSEEK:
            self.client = OpenAI(
                base_url=os.getenv("DEEPSEEK_BASE_URL"),
                api_key=os.getenv("DEEPSEEK_API_KEY")
            )
            self.model = "deepseek-chat"
            
        elif self.provider == ModelProvider.CLAUDE:
            # Claudeä½¿ç”¨ä¸åŒçš„SDK
            self.client = Anthropic(
                api_key=os.getenv("ANTHROPIC_API_KEY")
            )
            self.model = "claude-3-5-sonnet-20241022"
    
    def chat(
        self,
        user_message: str,
        system_message: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 1000
    ) -> str:
        """
        ç»Ÿä¸€çš„å¯¹è¯æ¥å£
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            system_message: ç³»ç»Ÿæ¶ˆæ¯
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            AIçš„å›å¤
        """
        try:
            if self.provider == ModelProvider.CLAUDE:
                # Claudeçš„APIæ ¼å¼ä¸åŒ
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    messages=[
                        {"role": "user", "content": user_message}
                    ]
                )
                return response.content[0].text
            else:
                # OpenAIå…¼å®¹æ ¼å¼
                messages = []
                if system_message:
                    messages.append({"role": "system", "content": system_message})
                messages.append({"role": "user", "content": user_message})
                
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                return response.choices[0].message.content
                
        except Exception as e:
            return f"é”™è¯¯ï¼š{str(e)}"
    
    def switch_provider(self, provider: ModelProvider):
        """åˆ‡æ¢æ¨¡å‹æä¾›å•†"""
        self.provider = provider
        self._init_client()
        print(f"âœ… å·²åˆ‡æ¢åˆ°ï¼š{provider.value}")


def demo_switch_models():
    """æ¼”ç¤ºæ¨¡å‹åˆ‡æ¢"""
    print("=" * 60)
    print("AI Client - çµæ´»åˆ‡æ¢æ¨¡å‹æ¼”ç¤º")
    print("=" * 60)
    
    # æµ‹è¯•é—®é¢˜
    question = "ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯å¿«é€Ÿæ’åºç®—æ³•"
    
    # æµ‹è¯•æœ¬åœ°æ¨¡å‹
    print("\nã€æµ‹è¯•1ï¼šæœ¬åœ°æ¨¡å‹ - LM Studioã€‘")
    print(f"é—®é¢˜ï¼š{question}")
    
    client = AIClient(ModelProvider.LOCAL)
    answer = client.chat(question, temperature=0.3)
    print(f"å›ç­”ï¼š{answer}")
    print(f"æˆæœ¬ï¼š0å…ƒ")
    
    # åˆ‡æ¢åˆ°DeepSeek
    print("\n" + "-" * 60)
    print("\nã€æµ‹è¯•2ï¼šDeepSeek APIã€‘")
    print(f"é—®é¢˜ï¼š{question}")
    
    client.switch_provider(ModelProvider.DEEPSEEK)
    answer = client.chat(question, temperature=0.3)
    print(f"å›ç­”ï¼š{answer}")
    print(f"æˆæœ¬ï¼šçº¦0.00001å…ƒ")
    
    # åˆ‡æ¢åˆ°OpenAIï¼ˆå¦‚æœæœ‰keyï¼‰
    if os.getenv("OPENAI_API_KEY"):
        print("\n" + "-" * 60)
        print("\nã€æµ‹è¯•3ï¼šOpenAI GPT-3.5ã€‘")
        print(f"é—®é¢˜ï¼š{question}")
        
        client.switch_provider(ModelProvider.OPENAI)
        answer = client.chat(question, temperature=0.3)
        print(f"å›ç­”ï¼š{answer}")
        print(f"æˆæœ¬ï¼šçº¦0.0001å…ƒ")


def demo_smart_routing():
    """æ¼”ç¤ºæ™ºèƒ½è·¯ç”±"""
    print("\n" + "=" * 60)
    print("æ™ºèƒ½è·¯ç”±æ¼”ç¤º - æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹")
    print("=" * 60)
    
    # å®šä¹‰ä¸åŒå¤æ‚åº¦çš„ä»»åŠ¡
    tasks = [
        {
            "question": "ä»Šå¤©æ˜ŸæœŸå‡ ï¼Ÿ",
            "complexity": "simple",
            "provider": ModelProvider.LOCAL
        },
        {
            "question": "è¯·åˆ†æä¸€ä¸‹é‡å­è®¡ç®—çš„å‘å±•è¶‹åŠ¿å’ŒæŠ€æœ¯æŒ‘æˆ˜",
            "complexity": "complex",
            "provider": ModelProvider.DEEPSEEK  # æˆ–GPT-4
        },
        {
            "question": "ä»‹ç»ä¸€ä¸‹Pythonçš„åˆ—è¡¨æ¨å¯¼å¼",
            "complexity": "medium",
            "provider": ModelProvider.LOCAL
        }
    ]
    
    client = AIClient(ModelProvider.LOCAL)
    
    for i, task in enumerate(tasks, 1):
        print(f"\nã€ä»»åŠ¡{i}ã€‘")
        print(f"é—®é¢˜ï¼š{task['question']}")
        print(f"å¤æ‚åº¦ï¼š{task['complexity']}")
        print(f"é€‰æ‹©æ¨¡å‹ï¼š{task['provider'].value}")
        
        # åˆ‡æ¢åˆ°åˆé€‚çš„æ¨¡å‹
        client.switch_provider(task['provider'])
        
        # è·å–å›ç­”
        answer = client.chat(task['question'], max_tokens=200)
        print(f"å›ç­”ï¼š{answer[:100]}...")
        print("-" * 60)


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    demo_switch_models()
    demo_smart_routing()
    
    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ æ€»ç»“ï¼š")
    print("1. ç»Ÿä¸€çš„æ¥å£è®¾è®¡è®©åˆ‡æ¢æ¨¡å‹éå¸¸ç®€å•")
    print("2. æ ¹æ®ä»»åŠ¡å¤æ‚åº¦æ™ºèƒ½é€‰æ‹©æ¨¡å‹")
    print("3. ç®€å•ä»»åŠ¡ç”¨æœ¬åœ°ï¼ˆ0æˆæœ¬ï¼‰")
    print("4. å¤æ‚ä»»åŠ¡ç”¨äº‘ç«¯ï¼ˆç²¾å‡†æŠ•å…¥ï¼‰")
    print("5. è¿™æ ·å¯ä»¥é™ä½80%ä»¥ä¸Šçš„æˆæœ¬ï¼")
```

### ç¬¬äºŒæ­¥ï¼šé…ç½®ç¯å¢ƒå˜é‡

æ›´æ–°`.env`æ–‡ä»¶ï¼š

```bash
# æœ¬åœ°æ¨¡å‹
LOCAL_LLM_BASE_URL=http://localhost:1234/v1
LOCAL_LLM_API_KEY=lm-studio
LOCAL_LLM_MODEL=qwen2.5-7b-instruct

# OpenAIï¼ˆå¯é€‰ï¼‰
# OPENAI_API_KEY=your-openai-key

# DeepSeekï¼ˆæ¨èï¼‰
# DEEPSEEK_API_KEY=your-deepseek-key
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# Claudeï¼ˆå¯é€‰ï¼‰
# ANTHROPIC_API_KEY=your-claude-key
```

### ç¬¬ä¸‰æ­¥ï¼šè¿è¡Œæ¼”ç¤º

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate  # macOS/Linux
# æˆ–
venv\Scripts\activate  # Windows

# å®‰è£…é¢å¤–ä¾èµ–ï¼ˆå¦‚æœè¦ç”¨Claudeï¼‰
pip install anthropic

# è¿è¡Œæ¼”ç¤º
python ai_client.py
```

---

## ğŸ“Š æˆæœ¬ä¼˜åŒ–å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

**éœ€æ±‚ï¼š**
- æ—¥å‡10000æ¬¡å¯¹è¯
- 80%æ˜¯ç®€å•é—®é¢˜ï¼ˆFAQç±»ï¼‰
- 20%æ˜¯å¤æ‚é—®é¢˜ï¼ˆéœ€è¦æ·±åº¦ç†è§£ï¼‰

**æ–¹æ¡ˆAï¼šå…¨éƒ¨ç”¨GPT-4**
```
æˆæœ¬è®¡ç®—ï¼š
10000æ¬¡ Ã— å¹³å‡500tokens Ã— $0.01/1K tokens = $50/å¤©
æœˆæˆæœ¬ï¼š$1500 â‰ˆ Â¥10000
```

**æ–¹æ¡ˆBï¼šå…¨éƒ¨ç”¨æœ¬åœ°æ¨¡å‹**
```
æˆæœ¬ï¼š0å…ƒ
ä½†æ˜¯ï¼šå¤æ‚é—®é¢˜å¤„ç†æ•ˆæœå·®ï¼Œç”¨æˆ·ä½“éªŒä¸‹é™
```

**æ–¹æ¡ˆCï¼šæ··åˆæ–¹æ¡ˆï¼ˆæ™ºèƒ½è·¯ç”±ï¼‰**
```
ç®€å•é—®é¢˜ï¼ˆ80%ï¼‰ï¼šæœ¬åœ°æ¨¡å‹
- 8000æ¬¡ Ã— 0å…ƒ = 0å…ƒ

å¤æ‚é—®é¢˜ï¼ˆ20%ï¼‰ï¼šDeepSeek
- 2000æ¬¡ Ã— å¹³å‡500tokens Ã— Â¥1/ç™¾ä¸‡tokens = Â¥1/å¤©

æœˆæˆæœ¬ï¼šÂ¥30
èŠ‚çœï¼š99.7%ï¼
```

---

## ğŸ¯ æœ€ä½³å®è·µå»ºè®®

### 1. å¼€å‘ç¯å¢ƒé…ç½®

```
å¼€å‘é˜¶æ®µå…¨ç”¨æœ¬åœ°ï¼š
âœ… å¿«é€Ÿè¿­ä»£
âœ… æ— æˆæœ¬å‹åŠ›
âœ… ç¦»çº¿å¯ç”¨

ç”Ÿäº§ç¯å¢ƒå‰åˆ‡æ¢æµ‹è¯•ï¼š
âœ… æµ‹è¯•äº‘ç«¯APIæ•ˆæœ
âœ… éªŒè¯æˆæœ¬
âœ… ç¡®ä¿ç¨³å®šæ€§
```

### 2. ä»£ç è®¾è®¡åŸåˆ™

```python
# âœ… å¥½çš„è®¾è®¡ï¼šç»Ÿä¸€æ¥å£
def get_ai_response(message, provider="local"):
    client = AIClient(provider)
    return client.chat(message)

# åˆ‡æ¢åªéœ€è¦æ”¹ä¸€ä¸ªå‚æ•°
response = get_ai_response("é—®é¢˜", provider="deepseek")


# âŒ åçš„è®¾è®¡ï¼šå†™æ­»æ¨¡å‹
def get_ai_response(message):
    client = OpenAI(base_url="http://localhost:1234/v1")
    # å†™æ­»äº†ï¼Œæ”¹èµ·æ¥éº»çƒ¦
```

### 3. æˆæœ¬ç›‘æ§

```python
# å»ºè®®ï¼šè®°å½•æ¯æ¬¡è°ƒç”¨çš„æˆæœ¬
class AIClient:
    def __init__(self):
        self.total_cost = 0
        self.call_count = 0
    
    def chat(self, message):
        response = ...
        
        # è®¡ç®—æˆæœ¬
        cost = self._calculate_cost(response)
        self.total_cost += cost
        self.call_count += 1
        
        return response
    
    def get_statistics(self):
        return {
            "total_calls": self.call_count,
            "total_cost": self.total_cost,
            "average_cost": self.total_cost / self.call_count
        }
```

---

## âœ… è¯¾åæ£€éªŒ

å®Œæˆæœ¬è¯¾åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] ç†è§£æœ¬åœ°å’Œäº‘ç«¯çš„ä¼˜åŠ£åŠ¿
- [ ] èƒ½æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚æ–¹æ¡ˆ
- [ ] ä¼šè®¾è®¡ç»Ÿä¸€çš„AIå®¢æˆ·ç«¯
- [ ] èƒ½åœ¨ä»£ç ä¸­çµæ´»åˆ‡æ¢æ¨¡å‹
- [ ] ç†è§£æ··åˆä½¿ç”¨çš„ç­–ç•¥
- [ ] èƒ½è¿›è¡Œæˆæœ¬ä¼˜åŒ–

---

## ğŸ“ ä¸‹ä¸€è¯¾é¢„å‘Š

**ç¬¬08è¯¾ï¼šæç¤ºè¯æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**

ç»ˆäºè¦å­¦ä¹ AIæ—¶ä»£æœ€é‡è¦çš„æŠ€èƒ½äº†â€”â€”æç¤ºè¯å·¥ç¨‹ï¼ä¸‹ä¸€è¯¾æˆ‘ä»¬å°†ï¼š
- ç†è§£æç¤ºè¯çš„æœ¬è´¨
- å­¦ä¹ æç¤ºè¯çš„åŸºæœ¬è¦ç´ 
- çœ‹çœŸå®çš„å¥½åæç¤ºè¯å¯¹æ¯”
- æŒæ¡æç¤ºè¯ä¼˜åŒ–æŠ€å·§

**å‡†å¤‡å¼€å¯æç¤ºè¯å·¥ç¨‹ä¹‹æ—…ï¼**

---

**ğŸ‰ æ­å–œä½ å®Œæˆç¬¬07è¯¾ï¼**

ç°åœ¨ä½ å·²ç»å­¦ä¼šäº†å¦‚ä½•çµæ´»é€‰æ‹©å’Œåˆ‡æ¢AIæ¨¡å‹ï¼

**ä¸‹ä¸€æ­¥ï¼š** æ‰“å¼€ `ç¬¬08è¯¾-æç¤ºè¯æ˜¯ä»€ä¹ˆ.md`

