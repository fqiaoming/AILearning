![Agentè¿›é˜¶æ¶æ„](./images/agent.svg)
*å›¾ï¼šAgentè¿›é˜¶æ¶æ„*

# ç¬¬90.2è¯¾ï¼šLangGraphçŠ¶æ€ç®¡ç†ä¸æµç¨‹æ§åˆ¶

> **æœ¬è¯¾ç›®æ ‡**ï¼šæ·±å…¥æŒæ¡LangGraphçš„çŠ¶æ€ç®¡ç†å’Œå¤æ‚æµç¨‹æ§åˆ¶
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šçŠ¶æ€è®¾è®¡ã€æ¡ä»¶è·¯ç”±ã€å¾ªç¯æ§åˆ¶ã€å¹¶å‘å¤„ç†ã€é”™è¯¯æ¢å¤
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š100åˆ†é’Ÿ
> 
> **é‡è¦æ€§**ï¼šâ­â­â­â­â­ï¼ˆLangGraphæ ¸å¿ƒè¿›é˜¶æŠ€èƒ½ï¼Œç”Ÿäº§çº§å¿…å¤‡ï¼‰

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ8åˆ†é’Ÿï¼‰

### ğŸ¯ å‰è¨€

"**æ¬¢è¿æ¥åˆ°LangGraphçŠ¶æ€ç®¡ç†æ·±åº¦è¯¾ç¨‹ï¼**

ä¸ŠèŠ‚è¯¾æˆ‘ä»¬å­¦ä¹ äº†LangGraphåŸºç¡€ï¼Œä»Šå¤©è¦æ·±å…¥å­¦ä¹ ï¼š**å¦‚ä½•æ„å»ºå¤æ‚ã€é²æ£’çš„ç”Ÿäº§çº§Agent**

**æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•è®¾è®¡å’Œç®¡ç†å¤æ‚Agentçš„çŠ¶æ€ï¼Ÿ**

```
åœºæ™¯1ï¼šå¤šæ­¥éª¤ä»»åŠ¡çŠ¶æ€ç®¡ç†

ä»»åŠ¡ï¼š"åˆ†æé”€å”®æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"

æ­¥éª¤ï¼š
1. åŠ è½½æ•°æ® â†’ éœ€è¦ä¿å­˜æ•°æ®ä½ç½®
2. æ•°æ®æ¸…æ´— â†’ éœ€è¦ä¿å­˜æ¸…æ´—åçš„æ•°æ®
3. æ•°æ®åˆ†æ â†’ éœ€è¦ä¿å­˜åˆ†æç»“æœ
4. ç”Ÿæˆå›¾è¡¨ â†’ éœ€è¦ä¿å­˜å›¾è¡¨è·¯å¾„
5. ç”ŸæˆæŠ¥å‘Š â†’ éœ€è¦æ±‡æ€»æ‰€æœ‰ä¿¡æ¯

é—®é¢˜ï¼š
â€¢ æ¯ä¸€æ­¥çš„è¾“å‡ºè¦è¢«åç»­æ­¥éª¤ä½¿ç”¨
â€¢ ä¸­é—´ç»“æœè¦æŒä¹…åŒ–
â€¢ å¤±è´¥åè¦èƒ½æ¢å¤
â€¢ çŠ¶æ€è¦æ¸…æ™°å¯è¿½è¸ª

éœ€è¦ï¼šå¤æ‚çš„çŠ¶æ€ç®¡ç†ï¼

åœºæ™¯2ï¼šåŠ¨æ€æµç¨‹æ§åˆ¶

ä»»åŠ¡ï¼š"æ™ºèƒ½å®¢æœç³»ç»Ÿ"

æµç¨‹ï¼š
1. åˆ†æé—®é¢˜ç±»å‹
2. å¦‚æœæ˜¯æŠ€æœ¯é—®é¢˜ â†’ æŸ¥è¯¢æ–‡æ¡£ â†’ å›ç­”
3. å¦‚æœæ˜¯è´¦åŠ¡é—®é¢˜ â†’ æŸ¥è¯¢æ•°æ®åº“ â†’ å›ç­”
4. å¦‚æœæ— æ³•è§£å†³ â†’ å‡çº§äººå·¥
5. å¦‚æœéœ€è¦è¡¥å……ä¿¡æ¯ â†’ è¯¢é—®ç”¨æˆ· â†’ å›åˆ°æ­¥éª¤1

é—®é¢˜ï¼š
â€¢ æµç¨‹æ˜¯åŠ¨æ€çš„
â€¢ å¯èƒ½å¾ªç¯
â€¢ éœ€è¦äººå·¥å¹²é¢„
â€¢ çŠ¶æ€è¦èƒ½å›æº¯

éœ€è¦ï¼šçµæ´»çš„æµç¨‹æ§åˆ¶ï¼

åœºæ™¯3ï¼šé”™è¯¯å¤„ç†ä¸æ¢å¤

é—®é¢˜ï¼š"Agentæ‰§è¡Œä¸­é‡åˆ°é”™è¯¯æ€ä¹ˆåŠï¼Ÿ"

æŒ‘æˆ˜ï¼š
â€¢ APIè°ƒç”¨å¤±è´¥
â€¢ LLMè¿”å›æ ¼å¼é”™è¯¯
â€¢ å·¥å…·æ‰§è¡Œè¶…æ—¶
â€¢ èµ„æºä¸è¶³

éœ€è¦ï¼š
â€¢ é”™è¯¯æ•è·
â€¢ çŠ¶æ€æ¢å¤
â€¢ é‡è¯•æœºåˆ¶
â€¢ é™çº§æ–¹æ¡ˆ
```

**ä»Šå¤©è¦å­¦ä¹ ï¼šLangGraphçš„é«˜çº§çŠ¶æ€ç®¡ç†å’Œæµç¨‹æ§åˆ¶ï¼**

---

## ğŸ“š æ ¸å¿ƒçŸ¥è¯†

### ä¸€ã€é«˜çº§çŠ¶æ€è®¾è®¡

#
![çŠ¶æ€ç®¡ç†](./images/state_machine.svg)
*å›¾ï¼šçŠ¶æ€ç®¡ç†*

### 1. å¤æ‚çŠ¶æ€ç»“æ„

```python
from typing import TypedDict, Annotated, Sequence, List, Dict, Optional
from langchain_core.messages import BaseMessage
import operator

class ComplexAgentState(TypedDict):
    """å¤æ‚AgentçŠ¶æ€è®¾è®¡"""
    
    # 1. å¯¹è¯å†å²ï¼ˆè¿½åŠ ï¼‰
    messages: Annotated[Sequence[BaseMessage], operator.add]
    
    # 2. å½“å‰æ­¥éª¤
    current_step: str
    next_step: Optional[str]
    
    # 3. æ•°æ®æµè½¬
    input_data: Dict  # è¾“å…¥æ•°æ®
    processed_data: Dict  # å¤„ç†åçš„æ•°æ®
    analysis_result: Dict  # åˆ†æç»“æœ
    output_data: Dict  # è¾“å‡ºæ•°æ®
    
    # 4. ä¸­é—´ç»“æœ
    intermediate_results: Annotated[List[Dict], operator.add]
    
    # 5. æ‰§è¡ŒçŠ¶æ€
    status: str  # "running" | "paused" | "completed" | "failed"
    error_message: Optional[str]
    retry_count: int
    
    # 6. å…ƒæ•°æ®
    task_id: str
    user_id: str
    start_time: float
    end_time: Optional[float]
    
    # 7. é…ç½®
    config: Dict
    max_iterations: int
    iteration_count: int
    
    # 8. å·¥å…·ä½¿ç”¨è®°å½•
    tool_calls: Annotated[List[Dict], operator.add]
    
    # 9. äººå·¥åé¦ˆ
    human_feedback: Optional[str]
    needs_human: bool
```

#### 2. çŠ¶æ€æ›´æ–°ç­–ç•¥

```python
def state_update_strategies():
    """ä¸åŒçš„çŠ¶æ€æ›´æ–°ç­–ç•¥"""
    
    # ç­–ç•¥1ï¼šå®Œå…¨æ›¿æ¢ï¼ˆé»˜è®¤ï¼‰
    class ReplaceState(TypedDict):
        value: int
    
    def update_node(state: ReplaceState):
        return {"value": 10}  # å®Œå…¨æ›¿æ¢
    
    # ç­–ç•¥2ï¼šè¿½åŠ ï¼ˆä½¿ç”¨operator.addï¼‰
    class AppendState(TypedDict):
        items: Annotated[List[str], operator.add]
    
    def append_node(state: AppendState):
        return {"items": ["new_item"]}  # è¿½åŠ 
    
    # ç­–ç•¥3ï¼šåˆå¹¶ï¼ˆä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°ï¼‰
    def merge_dicts(left: Dict, right: Dict) -> Dict:
        """åˆå¹¶å­—å…¸"""
        result = left.copy()
        result.update(right)
        return result
    
    class MergeState(TypedDict):
        data: Annotated[Dict, merge_dicts]
    
    def merge_node(state: MergeState):
        return {"data": {"new_key": "new_value"}}  # åˆå¹¶
    
    # ç­–ç•¥4ï¼šç´¯åŠ ï¼ˆæ•°å€¼ï¼‰
    class AccumulateState(TypedDict):
        count: Annotated[int, operator.add]
    
    def accumulate_node(state: AccumulateState):
        return {"count": 1}  # ç´¯åŠ 

# ä½¿ç”¨ç¤ºä¾‹
from langgraph.graph import StateGraph

# è¿½åŠ å‹çŠ¶æ€
workflow = StateGraph(AppendState)
workflow.add_node("append", append_node)
workflow.set_entry_point("append")

app = workflow.compile()

result = app.invoke({"items": ["item1", "item2"]})
print(result["items"])  # ["item1", "item2", "new_item"]
```

---

### äºŒã€æ¡ä»¶è·¯ç”±ä¸åŠ¨æ€æµç¨‹

#### 1. å¤æ‚æ¡ä»¶è·¯ç”±

```python
from langgraph.graph import StateGraph, END

class TaskState(TypedDict):
    task_type: str
    difficulty: str
    attempts: int
    max_attempts: int
    result: Optional[str]
    status: str

def route_by_task_type(state: TaskState) -> str:
    """æ ¹æ®ä»»åŠ¡ç±»å‹è·¯ç”±"""
    
    task_type = state["task_type"]
    
    if task_type == "analysis":
        return "analyze"
    elif task_type == "generation":
        return "generate"
    elif task_type == "translation":
        return "translate"
    else:
        return "unknown"

def route_by_difficulty(state: TaskState) -> str:
    """æ ¹æ®éš¾åº¦è·¯ç”±"""
    
    difficulty = state["difficulty"]
    
    if difficulty == "easy":
        return "simple_processor"
    elif difficulty == "medium":
        return "standard_processor"
    elif difficulty == "hard":
        return "advanced_processor"
    else:
        return "expert_processor"

def should_retry(state: TaskState) -> str:
    """æ˜¯å¦é‡è¯•"""
    
    if state["status"] == "success":
        return "complete"
    
    if state["attempts"] >= state["max_attempts"]:
        return "failed"
    
    return "retry"

# æ„å»ºå›¾
workflow = StateGraph(TaskState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("classify", classify_node)
workflow.add_node("analyze", analyze_node)
workflow.add_node("generate", generate_node)
workflow.add_node("translate", translate_node)
workflow.add_node("retry", retry_node)
workflow.add_node("complete", complete_node)
workflow.add_node("failed", failed_node)

# å¤šå±‚æ¡ä»¶è·¯ç”±
workflow.set_entry_point("classify")

workflow.add_conditional_edges(
    "classify",
    route_by_task_type,
    {
        "analyze": "analyze",
        "generate": "generate",
        "translate": "translate",
        "unknown": "failed"
    }
)

workflow.add_conditional_edges(
    "analyze",
    should_retry,
    {
        "complete": "complete",
        "retry": "retry",
        "failed": "failed"
    }
)

workflow.add_edge("complete", END)
workflow.add_edge("retry", "analyze")  # å¾ªç¯
workflow.add_edge("failed", END)
```

#### 2. åŠ¨æ€å¾ªç¯æ§åˆ¶

```python
class IterativeState(TypedDict):
    query: str
    iteration: int
    max_iterations: int
    results: Annotated[List[str], operator.add]
    quality_score: float
    threshold: float

def iterative_refinement_node(state: IterativeState):
    """è¿­ä»£ä¼˜åŒ–èŠ‚ç‚¹"""
    
    # æ‰§è¡Œä»»åŠ¡
    result = perform_task(state["query"])
    
    # è¯„ä¼°è´¨é‡
    quality = evaluate_quality(result)
    
    return {
        "results": [result],
        "quality_score": quality,
        "iteration": state["iteration"] + 1
    }

def should_continue_iteration(state: IterativeState) -> str:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­è¿­ä»£"""
    
    # æ¡ä»¶1ï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    if state["iteration"] >= state["max_iterations"]:
        return "max_reached"
    
    # æ¡ä»¶2ï¼šè´¨é‡è¾¾æ ‡
    if state["quality_score"] >= state["threshold"]:
        return "quality_met"
    
    # æ¡ä»¶3ï¼šè´¨é‡æå‡åœæ»
    if len(state["results"]) >= 3:
        last_three = state["results"][-3:]
        # æ£€æŸ¥è´¨é‡æ˜¯å¦åœæ»
        if is_stagnant(last_three):
            return "stagnant"
    
    # ç»§ç»­è¿­ä»£
    return "continue"

# æ„å»ºè¿­ä»£æµç¨‹
workflow = StateGraph(IterativeState)

workflow.add_node("refine", iterative_refinement_node)
workflow.add_node("finalize", finalize_node)

workflow.set_entry_point("refine")

workflow.add_conditional_edges(
    "refine",
    should_continue_iteration,
    {
        "continue": "refine",  # å¾ªç¯
        "quality_met": "finalize",
        "max_reached": "finalize",
        "stagnant": "finalize"
    }
)

workflow.add_edge("finalize", END)

app = workflow.compile()
```

---

### ä¸‰ã€å¹¶å‘ä¸å¹¶è¡Œå¤„ç†

#### 1. å¹¶è¡Œåˆ†æ”¯

```python
class ParallelState(TypedDict):
    input_data: str
    branch1_result: Optional[str]
    branch2_result: Optional[str]
    branch3_result: Optional[str]
    combined_result: Optional[str]

def branch1_node(state: ParallelState):
    """åˆ†æ”¯1ï¼šå¤„ç†ä»»åŠ¡A"""
    result = process_task_a(state["input_data"])
    return {"branch1_result": result}

def branch2_node(state: ParallelState):
    """åˆ†æ”¯2ï¼šå¤„ç†ä»»åŠ¡B"""
    result = process_task_b(state["input_data"])
    return {"branch2_result": result}

def branch3_node(state: ParallelState):
    """åˆ†æ”¯3ï¼šå¤„ç†ä»»åŠ¡C"""
    result = process_task_c(state["input_data"])
    return {"branch3_result": result}

def combine_node(state: ParallelState):
    """åˆå¹¶ç»“æœ"""
    combined = combine_results(
        state["branch1_result"],
        state["branch2_result"],
        state["branch3_result"]
    )
    return {"combined_result": combined}

# æ„å»ºå¹¶è¡Œæµç¨‹
workflow = StateGraph(ParallelState)

workflow.add_node("branch1", branch1_node)
workflow.add_node("branch2", branch2_node)
workflow.add_node("branch3", branch3_node)
workflow.add_node("combine", combine_node)

workflow.set_entry_point("branch1")
workflow.set_entry_point("branch2")  # å¹¶è¡Œå…¥å£
workflow.set_entry_point("branch3")  # å¹¶è¡Œå…¥å£

# æ‰€æœ‰åˆ†æ”¯å®Œæˆåæ±‡æ€»
workflow.add_edge("branch1", "combine")
workflow.add_edge("branch2", "combine")
workflow.add_edge("branch3", "combine")

workflow.add_edge("combine", END)

app = workflow.compile()
```

#### 2. Map-Reduceæ¨¡å¼

```python
class MapReduceState(TypedDict):
    items: List[str]
    mapped_results: Annotated[List[Dict], operator.add]
    reduced_result: Optional[Dict]

def map_node(state: MapReduceState):
    """Mapé˜¶æ®µï¼šå¹¶è¡Œå¤„ç†æ¯ä¸ªé¡¹ç›®"""
    
    results = []
    for item in state["items"]:
        result = process_single_item(item)
        results.append(result)
    
    return {"mapped_results": results}

def reduce_node(state: MapReduceState):
    """Reduceé˜¶æ®µï¼šåˆå¹¶ç»“æœ"""
    
    reduced = aggregate_results(state["mapped_results"])
    return {"reduced_result": reduced}

# ä½¿ç”¨LangGraphçš„å¹¶è¡Œå¤„ç†
from langgraph.graph import StateGraph

workflow = StateGraph(MapReduceState)
workflow.add_node("map", map_node)
workflow.add_node("reduce", reduce_node)

workflow.set_entry_point("map")
workflow.add_edge("map", "reduce")
workflow.add_edge("reduce", END)

app = workflow.compile()

# æ‰§è¡Œ
result = app.invoke({
    "items": ["item1", "item2", "item3"],
    "mapped_results": [],
    "reduced_result": None
})
```

---

### å››ã€é”™è¯¯å¤„ç†ä¸æ¢å¤

#### 1. Try-Catchæ¨¡å¼

```python
class RobustState(TypedDict):
    task: str
    result: Optional[str]
    error: Optional[str]
    retry_count: int
    max_retries: int

def execute_with_retry_node(state: RobustState):
    """å¸¦é‡è¯•çš„æ‰§è¡ŒèŠ‚ç‚¹"""
    
    try:
        # æ‰§è¡Œä»»åŠ¡
        result = execute_task(state["task"])
        
        return {
            "result": result,
            "error": None
        }
    
    except Exception as e:
        return {
            "error": str(e),
            "retry_count": state["retry_count"] + 1
        }

def handle_error_node(state: RobustState):
    """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
    
    error_type = classify_error(state["error"])
    
    if error_type == "transient":
        # ä¸´æ—¶é”™è¯¯ï¼Œå¯é‡è¯•
        return {"task": state["task"]}
    
    elif error_type == "permanent":
        # æ°¸ä¹…é”™è¯¯ï¼Œå°è¯•é™çº§
        degraded_task = degrade_task(state["task"])
        return {"task": degraded_task}
    
    else:
        # æœªçŸ¥é”™è¯¯ï¼Œè®°å½•å¹¶å¤±è´¥
        log_error(state["error"])
        return {"result": "FAILED"}

def should_retry_or_fail(state: RobustState) -> str:
    """åˆ¤æ–­é‡è¯•è¿˜æ˜¯å¤±è´¥"""
    
    if state["error"] is None:
        return "success"
    
    if state["retry_count"] >= state["max_retries"]:
        return "failed"
    
    return "retry"

# æ„å»ºå®¹é”™æµç¨‹
workflow = StateGraph(RobustState)

workflow.add_node("execute", execute_with_retry_node)
workflow.add_node("handle_error", handle_error_node)
workflow.add_node("success", success_node)
workflow.add_node("failed", failed_node)

workflow.set_entry_point("execute")

workflow.add_conditional_edges(
    "execute",
    should_retry_or_fail,
    {
        "success": "success",
        "retry": "handle_error",
        "failed": "failed"
    }
)

workflow.add_edge("handle_error", "execute")  # é‡è¯•
workflow.add_edge("success", END)
workflow.add_edge("failed", END)

app = workflow.compile()
```

#### 2. çŠ¶æ€æ¢å¤

```python
from langgraph.checkpoint.memory import MemorySaver

class RecoverableState(TypedDict):
    task_id: str
    checkpoint_id: Optional[str]
    data: Dict
    completed_steps: List[str]

# å¯ç”¨æ£€æŸ¥ç‚¹
memory = MemorySaver()

app = workflow.compile(checkpointer=memory)

# æ‰§è¡Œä»»åŠ¡ï¼ˆè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼‰
config = {"configurable": {"thread_id": "task_123"}}

try:
    result = app.invoke(initial_state, config=config)
except Exception as e:
    print(f"ä»»åŠ¡å¤±è´¥ï¼š{e}")
    
    # ä»æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤
    print("ä»æ£€æŸ¥ç‚¹æ¢å¤...")
    result = app.invoke(initial_state, config=config)
```

---

### äº”ã€äººå·¥å¹²é¢„ï¼ˆHuman-in-the-Loopï¼‰

#### 1. æš‚åœç­‰å¾…äººå·¥å®¡æ ¸

```python
class HumanInLoopState(TypedDict):
    task: str
    proposed_action: Optional[Dict]
    human_approved: Optional[bool]
    human_feedback: Optional[str]
    result: Optional[str]

def propose_action_node(state: HumanInLoopState):
    """æè®®è¡ŒåŠ¨"""
    
    action = generate_action(state["task"])
    
    return {
        "proposed_action": action
    }

def wait_for_human_node(state: HumanInLoopState):
    """ç­‰å¾…äººå·¥å®¡æ ¸ï¼ˆé˜»å¡ï¼‰"""
    
    print(f"\nã€éœ€è¦äººå·¥å®¡æ ¸ã€‘")
    print(f"ä»»åŠ¡ï¼š{state['task']}")
    print(f"æè®®è¡ŒåŠ¨ï¼š{state['proposed_action']}")
    
    # ç­‰å¾…äººå·¥è¾“å…¥
    approval = input("æ˜¯å¦æ‰¹å‡†ï¼Ÿ(y/n): ")
    feedback = input("åé¦ˆæ„è§ï¼ˆå¯é€‰ï¼‰: ")
    
    return {
        "human_approved": approval.lower() == 'y',
        "human_feedback": feedback if feedback else None
    }

def execute_action_node(state: HumanInLoopState):
    """æ‰§è¡Œè¡ŒåŠ¨"""
    
    if state["human_approved"]:
        result = execute_action(state["proposed_action"])
        return {"result": result}
    else:
        # æ ¹æ®åé¦ˆä¿®æ”¹
        modified_action = modify_action(
            state["proposed_action"],
            state["human_feedback"]
        )
        result = execute_action(modified_action)
        return {"result": result}

# æ„å»ºæµç¨‹
workflow = StateGraph(HumanInLoopState)

workflow.add_node("propose", propose_action_node)
workflow.add_node("wait_human", wait_for_human_node)
workflow.add_node("execute", execute_action_node)

workflow.set_entry_point("propose")
workflow.add_edge("propose", "wait_human")
workflow.add_edge("wait_human", "execute")
workflow.add_edge("execute", END)

app = workflow.compile(checkpointer=MemorySaver())

# æ‰§è¡Œï¼ˆä¼šæš‚åœç­‰å¾…äººå·¥è¾“å…¥ï¼‰
config = {"configurable": {"thread_id": "review_123"}}
result = app.invoke(initial_state, config=config)
```

#### 2. å¼‚æ­¥äººå·¥åé¦ˆ

```python
# å¼‚æ­¥æ¨¡å¼ï¼šå…ˆæš‚åœï¼Œç­‰æ”¶åˆ°åé¦ˆåç»§ç»­

# ç¬¬ä¸€æ­¥ï¼šæäº¤å®¡æ ¸è¯·æ±‚
result1 = app.invoke(initial_state, config=config)
print("å·²æäº¤å®¡æ ¸ï¼Œç­‰å¾…åé¦ˆ...")

# ç¬¬äºŒæ­¥ï¼šæ”¶åˆ°äººå·¥åé¦ˆåç»§ç»­
# ï¼ˆå¯èƒ½æ˜¯å‡ åˆ†é’Ÿæˆ–å‡ å°æ—¶åï¼‰
feedback_state = {
    **result1,
    "human_approved": True,
    "human_feedback": "å»ºè®®è°ƒæ•´å‚æ•°"
}

result2 = app.invoke(feedback_state, config=config)
```

---

## ğŸ’» å®Œæ•´å®æˆ˜ï¼šå¤æ‚æ•°æ®åˆ†æAgent

```python
from typing import TypedDict, Annotated, List, Dict, Optional
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
import operator

# çŠ¶æ€å®šä¹‰
class DataAnalysisState(TypedDict):
    # è¾“å…¥
    task_description: str
    data_path: str
    
    # å¯¹è¯å†å²
    messages: Annotated[List, operator.add]
    
    # æ‰§è¡Œæµç¨‹
    current_step: str
    completed_steps: Annotated[List[str], operator.add]
    
    # æ•°æ®
    raw_data: Optional[Dict]
    cleaned_data: Optional[Dict]
    analysis_results: Optional[Dict]
    visualizations: Annotated[List[str], operator.add]
    
    # æŠ¥å‘Š
    report_sections: Annotated[List[Dict], operator.add]
    final_report: Optional[str]
    
    # æ§åˆ¶
    needs_clarification: bool
    clarification_question: Optional[str]
    human_input: Optional[str]
    
    # é”™è¯¯å¤„ç†
    error: Optional[str]
    retry_count: int
    max_retries: int
    
    # å…ƒæ•°æ®
    task_id: str
    status: str  # "running" | "paused" | "completed" | "failed"

# èŠ‚ç‚¹å®ç°
def load_data_node(state: DataAnalysisState):
    """åŠ è½½æ•°æ®"""
    try:
        data = load_data_from_path(state["data_path"])
        
        return {
            "raw_data": data,
            "completed_steps": ["load_data"],
            "current_step": "clean_data",
            "messages": [AIMessage(content=f"å·²åŠ è½½æ•°æ®ï¼š{len(data)}è¡Œ")]
        }
    except Exception as e:
        return {
            "error": str(e),
            "retry_count": state["retry_count"] + 1
        }

def clean_data_node(state: DataAnalysisState):
    """æ¸…æ´—æ•°æ®"""
    try:
        cleaned = clean_data(state["raw_data"])
        
        return {
            "cleaned_data": cleaned,
            "completed_steps": ["clean_data"],
            "current_step": "analyze_data",
            "messages": [AIMessage(content="æ•°æ®æ¸…æ´—å®Œæˆ")]
        }
    except Exception as e:
        return {
            "error": str(e),
            "retry_count": state["retry_count"] + 1
        }

def analyze_data_node(state: DataAnalysisState):
    """åˆ†ææ•°æ®"""
    
    # ä½¿ç”¨LLMå†³å®šåˆ†æç­–ç•¥
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    prompt = f"""
    ä»»åŠ¡ï¼š{state['task_description']}
    æ•°æ®æ¦‚å†µï¼š{summarize_data(state['cleaned_data'])}
    
    è¯·å†³å®šéœ€è¦è¿›è¡Œå“ªäº›åˆ†æï¼Œè¿”å›JSONæ ¼å¼ï¼š
    {{"analyses": ["åˆ†æ1", "åˆ†æ2", ...]}}
    """
    
    response = llm.invoke([HumanMessage(content=prompt)])
    
    # æ‰§è¡Œåˆ†æ
    analyses = parse_analyses(response.content)
    results = {}
    
    for analysis in analyses:
        results[analysis] = perform_analysis(
            state["cleaned_data"],
            analysis
        )
    
    return {
        "analysis_results": results,
        "completed_steps": ["analyze_data"],
        "current_step": "generate_visualizations",
        "messages": [AIMessage(content=f"å®Œæˆ{len(analyses)}é¡¹åˆ†æ")]
    }

def generate_visualizations_node(state: DataAnalysisState):
    """ç”Ÿæˆå¯è§†åŒ–"""
    
    viz_paths = []
    
    for analysis_name, result in state["analysis_results"].items():
        viz_path = create_visualization(analysis_name, result)
        viz_paths.append(viz_path)
    
    return {
        "visualizations": viz_paths,
        "completed_steps": ["generate_visualizations"],
        "current_step": "generate_report",
        "messages": [AIMessage(content=f"ç”Ÿæˆ{len(viz_paths)}ä¸ªå›¾è¡¨")]
    }

def generate_report_node(state: DataAnalysisState):
    """ç”ŸæˆæŠ¥å‘Š"""
    
    llm = ChatOpenAI(model="gpt-4", temperature=0.7)
    
    prompt = f"""
    åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Šï¼š
    
    ä»»åŠ¡ï¼š{state['task_description']}
    åˆ†æç»“æœï¼š{state['analysis_results']}
    å¯è§†åŒ–ï¼š{state['visualizations']}
    
    ç”Ÿæˆå®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Šã€‚
    """
    
    response = llm.invoke([HumanMessage(content=prompt)])
    
    return {
        "final_report": response.content,
        "completed_steps": ["generate_report"],
        "current_step": "complete",
        "status": "completed",
        "messages": [AIMessage(content="æŠ¥å‘Šç”Ÿæˆå®Œæˆ")]
    }

# æ¡ä»¶è·¯ç”±
def route_after_load(state: DataAnalysisState) -> str:
    if state.get("error"):
        return "error"
    return "clean"

def route_after_clean(state: DataAnalysisState) -> str:
    if state.get("error"):
        return "error"
    return "analyze"

def route_after_analyze(state: DataAnalysisState) -> str:
    if state.get("error"):
        return "error"
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…
    if needs_clarification(state):
        return "clarify"
    
    return "visualize"

def handle_error(state: DataAnalysisState) -> str:
    if state["retry_count"] >= state["max_retries"]:
        return "failed"
    return "retry"

# æ„å»ºå›¾
workflow = StateGraph(DataAnalysisState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("load", load_data_node)
workflow.add_node("clean", clean_data_node)
workflow.add_node("analyze", analyze_data_node)
workflow.add_node("visualize", generate_visualizations_node)
workflow.add_node("report", generate_report_node)
workflow.add_node("error_handler", error_handler_node)
workflow.add_node("complete", complete_node)

# æ·»åŠ è¾¹
workflow.set_entry_point("load")

workflow.add_conditional_edges(
    "load",
    route_after_load,
    {"clean": "clean", "error": "error_handler"}
)

workflow.add_conditional_edges(
    "clean",
    route_after_clean,
    {"analyze": "analyze", "error": "error_handler"}
)

workflow.add_conditional_edges(
    "analyze",
    route_after_analyze,
    {
        "visualize": "visualize",
        "clarify": "clarify",
        "error": "error_handler"
    }
)

workflow.add_edge("visualize", "report")
workflow.add_edge("report", "complete")
workflow.add_edge("complete", END)

workflow.add_conditional_edges(
    "error_handler",
    handle_error,
    {
        "retry": "load",
        "failed": END
    }
)

# ç¼–è¯‘ï¼ˆå¯ç”¨æ£€æŸ¥ç‚¹ï¼‰
app = workflow.compile(checkpointer=MemorySaver())

# ä½¿ç”¨
config = {"configurable": {"thread_id": "analysis_task_001"}}

initial_state = {
    "task_description": "åˆ†æé”€å”®æ•°æ®ï¼Œæ‰¾å‡ºå¢é•¿è¶‹åŠ¿",
    "data_path": "sales_data.csv",
    "messages": [],
    "completed_steps": [],
    "visualizations": [],
    "report_sections": [],
    "needs_clarification": False,
    "retry_count": 0,
    "max_retries": 3,
    "task_id": "task_001",
    "status": "running"
}

try:
    result = app.invoke(initial_state, config=config)
    
    print("=== åˆ†æå®Œæˆ ===")
    print(f"çŠ¶æ€ï¼š{result['status']}")
    print(f"å®Œæˆæ­¥éª¤ï¼š{result['completed_steps']}")
    print(f"\næœ€ç»ˆæŠ¥å‘Šï¼š\n{result['final_report']}")
    
except Exception as e:
    print(f"ä»»åŠ¡å¤±è´¥ï¼š{e}")
    
    # ä»æ£€æŸ¥ç‚¹æ¢å¤
    print("å°è¯•ä»æ£€æŸ¥ç‚¹æ¢å¤...")
    result = app.invoke(initial_state, config=config)
```

---

## ğŸ¯ æœ¬è¯¾å°ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **çŠ¶æ€è®¾è®¡åŸåˆ™ï¼š**
   - æ¸…æ™°çš„ç»“æ„
   - åˆç†çš„æ›´æ–°ç­–ç•¥
   - å®Œæ•´çš„å…ƒæ•°æ®
   - é”™è¯¯ä¿¡æ¯è®°å½•

2. **æµç¨‹æ§åˆ¶æŠ€å·§ï¼š**
   - å¤šå±‚æ¡ä»¶è·¯ç”±
   - åŠ¨æ€å¾ªç¯
   - å¹¶è¡Œå¤„ç†
   - é”™è¯¯æ¢å¤

3. **é«˜çº§ç‰¹æ€§ï¼š**
   - æ£€æŸ¥ç‚¹ï¼ˆçŠ¶æ€æŒä¹…åŒ–ï¼‰
   - äººå·¥å¹²é¢„
   - å¼‚æ­¥å¤„ç†
   - çŠ¶æ€å›æº¯

4. **æœ€ä½³å®è·µï¼š**
   - çŠ¶æ€æœ€å°åŒ–
   - æ¸…æ™°çš„å‘½å
   - å®Œå–„çš„é”™è¯¯å¤„ç†
   - å……åˆ†çš„æ—¥å¿—è®°å½•

---

## ğŸ“ è¯¾åä½œä¸š

### ä½œä¸šï¼šæ„å»ºæ™ºèƒ½æ•°æ®åˆ†æAgent

**è¦æ±‚ï¼š**
1. è®¾è®¡å¤æ‚çŠ¶æ€ç»“æ„
2. å®ç°å®Œæ•´åˆ†ææµç¨‹ï¼š
   - æ•°æ®åŠ è½½
   - æ•°æ®æ¸…æ´—
   - æ•°æ®åˆ†æ
   - å¯è§†åŒ–ç”Ÿæˆ
   - æŠ¥å‘Šç”Ÿæˆ
3. å®ç°é«˜çº§ç‰¹æ€§ï¼š
   - é”™è¯¯å¤„ç†ä¸é‡è¯•
   - äººå·¥å¹²é¢„
   - çŠ¶æ€æŒä¹…åŒ–
4. æµ‹è¯•å„ç§åœºæ™¯ï¼š
   - æ­£å¸¸æµç¨‹
   - é”™è¯¯æ¢å¤
   - äººå·¥å®¡æ ¸

---

**æŒæ¡LangGraphçš„çŠ¶æ€ç®¡ç†å’Œæµç¨‹æ§åˆ¶ï¼Œä½ å°±èƒ½æ„å»ºç”Ÿäº§çº§çš„å¤æ‚Agentï¼** ğŸš€

