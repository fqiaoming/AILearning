![Agent进阶架构](./images/agent.svg)
*图：Agent进阶架构*

# 第90.1课：LangGraph框架入门与核心概念

> **本课目标**：掌握LangGraph框架，构建复杂状态化Agent应用
> 
> **核心技能**：LangGraph基础、状态图、节点边、条件路由、持久化
> 
> **学习时长**：95分钟
> 
> **重要性**：⭐⭐⭐⭐⭐（LangChain官方推荐，工业界Agent开发标准）

---

## 📖 口播文案（8分钟）

### 🎯 前言

"**欢迎来到LangGraph核心课程！**

前面我们学习了：
- 第71-90课：LangChain Agent开发

今天要学习：**LangGraph - LangChain的下一代Agent框架**

**这是AI工程师必须掌握的最新技能！**

为什么？因为根据AI编程小朱博主的分享：
> "智能体的开发一定是基于LangChain框架或者**LangGraph框架**"

**LangGraph是什么？**

**问题1：传统Agent的局限**

```
场景：复杂的多步骤任务

传统LangChain Agent：
用户："帮我分析这份销售数据并生成报告"

Agent执行流程：
1. 调用数据分析工具 → 得到结果
2. 基于结果调用图表生成工具 → 得到图表
3. 基于图表调用报告生成工具 → 生成报告

问题：
• 每一步都重新推理，重复消耗token ❌
• 无法保存中间状态 ❌
• 难以实现复杂的条件分支 ❌
• 错误难以调试和恢复 ❌
• 无法实现人工审核环节 ❌

成本高、可控性差！
```

**问题2：需要精确控制流程**

```
场景：客服系统

需求：
1. 分析用户问题类型
2. 如果是技术问题 → 查询技术文档
3. 如果是账务问题 → 查询订单系统
4. 如果无法解决 → 转人工

传统Agent：
• 依赖LLM自主决策
• 流程不可控
• 容易出错

需要：
• 明确的状态转移
• 可预测的执行流程
• 人工干预的能力
```

**LangGraph的解决方案：**

```
LangGraph = 状态图 + LangChain

核心思想：
• 把Agent的执行流程建模为状态图
• 每个节点是一个操作
• 边定义状态转移
• 可以有条件分支
• 支持循环和并行

优势：
✅ 流程清晰可控
✅ 状态持久化
✅ 支持人工干预
✅ 易于调试
✅ 可视化执行流程
✅ 降低token消耗
```

**今天，我要告诉你：如何用LangGraph构建生产级Agent！**

---

### 💡 什么是LangGraph？

**直觉理解：**

```
【传统Agent】= 自动驾驶
• LLM自主决策
• 不透明
• 难控制
• 出错难定位

【LangGraph】= 地铁线路图
• 明确的站点（节点）
• 明确的路线（边）
• 可以转线（条件分支）
• 可以下车（人工干预）
• 透明可控

就像：
• 工作流程图
• 状态机
• 决策树
```

**技术定义：**

```
LangGraph是一个基于图的Agent编排框架：

核心概念：
1. 状态（State）：存储执行过程中的所有信息
2. 节点（Node）：执行具体操作的函数
3. 边（Edge）：定义节点间的转移
4. 条件边（Conditional Edge）：根据状态动态路由
5. 持久化（Checkpointing）：保存执行状态
```

**LangGraph vs LangChain Agent：**

```
场景：多步骤数据分析

【LangChain Agent】
while not done:
    action = llm.decide_action(state)  # 每次都推理
    result = execute(action)
    state.update(result)

成本：每步都调用LLM → token消耗大
控制：依赖LLM决策 → 不可控

【LangGraph】
graph = StateGraph()
graph.add_node("analyze", analyze_data)  # 明确节点
graph.add_node("visualize", create_chart)
graph.add_node("report", generate_report)
graph.add_edge("analyze", "visualize")   # 明确流程
graph.add_edge("visualize", "report")

成本：只在关键决策点调用LLM → token省50%+
控制：流程明确 → 完全可控

优势明显！
```

---

## 📚 核心知识

### 一、LangGraph核心概念

#
![LangGraph入门](./images/langgraph.svg)
*图：LangGraph入门*

### 1. 状态（State）

```python
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage
import operator

class AgentState(TypedDict):
    """Agent状态定义"""
    
    # 消息历史
    messages: Annotated[Sequence[BaseMessage], operator.add]
    
    # 当前步骤
    current_step: str
    
    # 中间结果
    analysis_result: dict
    chart_data: dict
    
    # 循环控制
    iteration_count: int
    max_iterations: int

# 说明：
# - TypedDict：定义状态的结构
# - Annotated：定义状态更新的方式
# - operator.add：表示追加而不是覆盖
```

#### 2. 节点（Node）

```python
def analyze_node(state: AgentState) -> AgentState:
    """分析节点：执行数据分析"""
    
    print(f"执行分析节点...")
    
    # 执行分析
    result = perform_analysis(state["messages"])
    
    # 更新状态
    return {
        **state,
        "analysis_result": result,
        "current_step": "analyze_done",
        "iteration_count": state["iteration_count"] + 1
    }

def visualize_node(state: AgentState) -> AgentState:
    """可视化节点：生成图表"""
    
    print(f"执行可视化节点...")
    
    # 生成图表
    chart = create_chart(state["analysis_result"])
    
    # 更新状态
    return {
        **state,
        "chart_data": chart,
        "current_step": "visualize_done"
    }
```

#### 3. 边（Edge）

```python
from langgraph.graph import StateGraph, END

# 创建状态图
workflow = StateGraph(AgentState)

# 添加节点
workflow.add_node("analyze", analyze_node)
workflow.add_node("visualize", visualize_node)
workflow.add_node("report", report_node)

# 添加边（固定路径）
workflow.add_edge("analyze", "visualize")  # 分析 → 可视化
workflow.add_edge("visualize", "report")   # 可视化 → 报告
workflow.add_edge("report", END)           # 报告 → 结束

# 设置入口
workflow.set_entry_point("analyze")
```

#### 4. 条件边（Conditional Edge）

```python
def should_continue(state: AgentState) -> str:
    """条件路由：决定下一步"""
    
    # 检查是否超过最大迭代次数
    if state["iteration_count"] >= state["max_iterations"]:
        return "end"
    
    # 根据当前步骤决定路径
    if state["current_step"] == "analyze_done":
        # 如果分析结果不理想，重新分析
        if state["analysis_result"]["confidence"] < 0.8:
            return "re_analyze"
        else:
            return "visualize"
    
    return "continue"

# 添加条件边
workflow.add_conditional_edges(
    "analyze",                    # 从哪个节点
    should_continue,              # 条件函数
    {
        "re_analyze": "analyze",  # 重新分析
        "visualize": "visualize", # 继续可视化
        "end": END                # 结束
    }
)
```

---

### 二、第一个LangGraph应用

#### 完整示例：简单的问答Agent

```python
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import operator

# 1. 定义状态
class ChatState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    iteration_count: int

# 2. 定义节点
def chatbot_node(state: ChatState):
    """聊天节点"""
    
    # 初始化LLM
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    
    # 获取最新消息
    messages = state["messages"]
    
    # 调用LLM
    response = llm.invoke(messages)
    
    # 返回更新后的状态
    return {
        "messages": [response],
        "iteration_count": state["iteration_count"] + 1
    }

def should_continue(state: ChatState) -> str:
    """判断是否继续"""
    
    # 限制最大对话轮数
    if state["iteration_count"] >= 5:
        return "end"
    
    # 检查最后一条消息
    last_message = state["messages"][-1]
    
    # 如果是用户消息，继续处理
    if isinstance(last_message, HumanMessage):
        return "continue"
    
    # 如果是AI回复，等待用户输入
    return "end"

# 3. 构建图
workflow = StateGraph(ChatState)

# 添加节点
workflow.add_node("chatbot", chatbot_node)

# 添加条件边
workflow.add_conditional_edges(
    "chatbot",
    should_continue,
    {
        "continue": "chatbot",
        "end": END
    }
)

# 设置入口
workflow.set_entry_point("chatbot")

# 4. 编译
app = workflow.compile()

# 5. 使用
def chat(question: str):
    """发起对话"""
    
    # 初始状态
    initial_state = {
        "messages": [HumanMessage(content=question)],
        "iteration_count": 0
    }
    
    # 执行
    result = app.invoke(initial_state)
    
    # 获取回复
    return result["messages"][-1].content

# 测试
print(chat("什么是LangGraph？"))
```

---

### 三、LangGraph高级特性

#### 1. 持久化（Checkpointing）

```python
from langgraph.checkpoint.memory import MemorySaver

# 创建检查点保存器
memory = MemorySaver()

# 编译时启用持久化
app = workflow.compile(checkpointer=memory)

# 使用配置指定会话ID
config = {"configurable": {"thread_id": "conversation_1"}}

# 第一次对话
response1 = app.invoke(
    {"messages": [HumanMessage(content="我叫张三")]},
    config=config
)

# 第二次对话（使用相同thread_id，会记住之前的对话）
response2 = app.invoke(
    {"messages": [HumanMessage(content="我叫什么？")]},
    config=config
)

# 输出："你叫张三"
print(response2["messages"][-1].content)
```

#### 2. 流式输出

```python
# 流式执行
for state in app.stream(initial_state):
    print(f"当前状态：{state}")
    print("-" * 50)

# 流式输出消息
for chunk in app.stream(initial_state, stream_mode="messages"):
    print(chunk.content, end="", flush=True)
```

#### 3. 人工干预（Human-in-the-loop）

```python
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolExecutor

def human_approval_node(state: AgentState):
    """人工审核节点"""
    
    # 暂停执行，等待人工审核
    action = state.get("proposed_action")
    
    print(f"\n需要审核的操作：{action}")
    approval = input("是否批准？(y/n): ")
    
    if approval.lower() == "y":
        return {"approved": True}
    else:
        return {"approved": False}

# 条件路由：根据审核结果决定
def check_approval(state: AgentState) -> str:
    if state.get("approved"):
        return "execute"
    else:
        return "reject"

# 构建图
workflow = StateGraph(AgentState)
workflow.add_node("propose", propose_action_node)
workflow.add_node("human_approval", human_approval_node)
workflow.add_node("execute", execute_action_node)
workflow.add_node("reject", reject_node)

workflow.add_edge("propose", "human_approval")
workflow.add_conditional_edges(
    "human_approval",
    check_approval,
    {
        "execute": "execute",
        "reject": "reject"
    }
)

workflow.set_entry_point("propose")

# 编译并启用持久化
app = workflow.compile(checkpointer=MemorySaver())

# 使用：可以暂停等待人工输入
config = {"configurable": {"thread_id": "task_1"}}
app.invoke(initial_state, config=config)
```

---

### 四、实战：智能客服系统

```python
from typing import TypedDict, Annotated, List
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import operator

# 1. 定义状态
class CustomerServiceState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    query_type: str  # "技术问题" | "账务问题" | "其他"
    context: dict
    need_human: bool

# 2. 分类节点
def classify_query_node(state: CustomerServiceState):
    """分类用户问题"""
    
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    
    classification_prompt = SystemMessage(content="""
    分析用户问题，分类为以下之一：
    - 技术问题：关于产品使用、功能、bug等
    - 账务问题：关于订单、支付、退款等
    - 其他：其他问题
    
    只回复分类结果，不要其他内容。
    """)
    
    messages = [classification_prompt] + state["messages"]
    response = llm.invoke(messages)
    
    query_type = response.content.strip()
    
    print(f"问题分类：{query_type}")
    
    return {
        "query_type": query_type
    }

# 3. 技术问题处理节点
def handle_technical_node(state: CustomerServiceState):
    """处理技术问题"""
    
    print("查询技术文档...")
    
    # 模拟RAG检索
    context = {
        "doc1": "产品使用文档...",
        "doc2": "常见问题解答..."
    }
    
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    
    system_msg = SystemMessage(content=f"""
    你是技术支持专家，基于以下文档回答用户问题：
    {context}
    """)
    
    messages = [system_msg] + state["messages"]
    response = llm.invoke(messages)
    
    return {
        "messages": [response],
        "context": context
    }

# 4. 账务问题处理节点
def handle_billing_node(state: CustomerServiceState):
    """处理账务问题"""
    
    print("查询订单系统...")
    
    # 模拟数据库查询
    order_info = {
        "order_id": "12345",
        "status": "已支付",
        "amount": 99.0
    }
    
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    
    system_msg = SystemMessage(content=f"""
    你是客服专员，基于以下订单信息回答用户问题：
    {order_info}
    """)
    
    messages = [system_msg] + state["messages"]
    response = llm.invoke(messages)
    
    return {
        "messages": [response],
        "context": order_info
    }

# 5. 其他问题处理节点
def handle_other_node(state: CustomerServiceState):
    """处理其他问题"""
    
    print("转人工客服...")
    
    return {
        "messages": [AIMessage(content="您的问题已转接人工客服，请稍候...")],
        "need_human": True
    }

# 6. 路由函数
def route_query(state: CustomerServiceState) -> str:
    """根据问题类型路由"""
    
    query_type = state["query_type"]
    
    if "技术" in query_type:
        return "technical"
    elif "账务" in query_type:
        return "billing"
    else:
        return "other"

# 7. 构建图
workflow = StateGraph(CustomerServiceState)

# 添加节点
workflow.add_node("classify", classify_query_node)
workflow.add_node("technical", handle_technical_node)
workflow.add_node("billing", handle_billing_node)
workflow.add_node("other", handle_other_node)

# 添加边
workflow.add_edge("classify", "route")  # 分类后路由
workflow.add_conditional_edges(
    "classify",
    route_query,
    {
        "technical": "technical",
        "billing": "billing",
        "other": "other"
    }
)
workflow.add_edge("technical", END)
workflow.add_edge("billing", END)
workflow.add_edge("other", END)

# 设置入口
workflow.set_entry_point("classify")

# 8. 编译
app = workflow.compile()

# 9. 使用
def handle_customer_query(query: str):
    """处理客户查询"""
    
    initial_state = {
        "messages": [HumanMessage(content=query)],
        "query_type": "",
        "context": {},
        "need_human": False
    }
    
    result = app.invoke(initial_state)
    
    return {
        "answer": result["messages"][-1].content,
        "type": result["query_type"],
        "need_human": result["need_human"]
    }

# 测试
print(handle_customer_query("我的产品无法登录"))
print(handle_customer_query("我想查询订单状态"))
print(handle_customer_query("你们公司在哪里？"))
```

---

## 🎯 LangGraph vs LangChain Agent对比

| 特性 | LangChain Agent | LangGraph |
|------|----------------|-----------|
| 控制流程 | LLM自主决策 | 显式定义 |
| 可预测性 | 低 | 高 |
| Token消耗 | 高（每步推理） | 低（按需推理） |
| 调试难度 | 高 | 低 |
| 可视化 | 困难 | 内置支持 |
| 人工干预 | 困难 | 原生支持 |
| 状态管理 | 简单 | 强大 |
| 复杂流程 | 困难 | 擅长 |
| 学习曲线 | 简单 | 中等 |

**结论：**
- 简单Agent → LangChain Agent
- 复杂流程 → LangGraph
- 生产环境 → LangGraph

---

## 🎯 本课小结

### 核心要点

1. **LangGraph = 状态图 + LangChain**
   - 明确的节点和边
   - 条件路由
   - 状态持久化
   - 人工干预

2. **核心概念：**
   - 状态（State）：TypedDict定义
   - 节点（Node）：执行操作的函数
   - 边（Edge）：固定路径
   - 条件边（Conditional Edge）：动态路由

3. **优势：**
   - 流程可控
   - 降低成本
   - 易于调试
   - 生产级特性

4. **工业界认可：**
   - LangChain官方推荐
   - 新一代Agent标准
   - AI工程师必备

### 为什么必须学LangGraph？

根据AI编程小朱博主的分享：
> "智能体的开发一定是基于LangChain框架或者**LangGraph框架**进行的"

**现在你掌握了！** ✅

---

## 📝 课后作业

### 作业：构建审批流程Agent

**需求：**
实现一个文档审批系统：
1. 提交文档
2. AI初审（检查格式、内容）
3. 如果通过 → 人工终审
4. 如果不通过 → 返回修改建议
5. 人工审批后 → 归档或拒绝

**要求：**
1. 使用LangGraph构建流程
2. 实现条件分支
3. 支持人工干预
4. 状态持久化

---

**LangGraph是未来Agent开发的标准！下一课深入学习！** 🚀

