![æµå¼å¤„ç†](./images/streaming.svg)
*å›¾ï¼šStreamingæµå¼å“åº”æå‡ç”¨æˆ·ä½“éªŒ*

# ç¬¬18è¯¾ï¼šStreamingä¸å¼‚æ­¥å¤„ç† - æå‡å“åº”ä½“éªŒ

> ğŸ“š **è¯¾ç¨‹ä¿¡æ¯**
> - æ‰€å±æ¨¡å—ï¼šç¬¬äºŒæ¨¡å— - APIä¸LangChainå¼€å‘  
> - ç« èŠ‚ï¼šç¬¬4ç«  - APIè°ƒç”¨åŸºç¡€ï¼ˆç¬¬3/7è¯¾ï¼‰
> - å­¦ä¹ ç›®æ ‡ï¼šæŒæ¡æµå¼å“åº”å’Œå¼‚æ­¥ç¼–ç¨‹ï¼Œæ‰“é€ æµç•…çš„ç”¨æˆ·ä½“éªŒ
> - é¢„è®¡æ—¶é—´ï¼š70-80åˆ†é’Ÿ
> - å‰ç½®çŸ¥è¯†ï¼šç¬¬16-17è¯¾

---

## ğŸ“¢ è¯¾ç¨‹å¯¼å…¥

### å‰è¨€

ä½ ç”¨ChatGPTçš„æ—¶å€™æœ‰æ²¡æœ‰æ³¨æ„åˆ°ï¼Œå®ƒçš„å›å¤æ˜¯ä¸€ä¸ªå­—ä¸€ä¸ªå­—è¹¦å‡ºæ¥çš„ï¼Œå°±åƒæœ‰äººåœ¨æ‰“å­—ï¼Ÿè¿™ä¸æ˜¯è£…é…·ï¼Œè€Œæ˜¯**æµå¼å“åº”ï¼ˆStreamingï¼‰**ï¼å®ƒè®©ç”¨æˆ·ä¸ç”¨å‚»ç­‰ï¼Œèƒ½ç«‹å³çœ‹åˆ°è¾“å‡ºï¼Œä½“éªŒæå‡å·¨å¤§ï¼

æ›´é‡è¦çš„æ˜¯ï¼Œå½“ä½ çš„AIåº”ç”¨éœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªç”¨æˆ·è¯·æ±‚æ—¶ï¼Œå¦‚æœç”¨åŒæ­¥æ–¹å¼ï¼Œç³»ç»Ÿä¼šå¡æ­»ã€‚ä½†ç”¨**å¼‚æ­¥ï¼ˆAsyncï¼‰**ï¼Œå°±èƒ½è½»æ¾åº”å¯¹é«˜å¹¶å‘ï¼ä»Šå¤©è¿™è¯¾ï¼Œå°±æ•™ä½ è¿™ä¸¤ä¸ªè®©AIåº”ç”¨æ›´ä¸“ä¸šçš„å…³é”®æŠ€æœ¯ï¼

---

### æ ¸å¿ƒä»·å€¼ç‚¹

**ç¬¬ä¸€ï¼Œæµå¼å“åº”ä¸æ˜¯é”¦ä¸Šæ·»èŠ±ï¼Œè€Œæ˜¯å¿…å¤‡åŠŸèƒ½ã€‚**

æƒ³è±¡ä¸¤ä¸ªåœºæ™¯ï¼š
- **åœºæ™¯Aï¼ˆæ— æµå¼ï¼‰**ï¼šç”¨æˆ·ç­‰å¾…15ç§’ï¼Œçªç„¶è¹¦å‡ºä¸€å¤§æ®µæ–‡å­—
- **åœºæ™¯Bï¼ˆæœ‰æµå¼ï¼‰**ï¼šç”¨æˆ·çœ‹åˆ°æ–‡å­—é€æ¸ç”Ÿæˆï¼ŒåƒçœŸäººåœ¨å›å¤

å“ªä¸ªä½“éªŒæ›´å¥½ï¼Ÿæ˜¾ç„¶æ˜¯Bï¼è€Œä¸”æµå¼å“åº”è¿˜æœ‰å®é™…å¥½å¤„ï¼š
- ç”¨æˆ·èƒ½æå‰åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ­£ç¡®
- é•¿æ–‡æœ¬ç”Ÿæˆæ—¶ä¸ä¼šè®©ç”¨æˆ·ç„¦è™‘
- çœ‹èµ·æ¥æ›´"æ™ºèƒ½"ã€æ›´"äººæ€§åŒ–"
- å¯ä»¥éšæ—¶ä¸­æ–­ï¼ˆä¸æ„Ÿå…´è¶£å°±åœæ­¢ï¼‰

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‰€æœ‰ä¸»æµAIäº§å“éƒ½ç”¨æµå¼å“åº”ï¼

**ç¬¬äºŒï¼Œå¼‚æ­¥ç¼–ç¨‹æ˜¯é«˜å¹¶å‘çš„å”¯ä¸€è§£ã€‚**

æƒ³è±¡ä½ çš„AIåº”ç”¨ç«äº†ï¼ŒåŒæ—¶æœ‰1000ä¸ªç”¨æˆ·åœ¨ç”¨ï¼š
- **åŒæ­¥æ–¹å¼**ï¼šä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªï¼Œå…¶ä»–999ä¸ªåœ¨æ’é˜Ÿï¼ˆå¡çˆ†ï¼ï¼‰
- **å¼‚æ­¥æ–¹å¼**ï¼š1000ä¸ªåŒæ—¶å¤„ç†ï¼Œäº’ä¸é˜»å¡ï¼ˆä¸æ»‘ï¼ï¼‰

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¼‚æ­¥ä¸æ˜¯å¯é€‰é¡¹ï¼Œæ˜¯å¿…é€‰é¡¹ï¼ä¸æ‡‚å¼‚æ­¥ï¼Œä½ çš„åº”ç”¨æ ¹æœ¬æ’‘ä¸ä½çœŸå®æµé‡ï¼

**ç¬¬ä¸‰ï¼ŒPythonçš„asyncioå¹¶ä¸éš¾ï¼Œå…³é”®æ˜¯ç†è§£åŸç†ã€‚**

å¾ˆå¤šäººè¢«async/awaitå“åˆ°ï¼Œè§‰å¾—å¼‚æ­¥ç¼–ç¨‹å¾ˆéš¾ã€‚å…¶å®ä¸ç„¶ï¼åªè¦ç†è§£æ ¸å¿ƒæ¦‚å¿µï¼š
- åŒæ­¥ï¼šä¸€ä»¶äº‹åšå®Œå†åšä¸‹ä¸€ä»¶ï¼ˆä¸²è¡Œï¼‰
- å¼‚æ­¥ï¼šå¤šä»¶äº‹åŒæ—¶è¿›è¡Œï¼ˆå¹¶å‘ï¼‰

Pythonçš„asyncioè¯­æ³•å¾ˆä¼˜é›…ï¼Œå­¦ä¼šäº†ä½ ä¼šçˆ±ä¸Šå®ƒï¼è€Œä¸”OpenAIçš„SDKå¤©ç”Ÿæ”¯æŒå¼‚æ­¥ï¼Œç”¨èµ·æ¥éå¸¸æ–¹ä¾¿ï¼

**ç¬¬å››ï¼Œè¿™æ˜¯ç”Ÿäº§çº§åº”ç”¨çš„æ ‡é…ã€‚**

çœ‹çœ‹ä½ ç”¨è¿‡çš„AIäº§å“ï¼š
- ChatGPTï¼šæµå¼å“åº” âœ“ å¼‚æ­¥å¤„ç† âœ“
- Claudeï¼šæµå¼å“åº” âœ“ å¼‚æ­¥å¤„ç† âœ“
- ä»»ä½•ä¸“ä¸šäº§å“ï¼šæµå¼å“åº” âœ“ å¼‚æ­¥å¤„ç† âœ“

å¦‚æœä½ çš„åº”ç”¨ä¸æ”¯æŒè¿™äº›ï¼Œç”¨æˆ·ä¼šè§‰å¾—ä½ çš„äº§å“å¾ˆä¸šä½™ï¼è¿™ä¸¤ä¸ªæŠ€æœ¯æ˜¯æŠŠç©å…·é¡¹ç›®å˜æˆä¸“ä¸šäº§å“çš„å…³é”®ï¼

---

### è¡ŒåŠ¨å·å¬

ä»Šå¤©è¿™ä¸€è¯¾ä¼šæ•™ä½ ï¼š
- æµå¼å“åº”çš„å®Œæ•´å®ç°
- Function Calling + Streamingçš„ç»„åˆ
- Pythonå¼‚æ­¥ç¼–ç¨‹åŸºç¡€
- å¼‚æ­¥APIè°ƒç”¨
- å®æˆ˜ï¼šé«˜å¹¶å‘èŠå¤©æœåŠ¡å™¨

**å­¦å®Œè¿™è¯¾ï¼Œä½ çš„AIåº”ç”¨ä½“éªŒä¼šè´¨çš„é£è·ƒï¼**

---

## ğŸ“– çŸ¥è¯†è®²è§£

### 1. æµå¼å“åº”ï¼ˆStreamingï¼‰

#
![Api Architecture](./images/api_architecture.svg)
*å›¾ï¼šApi Architecture*

### 1.1 ä»€ä¹ˆæ˜¯æµå¼å“åº”

```
æµå¼å“åº” vs æ™®é€šå“åº”ï¼š

æ™®é€šå“åº”ï¼ˆNon-streamingï¼‰ï¼š
è¯·æ±‚ â†’ ç­‰å¾… â†’ å®Œæ•´å“åº”
ç”¨æˆ·ä½“éªŒï¼šç­‰å¾…...ç­‰å¾…...çªç„¶å‡ºç°ä¸€å¤§æ®µæ–‡å­—

æµå¼å“åº”ï¼ˆStreamingï¼‰ï¼š
è¯·æ±‚ â†’ é€æ­¥è¿”å› â†’ æŒç»­æ¥æ”¶
ç”¨æˆ·ä½“éªŒï¼šæ–‡å­—é€æ¸å‡ºç°ï¼ŒåƒçœŸäººåœ¨æ‰“å­—

æŠ€æœ¯åŸç†ï¼š
- æœåŠ¡å™¨è¾¹ç”Ÿæˆè¾¹å‘é€
- å®¢æˆ·ç«¯è¾¹æ¥æ”¶è¾¹æ˜¾ç¤º
- ä½¿ç”¨Server-Sent Events (SSE)
```

#### 1.2 åŸºç¡€æµå¼è°ƒç”¨

```python
from openai import OpenAI

client = OpenAI()

# å¼€å¯stream=True
stream = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "å†™ä¸€é¦–è¯—"}],
    stream=True  # å…³é”®å‚æ•°
)

# é€å—æ¥æ”¶
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

**chunkç»“æ„ï¼š**
```python
{
    "id": "chatcmpl-xxx",
    "object": "chat.completion.chunk",
    "created": 1234567890,
    "model": "gpt-3.5-turbo",
    "choices": [
        {
            "index": 0,
            "delta": {
                "content": "ä»Š"  # æ¯æ¬¡è¿”å›ä¸€å°æ®µ
            },
            "finish_reason": null
        }
    ]
}
```

---

#### 1.3 æµå¼å“åº”çš„å®Œæ•´å¤„ç†

```python
def stream_chat(messages):
    """å®Œæ•´çš„æµå¼å“åº”å¤„ç†"""
    stream = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        stream=True
    )
    
    full_response = ""
    
    for chunk in stream:
        # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹
        if chunk.choices[0].delta.content is not None:
            content = chunk.choices[0].delta.content
            full_response += content
            print(content, end="", flush=True)
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        if chunk.choices[0].finish_reason is not None:
            print()  # æ¢è¡Œ
            print(f"\nç»“æŸåŸå› ï¼š{chunk.choices[0].finish_reason}")
            break
    
    return full_response
```

**finish_reasonç±»å‹ï¼š**
```
stop: æ­£å¸¸ç»“æŸ
length: è¾¾åˆ°max_tokensé™åˆ¶
content_filter: è§¦å‘å†…å®¹è¿‡æ»¤
function_call: éœ€è¦è°ƒç”¨å‡½æ•°ï¼ˆéæµå¼ï¼‰
```

---

### 2. Function Calling + Streaming

#### 2.1 æŒ‘æˆ˜

```
é—®é¢˜ï¼šFunction Callingå’ŒStreamingä¸èƒ½ç›´æ¥ç»“åˆ

åŸå› ï¼š
- Function Callingéœ€è¦å®Œæ•´å‚æ•°æ‰èƒ½æ‰§è¡Œ
- Streamingæ˜¯é€æ­¥è¿”å›çš„
- çŸ›ç›¾ï¼

è§£å†³æ–¹æ¡ˆï¼š
1. ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šéæµå¼ï¼Œè·å–å‡½æ•°è°ƒç”¨ä¿¡æ¯
2. æ‰§è¡Œå‡½æ•°
3. ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šæµå¼ï¼Œç”Ÿæˆæœ€ç»ˆå›å¤
```

#### 2.2 å®ç°ä»£ç 

```python
def chat_with_functions_streaming(user_message, tools):
    """Function Calling + Streaming"""
    messages = [{"role": "user", "content": user_message}]
    
    # æ­¥éª¤1ï¼šéæµå¼è°ƒç”¨ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å‡½æ•°
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        tools=tools,
        stream=False  # ç¬¬ä¸€æ¬¡ä¸ç”¨æµå¼
    )
    
    response_message = response.choices[0].message
    
    # æ­¥éª¤2ï¼šå¦‚æœéœ€è¦è°ƒç”¨å‡½æ•°
    if response_message.tool_calls:
        # æ‰§è¡Œå‡½æ•°...
        messages.append(response_message)
        messages.append(function_result_message)
        
        # æ­¥éª¤3ï¼šæµå¼ç”Ÿæˆæœ€ç»ˆå›å¤
        print("åŠ©æ‰‹ï¼š", end="", flush=True)
        stream = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            stream=True  # ç¬¬äºŒæ¬¡ç”¨æµå¼
        )
        
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        print()
    else:
        # ä¸éœ€è¦å‡½æ•°ï¼Œç›´æ¥æµå¼è¾“å‡º
        print(response_message.content)
```

---

### 3. Pythonå¼‚æ­¥ç¼–ç¨‹åŸºç¡€

#### 3.1 åŒæ­¥ vs å¼‚æ­¥

```python
# åŒæ­¥æ–¹å¼ï¼ˆSynchronousï¼‰
def sync_task():
    print("ä»»åŠ¡1å¼€å§‹")
    time.sleep(2)  # é˜»å¡2ç§’
    print("ä»»åŠ¡1å®Œæˆ")
    
    print("ä»»åŠ¡2å¼€å§‹")
    time.sleep(2)  # é˜»å¡2ç§’
    print("ä»»åŠ¡2å®Œæˆ")
    
# æ‰§è¡Œæ—¶é—´ï¼š4ç§’
# ä»»åŠ¡1å’Œä»»åŠ¡2æ˜¯ä¸²è¡Œçš„

---

# å¼‚æ­¥æ–¹å¼ï¼ˆAsynchronousï¼‰
import asyncio

async def async_task_1():
    print("ä»»åŠ¡1å¼€å§‹")
    await asyncio.sleep(2)  # ä¸é˜»å¡ï¼Œå¯ä»¥åˆ‡æ¢åˆ°å…¶ä»–ä»»åŠ¡
    print("ä»»åŠ¡1å®Œæˆ")

async def async_task_2():
    print("ä»»åŠ¡2å¼€å§‹")
    await asyncio.sleep(2)
    print("ä»»åŠ¡2å®Œæˆ")

async def main():
    # å¹¶å‘æ‰§è¡Œ
    await asyncio.gather(
        async_task_1(),
        async_task_2()
    )

# æ‰§è¡Œæ—¶é—´ï¼š2ç§’
# ä»»åŠ¡1å’Œä»»åŠ¡2æ˜¯å¹¶å‘çš„
```

#### 3.2 æ ¸å¿ƒæ¦‚å¿µ

```python
# 1. async defï¼šå®šä¹‰å¼‚æ­¥å‡½æ•°
async def my_function():
    pass

# 2. awaitï¼šç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆ
result = await some_async_function()

# 3. asyncio.gatherï¼šå¹¶å‘æ‰§è¡Œå¤šä¸ªä»»åŠ¡
results = await asyncio.gather(task1(), task2(), task3())

# 4. asyncio.runï¼šè¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
asyncio.run(main())
```

---

### 4. å¼‚æ­¥APIè°ƒç”¨

#### 4.1 OpenAIå¼‚æ­¥SDK

```python
from openai import AsyncOpenAI
import asyncio

# åˆ›å»ºå¼‚æ­¥å®¢æˆ·ç«¯
client = AsyncOpenAI()

async def async_chat(message):
    """å¼‚æ­¥è°ƒç”¨API"""
    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": message}]
    )
    return response.choices[0].message.content

# å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚
async def main():
    tasks = [
        async_chat("ä»€ä¹ˆæ˜¯Pythonï¼Ÿ"),
        async_chat("ä»€ä¹ˆæ˜¯JavaScriptï¼Ÿ"),
        async_chat("ä»€ä¹ˆæ˜¯Goï¼Ÿ")
    ]
    
    # å¹¶å‘æ‰§è¡Œï¼Œç­‰å¾…æ‰€æœ‰å®Œæˆ
    results = await asyncio.gather(*tasks)
    
    for i, result in enumerate(results, 1):
        print(f"å›ç­”{i}ï¼š{result}\n")

# è¿è¡Œ
asyncio.run(main())
```

#### 4.2 å¼‚æ­¥æµå¼å“åº”

```python
async def async_stream_chat(message):
    """å¼‚æ­¥æµå¼å“åº”"""
    stream = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": message}],
        stream=True
    )
    
    full_response = ""
    async for chunk in stream:
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            full_response += content
            print(content, end="", flush=True)
    
    print()
    return full_response
```

---

## ğŸ’» Demoæ¡ˆä¾‹ï¼šé«˜å¹¶å‘èŠå¤©æœåŠ¡å™¨

### æ¡ˆä¾‹è¯´æ˜

æ„å»ºä¸€ä¸ªæ”¯æŒæµå¼å“åº”å’Œå¼‚æ­¥å¤„ç†çš„èŠå¤©æœåŠ¡å™¨ã€‚

### ä»£ç å®ç°

åˆ›å»º`async_chat_server.py`ï¼š

```python
"""
å¼‚æ­¥èŠå¤©æœåŠ¡å™¨
æ”¯æŒæµå¼å“åº”å’Œé«˜å¹¶å‘å¤„ç†
"""

from openai import AsyncOpenAI
import asyncio
import time
from datetime import datetime
import os
from dotenv import load_dotenv

load_dotenv()


class AsyncChatServer:
    """å¼‚æ­¥èŠå¤©æœåŠ¡å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.active_sessions = {}
        self.request_count = 0
    
    async def stream_chat(self, session_id: str, message: str):
        """æµå¼å“åº”èŠå¤©"""
        print(f"\n[{session_id}] ç”¨æˆ·ï¼š{message}")
        print(f"[{session_id}] åŠ©æ‰‹ï¼š", end="", flush=True)
        
        start_time = time.time()
        
        try:
            stream = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": message}],
                stream=True
            )
            
            full_response = ""
            chunk_count = 0
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    print(content, end="", flush=True)
                    chunk_count += 1
                    
                    # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
                    await asyncio.sleep(0.01)
            
            elapsed_time = time.time() - start_time
            print(f"\n[{session_id}] âœ“ å®Œæˆ | è€—æ—¶ï¼š{elapsed_time:.2f}s | Chunksï¼š{chunk_count}")
            
            return full_response
            
        except Exception as e:
            print(f"\n[{session_id}] âœ— é”™è¯¯ï¼š{e}")
            return None
    
    async def handle_multiple_requests(self, requests):
        """å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚"""
        print(f"\n{'='*60}")
        print(f"å¹¶å‘å¤„ç† {len(requests)} ä¸ªè¯·æ±‚")
        print(f"{'='*60}")
        
        start_time = time.time()
        
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = [
            self.stream_chat(f"Session-{i+1}", request)
            for i, request in enumerate(requests)
        ]
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks)
        
        total_time = time.time() - start_time
        
        print(f"\n{'='*60}")
        print(f"âœ“ å…¨éƒ¨å®Œæˆ")
        print(f"  æ€»è€—æ—¶ï¼š{total_time:.2f}ç§’")
        print(f"  å¹³å‡è€—æ—¶ï¼š{total_time/len(requests):.2f}ç§’/è¯·æ±‚")
        print(f"  å¹¶å‘æ•ˆç‡ï¼š{len(requests)/total_time:.2f}è¯·æ±‚/ç§’")
        print(f"{'='*60}")
        
        return results
    
    async def benchmark_sync_vs_async(self):
        """å¯¹æ¯”åŒæ­¥vså¼‚æ­¥æ€§èƒ½"""
        print("\n" + "="*60)
        print("æ€§èƒ½å¯¹æ¯”ï¼šåŒæ­¥ vs å¼‚æ­¥")
        print("="*60)
        
        requests = [
            "ä»€ä¹ˆæ˜¯Pythonï¼Ÿ",
            "ä»€ä¹ˆæ˜¯JavaScriptï¼Ÿ",
            "ä»€ä¹ˆæ˜¯Goï¼Ÿ"
        ]
        
        # å¼‚æ­¥æ–¹å¼
        print("\nã€å¼‚æ­¥æ–¹å¼ã€‘")
        async_start = time.time()
        await self.handle_multiple_requests(requests)
        async_time = time.time() - async_start
        
        print(f"\nå¼‚æ­¥æ€»è€—æ—¶ï¼š{async_time:.2f}ç§’")
        
        # åŒæ­¥æ–¹å¼ï¼ˆæ¨¡æ‹Ÿï¼‰
        print("\n\nã€åŒæ­¥æ–¹å¼ï¼ˆä¼°ç®—ï¼‰ã€‘")
        sync_time_estimate = async_time * len(requests)
        print(f"åŒæ­¥é¢„ä¼°è€—æ—¶ï¼š{sync_time_estimate:.2f}ç§’")
        
        print(f"\næ€§èƒ½æå‡ï¼š{sync_time_estimate/async_time:.1f}å€")


class StreamingDemo:
    """æµå¼å“åº”æ¼”ç¤º"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    async def compare_streaming(self, message: str):
        """å¯¹æ¯”æµå¼vséæµå¼"""
        print("\n" + "="*60)
        print("å¯¹æ¯”ï¼šæµå¼ vs éæµå¼å“åº”")
        print("="*60)
        
        # éæµå¼
        print("\nã€éæµå¼å“åº”ã€‘")
        print("(æ¨¡æ‹Ÿç”¨æˆ·ç­‰å¾…...)")
        
        non_stream_start = time.time()
        response = await self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": message}],
            stream=False
        )
        non_stream_time = time.time() - non_stream_start
        
        print(f"\nç­‰å¾… {non_stream_time:.2f}ç§’å...")
        print(f"è¾“å‡ºï¼š{response.choices[0].message.content}")
        
        # æµå¼
        print("\n\nã€æµå¼å“åº”ã€‘")
        print("è¾“å‡ºï¼š", end="", flush=True)
        
        stream_start = time.time()
        stream = await self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": message}],
            stream=True
        )
        
        first_chunk_time = None
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                if first_chunk_time is None:
                    first_chunk_time = time.time() - stream_start
                
                print(chunk.choices[0].delta.content, end="", flush=True)
                await asyncio.sleep(0.03)  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
        
        stream_time = time.time() - stream_start
        
        print(f"\n\næ€»è€—æ—¶ï¼š{stream_time:.2f}ç§’")
        print(f"é¦–å­—å“åº”ï¼š{first_chunk_time:.2f}ç§’")
        print(f"\nç”¨æˆ·ä½“éªŒï¼šæµå¼å“åº”åœ¨{first_chunk_time:.2f}ç§’å°±å¼€å§‹æ˜¾ç¤ºï¼Œ"
              f"è€Œéæµå¼éœ€è¦ç­‰å¾…{non_stream_time:.2f}ç§’")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼‚æ­¥èŠå¤©æœåŠ¡å™¨ + æµå¼å“åº”æ¼”ç¤º")
    
    # æ¼”ç¤º1ï¼šæµå¼vséæµå¼
    demo = StreamingDemo()
    await demo.compare_streaming("ç”¨100å­—ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹")
    
    # æ¼”ç¤º2ï¼šå¼‚æ­¥å¹¶å‘å¤„ç†
    server = AsyncChatServer()
    
    # æ¨¡æ‹Ÿå¤šä¸ªç”¨æˆ·åŒæ—¶è¯·æ±‚
    concurrent_requests = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "Pythonçš„ä¼˜åŠ¿æœ‰å“ªäº›ï¼Ÿ",
        "å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    await server.handle_multiple_requests(concurrent_requests)
    
    # æ¼”ç¤º3ï¼šæ€§èƒ½å¯¹æ¯”
    await server.benchmark_sync_vs_async()
    
    print("\n" + "="*60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ æ ¸å¿ƒè¦ç‚¹ï¼š")
    print("1. æµå¼å“åº”ï¼šç”¨æˆ·ä½“éªŒå¥½ï¼Œé¦–å­—å¿«é€Ÿå“åº”")
    print("2. å¼‚æ­¥ç¼–ç¨‹ï¼šé«˜å¹¶å‘ï¼Œå¤šè¯·æ±‚åŒæ—¶å¤„ç†")
    print("3. asyncio.gatherï¼šå¹¶å‘æ‰§è¡Œå¤šä¸ªä»»åŠ¡")
    print("4. async/awaitï¼šPythonå¼‚æ­¥ç¼–ç¨‹çš„æ ¸å¿ƒ")
    print("5. ç”Ÿäº§ç¯å¢ƒå¿…å¤‡ï¼šæµå¼+å¼‚æ­¥=æµç•…+é«˜æ•ˆ")
    print("="*60)


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())
```

### è¿è¡Œæ¼”ç¤º

```bash
# ç¡®ä¿OPENAI_API_KEYå·²é…ç½®
python async_chat_server.py
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨æµå¼å“åº”

```
âœ… é€‚åˆåœºæ™¯ï¼š
- é•¿æ–‡æœ¬ç”Ÿæˆï¼ˆæ–‡ç« ã€æ•…äº‹ã€ä»£ç ï¼‰
- å®æ—¶èŠå¤©å¯¹è¯
- éœ€è¦å¿«é€Ÿé¦–å­—å“åº”
- ç”¨æˆ·éœ€è¦æŸ¥çœ‹ç”Ÿæˆè¿‡ç¨‹

âŒ ä¸é€‚åˆåœºæ™¯ï¼š
- çŸ­æ–‡æœ¬ï¼ˆ<50å­—ï¼‰
- éœ€è¦åå¤„ç†è¾“å‡º
- æ‰¹é‡å¤„ç†
- JSONç­‰ç»“æ„åŒ–è¾“å‡º
```

### 2. å¼‚æ­¥ç¼–ç¨‹æ³¨æ„äº‹é¡¹

```
âœ… å¥½çš„å®è·µï¼š
- æ‰€æœ‰IOæ“ä½œéƒ½ç”¨å¼‚æ­¥ï¼ˆAPIã€æ•°æ®åº“ã€æ–‡ä»¶ï¼‰
- ä½¿ç”¨asyncio.gatherå¹¶å‘æ‰§è¡Œ
- æ­£ç¡®å¤„ç†å¼‚å¸¸
- è®¾ç½®è¶…æ—¶é™åˆ¶

âŒ å¸¸è§é”™è¯¯ï¼š
- åœ¨å¼‚æ­¥å‡½æ•°ä¸­ä½¿ç”¨åŒæ­¥IOï¼ˆä¼šé˜»å¡ï¼‰
- å¿˜è®°awaitï¼ˆä»»åŠ¡ä¸ä¼šæ‰§è¡Œï¼‰
- ä¸å¤„ç†å¼‚å¸¸ï¼ˆä¸€ä¸ªå¤±è´¥å…¨å¤±è´¥ï¼‰
- æ— é™åˆ¶å¹¶å‘ï¼ˆå¯èƒ½è¢«é™æµï¼‰
```

### 3. é”™è¯¯å¤„ç†

```python
async def safe_chat(message):
    """å¸¦é”™è¯¯å¤„ç†çš„å¼‚æ­¥è°ƒç”¨"""
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": message}],
            timeout=30  # è¶…æ—¶è®¾ç½®
        )
        return response.choices[0].message.content
    except asyncio.TimeoutError:
        return "è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•"
    except Exception as e:
        return f"é”™è¯¯ï¼š{str(e)}"
```

### 4. å¹¶å‘æ§åˆ¶

```python
import asyncio

async def limited_concurrency(tasks, max_concurrent=5):
    """é™åˆ¶å¹¶å‘æ•°é‡"""
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def bounded_task(task):
        async with semaphore:
            return await task
    
    return await asyncio.gather(*[bounded_task(t) for t in tasks])

# ä½¿ç”¨
results = await limited_concurrency(
    [async_chat(msg) for msg in messages],
    max_concurrent=10  # æœ€å¤šåŒæ—¶10ä¸ªè¯·æ±‚
)
```

---

## âœ… è¯¾åæ£€éªŒ

å®Œæˆæœ¬è¯¾åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] å®ç°æµå¼å“åº”
- [ ] ç†è§£Pythonå¼‚æ­¥ç¼–ç¨‹åŸºç¡€
- [ ] ä½¿ç”¨AsyncOpenAIè¿›è¡Œå¼‚æ­¥è°ƒç”¨
- [ ] å®ç°Function Calling + Streaming
- [ ] å¤„ç†é«˜å¹¶å‘è¯·æ±‚
- [ ] å¯¹æ¯”åŒæ­¥å’Œå¼‚æ­¥çš„æ€§èƒ½å·®å¼‚

---

## ğŸ“ ä¸‹ä¸€è¯¾é¢„å‘Š

**ç¬¬19è¯¾ï¼šé”™è¯¯å¤„ç†ä¸é‡è¯•ç­–ç•¥**

APIè°ƒç”¨ä¸å¯èƒ½æ€»æ˜¯æˆåŠŸï¼Œä¸‹ä¸€è¯¾æˆ‘ä»¬å°†å­¦ä¹ ï¼š
- å„ç§é”™è¯¯ç±»å‹å’Œå¤„ç†æ–¹æ³•
- æ™ºèƒ½é‡è¯•ç­–ç•¥ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
- ç†”æ–­å™¨æ¨¡å¼
- é™çº§æ–¹æ¡ˆ
- ç›‘æ§å’Œå‘Šè­¦

**è®©ä½ çš„AIåº”ç”¨æ›´åŠ å¥å£®å¯é ï¼**

---

**ğŸ‰ æ­å–œä½ å®Œæˆç¬¬18è¯¾ï¼**

ä½ çš„AIåº”ç”¨ç°åœ¨èƒ½æµå¼å“åº”+å¼‚æ­¥å¤„ç†ï¼Œä½“éªŒå’Œæ€§èƒ½éƒ½å¤§å¹…æå‡ï¼

**ä¸‹ä¸€æ­¥ï¼š** å­¦ä¹ å¦‚ä½•è®©ç³»ç»Ÿæ›´åŠ å¥å£®å¯é ï¼

