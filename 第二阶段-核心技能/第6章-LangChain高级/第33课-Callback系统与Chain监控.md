![Callbackå›è°ƒç³»ç»Ÿ](./images/callback.svg)
*å›¾ï¼šCallbackå›è°ƒç³»ç»Ÿ*

# ç¬¬33è¯¾ï¼šCallbackç³»ç»Ÿä¸Chainç›‘æ§ - è®©æ‰§è¡Œé€æ˜å¯æ§

> ğŸ“š **è¯¾ç¨‹ä¿¡æ¯**
> - æ‰€å±æ¨¡å—ï¼šç¬¬äºŒæ¨¡å— - APIä¸LangChainå¼€å‘  
> - ç« èŠ‚ï¼šç¬¬6ç«  - Chainé«˜çº§åº”ç”¨ï¼ˆç¬¬4/7è¯¾ï¼‰
> - å­¦ä¹ ç›®æ ‡ï¼šæŒæ¡Callbackæœºåˆ¶ï¼Œå®ç°Chainçš„ç›‘æ§ã€æ—¥å¿—å’Œè°ƒè¯•
> - é¢„è®¡æ—¶é—´ï¼š80-90åˆ†é’Ÿ
> - å‰ç½®çŸ¥è¯†ï¼šç¬¬23-32è¯¾

---

## ğŸ“¢ è¯¾ç¨‹å¯¼å…¥

### å‰è¨€

ä½ çš„LangChainåº”ç”¨ä¸Šçº¿äº†ï¼Œçªç„¶ç”¨æˆ·åé¦ˆï¼š**"AIå›å¤å¾ˆæ…¢"** æˆ– **"æœ‰æ—¶å€™ä¸å›å¤"**ã€‚ä½ ä¸€è„¸æ‡µï¼šåˆ°åº•å“ªä¸ªç¯èŠ‚å‡ºé—®é¢˜äº†ï¼ŸPromptç”Ÿæˆæ…¢ï¼Ÿæ¨¡å‹è°ƒç”¨æ…¢ï¼Ÿè¿˜æ˜¯Parserè§£ææ…¢ï¼Ÿ

æ²¡æœ‰ç›‘æ§ï¼Œä½ åªèƒ½çŒœï¼ä½†å¦‚æœæœ‰ä¸ªæœºåˆ¶èƒ½è®°å½•Chainæ‰§è¡Œçš„æ¯ä¸€æ­¥ï¼š**è°ƒç”¨äº†ä»€ä¹ˆã€è€—æ—¶å¤šä¹…ã€è¾“å…¥è¾“å‡ºæ˜¯ä»€ä¹ˆ**ï¼Œé‚£æ’æŸ¥é—®é¢˜å°±å¤ªç®€å•äº†ï¼

**LangChainçš„Callbackç³»ç»Ÿå°±æ˜¯è¿™æ ·çš„ç›‘æ§ç¥å™¨ï¼**ä»Šå¤©è¿™è¯¾ï¼Œæˆ‘è¦æ•™ä½ å¦‚ä½•è®©Chainæ‰§è¡Œå®Œå…¨é€æ˜ã€å¯æ§ã€å¯ç›‘æ§ï¼

---

### æ ¸å¿ƒä»·å€¼ç‚¹

**ç¬¬ä¸€ï¼ŒCallbackæ˜¯ç”Ÿäº§ç¯å¢ƒçš„å¿…å¤‡å·¥å…·ã€‚**

æ²¡æœ‰Callbackçš„ç³»ç»Ÿæ˜¯"é»‘ç›’"ï¼Œå‡ºäº†é—®é¢˜ä½ éƒ½ä¸çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆï¼š
- **æ€§èƒ½é—®é¢˜**ï¼šå“ªä¸ªæ­¥éª¤æ…¢ï¼Ÿæ…¢å¤šä¹…ï¼Ÿ
- **é”™è¯¯æ’æŸ¥**ï¼šåœ¨å“ªä¸€æ­¥å¤±è´¥çš„ï¼Ÿé”™è¯¯ä¿¡æ¯æ˜¯ä»€ä¹ˆï¼Ÿ
- **æˆæœ¬ç›‘æ§**ï¼šè°ƒç”¨äº†å¤šå°‘æ¬¡LLMï¼ŸèŠ±äº†å¤šå°‘é’±ï¼Ÿ
- **ç”¨æˆ·è¡Œä¸º**ï¼šç”¨æˆ·é—®äº†ä»€ä¹ˆï¼ŸAIç­”äº†ä»€ä¹ˆï¼Ÿ

Callbackè®©è¿™äº›é—®é¢˜éƒ½æœ‰ç­”æ¡ˆï¼

**ç¬¬äºŒï¼ŒCallbackä¸åªæ˜¯æ—¥å¿—é‚£ä¹ˆç®€å•ã€‚**

å¾ˆå¤šäººä»¥ä¸ºCallbackå°±æ˜¯ï¼š
```python
print("Chainå¼€å§‹...")
result = chain.invoke(...)
print("Chainç»“æŸ")
```

é”™ï¼ä¸“ä¸šçš„Callbackç³»ç»Ÿèƒ½åšï¼š
- **å®æ—¶ç›‘æ§**ï¼šæ¯ä¸ªç»„ä»¶çš„æ‰§è¡ŒçŠ¶æ€
- **æ€§èƒ½åˆ†æ**ï¼šæ‰¾å‡ºæ€§èƒ½ç“¶é¢ˆ
- **é”™è¯¯è¿½è¸ª**ï¼šå®Œæ•´çš„é”™è¯¯å †æ ˆ
- **è‡ªå®šä¹‰é€»è¾‘**ï¼šåœ¨ç‰¹å®šæ—¶æœºæ‰§è¡Œä»£ç 
- **é›†æˆç¬¬ä¸‰æ–¹**ï¼šå‘é€åˆ°Sentryã€DataDogç­‰

è¿™æ‰æ˜¯ä¼ä¸šçº§çš„ç›‘æ§æ–¹æ¡ˆï¼

**ç¬¬ä¸‰ï¼ŒCallbackè®©è°ƒè¯•æ•ˆç‡æå‡10å€ã€‚**

å¯¹æ¯”ä¸¤ç§è°ƒè¯•æ–¹å¼ï¼š
- **æ— Callback**ï¼šåŠ printï¼Œæ”¹ä»£ç ï¼Œé‡è·‘ï¼ŒçŒœæµ‹é—®é¢˜
- **æœ‰Callback**ï¼šçœ‹æ—¥å¿—ï¼Œç²¾å‡†å®šä½ï¼Œç«‹å³ä¿®å¤

ç‰¹åˆ«æ˜¯å¤æ‚Chainï¼Œæ²¡æœ‰Callbackç®€ç›´æ˜¯å™©æ¢¦ï¼æœ‰äº†Callbackï¼Œè°ƒè¯•å˜å¾—è½»æ¾æ„‰å¿«ï¼

**ç¬¬å››ï¼Œè¿™æ˜¯ä»å¼€å‘åˆ°è¿ç»´çš„å…³é”®èƒ½åŠ›ã€‚**

å¼€å‘ç¯å¢ƒï¼šCallbackå¸®ä½ è°ƒè¯•
æµ‹è¯•ç¯å¢ƒï¼šCallbackå¸®ä½ éªŒè¯
ç”Ÿäº§ç¯å¢ƒï¼šCallbackå¸®ä½ ç›‘æ§

ä¸€å¥—Callbackç³»ç»Ÿï¼Œå…¨åœºæ™¯é€‚ç”¨ï¼æŒæ¡Callbackï¼Œä½ å°±å…·å¤‡äº†è¿ç»´ç”Ÿäº§ç³»ç»Ÿçš„èƒ½åŠ›ï¼

---

### è¡ŒåŠ¨å·å¬

ä»Šå¤©è¿™ä¸€è¯¾ä¼šæ•™ä½ ï¼š
- Callbackçš„å®Œæ•´æœºåˆ¶
- å†…ç½®Callbackçš„ä½¿ç”¨
- è‡ªå®šä¹‰Callback
- ç›‘æ§å’Œæ—¥å¿—æœ€ä½³å®è·µ
- ç”Ÿäº§ç¯å¢ƒçš„ç›‘æ§æ–¹æ¡ˆ

**å­¦å®Œè¿™è¯¾ï¼Œä½ çš„Chainæ‰§è¡Œä¼šå®Œå…¨é€æ˜ï¼**

---

## ğŸ“– çŸ¥è¯†è®²è§£

### 1. Callbackæ¦‚è¿°

#
![Monitoring](./images/monitoring.svg)
*å›¾ï¼šMonitoring*

### 1.1 ä»€ä¹ˆæ˜¯Callback

```
Callbackï¼ˆå›è°ƒï¼‰ï¼š
- åœ¨Chainæ‰§è¡Œè¿‡ç¨‹ä¸­è§¦å‘çš„é’©å­å‡½æ•°
- å¯ä»¥åœ¨ç‰¹å®šæ—¶æœºæ‰§è¡Œè‡ªå®šä¹‰é€»è¾‘
- ç”¨äºç›‘æ§ã€æ—¥å¿—ã€è°ƒè¯•ã€è¿½è¸ª

è§¦å‘æ—¶æœºï¼š
1. on_chain_startï¼šChainå¼€å§‹æ‰§è¡Œ
2. on_chain_endï¼šChainæ‰§è¡Œå®Œæˆ
3. on_chain_errorï¼šChainæ‰§è¡Œé”™è¯¯
4. on_llm_startï¼šLLMå¼€å§‹è°ƒç”¨
5. on_llm_endï¼šLLMè°ƒç”¨å®Œæˆ
6. on_llm_errorï¼šLLMè°ƒç”¨é”™è¯¯
7. on_tool_startï¼šå·¥å…·å¼€å§‹æ‰§è¡Œ
8. on_tool_endï¼šå·¥å…·æ‰§è¡Œå®Œæˆ
... æ›´å¤š
```

#### 1.2 Callbackçš„ä½¿ç”¨æ–¹å¼

```python
from langchain.callbacks import StdOutCallbackHandler

# æ–¹å¼1ï¼šå…¨å±€è®¾ç½®
from langchain.globals import set_verbose
set_verbose(True)

# æ–¹å¼2ï¼šChainçº§åˆ«
chain = prompt | llm | parser
result = chain.invoke(
    input_data,
    config={"callbacks": [StdOutCallbackHandler()]}
)

# æ–¹å¼3ï¼šæ„é€ å‡½æ•°
conversation = ConversationChain(
    llm=llm,
    callbacks=[StdOutCallbackHandler()]
)
```

---

### 2. å†…ç½®Callback

#### 2.1 StdOutCallbackHandlerï¼ˆæ ‡å‡†è¾“å‡ºï¼‰

```python
from langchain.callbacks import StdOutCallbackHandler
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

llm = ChatOpenAI()

chain = (
    ChatPromptTemplate.from_template("è§£é‡Š{topic}")
    | llm
)

# ä½¿ç”¨StdOutCallbackHandler
result = chain.invoke(
    {"topic": "é‡å­è®¡ç®—"},
    config={"callbacks": [StdOutCallbackHandler()]}
)

# ä¼šæ‰“å°è¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
> Entering new LLMChain chain...
Prompt after formatting:
è§£é‡Šé‡å­è®¡ç®—
> Finished chain.
```

---

#### 2.2 FileCallbackHandlerï¼ˆæ–‡ä»¶æ—¥å¿—ï¼‰

```python
from langchain.callbacks import FileCallbackHandler
import logging

# é…ç½®æ—¥å¿—æ–‡ä»¶
logfile = "chain_execution.log"
logger = logging.getLogger()
logger.setLevel(logging.INFO)

handler = FileCallbackHandler(logfile)

# ä½¿ç”¨
result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": [handler]}
)

# æ‰§è¡Œä¿¡æ¯ä¼šä¿å­˜åˆ°chain_execution.log
```

---

#### 2.3 StatsCallbackHandlerï¼ˆæ€§èƒ½ç»Ÿè®¡ï¼‰

```python
from langchain.callbacks import get_openai_callback
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain

llm = ChatOpenAI()

# ç»Ÿè®¡OpenAIè°ƒç”¨
with get_openai_callback() as cb:
    chain = LLMChain(llm=llm, prompt=prompt)
    result = chain.invoke({"input": "Hello"})
    
    # æŸ¥çœ‹ç»Ÿè®¡
    print(f"æ€»Tokenæ•°: {cb.total_tokens}")
    print(f"æç¤ºTokenæ•°: {cb.prompt_tokens}")
    print(f"è¡¥å…¨Tokenæ•°: {cb.completion_tokens}")
    print(f"æ€»æˆæœ¬: ${cb.total_cost}")
```

---

### 3. è‡ªå®šä¹‰Callback

#### 3.1 åŸºç¡€è‡ªå®šä¹‰

```python
from langchain.callbacks.base import BaseCallbackHandler
from typing import Any, Dict, List

class MyCallbackHandler(BaseCallbackHandler):
    """è‡ªå®šä¹‰Callbackç¤ºä¾‹"""
    
    def on_chain_start(
        self, 
        serialized: Dict[str, Any], 
        inputs: Dict[str, Any],
        **kwargs
    ):
        """Chainå¼€å§‹æ—¶è°ƒç”¨"""
        print(f"ğŸ”µ Chainå¼€å§‹")
        print(f"   è¾“å…¥: {inputs}")
    
    def on_chain_end(
        self, 
        outputs: Dict[str, Any],
        **kwargs
    ):
        """Chainç»“æŸæ—¶è°ƒç”¨"""
        print(f"ğŸŸ¢ Chainå®Œæˆ")
        print(f"   è¾“å‡º: {outputs}")
    
    def on_chain_error(
        self, 
        error: Exception,
        **kwargs
    ):
        """Chainé”™è¯¯æ—¶è°ƒç”¨"""
        print(f"ğŸ”´ Chainé”™è¯¯")
        print(f"   é”™è¯¯: {error}")
    
    def on_llm_start(
        self, 
        serialized: Dict[str, Any],
        prompts: List[str],
        **kwargs
    ):
        """LLMå¼€å§‹è°ƒç”¨æ—¶"""
        print(f"ğŸ”µ LLMè°ƒç”¨å¼€å§‹")
        print(f"   Prompts: {prompts[0][:50]}...")
    
    def on_llm_end(
        self, 
        response: Any,
        **kwargs
    ):
        """LLMè°ƒç”¨å®Œæˆæ—¶"""
        print(f"ğŸŸ¢ LLMè°ƒç”¨å®Œæˆ")
        # print(f"   Response: {response}")
    
    def on_llm_error(
        self, 
        error: Exception,
        **kwargs
    ):
        """LLMè°ƒç”¨é”™è¯¯æ—¶"""
        print(f"ğŸ”´ LLMé”™è¯¯: {error}")


# ä½¿ç”¨
callback = MyCallbackHandler()
result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": [callback]}
)
```

---

#### 3.2 æ€§èƒ½ç›‘æ§Callback

```python
import time
from langchain.callbacks.base import BaseCallbackHandler

class PerformanceCallback(BaseCallbackHandler):
    """æ€§èƒ½ç›‘æ§Callback"""
    
    def __init__(self):
        self.start_times = {}
        self.metrics = {
            "chain_calls": 0,
            "llm_calls": 0,
            "total_time": 0,
            "llm_time": 0
        }
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        """è®°å½•Chainå¼€å§‹æ—¶é—´"""
        run_id = kwargs.get("run_id")
        self.start_times[f"chain_{run_id}"] = time.time()
        self.metrics["chain_calls"] += 1
    
    def on_chain_end(self, outputs, **kwargs):
        """è®¡ç®—Chainæ‰§è¡Œæ—¶é—´"""
        run_id = kwargs.get("run_id")
        key = f"chain_{run_id}"
        if key in self.start_times:
            elapsed = time.time() - self.start_times[key]
            self.metrics["total_time"] += elapsed
            print(f"â±ï¸  Chainæ‰§è¡Œæ—¶é—´: {elapsed:.2f}ç§’")
            del self.start_times[key]
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """è®°å½•LLMå¼€å§‹æ—¶é—´"""
        run_id = kwargs.get("run_id")
        self.start_times[f"llm_{run_id}"] = time.time()
        self.metrics["llm_calls"] += 1
    
    def on_llm_end(self, response, **kwargs):
        """è®¡ç®—LLMæ‰§è¡Œæ—¶é—´"""
        run_id = kwargs.get("run_id")
        key = f"llm_{run_id}"
        if key in self.start_times:
            elapsed = time.time() - self.start_times[key]
            self.metrics["llm_time"] += elapsed
            print(f"â±ï¸  LLMè°ƒç”¨æ—¶é—´: {elapsed:.2f}ç§’")
            del self.start_times[key]
    
    def get_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        return f"""
æ€§èƒ½æŠ¥å‘Šï¼š
- Chainè°ƒç”¨æ¬¡æ•°: {self.metrics['chain_calls']}
- LLMè°ƒç”¨æ¬¡æ•°: {self.metrics['llm_calls']}
- æ€»æ‰§è¡Œæ—¶é—´: {self.metrics['total_time']:.2f}ç§’
- LLMæ€»è€—æ—¶: {self.metrics['llm_time']:.2f}ç§’
- å…¶ä»–è€—æ—¶: {self.metrics['total_time'] - self.metrics['llm_time']:.2f}ç§’
"""


# ä½¿ç”¨
perf_callback = PerformanceCallback()
result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": [perf_callback]}
)

print(perf_callback.get_report())
```

---

#### 3.3 æ—¥å¿—è®°å½•Callback

```python
import logging
from datetime import datetime

class LoggingCallback(BaseCallbackHandler):
    """è¯¦ç»†æ—¥å¿—Callback"""
    
    def __init__(self, log_file="chain.log"):
        self.logger = logging.getLogger("ChainLogger")
        self.logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶å¤„ç†å™¨
        handler = logging.FileHandler(log_file)
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        """è®°å½•Chainå¼€å§‹"""
        self.logger.info(f"Chainå¼€å§‹ | è¾“å…¥: {inputs}")
    
    def on_chain_end(self, outputs, **kwargs):
        """è®°å½•Chainç»“æŸ"""
        self.logger.info(f"Chainå®Œæˆ | è¾“å‡º: {outputs}")
    
    def on_chain_error(self, error, **kwargs):
        """è®°å½•Chainé”™è¯¯"""
        self.logger.error(f"Chainé”™è¯¯ | é”™è¯¯: {error}")
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """è®°å½•LLMå¼€å§‹"""
        self.logger.info(f"LLMå¼€å§‹ | Prompt: {prompts[0][:100]}...")
    
    def on_llm_end(self, response, **kwargs):
        """è®°å½•LLMç»“æŸ"""
        self.logger.info(f"LLMå®Œæˆ | Tokenä½¿ç”¨: {response}")
```

---

#### 3.4 æˆæœ¬è¿½è¸ªCallback

```python
class CostTrackingCallback(BaseCallbackHandler):
    """æˆæœ¬è¿½è¸ªCallback"""
    
    def __init__(self):
        self.total_tokens = 0
        self.prompt_tokens = 0
        self.completion_tokens = 0
        self.total_cost = 0.0
        
        # å®šä»·ï¼ˆç¤ºä¾‹ï¼‰
        self.pricing = {
            "gpt-3.5-turbo": {
                "input": 0.0005 / 1000,
                "output": 0.0015 / 1000
            },
            "gpt-4": {
                "input": 0.03 / 1000,
                "output": 0.06 / 1000
            }
        }
    
    def on_llm_end(self, response, **kwargs):
        """ç»Ÿè®¡tokenå’Œæˆæœ¬"""
        if hasattr(response, 'llm_output'):
            token_usage = response.llm_output.get('token_usage', {})
            
            prompt_tokens = token_usage.get('prompt_tokens', 0)
            completion_tokens = token_usage.get('completion_tokens', 0)
            
            self.prompt_tokens += prompt_tokens
            self.completion_tokens += completion_tokens
            self.total_tokens += prompt_tokens + completion_tokens
            
            # è®¡ç®—æˆæœ¬ï¼ˆå‡è®¾gpt-3.5-turboï¼‰
            model = "gpt-3.5-turbo"
            cost = (
                prompt_tokens * self.pricing[model]["input"] +
                completion_tokens * self.pricing[model]["output"]
            )
            self.total_cost += cost
    
    def get_summary(self):
        """è·å–æˆæœ¬æ‘˜è¦"""
        return {
            "total_tokens": self.total_tokens,
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "total_cost": f"${self.total_cost:.4f}"
        }
```

---

### 4. å¤šä¸ªCallbackç»„åˆ

```python
# åŒæ—¶ä½¿ç”¨å¤šä¸ªCallback
callbacks = [
    MyCallbackHandler(),
    PerformanceCallback(),
    LoggingCallback("app.log"),
    CostTrackingCallback()
]

result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": callbacks}
)

# æ‰€æœ‰Callbackéƒ½ä¼šè¢«è°ƒç”¨
```

---

## ğŸ’» Demoæ¡ˆä¾‹ï¼šCallbackå®æˆ˜

åˆ›å»º`callback_demo.py`ï¼š

```python
"""
Callbackç³»ç»Ÿå®Œæ•´æ¼”ç¤º
ä»åŸºç¡€åˆ°ç”Ÿäº§çº§ç›‘æ§
"""

from langchain.callbacks.base import BaseCallbackHandler
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
import time
import logging
from datetime import datetime


def demo_1_builtin_callbacks():
    """ç¤ºä¾‹1ï¼šå†…ç½®Callbacks"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1ï¼šå†…ç½®Callbacks")
    print("="*60)
    
    from langchain.callbacks import StdOutCallbackHandler
    
    llm = ChatOpenAI()
    chain = (
        ChatPromptTemplate.from_template("ç”¨ä¸€å¥è¯è§£é‡Š{topic}")
        | llm
        | StrOutputParser()
    )
    
    print("\nä½¿ç”¨StdOutCallbackHandlerï¼š")
    result = chain.invoke(
        {"topic": "åŒºå—é“¾"},
        config={"callbacks": [StdOutCallbackHandler()]}
    )
    
    print(f"\nç»“æœï¼š{result}")


def demo_2_custom_callback():
    """ç¤ºä¾‹2ï¼šè‡ªå®šä¹‰Callback"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2ï¼šè‡ªå®šä¹‰Callback")
    print("="*60)
    
    class SimpleCallback(BaseCallbackHandler):
        """ç®€å•çš„è‡ªå®šä¹‰Callback"""
        
        def on_chain_start(self, serialized, inputs, **kwargs):
            print(f"â–¶ï¸  Chainå¼€å§‹")
            print(f"   è¾“å…¥: {inputs}")
        
        def on_chain_end(self, outputs, **kwargs):
            print(f"âœ… Chainå®Œæˆ")
            print(f"   è¾“å‡ºç±»å‹: {type(outputs)}")
        
        def on_llm_start(self, serialized, prompts, **kwargs):
            print(f"ğŸ”µ LLMè°ƒç”¨å¼€å§‹")
        
        def on_llm_end(self, response, **kwargs):
            print(f"ğŸŸ¢ LLMè°ƒç”¨å®Œæˆ")
    
    llm = ChatOpenAI()
    chain = (
        ChatPromptTemplate.from_template("è§£é‡Š{topic}")
        | llm
        | StrOutputParser()
    )
    
    callback = SimpleCallback()
    result = chain.invoke(
        {"topic": "é‡å­è®¡ç®—"},
        config={"callbacks": [callback]}
    )
    
    print(f"\næœ€ç»ˆç»“æœï¼š{result[:100]}...")


def demo_3_performance_monitoring():
    """ç¤ºä¾‹3ï¼šæ€§èƒ½ç›‘æ§"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3ï¼šæ€§èƒ½ç›‘æ§Callback")
    print("="*60)
    
    class PerformanceMonitor(BaseCallbackHandler):
        """æ€§èƒ½ç›‘æ§"""
        
        def __init__(self):
            self.start_time = None
            self.llm_start = None
            self.chain_time = 0
            self.llm_time = 0
        
        def on_chain_start(self, serialized, inputs, **kwargs):
            self.start_time = time.time()
            print(f"â±ï¸  Chainå¼€å§‹...")
        
        def on_chain_end(self, outputs, **kwargs):
            self.chain_time = time.time() - self.start_time
            print(f"â±ï¸  Chainå®Œæˆ - æ€»è€—æ—¶: {self.chain_time:.2f}ç§’")
        
        def on_llm_start(self, serialized, prompts, **kwargs):
            self.llm_start = time.time()
        
        def on_llm_end(self, response, **kwargs):
            self.llm_time = time.time() - self.llm_start
            print(f"â±ï¸  LLMè€—æ—¶: {self.llm_time:.2f}ç§’")
        
        def get_summary(self):
            other_time = self.chain_time - self.llm_time
            return f"""
æ€§èƒ½æ‘˜è¦ï¼š
- æ€»è€—æ—¶: {self.chain_time:.2f}ç§’
- LLMè€—æ—¶: {self.llm_time:.2f}ç§’ ({self.llm_time/self.chain_time*100:.1f}%)
- å…¶ä»–è€—æ—¶: {other_time:.2f}ç§’ ({other_time/self.chain_time*100:.1f}%)
"""
    
    monitor = PerformanceMonitor()
    
    llm = ChatOpenAI()
    chain = (
        ChatPromptTemplate.from_template("è¯¦ç»†è§£é‡Š{topic}")
        | llm
        | StrOutputParser()
    )
    
    result = chain.invoke(
        {"topic": "æ·±åº¦å­¦ä¹ "},
        config={"callbacks": [monitor]}
    )
    
    print(monitor.get_summary())


def demo_4_logging_callback():
    """ç¤ºä¾‹4ï¼šæ—¥å¿—è®°å½•"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4ï¼šæ—¥å¿—è®°å½•Callback")
    print("="*60)
    
    class DetailedLogger(BaseCallbackHandler):
        """è¯¦ç»†æ—¥å¿—è®°å½•"""
        
        def __init__(self):
            self.request_id = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.events = []
        
        def on_chain_start(self, serialized, inputs, **kwargs):
            event = {
                "timestamp": datetime.now().isoformat(),
                "type": "chain_start",
                "inputs": inputs
            }
            self.events.append(event)
            print(f"[{self.request_id}] Chainå¼€å§‹ | è¾“å…¥: {inputs}")
        
        def on_chain_end(self, outputs, **kwargs):
            event = {
                "timestamp": datetime.now().isoformat(),
                "type": "chain_end",
                "outputs": str(outputs)[:100]
            }
            self.events.append(event)
            print(f"[{self.request_id}] Chainå®Œæˆ")
        
        def on_chain_error(self, error, **kwargs):
            event = {
                "timestamp": datetime.now().isoformat(),
                "type": "chain_error",
                "error": str(error)
            }
            self.events.append(event)
            print(f"[{self.request_id}] Chainé”™è¯¯: {error}")
        
        def get_log_summary(self):
            """è·å–æ—¥å¿—æ‘˜è¦"""
            return {
                "request_id": self.request_id,
                "total_events": len(self.events),
                "events": self.events
            }
    
    logger = DetailedLogger()
    
    llm = ChatOpenAI()
    chain = (
        ChatPromptTemplate.from_template("æ€»ç»“{topic}")
        | llm
        | StrOutputParser()
    )
    
    result = chain.invoke(
        {"topic": "äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹"},
        config={"callbacks": [logger]}
    )
    
    print(f"\næ—¥å¿—è®°å½•äº† {len(logger.events)} ä¸ªäº‹ä»¶")


def demo_5_multiple_callbacks():
    """ç¤ºä¾‹5ï¼šå¤šä¸ªCallbacksç»„åˆ"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹5ï¼šå¤šä¸ªCallbacksç»„åˆä½¿ç”¨")
    print("="*60)
    
    class EventCounter(BaseCallbackHandler):
        """äº‹ä»¶è®¡æ•°å™¨"""
        def __init__(self):
            self.counts = {
                "chain_start": 0,
                "chain_end": 0,
                "llm_start": 0,
                "llm_end": 0
            }
        
        def on_chain_start(self, *args, **kwargs):
            self.counts["chain_start"] += 1
        
        def on_chain_end(self, *args, **kwargs):
            self.counts["chain_end"] += 1
        
        def on_llm_start(self, *args, **kwargs):
            self.counts["llm_start"] += 1
        
        def on_llm_end(self, *args, **kwargs):
            self.counts["llm_end"] += 1
    
    class ProgressPrinter(BaseCallbackHandler):
        """è¿›åº¦æ‰“å°"""
        def on_chain_start(self, *args, **kwargs):
            print("ğŸ”µ å¼€å§‹å¤„ç†...")
        
        def on_llm_start(self, *args, **kwargs):
            print("   ğŸ¤– è°ƒç”¨AIä¸­...")
        
        def on_llm_end(self, *args, **kwargs):
            print("   âœ… AIå›å¤å®Œæˆ")
        
        def on_chain_end(self, *args, **kwargs):
            print("ğŸŸ¢ å…¨éƒ¨å®Œæˆï¼")
    
    # ç»„åˆä½¿ç”¨
    counter = EventCounter()
    progress = ProgressPrinter()
    
    llm = ChatOpenAI()
    chain = (
        ChatPromptTemplate.from_template("ä»‹ç»{topic}")
        | llm
        | StrOutputParser()
    )
    
    result = chain.invoke(
        {"topic": "æœºå™¨å­¦ä¹ "},
        config={"callbacks": [counter, progress]}
    )
    
    print(f"\näº‹ä»¶ç»Ÿè®¡ï¼š{counter.counts}")


def demo_6_production_monitoring():
    """ç¤ºä¾‹6ï¼šç”Ÿäº§çº§ç›‘æ§"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹6ï¼šç”Ÿäº§çº§ç›‘æ§ç³»ç»Ÿ")
    print("="*60)
    
    class ProductionMonitor(BaseCallbackHandler):
        """ç”Ÿäº§çº§ç›‘æ§"""
        
        def __init__(self):
            self.metrics = {
                "request_count": 0,
                "success_count": 0,
                "error_count": 0,
                "total_time": 0,
                "avg_time": 0
            }
            self.current_start = None
        
        def on_chain_start(self, serialized, inputs, **kwargs):
            self.metrics["request_count"] += 1
            self.current_start = time.time()
        
        def on_chain_end(self, outputs, **kwargs):
            self.metrics["success_count"] += 1
            elapsed = time.time() - self.current_start
            self.metrics["total_time"] += elapsed
            self.metrics["avg_time"] = (
                self.metrics["total_time"] / 
                self.metrics["request_count"]
            )
        
        def on_chain_error(self, error, **kwargs):
            self.metrics["error_count"] += 1
            print(f"âŒ é”™è¯¯: {error}")
        
        def get_dashboard(self):
            """ç”Ÿæˆç›‘æ§é¢æ¿"""
            success_rate = (
                self.metrics["success_count"] / 
                self.metrics["request_count"] * 100
                if self.metrics["request_count"] > 0 else 0
            )
            
            return f"""
ğŸ“Š ç›‘æ§é¢æ¿
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¯·æ±‚æ€»æ•°ï¼š{self.metrics["request_count"]}
æˆåŠŸï¼š{self.metrics["success_count"]}
å¤±è´¥ï¼š{self.metrics["error_count"]}
æˆåŠŸç‡ï¼š{success_rate:.1f}%
å¹³å‡è€—æ—¶ï¼š{self.metrics["avg_time"]:.2f}ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
    
    monitor = ProductionMonitor()
    
    llm = ChatOpenAI()
    chain = (
        ChatPromptTemplate.from_template("å›ç­”{question}")
        | llm
        | StrOutputParser()
    )
    
    # æ¨¡æ‹Ÿå¤šä¸ªè¯·æ±‚
    questions = [
        "ä»€ä¹ˆæ˜¯AIï¼Ÿ",
        "ä»€ä¹ˆæ˜¯MLï¼Ÿ",
        "ä»€ä¹ˆæ˜¯DLï¼Ÿ"
    ]
    
    for q in questions:
        result = chain.invoke(
            {"question": q},
            config={"callbacks": [monitor]}
        )
        print(f"Q: {q}")
        print(f"A: {result[:50]}...\n")
    
    print(monitor.get_dashboard())


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Callbackç³»ç»Ÿå®Œæ•´æ¼”ç¤º")
    print("="*60)
    
    demo_1_builtin_callbacks()
    demo_2_custom_callback()
    demo_3_performance_monitoring()
    demo_4_logging_callback()
    demo_5_multiple_callbacks()
    demo_6_production_monitoring()
    
    print("\n" + "="*60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ æ ¸å¿ƒè¦ç‚¹ï¼š")
    print("1. Callbackåœ¨Chainæ‰§è¡Œæ—¶è§¦å‘")
    print("2. å¯ä»¥ç›‘æ§æ€§èƒ½ã€è®°å½•æ—¥å¿—ã€è¿½è¸ªæˆæœ¬")
    print("3. å¤šä¸ªCallbackå¯ä»¥ç»„åˆä½¿ç”¨")
    print("4. ç”Ÿäº§ç¯å¢ƒå¿…å¤‡ç›‘æ§å·¥å…·")
    print("="*60)


if __name__ == "__main__":
    main()
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### Callbackä½¿ç”¨å»ºè®®

```
å¼€å‘ç¯å¢ƒï¼š
âœ… StdOutCallbackHandlerï¼ˆè°ƒè¯•ï¼‰
âœ… PerformanceMonitorï¼ˆæ€§èƒ½åˆ†æï¼‰

æµ‹è¯•ç¯å¢ƒï¼š
âœ… LoggingCallbackï¼ˆè¯¦ç»†æ—¥å¿—ï¼‰
âœ… CostTrackingCallbackï¼ˆæˆæœ¬æ§åˆ¶ï¼‰

ç”Ÿäº§ç¯å¢ƒï¼š
âœ… é›†æˆAPMï¼ˆSentryã€DataDogï¼‰
âœ… ç›‘æ§é¢æ¿ï¼ˆGrafanaï¼‰
âœ… å‘Šè­¦ç³»ç»Ÿï¼ˆPagerDutyï¼‰
```

### æ€§èƒ½è€ƒè™‘

```python
# âœ… å¥½çš„åšæ³•ï¼šå¼‚æ­¥æ—¥å¿—
class AsyncLogger(BaseCallbackHandler):
    def on_chain_end(self, outputs, **kwargs):
        # å¼‚æ­¥å†™å…¥ï¼Œä¸é˜»å¡ä¸»æµç¨‹
        asyncio.create_task(self.log_async(outputs))

# âŒ ä¸å¥½çš„åšæ³•ï¼šåŒæ­¥é˜»å¡
class BadLogger(BaseCallbackHandler):
    def on_chain_end(self, outputs, **kwargs):
        # åŒæ­¥å†™å…¥ï¼Œå¯èƒ½å¾ˆæ…¢
        with open("log.txt", "a") as f:
            f.write(str(outputs))  # é˜»å¡ï¼
```

---

## âœ… è¯¾åæ£€éªŒ

å®Œæˆæœ¬è¯¾åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] ç†è§£Callbackçš„è§¦å‘æœºåˆ¶
- [ ] ä½¿ç”¨å†…ç½®Callbacks
- [ ] è‡ªå®šä¹‰Callbackç»„ä»¶
- [ ] å®ç°æ€§èƒ½ç›‘æ§
- [ ] æ­å»ºç”Ÿäº§çº§ç›‘æ§ç³»ç»Ÿ

---

## ğŸ“ ä¸‹ä¸€è¯¾é¢„å‘Š

**ç¬¬34è¯¾ï¼šChainè°ƒè¯•æŠ€å·§ä¸é—®é¢˜æ’æŸ¥**

ä¸‹ä¸€è¯¾æˆ‘ä»¬å°†å­¦ä¹ ï¼š
- Chainè°ƒè¯•çš„å¸¸è§é—®é¢˜
- ä½¿ç”¨LangSmithè°ƒè¯•
- é”™è¯¯è¿½è¸ªå’Œå®šä½
- æ€§èƒ½ç“¶é¢ˆåˆ†æ
- è°ƒè¯•å·¥å…·é›†

**è®©è°ƒè¯•å˜å¾—ç®€å•é«˜æ•ˆï¼**

---

**ğŸ‰ æ­å–œä½ å®Œæˆç¬¬33è¯¾ï¼**

ä½ çš„Chainæ‰§è¡Œç°åœ¨å®Œå…¨é€æ˜å¯æ§äº†ï¼

**è¿›åº¦ï¼š33/165è¯¾ï¼ˆ20.0%å®Œæˆï¼‰** ğŸŠ

**é‡Œç¨‹ç¢‘ï¼šå®Œæˆ20%è¿›åº¦ï¼**
