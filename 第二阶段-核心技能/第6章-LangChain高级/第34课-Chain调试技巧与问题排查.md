![è°ƒè¯•ä¸é—®é¢˜æ’æŸ¥](./images/debugging.svg)
*å›¾ï¼šè°ƒè¯•ä¸é—®é¢˜æ’æŸ¥*

# ç¬¬34è¯¾ï¼šChainè°ƒè¯•æŠ€å·§ä¸é—®é¢˜æ’æŸ¥ - å¿«é€Ÿå®šä½å’Œè§£å†³é—®é¢˜

> ğŸ“š **è¯¾ç¨‹ä¿¡æ¯**
> - æ‰€å±æ¨¡å—ï¼šç¬¬äºŒæ¨¡å— - APIä¸LangChainå¼€å‘  
> - ç« èŠ‚ï¼šç¬¬6ç«  - Chainé«˜çº§åº”ç”¨ï¼ˆç¬¬5/7è¯¾ï¼‰
> - å­¦ä¹ ç›®æ ‡ï¼šæŒæ¡Chainè°ƒè¯•æŠ€å·§ï¼Œå¿«é€Ÿå®šä½å’Œè§£å†³å„ç§é—®é¢˜
> - é¢„è®¡æ—¶é—´ï¼š80-90åˆ†é’Ÿ
> - å‰ç½®çŸ¥è¯†ï¼šç¬¬23-33è¯¾

---

## ğŸ“¢ è¯¾ç¨‹å¯¼å…¥

### å‰è¨€

ä½ çš„LangChainåº”ç”¨è¿è¡Œæ—¶çªç„¶å´©æºƒäº†ï¼Œé”™è¯¯ä¿¡æ¯æ˜¯ä¸€å¤§å †å †æ ˆè¿½è¸ªï¼Œçœ‹ä¸æ‡‚ï¼æˆ–è€…æ›´ç³Ÿç³•çš„æ˜¯ï¼šæ²¡æœ‰æŠ¥é”™ï¼Œä½†è¾“å‡ºå°±æ˜¯ä¸å¯¹ï¼Œä½ å®Œå…¨ä¸çŸ¥é“å“ªé‡Œå‡ºé—®é¢˜äº†ï¼

è¿™ç§æƒ…å†µå¤ªå¸¸è§äº†ï¼å¤æ‚çš„Chainå°±åƒé»‘ç›’ï¼Œå‡ºäº†é—®é¢˜æ ¹æœ¬ä¸çŸ¥é“ä»å“ªä¸‹æ‰‹ã€‚ä½†å¦‚æœä½ æŒæ¡äº†ä¸“ä¸šçš„è°ƒè¯•æŠ€å·§ï¼Œ**5åˆ†é’Ÿå°±èƒ½å®šä½é—®é¢˜ï¼Œ10åˆ†é’Ÿå°±èƒ½ä¿®å¤ï¼**

ä»Šå¤©è¿™è¯¾ï¼Œæˆ‘è¦æ•™ä½ æ‰€æœ‰LangChainè°ƒè¯•çš„ç§˜å¯†æ­¦å™¨å’Œæœ€ä½³å®è·µï¼è®©ä½ ä»"è°ƒè¯•å™©æ¢¦"å˜æˆ"è°ƒè¯•é«˜æ‰‹"ï¼

---

### æ ¸å¿ƒä»·å€¼ç‚¹

**ç¬¬ä¸€ï¼Œè°ƒè¯•èƒ½åŠ›ç›´æ¥å†³å®šå¼€å‘æ•ˆç‡ã€‚**

çœ‹çœ‹ä¸¤ä¸ªå¼€å‘è€…çš„å¯¹æ¯”ï¼š
- **æ–°æ‰‹**ï¼šå‡ºbugå°±æ‡µäº†ï¼Œåˆ°å¤„åŠ printï¼Œæ”¹äº†åˆæ”¹ï¼Œä¸€ä¸ªbugè°ƒ3å°æ—¶
- **é«˜æ‰‹**ï¼šçœ‹é”™è¯¯ä¿¡æ¯ç«‹å³å®šä½ï¼Œç”¨å·¥å…·å¿«é€ŸéªŒè¯ï¼Œ10åˆ†é’Ÿæå®š

å·®è·å°±åœ¨è°ƒè¯•èƒ½åŠ›ï¼æŒæ¡è°ƒè¯•æŠ€å·§ï¼Œå¼€å‘æ•ˆç‡èƒ½æå‡5-10å€ï¼

**ç¬¬äºŒï¼ŒLangChainçš„è°ƒè¯•ä¸åŒäºæ™®é€šä»£ç ã€‚**

ä¼ ç»Ÿä»£ç è°ƒè¯•ï¼š
- åŠ æ–­ç‚¹ï¼Œå•æ­¥æ‰§è¡Œ
- çœ‹å˜é‡å€¼
- è¿½è¸ªå‡½æ•°è°ƒç”¨

LangChainè°ƒè¯•ï¼š
- Chainæ˜¯å£°æ˜å¼çš„ï¼Œä¸èƒ½æ‰“æ–­ç‚¹
- ä¸­é—´ç»“æœæ˜¯å¼‚æ­¥çš„
- LLMè¾“å‡ºä¸ç¡®å®š
- å¤šä¸ªç»„ä»¶ç»„åˆï¼Œå®šä½å›°éš¾

éœ€è¦å…¨æ–°çš„è°ƒè¯•æ€è·¯å’Œå·¥å…·ï¼

**ç¬¬ä¸‰ï¼Œå¸¸è§é—®é¢˜éƒ½æœ‰å›ºå®šçš„æ’æŸ¥å¥—è·¯ã€‚**

LangChainå¼€å‘ä¸­90%çš„é—®é¢˜éƒ½æ˜¯ï¼š
- å˜é‡åä¸åŒ¹é…
- è¾“å…¥æ ¼å¼é”™è¯¯
- Promptè®¾è®¡ä¸å½“
- Memoryé…ç½®é—®é¢˜
- æ¨¡å‹é€‰æ‹©ä¸å¯¹

æ¯ç§é—®é¢˜éƒ½æœ‰å›ºå®šçš„æ’æŸ¥æ–¹æ³•ï¼å­¦ä¼šè¿™äº›å¥—è·¯ï¼Œé‡åˆ°é—®é¢˜ç«‹å³çŸ¥é“æ€ä¹ˆæŸ¥ï¼

**ç¬¬å››ï¼Œè¿™æ˜¯ä»èƒ½å†™ä»£ç åˆ°èƒ½è§£å†³é—®é¢˜çš„è·¨è¶Šã€‚**

åˆçº§å¼€å‘ï¼šèƒ½æŒ‰æ•™ç¨‹å†™ä»£ç 
ä¸­çº§å¼€å‘ï¼šé‡åˆ°é—®é¢˜èƒ½è‡ªå·±è§£å†³
é«˜çº§å¼€å‘ï¼šèƒ½é¢„é˜²é—®é¢˜å‘ç”Ÿ

å­¦ä¼šè°ƒè¯•ï¼Œä½ å°±æ˜¯ä¸­çº§å¼€å‘è€…äº†ï¼è¿™æ˜¯æ‰¾å·¥ä½œçš„æ ¸å¿ƒç«äº‰åŠ›ï¼

---

### è¡ŒåŠ¨å·å¬

ä»Šå¤©è¿™ä¸€è¯¾ä¼šæ•™ä½ ï¼š
- LangChainå¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ
- ç³»ç»ŸåŒ–çš„è°ƒè¯•æµç¨‹
- å¼ºå¤§çš„è°ƒè¯•å·¥å…·
- æ€§èƒ½é—®é¢˜æ’æŸ¥
- é¢„é˜²æ€§è°ƒè¯•ç­–ç•¥

**å­¦å®Œè¿™è¯¾ï¼Œè°ƒè¯•å¯¹ä½ æ¥è¯´å°±æ˜¯å°èœä¸€ç¢Ÿï¼**

---

## ğŸ“– çŸ¥è¯†è®²è§£

### 1. å¸¸è§é”™è¯¯ç±»å‹

#
![Monitoring](./images/monitoring.svg)
*å›¾ï¼šMonitoring*

### 1.1 å˜é‡åä¸åŒ¹é…

```python
# âŒ é”™è¯¯ç¤ºä¾‹
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template(
    "è§£é‡Š{topic}"  # å˜é‡åæ˜¯topic
)

chain = LLMChain(llm=ChatOpenAI(), prompt=prompt)

# é”™è¯¯ï¼ä¼ å…¥çš„æ˜¯subjectï¼Œä¸æ˜¯topic
result = chain.invoke({"subject": "AI"})
# KeyError: 'topic'
```

**è§£å†³æ–¹æ³•ï¼š**
```python
# æ–¹æ³•1ï¼šæ£€æŸ¥å˜é‡å
print(prompt.input_variables)  # ['topic']

# æ–¹æ³•2ï¼šä½¿ç”¨æ­£ç¡®çš„å˜é‡å
result = chain.invoke({"topic": "AI"})

# æ–¹æ³•3ï¼šä¿®æ”¹Promptæ¨¡æ¿
prompt = ChatPromptTemplate.from_template("è§£é‡Š{subject}")
```

---

#### 1.2 è¾“å…¥æ ¼å¼é”™è¯¯

```python
# âŒ é”™è¯¯ç¤ºä¾‹
from langchain.prompts import ChatPromptTemplate

# æœŸæœ›dictè¾“å…¥
prompt = ChatPromptTemplate.from_template("åˆ†æ{data}")

# é”™è¯¯ï¼šä¼ å…¥äº†å­—ç¬¦ä¸²
result = prompt.invoke("some data")
# TypeError: expected dict, got str
```

**è§£å†³æ–¹æ³•ï¼š**
```python
# âœ… æ­£ç¡®åšæ³•
result = prompt.invoke({"data": "some data"})

# æˆ–è€…ä½¿ç”¨formatæ–¹æ³•
result = prompt.format(data="some data")
```

---

#### 1.3 Chainç»„åˆé”™è¯¯

```python
# âŒ é”™è¯¯ç¤ºä¾‹
from langchain.schema.output_parser import StrOutputParser

# ç¬¬ä¸€ä¸ªChainè¿”å›dictï¼Œä½†ç¬¬äºŒä¸ªChainæœŸæœ›å­—ç¬¦ä¸²
chain1 = prompt1 | llm  # è¿”å›AIMessage
chain2 = ChatPromptTemplate.from_template("å¤„ç†{text}") | llm

# é”™è¯¯ï¼šchain1çš„è¾“å‡ºä¸åŒ¹é…chain2çš„è¾“å…¥
full_chain = chain1 | chain2
# è¿è¡Œæ—¶ä¼šæŠ¥é”™
```

**è§£å†³æ–¹æ³•ï¼š**
```python
# âœ… æ·»åŠ ä¸­é—´è½¬æ¢
chain1 = prompt1 | llm | StrOutputParser()  # è½¬æˆå­—ç¬¦ä¸²
chain2 = ChatPromptTemplate.from_template("å¤„ç†{text}") | llm

# æˆ–è€…ä½¿ç”¨æ­£ç¡®çš„æ•°æ®æ˜ å°„
full_chain = chain1 | {"text": RunnablePassthrough()} | chain2
```

---

#### 1.4 Memoryé…ç½®é”™è¯¯

```python
# âŒ é”™è¯¯ç¤ºä¾‹
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# é”™è¯¯ï¼šmemory_keyå’Œpromptä¸­çš„å˜é‡ä¸åŒ¹é…
memory = ConversationBufferMemory(memory_key="history")
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯åŠ©æ‰‹"),
    MessagesPlaceholder(variable_name="chat_history"),  # ä¸åŒ¹é…ï¼
    ("human", "{input}")
])

chain = ConversationChain(memory=memory, prompt=prompt)
# è¿è¡Œæ—¶æ‰¾ä¸åˆ°å˜é‡
```

**è§£å†³æ–¹æ³•ï¼š**
```python
# âœ… ç»Ÿä¸€å˜é‡å
memory = ConversationBufferMemory(
    memory_key="chat_history",  # å’ŒPromptä¸­ä¸€è‡´
    return_messages=True
)
```

---

### 2. ç³»ç»ŸåŒ–è°ƒè¯•æµç¨‹

#### 2.1 äº”æ­¥è°ƒè¯•æ³•

```
æ­¥éª¤1ï¼šå¤ç°é—®é¢˜
- æ‰¾åˆ°æœ€å°å¯å¤ç°æ¡ˆä¾‹
- è®°å½•è¾“å…¥å’Œé¢„æœŸè¾“å‡º

æ­¥éª¤2ï¼šå®šä½ä½ç½®
- ä½¿ç”¨verbose=True
- æ·»åŠ Callback
- åˆ†æ®µæµ‹è¯•

æ­¥éª¤3ï¼šåˆ†æåŸå› 
- æ£€æŸ¥è¾“å…¥è¾“å‡º
- éªŒè¯å‡è®¾
- æŸ¥çœ‹æ—¥å¿—

æ­¥éª¤4ï¼šä¿®å¤é—®é¢˜
- å®æ–½è§£å†³æ–¹æ¡ˆ
- éªŒè¯ä¿®å¤

æ­¥éª¤5ï¼šé¢„é˜²å¤å‘
- æ·»åŠ æµ‹è¯•
- æ›´æ–°æ–‡æ¡£
- æ”¹è¿›è®¾è®¡
```

---

#### 2.2 åˆ†æ®µæµ‹è¯•æ³•

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

# å¤æ‚çš„Chain
prompt = ChatPromptTemplate.from_template("åˆ†æ{topic}")
llm = ChatOpenAI()
parser = StrOutputParser()

full_chain = prompt | llm | parser

# é—®é¢˜ï¼šè¾“å‡ºä¸å¯¹

# âœ… åˆ†æ®µæµ‹è¯•
print("=== æµ‹è¯•æ­¥éª¤1ï¼šPrompt ===")
step1 = prompt.invoke({"topic": "AI"})
print(step1)

print("\n=== æµ‹è¯•æ­¥éª¤2ï¼šLLM ===")
step2 = llm.invoke(step1)
print(step2)

print("\n=== æµ‹è¯•æ­¥éª¤3ï¼šParser ===")
step3 = parser.invoke(step2)
print(step3)

# æ‰¾å‡ºå“ªä¸€æ­¥å‡ºé—®é¢˜
```

---

#### 2.3 ä½¿ç”¨verboseæ¨¡å¼

```python
from langchain.chains import LLMChain

# å¯ç”¨è¯¦ç»†æ—¥å¿—
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True  # å…³é”®ï¼
)

result = chain.invoke({"topic": "AI"})

# ä¼šæ‰“å°ï¼š
# - Promptæ¨¡æ¿
# - æ ¼å¼åŒ–åçš„Prompt
# - LLMè¾“å‡º
# - æœ€ç»ˆç»“æœ
```

---

### 3. è°ƒè¯•å·¥å…·

#### 3.1 ä½¿ç”¨LangSmithï¼ˆæ¨èï¼‰

```python
import os

# é…ç½®LangSmith
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "your-api-key"
os.environ["LANGCHAIN_PROJECT"] = "my-project"

# æ­£å¸¸è¿è¡ŒChainï¼Œè‡ªåŠ¨è¿½è¸ª
chain = prompt | llm | parser
result = chain.invoke({"topic": "AI"})

# LangSmithä¼šè®°å½•ï¼š
# - å®Œæ•´çš„æ‰§è¡Œæµç¨‹
# - æ¯æ­¥çš„è¾“å…¥è¾“å‡º
# - è€—æ—¶ç»Ÿè®¡
# - é”™è¯¯å †æ ˆ
```

**LangSmithçš„ä¼˜åŠ¿ï¼š**
```
âœ… å¯è§†åŒ–æ‰§è¡Œæµç¨‹
âœ… æ—¶é—´çº¿åˆ†æ
âœ… è¾“å…¥è¾“å‡ºè¿½è¸ª
âœ… é”™è¯¯å®šä½
âœ… æ€§èƒ½åˆ†æ
âœ… å›¢é˜Ÿåä½œ
```

---

#### 3.2 è‡ªå®šä¹‰è°ƒè¯•Callback

```python
from langchain.callbacks.base import BaseCallbackHandler

class DebugCallback(BaseCallbackHandler):
    """è°ƒè¯•ä¸“ç”¨Callback"""
    
    def __init__(self):
        self.step = 0
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        self.step += 1
        print(f"\n{'='*60}")
        print(f"æ­¥éª¤ {self.step}: Chainå¼€å§‹")
        print(f"{'='*60}")
        print(f"è¾“å…¥: {inputs}")
    
    def on_chain_end(self, outputs, **kwargs):
        print(f"\nè¾“å‡º: {outputs}")
        print(f"{'='*60}\n")
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        print(f"\nğŸ¤– LLMè°ƒç”¨")
        print(f"Prompt: {prompts[0][:200]}...")
    
    def on_llm_end(self, response, **kwargs):
        if hasattr(response, 'generations'):
            text = response.generations[0][0].text
            print(f"å›å¤: {text[:200]}...")
    
    def on_llm_error(self, error, **kwargs):
        print(f"\nâŒ LLMé”™è¯¯: {error}")


# ä½¿ç”¨
debug_callback = DebugCallback()
result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": [debug_callback]}
)
```

---

#### 3.3 æ‰“å°ä¸­é—´ç»“æœ

```python
from langchain.schema.runnable import RunnableLambda

def print_step(x):
    """æ‰“å°ä¸­é—´æ­¥éª¤"""
    print(f"\n[ä¸­é—´ç»“æœ] {type(x).__name__}: {str(x)[:100]}...")
    return x

# åœ¨Chainä¸­æ’å…¥æ‰“å°
chain = (
    prompt 
    | RunnableLambda(print_step)  # æ‰“å°Promptè¾“å‡º
    | llm 
    | RunnableLambda(print_step)  # æ‰“å°LLMè¾“å‡º
    | parser
    | RunnableLambda(print_step)  # æ‰“å°Parserè¾“å‡º
)

result = chain.invoke({"topic": "AI"})
```

---

### 4. å¸¸è§é—®é¢˜æ’æŸ¥

#### 4.1 "KeyError: 'xxx'"

```python
# åŸå› ï¼šå˜é‡åä¸åŒ¹é…

# æ’æŸ¥æ­¥éª¤ï¼š
# 1. æ£€æŸ¥Promptçš„input_variables
print(prompt.input_variables)  # ['topic', 'style']

# 2. æ£€æŸ¥ä¼ å…¥çš„å‚æ•°
inputs = {"topic": "AI"}  # ç¼ºå°‘'style'

# 3. è§£å†³æ–¹æ³•
# æ–¹æ³•Aï¼šæ·»åŠ ç¼ºå°‘çš„å˜é‡
inputs = {"topic": "AI", "style": "ç®€æ´"}

# æ–¹æ³•Bï¼šä½¿ç”¨partial
prompt = prompt.partial(style="ç®€æ´")
inputs = {"topic": "AI"}
```

---

#### 4.2 "è¾“å‡ºæ ¼å¼ä¸å¯¹"

```python
# åŸå› ï¼šParseré…ç½®é”™è¯¯æˆ–è¾“å‡ºä¸ç¬¦åˆæ ¼å¼

# æ’æŸ¥æ­¥éª¤ï¼š
# 1. æ£€æŸ¥Parserçš„æ ¼å¼è¯´æ˜
from langchain.output_parsers import PydanticOutputParser

parser = PydanticOutputParser(pydantic_object=MyModel)
print(parser.get_format_instructions())

# 2. æ£€æŸ¥LLMå®é™…è¾“å‡º
from langchain.schema.output_parser import StrOutputParser

temp_chain = prompt | llm | StrOutputParser()
raw_output = temp_chain.invoke({"topic": "AI"})
print(f"åŸå§‹è¾“å‡º:\n{raw_output}")

# 3. ä¿®æ”¹Promptï¼ŒåŠ å…¥æ ¼å¼è¯´æ˜
better_prompt = ChatPromptTemplate.from_template(
    """{format_instructions}

è¯·åˆ†æï¼š{topic}"""
).partial(format_instructions=parser.get_format_instructions())
```

---

#### 4.3 "å“åº”å¾ˆæ…¢"

```python
# æ’æŸ¥æ­¥éª¤ï¼š
from langchain.callbacks.base import BaseCallbackHandler
import time

class TimingCallback(BaseCallbackHandler):
    """è®¡æ—¶Callback"""
    
    def __init__(self):
        self.times = {}
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        run_id = kwargs.get("run_id")
        self.times[run_id] = time.time()
    
    def on_llm_end(self, response, **kwargs):
        run_id = kwargs.get("run_id")
        if run_id in self.times:
            elapsed = time.time() - self.times[run_id]
            print(f"â±ï¸  LLMè€—æ—¶: {elapsed:.2f}ç§’")
            
            # æ€§èƒ½ç“¶é¢ˆåˆ¤æ–­
            if elapsed > 5:
                print("âš ï¸  LLMå“åº”æ…¢ï¼Œå¯èƒ½åŸå› ï¼š")
                print("  - ç½‘ç»œé—®é¢˜")
                print("  - æ¨¡å‹é€‰æ‹©ï¼ˆGPT-4æ›´æ…¢ï¼‰")
                print("  - Promptå¤ªé•¿")
                print("  - max_tokensè®¾ç½®è¿‡å¤§")

# ä½¿ç”¨
timer = TimingCallback()
result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": [timer]}
)

# ä¼˜åŒ–æ–¹æ¡ˆï¼š
# 1. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆGPT-4 â†’ GPT-3.5ï¼‰
# 2. å‡å°‘Prompté•¿åº¦
# 3. é™ä½max_tokens
# 4. ä½¿ç”¨æµå¼è¾“å‡º
# 5. æ·»åŠ ç¼“å­˜
```

---

#### 4.4 "Memoryä¸å·¥ä½œ"

```python
# æ’æŸ¥æ­¥éª¤ï¼š
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()

# 1. æ£€æŸ¥memoryæ˜¯å¦æ­£ç¡®ä¿å­˜
memory.save_context({"input": "ä½ å¥½"}, {"output": "ä½ å¥½ï¼"})
print(memory.load_memory_variables({}))

# 2. æ£€æŸ¥å˜é‡å
print(f"Memory key: {memory.memory_key}")
# ç¡®ä¿å’ŒPromptä¸­çš„MessagesPlaceholderå˜é‡åä¸€è‡´

# 3. æ£€æŸ¥return_messages
# å¦‚æœä½¿ç”¨ChatPromptTemplateï¼Œéœ€è¦return_messages=True
memory = ConversationBufferMemory(return_messages=True)

# 4. æ£€æŸ¥Chainé…ç½®
from langchain.chains import ConversationChain

conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True  # çœ‹çœ‹memoryæ˜¯å¦è¢«åŠ è½½
)
```

---

## ğŸ’» Demoæ¡ˆä¾‹ï¼šè°ƒè¯•å®æˆ˜

åˆ›å»º`debugging_demo.py`ï¼š

```python
"""
Chainè°ƒè¯•å®Œæ•´æ¼”ç¤º
å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
"""

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.callbacks.base import BaseCallbackHandler
import time


def demo_1_variable_mismatch():
    """ç¤ºä¾‹1ï¼šå˜é‡åä¸åŒ¹é…é—®é¢˜"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1ï¼šå˜é‡åä¸åŒ¹é… - é—®é¢˜æ¼”ç¤ºä¸è§£å†³")
    print("="*60)
    
    # é—®é¢˜ä»£ç 
    prompt = ChatPromptTemplate.from_template(
        "è§£é‡Š{topic}ï¼Œç”¨{style}çš„æ–¹å¼"
    )
    
    print("Promptéœ€è¦çš„å˜é‡ï¼š", prompt.input_variables)
    
    # âŒ é”™è¯¯ï¼šç¼ºå°‘styleå˜é‡
    try:
        result = prompt.invoke({"topic": "AI"})
        print("ç»“æœï¼š", result)
    except KeyError as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        print("   åŸå› ï¼šç¼ºå°‘requiredå˜é‡'style'")
    
    # âœ… è§£å†³æ–¹æ¡ˆ1ï¼šæä¾›æ‰€æœ‰å˜é‡
    print("\nè§£å†³æ–¹æ¡ˆ1ï¼šæä¾›å®Œæ•´å˜é‡")
    result = prompt.invoke({"topic": "AI", "style": "ç®€æ´"})
    print(f"âœ“ æˆåŠŸ")
    
    # âœ… è§£å†³æ–¹æ¡ˆ2ï¼šä½¿ç”¨partial
    print("\nè§£å†³æ–¹æ¡ˆ2ï¼šä½¿ç”¨partialå›ºå®šå˜é‡")
    prompt_partial = prompt.partial(style="ç®€æ´")
    result = prompt_partial.invoke({"topic": "AI"})
    print(f"âœ“ æˆåŠŸ")


def demo_2_chain_debugging():
    """ç¤ºä¾‹2ï¼šChainé€æ­¥è°ƒè¯•"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2ï¼šChainé€æ­¥è°ƒè¯•")
    print("="*60)
    
    llm = ChatOpenAI()
    
    # å¤æ‚Chain
    prompt = ChatPromptTemplate.from_template("ç”¨50å­—ä»‹ç»{topic}")
    chain = prompt | llm | StrOutputParser()
    
    print("å®Œæ•´Chainæµ‹è¯•ï¼š")
    topic = "æœºå™¨å­¦ä¹ "
    
    # åˆ†æ­¥è°ƒè¯•
    print("\næ­¥éª¤1ï¼šæµ‹è¯•Prompt")
    step1 = prompt.invoke({"topic": topic})
    print(f"  Promptè¾“å‡ºç±»å‹ï¼š{type(step1).__name__}")
    print(f"  å†…å®¹ï¼š{step1.messages[0].content}")
    
    print("\næ­¥éª¤2ï¼šæµ‹è¯•LLM")
    step2 = llm.invoke(step1)
    print(f"  LLMè¾“å‡ºç±»å‹ï¼š{type(step2).__name__}")
    print(f"  å†…å®¹ï¼š{step2.content[:100]}...")
    
    print("\næ­¥éª¤3ï¼šæµ‹è¯•Parser")
    step3 = StrOutputParser().invoke(step2)
    print(f"  Parserè¾“å‡ºç±»å‹ï¼š{type(step3).__name__}")
    print(f"  å†…å®¹ï¼š{step3[:100]}...")
    
    print("\nå®Œæ•´Chainï¼š")
    final = chain.invoke({"topic": topic})
    print(f"  æœ€ç»ˆç»“æœï¼š{final}")


def demo_3_performance_debugging():
    """ç¤ºä¾‹3ï¼šæ€§èƒ½é—®é¢˜æ’æŸ¥"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3ï¼šæ€§èƒ½ç“¶é¢ˆåˆ†æ")
    print("="*60)
    
    class PerformanceDebugger(BaseCallbackHandler):
        """æ€§èƒ½è°ƒè¯•å™¨"""
        
        def __init__(self):
            self.times = {}
            self.counts = {"chain": 0, "llm": 0}
        
        def on_chain_start(self, serialized, inputs, **kwargs):
            run_id = kwargs.get("run_id")
            self.times[f"chain_{run_id}"] = time.time()
            self.counts["chain"] += 1
            print(f"â–¶ï¸  Chain #{self.counts['chain']} å¼€å§‹")
        
        def on_chain_end(self, outputs, **kwargs):
            run_id = kwargs.get("run_id")
            key = f"chain_{run_id}"
            if key in self.times:
                elapsed = time.time() - self.times[key]
                print(f"âœ“ Chain #{self.counts['chain']} å®Œæˆ ({elapsed:.2f}ç§’)")
                
                if elapsed > 3:
                    print(f"   âš ï¸  è€—æ—¶è¾ƒé•¿ï¼å¯èƒ½çš„åŸå› ï¼š")
                    print(f"      - LLMå“åº”æ…¢")
                    print(f"      - ç½‘ç»œé—®é¢˜")
                    print(f"      - Promptå¤ªé•¿")
        
        def on_llm_start(self, serialized, prompts, **kwargs):
            run_id = kwargs.get("run_id")
            self.times[f"llm_{run_id}"] = time.time()
            self.counts["llm"] += 1
            
            prompt_len = len(prompts[0])
            print(f"  ğŸ¤– LLMè°ƒç”¨ (Prompté•¿åº¦: {prompt_len}å­—ç¬¦)")
            
            if prompt_len > 1000:
                print(f"     âš ï¸  Promptè¿‡é•¿ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
        
        def on_llm_end(self, response, **kwargs):
            run_id = kwargs.get("run_id")
            key = f"llm_{run_id}"
            if key in self.times:
                elapsed = time.time() - self.times[key]
                print(f"  âœ“ LLMå“åº” ({elapsed:.2f}ç§’)")
    
    debugger = PerformanceDebugger()
    
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    prompt = ChatPromptTemplate.from_template("è¯¦ç»†åˆ†æ{topic}")
    chain = prompt | llm | StrOutputParser()
    
    result = chain.invoke(
        {"topic": "æ·±åº¦å­¦ä¹ çš„å‘å±•å†ç¨‹"},
        config={"callbacks": [debugger]}
    )
    
    print(f"\nç»“æœï¼š{result[:100]}...")


def demo_4_error_handling():
    """ç¤ºä¾‹4ï¼šé”™è¯¯å¤„ç†å’Œæ¢å¤"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4ï¼šé”™è¯¯å¤„ç†")
    print("="*60)
    
    class ErrorHandler(BaseCallbackHandler):
        """é”™è¯¯å¤„ç†å™¨"""
        
        def on_chain_error(self, error, **kwargs):
            print(f"âŒ Chainé”™è¯¯æ•è·")
            print(f"   é”™è¯¯ç±»å‹ï¼š{type(error).__name__}")
            print(f"   é”™è¯¯ä¿¡æ¯ï¼š{error}")
            print(f"   å»ºè®®ï¼šæ£€æŸ¥è¾“å…¥æ ¼å¼å’Œå˜é‡å")
        
        def on_llm_error(self, error, **kwargs):
            print(f"âŒ LLMé”™è¯¯æ•è·")
            print(f"   é”™è¯¯ç±»å‹ï¼š{type(error).__name__}")
            print(f"   é”™è¯¯ä¿¡æ¯ï¼š{error}")
            print(f"   å»ºè®®ï¼š")
            print(f"   - æ£€æŸ¥APIå¯†é’¥")
            print(f"   - æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print(f"   - æ£€æŸ¥æ¨¡å‹åç§°")
            print(f"   - æ£€æŸ¥tokené™åˆ¶")
    
    error_handler = ErrorHandler()
    
    # æ•…æ„åˆ¶é€ é”™è¯¯
    prompt = ChatPromptTemplate.from_template("åˆ†æ{topic}")
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    chain = prompt | llm | StrOutputParser()
    
    # é”™è¯¯1ï¼šç¼ºå°‘å˜é‡
    print("æµ‹è¯•1ï¼šå˜é‡ç¼ºå¤±")
    try:
        result = chain.invoke(
            {},  # ç©ºå­—å…¸ï¼Œç¼ºå°‘topic
            config={"callbacks": [error_handler]}
        )
    except Exception as e:
        print(f"æ•è·å¼‚å¸¸ï¼š{type(e).__name__}")
    
    # é”™è¯¯2ï¼šæ— æ•ˆæ¨¡å‹
    print("\næµ‹è¯•2ï¼šæ— æ•ˆæ¨¡å‹å")
    try:
        bad_llm = ChatOpenAI(model="invalid-model-name")
        bad_chain = prompt | bad_llm | StrOutputParser()
        result = bad_chain.invoke(
            {"topic": "AI"},
            config={"callbacks": [error_handler]}
        )
    except Exception as e:
        print(f"æ•è·å¼‚å¸¸ï¼š{type(e).__name__}")


def demo_5_debugging_checklist():
    """ç¤ºä¾‹5ï¼šè°ƒè¯•æ£€æŸ¥æ¸…å•"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹5ï¼šè°ƒè¯•æ£€æŸ¥æ¸…å•")
    print("="*60)
    
    checklist = """
ğŸ” LangChainè°ƒè¯•æ£€æŸ¥æ¸…å•

ğŸ“‹ åŸºç¡€æ£€æŸ¥ï¼š
  â–¡ APIå¯†é’¥æ˜¯å¦é…ç½®ï¼Ÿ
  â–¡ ä¾èµ–åŒ…æ˜¯å¦å®‰è£…ï¼Ÿ
  â–¡ ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼Ÿ

ğŸ”§ Promptæ£€æŸ¥ï¼š
  â–¡ input_variablesæ˜¯å¦æ­£ç¡®ï¼Ÿ
  â–¡ æ‰€æœ‰å˜é‡æ˜¯å¦éƒ½æä¾›äº†å€¼ï¼Ÿ
  â–¡ æ¨¡æ¿è¯­æ³•æ˜¯å¦æ­£ç¡®ï¼Ÿ

ğŸ”— Chainæ£€æŸ¥ï¼š
  â–¡ ç»„ä»¶ç±»å‹æ˜¯å¦åŒ¹é…ï¼Ÿ
  â–¡ è¾“å…¥è¾“å‡ºæ ¼å¼æ˜¯å¦ä¸€è‡´ï¼Ÿ
  â–¡ Parseræ˜¯å¦æ­£ç¡®é…ç½®ï¼Ÿ

ğŸ’¾ Memoryæ£€æŸ¥ï¼š
  â–¡ memory_keyæ˜¯å¦åŒ¹é…ï¼Ÿ
  â–¡ return_messagesæ˜¯å¦æ­£ç¡®ï¼Ÿ
  â–¡ æ˜¯å¦æ­£ç¡®ä¿å­˜å’ŒåŠ è½½ï¼Ÿ

âš¡ æ€§èƒ½æ£€æŸ¥ï¼š
  â–¡ æ˜¯å¦å¯ç”¨äº†ç¼“å­˜ï¼Ÿ
  â–¡ Prompté•¿åº¦æ˜¯å¦åˆç†ï¼Ÿ
  â–¡ æ¨¡å‹é€‰æ‹©æ˜¯å¦åˆé€‚ï¼Ÿ
  â–¡ æ˜¯å¦æœ‰ä¸å¿…è¦çš„é‡å¤è°ƒç”¨ï¼Ÿ

ğŸ“Š ç›‘æ§æ£€æŸ¥ï¼š
  â–¡ æ˜¯å¦å¯ç”¨verboseï¼Ÿ
  â–¡ æ˜¯å¦æ·»åŠ Callbackï¼Ÿ
  â–¡ æ˜¯å¦è®°å½•æ—¥å¿—ï¼Ÿ
  â–¡ æ˜¯å¦æœ‰é”™è¯¯å‘Šè­¦ï¼Ÿ
"""
    
    print(checklist)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Chainè°ƒè¯•å®Œæ•´æ¼”ç¤º")
    print("="*60)
    
    demo_1_variable_mismatch()
    demo_2_chain_debugging()
    demo_3_performance_debugging()
    demo_4_error_handling()
    demo_5_debugging_checklist()
    
    print("\n" + "="*60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ è°ƒè¯•æŠ€å·§æ€»ç»“ï¼š")
    print("1. ä½¿ç”¨verbose=TrueæŸ¥çœ‹æ‰§è¡Œæµç¨‹")
    print("2. åˆ†æ­¥æµ‹è¯•ï¼Œé€ä¸ªæ’æŸ¥")
    print("3. æ£€æŸ¥å˜é‡ååŒ¹é…")
    print("4. ä½¿ç”¨Callbackç›‘æ§æ€§èƒ½")
    print("5. å–„ç”¨LangSmithå¯è§†åŒ–å·¥å…·")
    print("="*60)


if __name__ == "__main__":
    main()
```

---

## ğŸ¯ è°ƒè¯•æœ€ä½³å®è·µ

### è°ƒè¯•å·¥å…·ç®±

```python
# å·¥å…·1ï¼šå¿«é€Ÿæ£€æŸ¥
def quick_check(chain):
    """å¿«é€Ÿæ£€æŸ¥Chainé…ç½®"""
    print("Chainç±»å‹ï¼š", type(chain).__name__)
    if hasattr(chain, 'input_variables'):
        print("è¾“å…¥å˜é‡ï¼š", chain.input_variables)
    if hasattr(chain, 'output_keys'):
        print("è¾“å‡ºé”®ï¼š", chain.output_keys)

# å·¥å…·2ï¼šè¾“å…¥éªŒè¯
def validate_input(chain, inputs):
    """éªŒè¯è¾“å…¥æ˜¯å¦å®Œæ•´"""
    if hasattr(chain, 'input_variables'):
        required = set(chain.input_variables)
        provided = set(inputs.keys())
        missing = required - provided
        if missing:
            print(f"âŒ ç¼ºå°‘å˜é‡ï¼š{missing}")
            return False
    return True

# å·¥å…·3ï¼šå®‰å…¨æ‰§è¡Œ
def safe_invoke(chain, inputs, **kwargs):
    """å®‰å…¨æ‰§è¡Œï¼Œæ•è·é”™è¯¯"""
    try:
        if not validate_input(chain, inputs):
            return None
        return chain.invoke(inputs, **kwargs)
    except Exception as e:
        print(f"âŒ æ‰§è¡Œé”™è¯¯ï¼š{type(e).__name__}: {e}")
        return None
```

---

## âœ… è¯¾åæ£€éªŒ

å®Œæˆæœ¬è¯¾åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] è¯†åˆ«å’Œè§£å†³å¸¸è§é”™è¯¯
- [ ] ä½¿ç”¨ç³»ç»ŸåŒ–æ–¹æ³•è°ƒè¯•
- [ ] è¿ç”¨å„ç§è°ƒè¯•å·¥å…·
- [ ] å¿«é€Ÿå®šä½æ€§èƒ½ç“¶é¢ˆ
- [ ] é¢„é˜²å¸¸è§é—®é¢˜

---

## ğŸ“ ä¸‹ä¸€è¯¾é¢„å‘Š

**ç¬¬35è¯¾ï¼šChainæ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ**

ä¸‹ä¸€è¯¾æˆ‘ä»¬å°†å­¦ä¹ ï¼š
- Chainæ€§èƒ½ä¼˜åŒ–æŠ€å·§
- ç¼“å­˜ç­–ç•¥
- å¹¶å‘å¤„ç†
- æˆæœ¬ä¼˜åŒ–
- ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

**è®©ä½ çš„Chainåˆå¿«åˆçœï¼**

---

**ğŸ‰ æ­å–œä½ å®Œæˆç¬¬34è¯¾ï¼**

ä½ ç°åœ¨æ˜¯è°ƒè¯•é«˜æ‰‹äº†ï¼

**è¿›åº¦ï¼š34/165è¯¾ï¼ˆ20.6%å®Œæˆï¼‰** ğŸš€
