![è·¯ç”±é“¾æ¶æ„è®¾è®¡](./images/router_chain.svg)
*å›¾ï¼šè·¯ç”±é“¾æ¶æ„è®¾è®¡*

# ç¬¬36è¯¾ï¼šç¬¬6ç« ç»¼åˆå®æˆ˜é¡¹ç›® - æ„å»ºæ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿ

> ğŸ“š **è¯¾ç¨‹ä¿¡æ¯**
> - æ‰€å±æ¨¡å—ï¼šç¬¬äºŒæ¨¡å— - APIä¸LangChainå¼€å‘  
> - ç« èŠ‚ï¼šç¬¬6ç«  - Chainé«˜çº§åº”ç”¨ï¼ˆç¬¬7/7è¯¾ - å®Œç»“ï¼‰
> - å­¦ä¹ ç›®æ ‡ï¼šæ•´åˆç¬¬6ç« æ‰€æœ‰çŸ¥è¯†ï¼Œæ„å»ºå®Œæ•´çš„ç”Ÿäº§çº§Chainç³»ç»Ÿ
> - é¢„è®¡æ—¶é—´ï¼š120-150åˆ†é’Ÿ
> - å‰ç½®çŸ¥è¯†ï¼šç¬¬30-35è¯¾

---

## ğŸ“¢ è¯¾ç¨‹å¯¼å…¥

### å‰è¨€

å‰é¢6èŠ‚è¯¾ï¼Œæˆ‘ä»¬å­¦äº†Chainçš„æ‰€æœ‰é«˜çº§æŠ€èƒ½ï¼šSequentialChainä¸²è”ã€RouterChainè·¯ç”±ã€Memoryå¯¹è¯ç®¡ç†ã€Callbackç›‘æ§ã€è°ƒè¯•æŠ€å·§ã€æ€§èƒ½ä¼˜åŒ–... çŸ¥è¯†ç‚¹æ˜¯å­¦äº†ä¸å°‘ï¼Œä½†æ€ä¹ˆç»„åˆèµ·æ¥ç”¨ï¼Ÿæ€ä¹ˆæ„å»ºä¸€ä¸ªçœŸå®çš„ç³»ç»Ÿï¼Ÿ

**å…‰å­¦ä¸ç»ƒå‡æŠŠå¼ï¼**ä»Šå¤©è¿™è¯¾ï¼Œæˆ‘ä»¬è¦æŠŠæ‰€æœ‰çŸ¥è¯†èä¼šè´¯é€šï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„**æ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿ**ï¼šæ¥æ”¶ç”¨æˆ·æ–‡ç« ï¼Œè‡ªåŠ¨åˆ†æã€æ€»ç»“ã€ç¿»è¯‘ã€é…å›¾ï¼Œè¿˜æœ‰å®Œæ•´çš„ç›‘æ§ã€ç¼“å­˜ã€é”™è¯¯å¤„ç†ï¼

è¿™æ˜¯ä¸€ä¸ªçœŸæ­£çš„**ç”Ÿäº§çº§é¡¹ç›®**ï¼å­¦å®Œè¿™è¯¾ï¼Œä½ å°±æœ‰äº†æ‹¿å¾—å‡ºæ‰‹çš„é¡¹ç›®ä½œå“ï¼

---

### æ ¸å¿ƒä»·å€¼ç‚¹

**ç¬¬ä¸€ï¼Œè¿™æ˜¯ä»å­¦çŸ¥è¯†åˆ°ç”¨çŸ¥è¯†çš„å…³é”®è·¨è¶Šã€‚**

å­¦äº†30-35è¯¾ï¼Œä½ æŒæ¡äº†ï¼š
- Sequentialå’ŒRouterç»„åˆ
- Memoryå¯¹è¯ç®¡ç†
- Callbackç›‘æ§
- è°ƒè¯•æŠ€å·§
- æ€§èƒ½ä¼˜åŒ–

ä½†è¿™äº›çŸ¥è¯†æ˜¯ç¢ç‰‡åŒ–çš„ï¼åªæœ‰é€šè¿‡å®Œæ•´é¡¹ç›®ï¼Œæ‰èƒ½ï¼š
- ç†è§£çŸ¥è¯†çš„è¿æ¥ç‚¹
- æŒæ¡å®é™…åº”ç”¨åœºæ™¯
- å½¢æˆç³»ç»ŸåŒ–æ€ç»´

**ç¬¬äºŒï¼Œè¿™ä¸ªé¡¹ç›®åŒ…å«ä¼ä¸šçº§çš„æ‰€æœ‰è¦ç´ ã€‚**

æˆ‘ä»¬è¦æ„å»ºçš„ç³»ç»Ÿæœ‰ï¼š
- âœ… å¤æ‚çš„Chainç»„åˆï¼ˆSequential + Router + Memoryï¼‰
- âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•
- âœ… æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦
- âœ… ç¼“å­˜ä¼˜åŒ–
- âœ… æˆæœ¬æ§åˆ¶
- âœ… æ—¥å¿—è®°å½•

è¿™å°±æ˜¯ä¼ä¸šçœŸå®ç³»ç»Ÿçš„æ ·å­ï¼

**ç¬¬ä¸‰ï¼Œè¿™æ˜¯å¯ä»¥å†™è¿›ç®€å†çš„é¡¹ç›®ã€‚**

é¢è¯•å®˜é—®ï¼š"ä½ æœ‰LangChainé¡¹ç›®ç»éªŒå—ï¼Ÿ"
- âŒ å¼±ï¼šæˆ‘å­¦è¿‡LangChainï¼Œå†™è¿‡ä¸€äº›demo
- âœ… å¼ºï¼šæˆ‘å¼€å‘è¿‡æ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿï¼Œä½¿ç”¨äº†Chainç»„åˆã€Memoryç®¡ç†ã€æ€§èƒ½ä¼˜åŒ–ç­‰æŠ€æœ¯ï¼Œå¤„ç†äº†xxxçš„QPSï¼Œæˆæœ¬é™ä½äº†xx%

æœ‰é¡¹ç›®ç»éªŒçš„äººï¼Œç«äº‰åŠ›å®Œå…¨ä¸åŒï¼

**ç¬¬å››ï¼Œè¿™æ˜¯ç¬¬6ç« çš„å®Œç¾æ”¶å®˜ã€‚**

å›é¡¾ç¬¬6ç« å­¦ä¹ è·¯å¾„ï¼š
- ç¬¬30è¯¾ï¼šSequentialChain
- ç¬¬31è¯¾ï¼šRouterChain
- ç¬¬32è¯¾ï¼šMemoryæ·±å…¥
- ç¬¬33è¯¾ï¼šCallbackç›‘æ§
- ç¬¬34è¯¾ï¼šè°ƒè¯•æŠ€å·§
- ç¬¬35è¯¾ï¼šæ€§èƒ½ä¼˜åŒ–
- **ç¬¬36è¯¾ï¼šç»¼åˆå®æˆ˜**ï¼ˆä»Šå¤©ï¼‰

7è¯¾å­¦å®Œï¼Œä½ çš„ChainæŠ€èƒ½å·²ç»è¾¾åˆ°é«˜çº§æ°´å¹³ï¼

---

### è¡ŒåŠ¨å·å¬

ä»Šå¤©è¿™ä¸€è¯¾æˆ‘ä»¬å°†ï¼š
- è®¾è®¡å®Œæ•´çš„ç³»ç»Ÿæ¶æ„
- å®ç°æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½
- é›†æˆç›‘æ§å’Œä¼˜åŒ–
- æµ‹è¯•å’Œè°ƒè¯•ç³»ç»Ÿ
- å®Œæ•´å¯è¿è¡Œçš„é¡¹ç›®

**åšå®Œè¿™ä¸ªé¡¹ç›®ï¼Œä½ å°±æœ‰äº†ä¼ä¸šçº§å¼€å‘ç»éªŒï¼**

---

## ğŸ“– é¡¹ç›®è®¾è®¡

### 1. é¡¹ç›®æ¦‚è¿°

**é¡¹ç›®åç§°**ï¼šæ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿï¼ˆSmart Content Processorï¼‰

**åŠŸèƒ½æè¿°**ï¼š
ç”¨æˆ·æäº¤ä¸€ç¯‡æ–‡ç« ï¼Œç³»ç»Ÿè‡ªåŠ¨ï¼š
1. åˆ†ææ–‡ç« ä¸»é¢˜å’Œç±»å‹
2. æ ¹æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†æµç¨‹
3. ç”Ÿæˆæ‘˜è¦
4. æå–å…³é”®è¯
5. ç¿»è¯‘æˆè‹±æ–‡
6. ç”Ÿæˆé…å›¾å»ºè®®
7. è®°å½•å¯¹è¯å†å²
8. ç›‘æ§æ€§èƒ½å’Œæˆæœ¬

**æŠ€æœ¯æ ˆ**ï¼š
- LangChainï¼šæ ¸å¿ƒæ¡†æ¶
- RouterChainï¼šæ™ºèƒ½è·¯ç”±
- SequentialChainï¼šæµç¨‹ç¼–æ’
- Memoryï¼šå¯¹è¯ç®¡ç†
- Callbackï¼šç›‘æ§ç³»ç»Ÿ
- Cacheï¼šæ€§èƒ½ä¼˜åŒ–

---

### 2. ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ·è¾“å…¥
   â†“
[æ–‡ç« åˆ†æ] â† Routerå†³ç­–
   â†“
[ç±»å‹åˆ¤æ–­]
   â”œâ”€ æŠ€æœ¯æ–‡ç«  â†’ [æŠ€æœ¯å¤„ç†æµç¨‹]
   â”œâ”€ æ–°é—»æŠ¥é“ â†’ [æ–°é—»å¤„ç†æµç¨‹]
   â””â”€ æ™®é€šæ–‡ç«  â†’ [é€šç”¨å¤„ç†æµç¨‹]
   â†“
[Sequential Pipeline]
   â”œâ”€ æ€»ç»“ç”Ÿæˆ
   â”œâ”€ å…³é”®è¯æå–
   â”œâ”€ è‹±æ–‡ç¿»è¯‘
   â””â”€ é…å›¾å»ºè®®
   â†“
[ç»“æœæ•´åˆ]
   â†“
[Memoryä¿å­˜] + [æ€§èƒ½ç›‘æ§]
   â†“
è¿”å›ç»“æœ
```

---

### 3. æ ¸å¿ƒç»„ä»¶

#
![Monitoring](./images/monitoring.svg)
*å›¾ï¼šMonitoring*

### 3.1 ç³»ç»Ÿç›‘æ§ç»„ä»¶

```python
from langchain.callbacks.base import BaseCallbackHandler
import time
from datetime import datetime

class SystemMonitor(BaseCallbackHandler):
    """ç³»ç»Ÿç›‘æ§ç»„ä»¶"""
    
    def __init__(self):
        self.metrics = {
            "total_requests": 0,
            "success": 0,
            "errors": 0,
            "total_time": 0,
            "llm_calls": 0,
            "llm_time": 0,
            "total_tokens": 0
        }
        self.start_times = {}
        self.request_logs = []
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        """è¯·æ±‚å¼€å§‹"""
        run_id = kwargs.get("run_id")
        self.start_times[f"chain_{run_id}"] = time.time()
        self.metrics["total_requests"] += 1
        
        # è®°å½•æ—¥å¿—
        log = {
            "type": "request_start",
            "timestamp": datetime.now(),
            "run_id": str(run_id),
            "inputs": str(inputs)[:100]
        }
        self.request_logs.append(log)
    
    def on_chain_end(self, outputs, **kwargs):
        """è¯·æ±‚æˆåŠŸ"""
        run_id = kwargs.get("run_id")
        key = f"chain_{run_id}"
        
        if key in self.start_times:
            elapsed = time.time() - self.start_times[key]
            self.metrics["total_time"] += elapsed
            self.metrics["success"] += 1
            
            log = {
                "type": "request_success",
                "timestamp": datetime.now(),
                "run_id": str(run_id),
                "duration": elapsed
            }
            self.request_logs.append(log)
            
            # æ€§èƒ½å‘Šè­¦
            if elapsed > 10:
                print(f"âš ï¸  æ€§èƒ½å‘Šè­¦ï¼šè¯·æ±‚è€—æ—¶{elapsed:.2f}ç§’")
    
    def on_chain_error(self, error, **kwargs):
        """è¯·æ±‚å¤±è´¥"""
        self.metrics["errors"] += 1
        
        log = {
            "type": "request_error",
            "timestamp": datetime.now(),
            "error": str(error)
        }
        self.request_logs.append(log)
        
        print(f"âŒ é”™è¯¯ï¼š{error}")
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """LLMè°ƒç”¨å¼€å§‹"""
        run_id = kwargs.get("run_id")
        self.start_times[f"llm_{run_id}"] = time.time()
        self.metrics["llm_calls"] += 1
    
    def on_llm_end(self, response, **kwargs):
        """LLMè°ƒç”¨ç»“æŸ"""
        run_id = kwargs.get("run_id")
        key = f"llm_{run_id}"
        
        if key in self.start_times:
            elapsed = time.time() - self.start_times[key]
            self.metrics["llm_time"] += elapsed
        
        # ç»Ÿè®¡token
        if hasattr(response, 'llm_output'):
            usage = response.llm_output.get('token_usage', {})
            self.metrics["total_tokens"] += usage.get('total_tokens', 0)
    
    def get_dashboard(self):
        """ç”Ÿæˆç›‘æ§é¢æ¿"""
        avg_time = (
            self.metrics["total_time"] / self.metrics["total_requests"]
            if self.metrics["total_requests"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["success"] / self.metrics["total_requests"] * 100
            if self.metrics["total_requests"] > 0 else 0
        )
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     ç³»ç»Ÿç›‘æ§é¢æ¿                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ æ€»è¯·æ±‚æ•°ï¼š{self.metrics['total_requests']:>6} 
â•‘ æˆåŠŸï¼š{self.metrics['success']:>6}   å¤±è´¥ï¼š{self.metrics['errors']:>6}
â•‘ æˆåŠŸç‡ï¼š{success_rate:>5.1f}%
â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â•‘ å¹³å‡å“åº”æ—¶é—´ï¼š{avg_time:>6.2f}ç§’
â•‘ LLMè°ƒç”¨æ¬¡æ•°ï¼š{self.metrics['llm_calls']:>6}
â•‘ LLMæ€»è€—æ—¶ï¼š{self.metrics['llm_time']:>6.2f}ç§’
â•‘ æ€»Tokenæ•°ï¼š{self.metrics['total_tokens']:>6}
â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â•‘ æˆæœ¬ä¼°ç®—ï¼š${self.metrics['total_tokens'] * 0.0005 / 1000:.4f}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
```

---

#### 3.2 æ–‡ç« ç±»å‹åˆ†æå™¨

```python
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema.output_parser import StrOutputParser

class ArticleAnalyzer:
    """æ–‡ç« ç±»å‹åˆ†æå™¨"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        
        self.prompt = ChatPromptTemplate.from_template("""
åˆ†æä»¥ä¸‹æ–‡ç« çš„ç±»å‹ï¼Œåªè¿”å›ä¸€ä¸ªè¯ï¼štechï¼ˆæŠ€æœ¯ï¼‰ã€newsï¼ˆæ–°é—»ï¼‰ã€generalï¼ˆæ™®é€šï¼‰

æ–‡ç« å†…å®¹ï¼š
{article}

ç±»å‹ï¼š""")
        
        self.chain = self.prompt | self.llm | StrOutputParser()
    
    def analyze(self, article: str, callbacks=None) -> str:
        """åˆ†ææ–‡ç« ç±»å‹"""
        result = self.chain.invoke(
            {"article": article[:500]},  # åªç”¨å‰500å­—
            config={"callbacks": callbacks} if callbacks else {}
        )
        
        # æ¸…ç†ç»“æœ
        result = result.strip().lower()
        
        if "tech" in result:
            return "tech"
        elif "news" in result:
            return "news"
        else:
            return "general"
```

---

#### 3.3 å†…å®¹å¤„ç†Pipeline

```python
from langchain.chains import SequentialChain, LLMChain

class ContentProcessor:
    """å†…å®¹å¤„ç†æµæ°´çº¿"""
    
    def __init__(self, article_type: str):
        self.article_type = article_type
        self.llm = ChatOpenAI(model="gpt-3.5-turbo")
        
        # æ ¹æ®ç±»å‹å®šåˆ¶Prompt
        self._setup_chains()
    
    def _setup_chains(self):
        """è®¾ç½®å¤„ç†é“¾"""
        
        # 1. æ€»ç»“ç”Ÿæˆ
        if self.article_type == "tech":
            summary_prompt = "ä»æŠ€æœ¯è§’åº¦æ€»ç»“ä»¥ä¸‹æ–‡ç« ï¼ˆ100å­—å†…ï¼‰ï¼š\n{article}"
        elif self.article_type == "news":
            summary_prompt = "ç”¨æ–°é—»å¯¼è¯­æ–¹å¼æ€»ç»“ï¼ˆ50å­—å†…ï¼‰ï¼š\n{article}"
        else:
            summary_prompt = "ç®€è¦æ€»ç»“ï¼ˆ80å­—å†…ï¼‰ï¼š\n{article}"
        
        self.summary_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(summary_prompt),
            output_key="summary"
        )
        
        # 2. å…³é”®è¯æå–
        keywords_prompt = "æå–5ä¸ªå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼š\n{article}"
        self.keywords_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(keywords_prompt),
            output_key="keywords"
        )
        
        # 3. è‹±æ–‡ç¿»è¯‘ï¼ˆåªç¿»è¯‘æ‘˜è¦ï¼‰
        translation_prompt = "ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{summary}"
        self.translation_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(translation_prompt),
            output_key="translation"
        )
        
        # 4. é…å›¾å»ºè®®
        image_prompt = """
åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç»™å‡º3ä¸ªé…å›¾å»ºè®®ï¼š

æ‘˜è¦ï¼š{summary}
å…³é”®è¯ï¼š{keywords}

é…å›¾å»ºè®®ï¼š"""
        self.image_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(image_prompt),
            output_key="image_suggestions"
        )
        
        # ç»„åˆæˆSequential Chain
        self.pipeline = SequentialChain(
            chains=[
                self.summary_chain,
                self.keywords_chain,
                self.translation_chain,
                self.image_chain
            ],
            input_variables=["article"],
            output_variables=["summary", "keywords", "translation", "image_suggestions"],
            verbose=False
        )
    
    def process(self, article: str, callbacks=None):
        """å¤„ç†æ–‡ç« """
        return self.pipeline.invoke(
            {"article": article},
            config={"callbacks": callbacks} if callbacks else {}
        )
```

---

#### 3.4 æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ

```python
class SmartRouter:
    """æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ"""
    
    def __init__(self):
        self.analyzer = ArticleAnalyzer()
        self.processors = {}
    
    def route(self, article: str, callbacks=None):
        """è·¯ç”±å¹¶å¤„ç†"""
        
        # 1. åˆ†æç±»å‹
        print("ğŸ“Š åˆ†ææ–‡ç« ç±»å‹...")
        article_type = self.analyzer.analyze(article, callbacks)
        print(f"   ç±»å‹ï¼š{article_type}")
        
        # 2. è·å–æˆ–åˆ›å»ºå¯¹åº”çš„processor
        if article_type not in self.processors:
            self.processors[article_type] = ContentProcessor(article_type)
        
        processor = self.processors[article_type]
        
        # 3. å¤„ç†æ–‡ç« 
        print(f"âš™ï¸  ä½¿ç”¨{article_type}å¤„ç†æµç¨‹...")
        result = processor.process(article, callbacks)
        
        # 4. æ·»åŠ å…ƒæ•°æ®
        result["article_type"] = article_type
        
        return result
```

---

## ğŸ’» å®Œæ•´ç³»ç»Ÿå®ç°

åˆ›å»º`smart_content_processor.py`ï¼š

```python
"""
æ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿ - å®Œæ•´å®ç°
ç¬¬6ç« ç»¼åˆå®æˆ˜é¡¹ç›®
"""

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain, SequentialChain
from langchain.schema.output_parser import StrOutputParser
from langchain.callbacks.base import BaseCallbackHandler
from langchain.cache import InMemoryCache
from langchain.globals import set_llm_cache
from langchain.memory import ConversationBufferMemory
import time
from datetime import datetime
import json


# ============= 1. ç›‘æ§ç»„ä»¶ =============

class SystemMonitor(BaseCallbackHandler):
    """ç³»ç»Ÿç›‘æ§ï¼ˆå®Œæ•´ç‰ˆè§å‰é¢ï¼‰"""
    
    def __init__(self):
        self.metrics = {
            "total_requests": 0,
            "success": 0,
            "errors": 0,
            "total_time": 0,
            "llm_calls": 0,
            "total_tokens": 0
        }
        self.start_times = {}
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        run_id = kwargs.get("run_id")
        self.start_times[f"chain_{run_id}"] = time.time()
        self.metrics["total_requests"] += 1
    
    def on_chain_end(self, outputs, **kwargs):
        run_id = kwargs.get("run_id")
        key = f"chain_{run_id}"
        if key in self.start_times:
            elapsed = time.time() - self.start_times[key]
            self.metrics["total_time"] += elapsed
            self.metrics["success"] += 1
    
    def on_chain_error(self, error, **kwargs):
        self.metrics["errors"] += 1
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        self.metrics["llm_calls"] += 1
    
    def on_llm_end(self, response, **kwargs):
        if hasattr(response, 'llm_output'):
            usage = response.llm_output.get('token_usage', {})
            self.metrics["total_tokens"] += usage.get('total_tokens', 0)
    
    def get_dashboard(self):
        avg_time = (
            self.metrics["total_time"] / self.metrics["total_requests"]
            if self.metrics["total_requests"] > 0 else 0
        )
        success_rate = (
            self.metrics["success"] / self.metrics["total_requests"] * 100
            if self.metrics["total_requests"] > 0 else 0
        )
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     ç³»ç»Ÿç›‘æ§é¢æ¿                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ è¯·æ±‚ï¼š{self.metrics['total_requests']}æ¬¡  æˆåŠŸï¼š{self.metrics['success']}  å¤±è´¥ï¼š{self.metrics['errors']}  æˆåŠŸç‡ï¼š{success_rate:.1f}%
â•‘ å¹³å‡å“åº”ï¼š{avg_time:.2f}ç§’  LLMè°ƒç”¨ï¼š{self.metrics['llm_calls']}æ¬¡
â•‘ Tokenï¼š{self.metrics['total_tokens']}  æˆæœ¬ï¼š${self.metrics['total_tokens'] * 0.0005 / 1000:.4f}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""


# ============= 2. æ–‡ç« åˆ†æå™¨ =============

class ArticleAnalyzer:
    """æ–‡ç« ç±»å‹åˆ†æå™¨"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        prompt = ChatPromptTemplate.from_template("""
åˆ†ææ–‡ç« ç±»å‹ï¼Œåªè¿”å›ï¼štechï¼ˆæŠ€æœ¯ï¼‰ã€newsï¼ˆæ–°é—»ï¼‰æˆ– generalï¼ˆæ™®é€šï¼‰

æ–‡ç« ï¼š{article}

ç±»å‹ï¼š""")
        self.chain = prompt | self.llm | StrOutputParser()
    
    def analyze(self, article: str, callbacks=None):
        result = self.chain.invoke(
            {"article": article[:300]},
            config={"callbacks": callbacks} if callbacks else {}
        )
        result = result.strip().lower()
        if "tech" in result:
            return "tech"
        elif "news" in result:
            return "news"
        return "general"


# ============= 3. å†…å®¹å¤„ç†å™¨ =============

class ContentProcessor:
    """å†…å®¹å¤„ç†Pipeline"""
    
    def __init__(self, article_type: str):
        self.article_type = article_type
        self.llm = ChatOpenAI(model="gpt-3.5-turbo")
        self._setup_pipeline()
    
    def _setup_pipeline(self):
        """è®¾ç½®å¤„ç†æµæ°´çº¿"""
        
        # å®šåˆ¶åŒ–Prompt
        if self.article_type == "tech":
            summary_template = "æŠ€æœ¯æ€»ç»“ï¼ˆ100å­—ï¼‰ï¼š\n{article}"
        elif self.article_type == "news":
            summary_template = "æ–°é—»å¯¼è¯­ï¼ˆ50å­—ï¼‰ï¼š\n{article}"
        else:
            summary_template = "ç®€è¦æ€»ç»“ï¼ˆ80å­—ï¼‰ï¼š\n{article}"
        
        # 1. æ€»ç»“
        summary_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(summary_template),
            output_key="summary"
        )
        
        # 2. å…³é”®è¯
        keywords_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(
                "æå–5ä¸ªå…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼š\n{article}"
            ),
            output_key="keywords"
        )
        
        # 3. ç¿»è¯‘
        translation_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(
                "ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{summary}"
            ),
            output_key="translation"
        )
        
        # 4. é…å›¾
        image_chain = LLMChain(
            llm=self.llm,
            prompt=ChatPromptTemplate.from_template(
                "åŸºäºæ‘˜è¦ã€Œ{summary}ã€å’Œå…³é”®è¯ã€Œ{keywords}ã€ï¼Œç»™3ä¸ªé…å›¾å»ºè®®"
            ),
            output_key="image_suggestions"
        )
        
        # ç»„åˆ
        self.pipeline = SequentialChain(
            chains=[summary_chain, keywords_chain, translation_chain, image_chain],
            input_variables=["article"],
            output_variables=["summary", "keywords", "translation", "image_suggestions"],
            verbose=False
        )
    
    def process(self, article: str, callbacks=None):
        return self.pipeline.invoke(
            {"article": article},
            config={"callbacks": callbacks} if callbacks else {}
        )


# ============= 4. æ™ºèƒ½è·¯ç”±å™¨ =============

class SmartRouter:
    """æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ"""
    
    def __init__(self):
        self.analyzer = ArticleAnalyzer()
        self.processors = {}
    
    def route_and_process(self, article: str, callbacks=None):
        """åˆ†æç±»å‹å¹¶è·¯ç”±å¤„ç†"""
        
        # åˆ†æç±»å‹
        article_type = self.analyzer.analyze(article, callbacks)
        
        # è·å–processor
        if article_type not in self.processors:
            self.processors[article_type] = ContentProcessor(article_type)
        
        processor = self.processors[article_type]
        
        # å¤„ç†
        result = processor.process(article, callbacks)
        result["article_type"] = article_type
        
        return result


# ============= 5. ä¸»ç³»ç»Ÿ =============

class SmartContentProcessorSystem:
    """æ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿï¼ˆä¸»å…¥å£ï¼‰"""
    
    def __init__(self, enable_cache=True):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        
        print("ğŸš€ åˆå§‹åŒ–æ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿ...")
        
        # å¯ç”¨ç¼“å­˜
        if enable_cache:
            set_llm_cache(InMemoryCache())
            print("âœ“ ç¼“å­˜å·²å¯ç”¨")
        
        # ç›‘æ§
        self.monitor = SystemMonitor()
        print("âœ“ ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨")
        
        # è·¯ç”±å™¨
        self.router = SmartRouter()
        print("âœ“ æ™ºèƒ½è·¯ç”±å™¨å·²å°±ç»ª")
        
        # Memoryï¼ˆå¯é€‰ï¼Œè®°å½•å¤„ç†å†å²ï¼‰
        self.memory = ConversationBufferMemory()
        
        print("âœ“ ç³»ç»Ÿå°±ç»ªï¼\n")
    
    def process_article(self, article: str, show_progress=True):
        """å¤„ç†æ–‡ç« ï¼ˆä¸»æ–¹æ³•ï¼‰"""
        
        start_time = time.time()
        
        if show_progress:
            print(f"{'='*60}")
            print(f"ğŸ“ å¤„ç†æ–°æ–‡ç« ï¼ˆ{len(article)}å­—ï¼‰")
            print(f"{'='*60}")
        
        try:
            # è·¯ç”±å¹¶å¤„ç†
            result = self.router.route_and_process(
                article,
                callbacks=[self.monitor]
            )
            
            # è®°å½•åˆ°Memory
            self.memory.save_context(
                {"input": article[:100] + "..."},
                {"output": f"å¤„ç†å®Œæˆï¼š{result['article_type']}"}
            )
            
            elapsed = time.time() - start_time
            
            if show_progress:
                self._print_result(result, elapsed)
            
            return result
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ï¼š{e}")
            return None
    
    def _print_result(self, result, elapsed):
        """æ‰“å°å¤„ç†ç»“æœ"""
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼ˆ{elapsed:.2f}ç§’ï¼‰\n")
        print(f"ç±»å‹ï¼š{result['article_type']}")
        print(f"\nğŸ“„ æ‘˜è¦ï¼š")
        print(f"   {result['summary']}\n")
        print(f"ğŸ”– å…³é”®è¯ï¼š{result['keywords']}\n")
        print(f"ğŸŒ è‹±æ–‡ç¿»è¯‘ï¼š")
        print(f"   {result['translation']}\n")
        print(f"ğŸ–¼ï¸  é…å›¾å»ºè®®ï¼š")
        print(f"   {result['image_suggestions']}\n")
        print(f"{'='*60}\n")
    
    def batch_process(self, articles: list):
        """æ‰¹é‡å¤„ç†"""
        
        print(f"ğŸ“¦ æ‰¹é‡å¤„ç† {len(articles)} ç¯‡æ–‡ç« \n")
        
        results = []
        for i, article in enumerate(articles, 1):
            print(f"[{i}/{len(articles)}] å¤„ç†ä¸­...")
            result = self.process_article(article, show_progress=False)
            results.append(result)
            print(f"[{i}/{len(articles)}] å®Œæˆ\n")
        
        return results
    
    def get_statistics(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.monitor.get_dashboard()
    
    def get_history(self):
        """è·å–å¤„ç†å†å²"""
        return self.memory.load_memory_variables({})


# ============= 6. Demoæ¼”ç¤º =============

def demo_single_article():
    """æ¼”ç¤ºï¼šå•ç¯‡æ–‡ç« å¤„ç†"""
    
    print("\n" + "="*60)
    print("æ¼”ç¤º1ï¼šå•ç¯‡æ–‡ç« å¤„ç†")
    print("="*60 + "\n")
    
    system = SmartContentProcessorSystem(enable_cache=True)
    
    article = """
LangChainæ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œç”¨äºå¼€å‘ç”±å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºã€‚
å®ƒæä¾›äº†ä¸€ç³»åˆ—å·¥å…·å’ŒæŠ½è±¡ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿè½»æ¾æ„å»ºå¤æ‚çš„AIåº”ç”¨ã€‚
LangChainçš„æ ¸å¿ƒæ¦‚å¿µåŒ…æ‹¬Chainsã€Agentsã€Memoryç­‰ï¼Œè¿™äº›ç»„ä»¶å¯ä»¥
çµæ´»ç»„åˆï¼Œåˆ›å»ºå‡ºå¼ºå¤§çš„AIç³»ç»Ÿã€‚é€šè¿‡LangChainï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿ
æ„å»ºèŠå¤©æœºå™¨äººã€é—®ç­”ç³»ç»Ÿã€æ–‡æ¡£åˆ†æå·¥å…·ç­‰å„ç§åº”ç”¨ã€‚
"""
    
    result = system.process_article(article)
    print(system.get_statistics())


def demo_batch_processing():
    """æ¼”ç¤ºï¼šæ‰¹é‡å¤„ç†"""
    
    print("\n" + "="*60)
    print("æ¼”ç¤º2ï¼šæ‰¹é‡å¤„ç†å¤šç¯‡æ–‡ç« ")
    print("="*60 + "\n")
    
    system = SmartContentProcessorSystem(enable_cache=True)
    
    articles = [
        "Python 3.12 å‘å¸ƒäº†è®¸å¤šæ–°ç‰¹æ€§ï¼ŒåŒ…æ‹¬æ€§èƒ½æ”¹è¿›å’Œæ–°çš„è¯­æ³•ã€‚",
        "æœ¬åœ°æ—¶é—´å‘¨ä¸€ï¼Œç¾å›½ç§‘æŠ€å…¬å¸å®£å¸ƒæ¨å‡ºæ–°ä¸€ä»£AIèŠ¯ç‰‡ã€‚",
        "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥ï¼Œäº«å—æ˜¥æ—¥çš„é˜³å…‰ã€‚"
    ]
    
    results = system.batch_process(articles)
    
    print(system.get_statistics())


def demo_cache_performance():
    """æ¼”ç¤ºï¼šç¼“å­˜æ€§èƒ½æå‡"""
    
    print("\n" + "="*60)
    print("æ¼”ç¤º3ï¼šç¼“å­˜æ€§èƒ½å¯¹æ¯”")
    print("="*60 + "\n")
    
    system = SmartContentProcessorSystem(enable_cache=True)
    
    article = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œï¼Œä»åŒ»ç–—åˆ°é‡‘èï¼ŒAIçš„åº”ç”¨æ— å¤„ä¸åœ¨ã€‚"
    
    # ç¬¬ä¸€æ¬¡ï¼ˆæ— ç¼“å­˜ï¼‰
    print("ç¬¬ä¸€æ¬¡å¤„ç†ï¼ˆæ— ç¼“å­˜ï¼‰ï¼š")
    start = time.time()
    result1 = system.process_article(article, show_progress=False)
    time1 = time.time() - start
    print(f"è€—æ—¶ï¼š{time1:.2f}ç§’\n")
    
    # ç¬¬äºŒæ¬¡ï¼ˆæœ‰ç¼“å­˜ï¼‰
    print("ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆæœ‰ç¼“å­˜ï¼‰ï¼š")
    start = time.time()
    result2 = system.process_article(article, show_progress=False)
    time2 = time.time() - start
    print(f"è€—æ—¶ï¼š{time2:.2f}ç§’\n")
    
    print(f"åŠ é€Ÿï¼š{time1/time2:.1f}å€\n")
    print(system.get_statistics())


def main():
    """ä¸»å‡½æ•°"""
    
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘          æ™ºèƒ½å†…å®¹å¤„ç†ç³»ç»Ÿ - ç¬¬6ç« ç»¼åˆå®æˆ˜é¡¹ç›®             â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    demo_single_article()
    demo_batch_processing()
    demo_cache_performance()
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
    print("="*60)
    print("\nğŸ’¡ é¡¹ç›®ç‰¹ç‚¹ï¼š")
    print("  âœ“ RouterChainæ™ºèƒ½è·¯ç”±")
    print("  âœ“ SequentialChainæµç¨‹ç¼–æ’")
    print("  âœ“ Memoryå†å²è®°å½•")
    print("  âœ“ Callbackå®Œæ•´ç›‘æ§")
    print("  âœ“ ç¼“å­˜æ€§èƒ½ä¼˜åŒ–")
    print("  âœ“ é”™è¯¯å¤„ç†æœºåˆ¶")
    print("\nğŸ¯ è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç”Ÿäº§çº§ç³»ç»Ÿç¤ºä¾‹ï¼")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
```

---

## ğŸ¯ é¡¹ç›®æ€»ç»“

### ä½¿ç”¨çš„æŠ€æœ¯

```
âœ… RouterChainï¼šæ™ºèƒ½ç±»å‹è¯†åˆ«å’Œè·¯ç”±
âœ… SequentialChainï¼š4æ­¥å¤„ç†æµç¨‹
âœ… Memoryï¼šè®°å½•å¤„ç†å†å²
âœ… Callbackï¼šå®Œæ•´çš„ç›‘æ§ç³»ç»Ÿ
âœ… Cacheï¼šInMemoryCacheæ€§èƒ½ä¼˜åŒ–
âœ… é”™è¯¯å¤„ç†ï¼štry-catchä¿æŠ¤
âœ… æ€§èƒ½ç›‘æ§ï¼šå®æ—¶ç»Ÿè®¡å’Œå‘Šè­¦
```

### ç³»ç»Ÿäº®ç‚¹

```
1. æ¨¡å—åŒ–è®¾è®¡ï¼šå„ç»„ä»¶ç‹¬ç«‹ï¼Œæ˜“äºç»´æŠ¤
2. æ™ºèƒ½è·¯ç”±ï¼šæ ¹æ®å†…å®¹ç±»å‹è‡ªåŠ¨é€‰æ‹©æµç¨‹
3. å®Œæ•´ç›‘æ§ï¼šè¯·æ±‚æ•°ã€æˆåŠŸç‡ã€è€—æ—¶ã€æˆæœ¬
4. æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜ã€æ‰¹å¤„ç†
5. ç”Ÿäº§å°±ç»ªï¼šé”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•
```

### å¯æ‰©å±•æ–¹å‘

```
1. æ·»åŠ æ›´å¤šæ–‡ç« ç±»å‹ï¼ˆè´¢ç»ã€å¨±ä¹ç­‰ï¼‰
2. æ¥å…¥å‘é‡æ•°æ®åº“ï¼ˆå­˜å‚¨å†å²ï¼‰
3. Web APIå°è£…ï¼ˆFlask/FastAPIï¼‰
4. å¼‚æ­¥å¤„ç†ï¼ˆæå‡å¹¶å‘ï¼‰
5. åˆ†å¸ƒå¼ç¼“å­˜ï¼ˆRedisï¼‰
6. ç›‘æ§å‘Šè­¦ï¼ˆé›†æˆSentryï¼‰
```

---

## âœ… ç¬¬6ç« å®Œç»“

### å­¦ä¹ å›é¡¾

**ç¬¬6ç« ï¼šChainé«˜çº§åº”ç”¨ï¼ˆ7è¯¾æ—¶ï¼‰**

- âœ… ç¬¬30è¯¾ï¼šSequentialChainä¸²è”
- âœ… ç¬¬31è¯¾ï¼šRouterChainåŠ¨æ€è·¯ç”±
- âœ… ç¬¬32è¯¾ï¼šMemoryä¸å¯¹è¯ç®¡ç†æ·±å…¥
- âœ… ç¬¬33è¯¾ï¼šCallbackç³»ç»Ÿä¸ç›‘æ§
- âœ… ç¬¬34è¯¾ï¼šè°ƒè¯•æŠ€å·§ä¸é—®é¢˜æ’æŸ¥
- âœ… ç¬¬35è¯¾ï¼šæ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ
- âœ… ç¬¬36è¯¾ï¼šç»¼åˆå®æˆ˜é¡¹ç›®ï¼ˆæœ¬è¯¾ï¼‰

### èƒ½åŠ›æ¸…å•

å®Œæˆç¬¬6ç« åï¼Œä½ åº”è¯¥æŒæ¡ï¼š

- [ ] SequentialChainçš„ä½¿ç”¨å’Œåœºæ™¯
- [ ] RouterChainçš„è·¯ç”±ç­–ç•¥
- [ ] Memoryçš„é«˜çº§ç®¡ç†
- [ ] Callbackçš„ç›‘æ§å’Œæ—¥å¿—
- [ ] Chainçš„è°ƒè¯•æŠ€å·§
- [ ] æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
- [ ] æ„å»ºå®Œæ•´çš„ç”Ÿäº§çº§ç³»ç»Ÿ

---

## ğŸ“ ä¸‹ä¸€æ­¥å­¦ä¹ 

**ç¬¬37è¯¾ï¼šAgentåŸºç¡€æ¦‚å¿µï¼ˆæ¨¡å—3å¼€å§‹ï¼‰**

ä¸‹ä¸ªæ¨¡å—æˆ‘ä»¬å°†å­¦ä¹ ï¼š
- Agentçš„æ ¸å¿ƒæ¦‚å¿µ
- Toolçš„ä½¿ç”¨
- ReActæ¡†æ¶
- Agentçš„æ‰§è¡Œæµç¨‹
- è‡ªå®šä¹‰Agent

**ä»Chainè¿›åŒ–åˆ°Agentï¼**

---

**ğŸ‰ æ­å–œä½ å®Œæˆç¬¬36è¯¾ï¼**

**ç¬¬6ç« å®Œç¾æ”¶å®˜ï¼ä½ å·²ç»æŒæ¡äº†Chainçš„æ‰€æœ‰é«˜çº§æŠ€èƒ½ï¼**

**è¿›åº¦ï¼š36/165è¯¾ï¼ˆ21.8%å®Œæˆï¼‰** ğŸŠ

**ç¬¬äºŒæ¨¡å—è¿›åº¦ï¼š36/40è¯¾ï¼ˆ90%å®Œæˆï¼‰** ğŸš€
