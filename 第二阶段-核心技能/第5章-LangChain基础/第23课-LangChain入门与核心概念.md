![LangChainæ ¸å¿ƒæ¶æ„](./images/langchain_arch.svg)
*å›¾ï¼šLangChainæ ¸å¿ƒæ¶æ„*

# ç¬¬23è¯¾ï¼šLangChainå…¥é—¨ä¸æ ¸å¿ƒæ¦‚å¿µ

> ğŸ“š **è¯¾ç¨‹ä¿¡æ¯**
> - æ‰€å±æ¨¡å—ï¼šç¬¬äºŒæ¨¡å— - APIä¸LangChainå¼€å‘  
> - ç« èŠ‚ï¼šç¬¬5ç«  - LangChainæ ¸å¿ƒæ¦‚å¿µï¼ˆç¬¬1/7è¯¾ï¼‰
> - å­¦ä¹ ç›®æ ‡ï¼šç†è§£LangChainçš„è®¾è®¡å“²å­¦ï¼ŒæŒæ¡æ ¸å¿ƒæ¦‚å¿µå’ŒåŸºæœ¬ç”¨æ³•
> - é¢„è®¡æ—¶é—´ï¼š70-80åˆ†é’Ÿ
> - å‰ç½®çŸ¥è¯†ï¼šç¬¬16-22è¯¾ï¼ˆAPIè°ƒç”¨åŸºç¡€ï¼‰

---

## ğŸ“¢ è¯¾ç¨‹å¯¼å…¥

### å‰è¨€

å‰é¢7è¯¾æˆ‘ä»¬å­¦ä¼šäº†ç›´æ¥è°ƒç”¨OpenAI APIï¼Œå†™äº†å¾ˆå¤šä»£ç ï¼šé”™è¯¯å¤„ç†ã€é‡è¯•ã€ç¼“å­˜ã€æˆæœ¬ä¼˜åŒ–...æ¯æ¬¡éƒ½è¦é‡å¤å†™è¿™äº›ä»£ç ï¼Œå¤ªç´¯äº†ï¼

æœ‰æ²¡æœ‰ä¸€ä¸ªæ¡†æ¶èƒ½æŠŠè¿™äº›å¸¸ç”¨åŠŸèƒ½å°è£…å¥½ï¼Œè®©æˆ‘ä»¬ä¸“æ³¨äºä¸šåŠ¡é€»è¾‘ï¼Ÿ**æœ‰ï¼å®ƒå°±æ˜¯LangChainâ€”â€”æœ€æµè¡Œçš„LLMåº”ç”¨å¼€å‘æ¡†æ¶ï¼**

**2025å¹´ï¼ŒLangChainå·²ç»å‘å¸ƒäº†1.0æ­£å¼ç‰ˆæœ¬ï¼** è¿™æ ‡å¿—ç€æ¡†æ¶å·²ç»éå¸¸æˆç†Ÿå’Œç¨³å®šã€‚LangChainä¸æ˜¯ç®€å•çš„APIå°è£…ï¼Œè€Œæ˜¯ä¸€å¥—å®Œæ•´çš„å¼€å‘èŒƒå¼ï¼å®ƒè®©AIåº”ç”¨å¼€å‘å˜å¾—åƒæ­ç§¯æœ¨ä¸€æ ·ç®€å•ï¼ä»Šå¤©è¿™è¯¾ï¼Œæˆ‘ä»¬æ­£å¼è¿›å…¥LangChain 1.0çš„ä¸–ç•Œï¼

---

### æ ¸å¿ƒä»·å€¼ç‚¹

**ç¬¬ä¸€ï¼ŒLangChainæ˜¯LLMåº”ç”¨å¼€å‘çš„äº‹å®æ ‡å‡†ã€‚**

ä¸ºä»€ä¹ˆè¦å­¦LangChainï¼Ÿçœ‹çœ‹è¿™äº›æ•°æ®ï¼š
- GitHub staræ•°ï¼š90k+
- æ¯æœˆä¸‹è½½é‡ï¼š500ä¸‡+
- å¤§å‚éƒ½åœ¨ç”¨ï¼šå¾®è½¯ã€è°·æ­Œã€äºšé©¬é€Š
- æ‹›è˜éœ€æ±‚ï¼šå‡ ä¹æ‰€æœ‰AIå²—ä½éƒ½è¦æ±‚ä¼šLangChain

ä¸ä¼šLangChainï¼Œå°±åƒå‰ç«¯ä¸ä¼šReactï¼Œåç«¯ä¸ä¼šSpringï¼è¿™æ˜¯AIå¼€å‘çš„å¿…å¤‡æŠ€èƒ½ï¼

**ç¬¬äºŒï¼ŒLangChainä¸æ˜¯ç®€å•çš„APIå°è£…ï¼Œè€Œæ˜¯å¼€å‘èŒƒå¼ã€‚**

å¾ˆå¤šäººä»¥ä¸ºLangChainåªæ˜¯å°è£…äº†OpenAI APIï¼Œé”™ï¼LangChainæä¾›çš„æ˜¯ï¼š
- **ç»„ä»¶åŒ–**ï¼šæŠŠå¤æ‚åŠŸèƒ½æ‹†æˆå¯å¤ç”¨ç»„ä»¶
- **é“¾å¼è°ƒç”¨**ï¼šç»„ä»¶ä¹‹é—´çµæ´»ç»„åˆ
- **æŠ½è±¡ç»Ÿä¸€**ï¼šä¸åŒæ¨¡å‹ç”¨ç»Ÿä¸€æ¥å£
- **æœ€ä½³å®è·µ**ï¼šå†…ç½®äº†å¾ˆå¤šä¼˜åŒ–å’Œæ¨¡å¼

å­¦ä¼šLangChainï¼Œä½ çš„å¼€å‘æ•ˆç‡èƒ½æå‡5-10å€ï¼

**ç¬¬ä¸‰ï¼ŒLangChainçš„æ ¸å¿ƒæ¦‚å¿µéå¸¸ä¼˜é›…ã€‚**

LangChainçš„è®¾è®¡ç†å¿µæ˜¯ï¼š
- **Components**ï¼šå¯å¤ç”¨çš„ç»„ä»¶ï¼ˆPromptã€Modelã€Parserï¼‰
- **Chains**ï¼šç»„ä»¶çš„ç»„åˆï¼ˆInput â†’ Process â†’ Outputï¼‰
- **Agents**ï¼šè‡ªä¸»å†³ç­–çš„æ™ºèƒ½ä½“
- **Memory**ï¼šè®°ä½å¯¹è¯å†å²

è¿™å¥—ç†å¿µæ¸…æ™°ã€ä¼˜é›…ï¼Œä¸€æ—¦ç†è§£ï¼Œå¼€å‘AIåº”ç”¨å°±åƒæ­ä¹é«˜ä¸€æ ·ç®€å•ï¼

**ç¬¬å››ï¼Œç°åœ¨å­¦LangChainæ˜¯æœ€å¥½çš„æ—¶æœºã€‚**

LangChainåœ¨2023å¹´çˆ†ç«ï¼Œç°åœ¨å·²ç»å¾ˆæˆç†Ÿäº†ï¼š
- æ–‡æ¡£å®Œå–„
- ç¤¾åŒºæ´»è·ƒ
- ç”Ÿæ€ä¸°å¯Œ
- ç‰ˆæœ¬ç¨³å®š

è€Œä¸”è¶Šæ¥è¶Šå¤šçš„å…¬å¸åœ¨ç”¨ï¼Œç°åœ¨å­¦ä¼šï¼Œæ‰¾å·¥ä½œå¤§å¤§åŠ åˆ†ï¼

---

### è¡ŒåŠ¨å·å¬

ä»Šå¤©è¿™ä¸€è¯¾ä¼šæ•™ä½ ï¼š
- LangChainçš„è®¾è®¡å“²å­¦å’Œæ¶æ„
- æ ¸å¿ƒæ¦‚å¿µï¼šComponentsã€Chainsã€Agents
- å®‰è£…å’ŒåŸºç¡€é…ç½®
- ç¬¬ä¸€ä¸ªLangChainç¨‹åº
- ä¸åŸç”ŸAPIçš„å¯¹æ¯”

**å­¦å®Œè¿™è¯¾ï¼Œä½ å°±æ­£å¼è¿›å…¥LangChainçš„ä¸–ç•Œäº†ï¼**

---

## ğŸ“– çŸ¥è¯†è®²è§£

### 1. LangChainæ˜¯ä»€ä¹ˆ

#
![Model Io](./images/model_io.svg)
*å›¾ï¼šModel Io*

### 1.1 å®˜æ–¹å®šä¹‰ï¼ˆLangChain 1.0ï¼‰

```
LangChain 1.0 æ˜¯ç”¨äºæ„å»ºç”±LLMé©±åŠ¨çš„Agentså’Œåº”ç”¨çš„æœ€ç®€å•æ–¹å¼ã€‚

æ ¸å¿ƒç‰¹æ€§ï¼š
1. æ ‡å‡†åŒ–æ¨¡å‹æ¥å£ï¼šè½»æ¾è¿æ¥OpenAIã€Anthropicã€Googleç­‰
2. é¢„æ„å»ºAgentæ¶æ„ï¼šä¸åˆ°10è¡Œä»£ç å³å¯åˆ›å»ºAgent
3. åŸºäºLangGraphï¼šæä¾›æŒä¹…åŒ–ã€æµå¼è¾“å‡ºã€äººæœºäº¤äº’æ”¯æŒ
4. ä¸LangSmithé›†æˆï¼šå¼ºå¤§çš„è°ƒè¯•å’Œå¯è§†åŒ–å·¥å…·
5. ç”Ÿäº§å°±ç»ªï¼šç¨³å®šçš„1.0ç‰ˆæœ¬API

æ¨èåœºæ™¯ï¼š
- å¿«é€Ÿæ„å»ºAgentså’Œè‡ªæ²»åº”ç”¨
- éœ€è¦å¿«é€ŸåŸå‹å¼€å‘
- åŸºç¡€åˆ°ä¸­ç­‰å¤æ‚åº¦çš„Agentéœ€æ±‚
```

#### 1.2 ä¸ºä»€ä¹ˆéœ€è¦LangChain

**æ²¡æœ‰LangChainçš„å¼€å‘æ–¹å¼ï¼š**
```python
# åŸç”ŸAPIè°ƒç”¨
from openai import OpenAI

client = OpenAI()

# æ¯æ¬¡éƒ½è¦å†™å¤§é‡é‡å¤ä»£ç 
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯Pythonä¸“å®¶"},
        {"role": "user", "content": "è§£é‡Šè£…é¥°å™¨"}
    ],
    temperature=0.7
)

# æ‰‹åŠ¨å¤„ç†è¾“å‡º
result = response.choices[0].message.content

# æ‰‹åŠ¨è§£æJSON
# æ‰‹åŠ¨é”™è¯¯å¤„ç†
# æ‰‹åŠ¨ç¼“å­˜
# ...
```

**ä½¿ç”¨LangChain 1.0ï¼š**
```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# 1. å®šä¹‰æ¨¡å‹
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

# 2. å®šä¹‰æç¤ºè¯æ¨¡æ¿
prompt = ChatPromptTemplate.from_template(
    "ä½œä¸º{role}ï¼Œè¯·{task}"
)

# 3. ç»„æˆé“¾
chain = prompt | llm

# 4. æ‰§è¡Œ
result = chain.invoke({"role": "Pythonä¸“å®¶", "task": "è§£é‡Šè£…é¥°å™¨"})
```

**å¯¹æ¯”ä¼˜åŠ¿ï¼š**
```
âœ… ä»£ç ç®€æ´ï¼ˆå°‘70%ï¼‰
âœ… å¯è¯»æ€§å¼ºï¼ˆæ„å›¾æ¸…æ™°ï¼‰
âœ… å¯å¤ç”¨æ€§é«˜ï¼ˆç»„ä»¶åŒ–ï¼‰
âœ… å†…ç½®æœ€ä½³å®è·µï¼ˆé”™è¯¯å¤„ç†ã€é‡è¯•ç­‰ï¼‰
âœ… æ˜“äºæ‰©å±•ï¼ˆæ·»åŠ åŠŸèƒ½åªéœ€ç»„åˆç»„ä»¶ï¼‰
```

---

### 2. LangChainæ¶æ„

#### 2.1 æ ¸å¿ƒå±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Applications                 â”‚
â”‚  (ä½ çš„AIåº”ç”¨)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Chains                    â”‚
â”‚  (ç»„ä»¶çš„ç»„åˆå’Œç¼–æ’)                    â”‚
â”‚  â€¢ LLMChain                         â”‚
â”‚  â€¢ SequentialChain                  â”‚
â”‚  â€¢ RouterChain                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Components                  â”‚
â”‚  (å¯å¤ç”¨çš„åŸºç¡€ç»„ä»¶)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Models (LLMs, Chat Models)        â”‚
â”‚ â€¢ Prompts (Templates)               â”‚
â”‚ â€¢ Output Parsers                    â”‚
â”‚ â€¢ Memory (ConversationBuffer...)    â”‚
â”‚ â€¢ Tools (APIs, Databases...)        â”‚
â”‚ â€¢ Embeddings                        â”‚
â”‚ â€¢ Vector Stores                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Integrations                 â”‚
â”‚  (ç¬¬ä¸‰æ–¹æœåŠ¡é›†æˆ)                      â”‚
â”‚  â€¢ OpenAI, Anthropic, Hugging Face  â”‚
â”‚  â€¢ Pinecone, Chroma, Weaviate      â”‚
â”‚  â€¢ MongoDB, PostgreSQL              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 2.2 æ ¸å¿ƒæ¦‚å¿µ

**1. Modelsï¼ˆæ¨¡å‹ï¼‰- LangChain 1.0ç»Ÿä¸€æ¥å£**
```python
# LangChain 1.0 æ¨èä½¿ç”¨æ ‡å‡†åŒ–çš„å¯¼å…¥æ–¹å¼
from langchain_openai import ChatOpenAI

# åˆ›å»ºæ¨¡å‹å®ä¾‹
chat_model = ChatOpenAI(model="gpt-4")

# ç»Ÿä¸€çš„invokeæ¥å£
result = chat_model.invoke("Hello")

# ä¹Ÿæ”¯æŒå…¶ä»–æä¾›å•†
from langchain_anthropic import ChatAnthropic
claude = ChatAnthropic(model="claude-sonnet-4")
```

**2. Promptsï¼ˆæç¤ºè¯ï¼‰**
```python
# æ¨¡æ¿åŒ–æç¤ºè¯
from langchain.prompts import PromptTemplate

prompt = PromptTemplate(
    input_variables=["topic"],
    template="å†™ä¸€é¦–å…³äº{topic}çš„è¯—"
)

# å¡«å……å˜é‡
formatted = prompt.format(topic="AI")
```

**3. Output Parsersï¼ˆè¾“å‡ºè§£æå™¨ï¼‰**
```python
# è§£æç»“æ„åŒ–è¾“å‡º
from langchain.output_parsers import JSONOutputParser

parser = JSONOutputParser()

# è‡ªåŠ¨è§£æJSON
result = parser.parse('{"name": "Alice", "age": 25}')
```

**4. Chainsï¼ˆé“¾ï¼‰**
```python
# ç»„åˆç»„ä»¶
chain = prompt | llm | parser

# æ‰§è¡Œ
result = chain.invoke({"topic": "AI"})
```

**5. Memoryï¼ˆè®°å¿†ï¼‰**
```python
# è®°ä½å¯¹è¯å†å²
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.save_context({"input": "ä½ å¥½"}, {"output": "ä½ å¥½ï¼"})
```

**6. Agentsï¼ˆæ™ºèƒ½ä½“ï¼‰**
```python
# è‡ªä¸»å†³ç­–å’Œä½¿ç”¨å·¥å…·
from langchain.agents import create_react_agent

agent = create_react_agent(llm, tools, prompt)
```

---

### 3. å®‰è£…å’Œé…ç½®

#### 3.1 å®‰è£…ï¼ˆLangChain 1.0ï¼‰

```bash
# åŸºç¡€å®‰è£…ï¼ˆPython 3.10+ï¼‰
pip install -U langchain

# å®‰è£…OpenAIé›†æˆï¼ˆæ¨èï¼‰
pip install -U "langchain[anthropic]"
# æˆ–è€…æ ¹æ®éœ€è¦é€‰æ‹©å…¶ä»–æ¨¡å‹
pip install -U "langchain[openai]"

# å®Œæ•´å®‰è£…ï¼ˆåŒ…å«æ‰€æœ‰åŠŸèƒ½ï¼‰
pip install -U langchain[all]

# æ¨èå®‰è£…æ–¹å¼ï¼ˆä½¿ç”¨uvæ›´å¿«ï¼‰
uv add langchain
```

#### 3.2 ç¯å¢ƒé…ç½®

```python
# .envæ–‡ä»¶
OPENAI_API_KEY=sk-xxxxxxxxxxxxx

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# æˆ–è€…ç›´æ¥è®¾ç½®
import os
os.environ["OPENAI_API_KEY"] = "sk-xxxxx"
```

---

### 4. ç¬¬ä¸€ä¸ªLangChainç¨‹åº

#### 4.1 Hello World

```python
from langchain_openai import ChatOpenAI

# åˆ›å»ºæ¨¡å‹
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

# è°ƒç”¨
response = llm.invoke("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è‡ªå·±")

print(response.content)
```

#### 4.2 ä½¿ç”¨Prompt Template

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# 1. åˆ›å»ºæ¨¡å‹
llm = ChatOpenAI(model="gpt-3.5-turbo")

# 2. åˆ›å»ºæç¤ºè¯æ¨¡æ¿
prompt = ChatPromptTemplate.from_template(
    "ä½ æ˜¯ä¸€ä½{role}ã€‚è¯·{task}ï¼Œç”¨{style}çš„é£æ ¼ã€‚"
)

# 3. åˆ›å»ºé“¾
chain = prompt | llm

# 4. æ‰§è¡Œ
result = chain.invoke({
    "role": "Pythonè€å¸ˆ",
    "task": "è§£é‡Šè£…é¥°å™¨",
    "style": "é€šä¿—æ˜“æ‡‚"
})

print(result.content)
```

#### 4.3 æ·»åŠ Output Parser

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import StrOutputParser

# é“¾å¼ç»„åˆ
chain = (
    ChatPromptTemplate.from_template("å†™ä¸€é¦–å…³äº{topic}çš„è¯—")
    | ChatOpenAI(model="gpt-3.5-turbo")
    | StrOutputParser()  # æå–contentå­—æ®µ
)

# æ‰§è¡Œ
poem = chain.invoke({"topic": "äººå·¥æ™ºèƒ½"})
print(poem)  # ç›´æ¥æ˜¯å­—ç¬¦ä¸²ï¼Œä¸æ˜¯å¯¹è±¡
```

---

### 5. LCELï¼ˆLangChain Expression Languageï¼‰

#### 5.1 ä»€ä¹ˆæ˜¯LCEL

```
LCELæ˜¯LangChainçš„æ ¸å¿ƒè¯­æ³•ï¼Œä½¿ç”¨ç®¡é“æ“ä½œç¬¦ | è¿æ¥ç»„ä»¶

ä¼˜åŠ¿ï¼š
âœ… ä»£ç ç®€æ´æ¸…æ™°
âœ… è‡ªåŠ¨æ”¯æŒæµå¼ã€æ‰¹å¤„ç†ã€å¼‚æ­¥
âœ… æ˜“äºè°ƒè¯•å’Œç›‘æ§
âœ… ç»„ä»¶å¯å¤ç”¨

è¯­æ³•ï¼š
chain = component1 | component2 | component3
```

#### 5.2 LCELç¤ºä¾‹

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import StrOutputParser

# å®šä¹‰ç»„ä»¶
prompt = ChatPromptTemplate.from_template("ç¿»è¯‘æˆè‹±æ–‡ï¼š{text}")
model = ChatOpenAI(model="gpt-3.5-turbo")
output_parser = StrOutputParser()

# ç»„åˆæˆé“¾
chain = prompt | model | output_parser

# æ‰§è¡Œ
result = chain.invoke({"text": "ä½ å¥½ï¼Œä¸–ç•Œ"})
print(result)  # "Hello, world"

# æµå¼æ‰§è¡Œ
for chunk in chain.stream({"text": "ä½ å¥½ï¼Œä¸–ç•Œ"}):
    print(chunk, end="", flush=True)

# æ‰¹å¤„ç†
results = chain.batch([
    {"text": "ä½ å¥½"},
    {"text": "å†è§"},
    {"text": "è°¢è°¢"}
])
```

---

## ğŸ’» Demoæ¡ˆä¾‹ï¼šLangChainåŸºç¡€å®æˆ˜

åˆ›å»º`langchain_basics_demo.py`ï¼š

```python
"""
LangChainåŸºç¡€åŠŸèƒ½æ¼”ç¤º
ä»Hello Worldåˆ°å¤æ‚é“¾
"""

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.output_parsers import StrOutputParser, JSONOutputParser
from langchain.schema import HumanMessage, SystemMessage
import os
from dotenv import load_dotenv

load_dotenv()


def demo_1_basic_call():
    """ç¤ºä¾‹1ï¼šæœ€ç®€å•çš„è°ƒç”¨"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1ï¼šåŸºç¡€è°ƒç”¨")
    print("="*60)
    
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    
    response = llm.invoke("ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯LangChain")
    
    print(f"å›å¤ï¼š{response.content}")
    print(f"ç±»å‹ï¼š{type(response)}")


def demo_2_with_template():
    """ç¤ºä¾‹2ï¼šä½¿ç”¨æç¤ºè¯æ¨¡æ¿"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2ï¼šæç¤ºè¯æ¨¡æ¿")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ¿
    prompt = ChatPromptTemplate.from_template(
        "ä½ æ˜¯ä¸€ä½{role}ã€‚è¯·ç”¨{words}å­—ä»¥å†…å›ç­”ï¼š{question}"
    )
    
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    
    # åˆ›å»ºé“¾
    chain = prompt | llm | StrOutputParser()
    
    # æ‰§è¡Œ
    result = chain.invoke({
        "role": "Pythonä¸“å®¶",
        "words": 50,
        "question": "ä»€ä¹ˆæ˜¯åˆ—è¡¨æ¨å¯¼å¼ï¼Ÿ"
    })
    
    print(f"å›å¤ï¼š{result}")


def demo_3_multiple_templates():
    """ç¤ºä¾‹3ï¼šå¤šæ¶ˆæ¯æ¨¡æ¿"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3ï¼šå¤šæ¶ˆæ¯æ¨¡æ¿")
    print("="*60)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä½{role}ï¼Œæ“…é•¿{skill}"),
        ("human", "{question}")
    ])
    
    chain = prompt | ChatOpenAI() | StrOutputParser()
    
    result = chain.invoke({
        "role": "æŠ€æœ¯å¯¼å¸ˆ",
        "skill": "ç”¨ç®€å•çš„æ¯”å–»è§£é‡Šå¤æ‚æ¦‚å¿µ",
        "question": "ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ"
    })
    
    print(f"å›å¤ï¼š{result}")


def demo_4_json_output():
    """ç¤ºä¾‹4ï¼šç»“æ„åŒ–è¾“å‡º"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4ï¼šJSONè¾“å‡ºè§£æ")
    print("="*60)
    
    # è¦æ±‚è¾“å‡ºJSONæ ¼å¼
    prompt = ChatPromptTemplate.from_template(
        "è¯·ç”¨JSONæ ¼å¼å›ç­”ä»¥ä¸‹é—®é¢˜ï¼ŒåŒ…å«nameã€ageã€hobbyå­—æ®µï¼š\n"
        "ä»‹ç»ä¸€ä¸ªè™šæ„çš„ç¨‹åºå‘˜è§’è‰²ã€‚\n"
        "åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"
    )
    
    chain = prompt | ChatOpenAI() | JSONOutputParser()
    
    try:
        result = chain.invoke({})
        print(f"è§£æç»“æœï¼š{result}")
        print(f"ç±»å‹ï¼š{type(result)}")
        print(f"å§“åï¼š{result.get('name')}")
    except Exception as e:
        print(f"è§£æå¤±è´¥ï¼š{e}")


def demo_5_streaming():
    """ç¤ºä¾‹5ï¼šæµå¼è¾“å‡º"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹5ï¼šæµå¼è¾“å‡º")
    print("="*60)
    
    prompt = ChatPromptTemplate.from_template(
        "å†™ä¸€é¦–å…³äº{topic}çš„å››è¡Œè¯—"
    )
    
    chain = prompt | ChatOpenAI() | StrOutputParser()
    
    print("è¯—æ­Œï¼ˆæµå¼è¾“å‡ºï¼‰ï¼š\n")
    for chunk in chain.stream({"topic": "äººå·¥æ™ºèƒ½"}):
        print(chunk, end="", flush=True)
    print("\n")


def demo_6_batch():
    """ç¤ºä¾‹6ï¼šæ‰¹å¤„ç†"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹6ï¼šæ‰¹é‡å¤„ç†")
    print("="*60)
    
    prompt = ChatPromptTemplate.from_template(
        "ç”¨ä¸€å¥è¯æè¿°{language}çš„ç‰¹ç‚¹"
    )
    
    chain = prompt | ChatOpenAI() | StrOutputParser()
    
    # æ‰¹é‡æ‰§è¡Œ
    languages = ["Python", "JavaScript", "Go", "Rust"]
    inputs = [{"language": lang} for lang in languages]
    
    results = chain.batch(inputs)
    
    for lang, result in zip(languages, results):
        print(f"{lang}: {result}")


def demo_7_complex_chain():
    """ç¤ºä¾‹7ï¼šå¤æ‚é“¾"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹7ï¼šå¤šæ­¥éª¤é“¾")
    print("="*60)
    
    from langchain.schema.runnable import RunnablePassthrough
    
    # æ­¥éª¤1ï¼šç”Ÿæˆä¸»é¢˜
    topic_chain = (
        ChatPromptTemplate.from_template("ç»™æˆ‘ä¸€ä¸ª{category}ç›¸å…³çš„è¯é¢˜")
        | ChatOpenAI()
        | StrOutputParser()
    )
    
    # æ­¥éª¤2ï¼šåŸºäºä¸»é¢˜å†™å†…å®¹
    content_chain = (
        ChatPromptTemplate.from_template("å†™ä¸€æ®µå…³äº{topic}çš„ä»‹ç»ï¼ˆ50å­—ï¼‰")
        | ChatOpenAI()
        | StrOutputParser()
    )
    
    # ç»„åˆé“¾
    full_chain = {
        "topic": topic_chain
    } | content_chain
    
    result = full_chain.invoke({"category": "äººå·¥æ™ºèƒ½"})
    print(f"ç”Ÿæˆå†…å®¹ï¼š\n{result}")


def demo_8_langchain_vs_native():
    """ç¤ºä¾‹8ï¼šLangChain vs åŸç”ŸAPIå¯¹æ¯”"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹8ï¼šLangChain vs åŸç”ŸAPI")
    print("="*60)
    
    from openai import OpenAI
    import time
    
    # åŸç”ŸAPI
    print("ã€åŸç”ŸAPIæ–¹å¼ã€‘")
    start = time.time()
    
    native_client = OpenAI()
    response = native_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯Pythonä¸“å®¶"},
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ"}
        ]
    )
    native_result = response.choices[0].message.content
    native_time = time.time() - start
    
    print(f"ç»“æœï¼š{native_result[:100]}...")
    print(f"è€—æ—¶ï¼š{native_time:.2f}s")
    
    # LangChain
    print("\nã€LangChainæ–¹å¼ã€‘")
    start = time.time()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯Pythonä¸“å®¶"),
        ("human", "ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ")
    ])
    chain = prompt | ChatOpenAI() | StrOutputParser()
    lc_result = chain.invoke({})
    lc_time = time.time() - start
    
    print(f"ç»“æœï¼š{lc_result[:100]}...")
    print(f"è€—æ—¶ï¼š{lc_time:.2f}s")
    
    print(f"\nä»£ç ç®€æ´åº¦ï¼šLangChainæ›´ä¼˜")
    print(f"å¯è¯»æ€§ï¼šLangChainæ›´ä¼˜")
    print(f"å¯æ‰©å±•æ€§ï¼šLangChainæ›´ä¼˜")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ LangChainåŸºç¡€åŠŸèƒ½æ¼”ç¤º")
    print("="*60)
    
    demo_1_basic_call()
    demo_2_with_template()
    demo_3_multiple_templates()
    demo_4_json_output()
    demo_5_streaming()
    demo_6_batch()
    demo_7_complex_chain()
    demo_8_langchain_vs_native()
    
    print("\n" + "="*60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ æ ¸å¿ƒè¦ç‚¹ï¼š")
    print("1. LangChainä½¿ç”¨ç»„ä»¶åŒ–è®¾è®¡")
    print("2. LCELï¼ˆ|æ“ä½œç¬¦ï¼‰è®©ä»£ç ç®€æ´æ¸…æ™°")
    print("3. è‡ªåŠ¨æ”¯æŒæµå¼ã€æ‰¹å¤„ç†ã€å¼‚æ­¥")
    print("4. æç¤ºè¯æ¨¡æ¿åŒ–ï¼Œæ˜“äºå¤ç”¨")
    print("5. Output Parserè‡ªåŠ¨è§£æè¾“å‡º")
    print("="*60)


if __name__ == "__main__":
    main()
```

---

## ğŸ¯ LangChain vs åŸç”ŸAPI

### ä»£ç å¯¹æ¯”

```python
# ===== ä»»åŠ¡ï¼šç¿»è¯‘+æ€»ç»“ =====

# ã€åŸç”ŸAPIã€‘
from openai import OpenAI
client = OpenAI()

# æ­¥éª¤1ï¼šç¿»è¯‘
response1 = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": f"ç¿»è¯‘æˆè‹±æ–‡ï¼š{chinese_text}"}]
)
english_text = response1.choices[0].message.content

# æ­¥éª¤2ï¼šæ€»ç»“
response2 = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": f"æ€»ç»“ï¼š{english_text}"}]
)
summary = response2.choices[0].message.content

# ã€LangChainã€‘
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

llm = ChatOpenAI()

# ç¿»è¯‘é“¾
translate_chain = (
    ChatPromptTemplate.from_template("ç¿»è¯‘æˆè‹±æ–‡ï¼š{text}")
    | llm
    | StrOutputParser()
)

# æ€»ç»“é“¾
summarize_chain = (
    ChatPromptTemplate.from_template("æ€»ç»“ï¼š{text}")
    | llm
    | StrOutputParser()
)

# ç»„åˆ
full_chain = {"text": translate_chain} | summarize_chain
summary = full_chain.invoke({"text": chinese_text})
```

**å¯¹æ¯”ï¼š**
```
ä»£ç è¡Œæ•°ï¼šåŸç”Ÿ25è¡Œ vs LangChain 15è¡Œ
å¯è¯»æ€§ï¼šLangChainæ›´æ¸…æ™°
å¯å¤ç”¨æ€§ï¼šLangChainç»„ä»¶å¯å•ç‹¬ä½¿ç”¨
é”™è¯¯å¤„ç†ï¼šLangChainå†…ç½®
```

---

## âœ… è¯¾åæ£€éªŒ

å®Œæˆæœ¬è¯¾åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] ç†è§£LangChainçš„æ ¸å¿ƒæ¦‚å¿µ
- [ ] å®‰è£…å’Œé…ç½®LangChain
- [ ] ä½¿ç”¨åŸºç¡€ç»„ä»¶ï¼ˆModelã€Promptã€Parserï¼‰
- [ ] ç†è§£LCELè¯­æ³•
- [ ] åˆ›å»ºç®€å•çš„é“¾
- [ ] å¯¹æ¯”LangChainå’ŒåŸç”ŸAPIçš„ä¼˜åŠ£

---

## ğŸ“ ä¸‹ä¸€è¯¾é¢„å‘Š

**ç¬¬24è¯¾ï¼šPrompt Templateæ·±å…¥ - æ‰“é€ çµæ´»çš„æç¤ºè¯ç³»ç»Ÿ**

ä¸‹ä¸€è¯¾æˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ ï¼š
- Prompt Templateçš„é«˜çº§ç”¨æ³•
- Few-shot Template
- Chat Prompt Template
- è‡ªå®šä¹‰Template
- æç¤ºè¯å·¥ç¨‹æœ€ä½³å®è·µ

**è®©æç¤ºè¯ç®¡ç†æ›´åŠ ä¸“ä¸šï¼**

---

**ğŸ‰ æ­å–œä½ å®Œæˆç¬¬23è¯¾ï¼**

ä½ å·²ç»æ­£å¼è¿›å…¥LangChainçš„ä¸–ç•Œï¼

**è¿›åº¦ï¼š23/165è¯¾ï¼ˆ13.9%å®Œæˆï¼‰** ğŸš€
