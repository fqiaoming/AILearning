![æ¨¡å‹é‡åŒ–ä¼˜åŒ–](./images/quantization.svg)
*å›¾ï¼šæ¨¡å‹é‡åŒ–ä¼˜åŒ–*

# ç¬¬98è¯¾ï¼šåˆ†å¸ƒå¼è®­ç»ƒåŸºç¡€

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŒæ¡å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒæŠ€æœ¯
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šæ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œã€DeepSpeedã€ZeROä¼˜åŒ–
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š95åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ6åˆ†é’Ÿ)
![Qlora](./images/qlora.svg)
*å›¾ï¼šQlora*


### ğŸ¯ å‰è¨€

"ä¸ŠèŠ‚è¯¾æˆ‘ä»¬å­¦ä¹ äº†å•å¡ä¼˜åŒ–æŠ€æœ¯ã€‚

ä½†å¦‚æœä½ æœ‰å¤šå¼ GPUï¼Œæˆ–è€…æ¨¡å‹å®åœ¨å¤ªå¤§ï¼Œå•å¡è£…ä¸ä¸‹æ€ä¹ˆåŠï¼Ÿ

**ç­”æ¡ˆï¼šåˆ†å¸ƒå¼è®­ç»ƒï¼**

**ä¸ºä»€ä¹ˆéœ€è¦åˆ†å¸ƒå¼ï¼Ÿ**

```
åœºæ™¯1ï¼šæ¨¡å‹å¤ªå¤§
â€¢ 70Bæ¨¡å‹ï¼š140GB
â€¢ å•å¼ A100ï¼š80GB
â€¢ æ ¹æœ¬è£…ä¸ä¸‹ï¼

åœºæ™¯2ï¼šè®­ç»ƒå¤ªæ…¢
â€¢ 7Bæ¨¡å‹ï¼Œ10ä¸‡æ•°æ®
â€¢ å•å¡ï¼š3å¤©
â€¢ å¤ªæ…¢äº†ï¼

åœºæ™¯3ï¼šèµ„æºåˆ©ç”¨
â€¢ æœ‰4å¼ 3090é—²ç½®
â€¢ åªç”¨1å¼ å¤ªæµªè´¹

åˆ†å¸ƒå¼è®­ç»ƒè§£å†³æ‰€æœ‰é—®é¢˜ï¼
```

**åˆ†å¸ƒå¼è®­ç»ƒçš„å¨åŠ›ï¼š**

```
ã€é€Ÿåº¦æå‡ã€‘

7Bæ¨¡å‹ï¼Œ1ä¸‡æ¡æ•°æ®ï¼š

å•å¡3090ï¼š
â€¢ è®­ç»ƒæ—¶é—´ï¼š6å°æ—¶

4å¡3090ï¼ˆæ•°æ®å¹¶è¡Œï¼‰ï¼š
â€¢ è®­ç»ƒæ—¶é—´ï¼š1.5å°æ—¶
â€¢ åŠ é€Ÿï¼š4å€ï¼
â€¢ çº¿æ€§åŠ é€Ÿï¼

8å¡A100ï¼š
â€¢ è®­ç»ƒæ—¶é—´ï¼š45åˆ†é’Ÿ
â€¢ åŠ é€Ÿï¼š8å€ï¼

ã€æ¨¡å‹è§„æ¨¡çªç ´ã€‘

70Bæ¨¡å‹å¾®è°ƒï¼š

å•å¡ï¼š
â€¢ âŒ æ— æ³•è®­ç»ƒ

4å¡ï¼ˆæ¨¡å‹å¹¶è¡Œï¼‰ï¼š
â€¢ âœ… å¯ä»¥è®­ç»ƒ
â€¢ æ¯å¡ï¼š35GB

8å¡ï¼ˆZeRO-3ï¼‰ï¼š
â€¢ âœ… è½»æ¾è®­ç»ƒ
â€¢ æ¯å¡ï¼š20GB

çªç ´é™åˆ¶ï¼
```

**åˆ†å¸ƒå¼è®­ç»ƒçš„3ç§æ¨¡å¼ï¼š**

```
ã€æ¨¡å¼1ï¼šæ•°æ®å¹¶è¡Œï¼ˆData Parallelï¼‰ã€‘

åŸç†ï¼š
â€¢ æ¯å¼ å¡å¤åˆ¶å®Œæ•´æ¨¡å‹
â€¢ åˆ†å‰²æ•°æ®åˆ°å„å¡
â€¢ å„å¡ç‹¬ç«‹è®¡ç®—
â€¢ æ±‡æ€»æ¢¯åº¦æ›´æ–°

é€‚åˆï¼š
â€¢ æ¨¡å‹è¾ƒå°
â€¢ æ•°æ®é‡å¤§
â€¢ æœ€å¸¸ç”¨

ä¼˜ç‚¹ï¼š
â€¢ å®ç°ç®€å•
â€¢ çº¿æ€§åŠ é€Ÿ
â€¢ é€šç”¨æ€§å¼º

ç¼ºç‚¹ï¼š
â€¢ æ¯å¡è¦è£…å®Œæ•´æ¨¡å‹
â€¢ å¤§æ¨¡å‹è£…ä¸ä¸‹

ã€æ¨¡å¼2ï¼šæ¨¡å‹å¹¶è¡Œï¼ˆModel Parallelï¼‰ã€‘

åŸç†ï¼š
â€¢ æ¨¡å‹åˆ‡åˆ†åˆ°å„å¡
â€¢ æ•°æ®æµç»æ‰€æœ‰å¡
â€¢ é€å±‚è®¡ç®—

é€‚åˆï¼š
â€¢ æ¨¡å‹å¾ˆå¤§
â€¢ å•å¡è£…ä¸ä¸‹

ä¼˜ç‚¹ï¼š
â€¢ å¯è®­ç»ƒè¶…å¤§æ¨¡å‹
â€¢ çªç ´æ˜¾å­˜é™åˆ¶

ç¼ºç‚¹ï¼š
â€¢ å®ç°å¤æ‚
â€¢ é€šä¿¡å¼€é”€å¤§
â€¢ åŠ é€Ÿä¸ç†æƒ³

ã€æ¨¡å¼3ï¼šæ··åˆå¹¶è¡Œã€‘

åŸç†ï¼š
â€¢ æ•°æ®å¹¶è¡Œ + æ¨¡å‹å¹¶è¡Œ
â€¢ æœ€ä¼˜ç»„åˆ

é€‚åˆï¼š
â€¢ è¶…å¤§æ¨¡å‹
â€¢ å¤šæœºå¤šå¡
â€¢ ä¼ä¸šåœºæ™¯

DeepSpeedå°±æ˜¯æ··åˆå¹¶è¡Œçš„æ°ä½œï¼
```

**æ•°æ®å¹¶è¡Œè¯¦è§£ï¼š**

```
ã€å·¥ä½œæµç¨‹ã€‘

4å¡è®­ç»ƒï¼ŒBatch Size=32ï¼š

Step 1: æ•°æ®åˆ†å‰²
â€¢ GPU0: å¤„ç†æ ·æœ¬1-8
â€¢ GPU1: å¤„ç†æ ·æœ¬9-16
â€¢ GPU2: å¤„ç†æ ·æœ¬17-24
â€¢ GPU3: å¤„ç†æ ·æœ¬25-32

Step 2: å‰å‘ä¼ æ’­
â€¢ å„GPUç‹¬ç«‹è®¡ç®—
â€¢ å¾—åˆ°å„è‡ªçš„loss

Step 3: åå‘ä¼ æ’­
â€¢ å„GPUè®¡ç®—æ¢¯åº¦

Step 4: æ¢¯åº¦æ±‡æ€»ï¼ˆAllReduceï¼‰
â€¢ æ‰€æœ‰GPUçš„æ¢¯åº¦æ±‚å¹³å‡
â€¢ åŒæ­¥åˆ°æ¯å¼ å¡

Step 5: å‚æ•°æ›´æ–°
â€¢ å„GPUç”¨ç›¸åŒæ¢¯åº¦æ›´æ–°
â€¢ ä¿æŒå‚æ•°ä¸€è‡´

æ•ˆæœï¼š
â€¢ ç›¸å½“äºBatch Sizeæ‰©å¤§4å€
â€¢ è®­ç»ƒé€Ÿåº¦æå‡4å€
```

**DeepSpeedï¼šåˆ†å¸ƒå¼è®­ç»ƒç¥å™¨ï¼**

```
ã€ä»€ä¹ˆæ˜¯DeepSpeedï¼Ÿã€‘

å¾®è½¯å¼€æºçš„åˆ†å¸ƒå¼è®­ç»ƒåº“ï¼š
â€¢ è®­ç»ƒè¶…å¤§æ¨¡å‹
â€¢ æè‡´ä¼˜åŒ–
â€¢ ç®€å•æ˜“ç”¨

æ ¸å¿ƒæŠ€æœ¯ï¼š
â€¢ ZeROï¼ˆé›¶å†—ä½™ä¼˜åŒ–ï¼‰
â€¢ 3Då¹¶è¡Œ
â€¢ æ··åˆç²¾åº¦
â€¢ æ¢¯åº¦ç´¯ç§¯

ã€ZeROçš„é©å‘½ã€‘

ä¼ ç»Ÿæ•°æ®å¹¶è¡Œï¼š
â€¢ æ¯å¡éƒ½å­˜å‚¨ï¼š
  - å®Œæ•´æ¨¡å‹æƒé‡
  - å®Œæ•´æ¢¯åº¦
  - å®Œæ•´ä¼˜åŒ–å™¨çŠ¶æ€
â€¢ å†—ä½™ï¼4å¡å°±4å€å†—ä½™

ZeROä¼˜åŒ–ï¼š
â€¢ åˆ†ç‰‡å­˜å‚¨
â€¢ éœ€è¦æ—¶é€šä¿¡
â€¢ æ¶ˆé™¤å†—ä½™

ZeRO-1ï¼ˆä¼˜åŒ–å™¨åˆ†ç‰‡ï¼‰ï¼š
â€¢ ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡
â€¢ èŠ‚çœï¼š4å€ï¼ˆ4å¡ï¼‰

ZeRO-2ï¼ˆæ¢¯åº¦åˆ†ç‰‡ï¼‰ï¼š
â€¢ æ¢¯åº¦+ä¼˜åŒ–å™¨åˆ†ç‰‡
â€¢ èŠ‚çœï¼š8å€

ZeRO-3ï¼ˆå‚æ•°åˆ†ç‰‡ï¼‰ï¼š
â€¢ å‚æ•°+æ¢¯åº¦+ä¼˜åŒ–å™¨å…¨åˆ†ç‰‡
â€¢ èŠ‚çœï¼šNå€ï¼ˆNå¡ï¼‰
â€¢ å¯è®­ç»ƒåƒäº¿çº§æ¨¡å‹ï¼

æ•ˆæœéœ‡æ’¼ï¼
```

**å®é™…æ•ˆæœå¯¹æ¯”ï¼š**

```
ã€13Bæ¨¡å‹å¾®è°ƒã€‘

å•å¡ï¼ˆé‡åŒ–+ä¼˜åŒ–ï¼‰ï¼š
â€¢ æ˜¾å­˜ï¼š20GB
â€¢ æ—¶é—´ï¼š6å°æ—¶
â€¢ å¯è¡Œä½†æ…¢

4å¡æ•°æ®å¹¶è¡Œï¼š
â€¢ æ¯å¡æ˜¾å­˜ï¼š20GB
â€¢ æ—¶é—´ï¼š1.5å°æ—¶
â€¢ å¿«4å€

4å¡DeepSpeed ZeRO-2ï¼š
â€¢ æ¯å¡æ˜¾å­˜ï¼š12GB
â€¢ æ—¶é—´ï¼š2å°æ—¶
â€¢ çœæ˜¾å­˜ï¼Œç•¥å¿«

ã€70Bæ¨¡å‹å¾®è°ƒã€‘

å•å¡ï¼š
â€¢ âŒ å®Œå…¨æ— æ³•è®­ç»ƒ

4å¡æ•°æ®å¹¶è¡Œï¼š
â€¢ âŒ æ¯å¡éœ€è¦140GBï¼Œä¸å¤Ÿ

4å¡ZeRO-2ï¼š
â€¢ âŒ æ¯å¡éœ€è¦40GB+ï¼Œå‹‰å¼º

8å¡ZeRO-3ï¼š
â€¢ âœ… æ¯å¡20GBï¼Œå®Œç¾ï¼
â€¢ 4bité‡åŒ–ï¼šæ¯å¡10GB

ZeRO-3è®©ä¸å¯èƒ½å˜å¯èƒ½ï¼
```

**PyTorch DDP vs DeepSpeedï¼š**

```
ã€PyTorch DDPã€‘

ä¼˜ç‚¹ï¼š
â€¢ PyTorchåŸç”Ÿæ”¯æŒ
â€¢ ç¨³å®šå¯é 
â€¢ æ–‡æ¡£å®Œå–„

ç¼ºç‚¹ï¼š
â€¢ åªæœ‰æ•°æ®å¹¶è¡Œ
â€¢ æ˜¾å­˜ä¼˜åŒ–æœ‰é™
â€¢ å¤§æ¨¡å‹åƒåŠ›

é€‚åˆï¼š
â€¢ ä¸­å°æ¨¡å‹ï¼ˆ<13Bï¼‰
â€¢ ç®€å•åœºæ™¯
â€¢ å¿«é€ŸåŸå‹

ã€DeepSpeedã€‘

ä¼˜ç‚¹ï¼š
â€¢ ZeROä¼˜åŒ–
â€¢ æ”¯æŒè¶…å¤§æ¨¡å‹
â€¢ åŠŸèƒ½ä¸°å¯Œ

ç¼ºç‚¹ï¼š
â€¢ é…ç½®å¤æ‚
â€¢ å­¦ä¹ æ›²çº¿

é€‚åˆï¼š
â€¢ å¤§æ¨¡å‹ï¼ˆ13B+ï¼‰
â€¢ è¿½æ±‚æè‡´
â€¢ ç”Ÿäº§ç¯å¢ƒ

æ¨èï¼š
â€¢ 13Bä»¥ä¸‹ï¼šDDP
â€¢ 13Bä»¥ä¸Šï¼šDeepSpeed
```

**Accelerateï¼šç®€åŒ–åˆ†å¸ƒå¼**

```
ã€Hugging Face Accelerateã€‘

ç‰¹ç‚¹ï¼š
â€¢ ç»Ÿä¸€æ¥å£
â€¢ è‡ªåŠ¨é€‚é…DDP/DeepSpeed
â€¢ é…ç½®ç®€å•

ä»£ç å¯¹æ¯”ï¼š

åŸç”ŸPyTorchï¼š
â€¢ éœ€è¦æ‰‹åŠ¨è®¾ç½®rankã€world_size
â€¢ éœ€è¦æ‰‹åŠ¨åŒ…è£…æ¨¡å‹
â€¢ éœ€è¦æ‰‹åŠ¨æ•°æ®åˆ†ç‰‡
â€¢ 100+è¡Œä»£ç 

Accelerateï¼š
â€¢ è‡ªåŠ¨å¤„ç†æ‰€æœ‰ç»†èŠ‚
â€¢ 10è¡Œä»£ç 
â€¢ æ”¯æŒå•å¡ã€å¤šå¡ã€å¤šæœº

from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, dataloader = accelerator.prepare(
    model, optimizer, dataloader
)

# è®­ç»ƒå¾ªç¯ä¸å˜ï¼
for batch in dataloader:
    outputs = model(batch)
    loss = outputs.loss
    accelerator.backward(loss)
    optimizer.step()

å®Œæˆï¼

ç¥å™¨ï¼
```

**å¸¸è§é—®é¢˜ï¼š**

```
Q1: åˆ†å¸ƒå¼è®­ç»ƒä¸€å®šæ›´å¿«å—ï¼Ÿ
A: ä¸ä¸€å®š
   â€¢ é€šä¿¡å¼€é”€
   â€¢ å°æ¨¡å‹å¯èƒ½æ›´æ…¢
   â€¢ å»ºè®®7B+æ‰ç”¨

Q2: éœ€è¦ä»€ä¹ˆç¡¬ä»¶ï¼Ÿ
A: 
   â€¢ åŒä¸€å°æœºå™¨çš„å¤šGPU
   â€¢ æˆ–å¤šå°æœºå™¨ï¼ˆéœ€ç½‘ç»œï¼‰
   â€¢ æ˜¾å¡æœ€å¥½åŒå‹å·

Q3: ä¼šæ›´éš¾è°ƒè¯•å—ï¼Ÿ
A: æ˜¯çš„
   â€¢ å¤šè¿›ç¨‹
   â€¢ åŒæ­¥é—®é¢˜
   â€¢ å»ºè®®å…ˆå•å¡è°ƒé€š

Q4: æˆæœ¬æ€ä¹ˆç®—ï¼Ÿ
A: 
   â€¢ 4å¡ä¸æ˜¯4å€æˆæœ¬
   â€¢ å› ä¸ºæ—¶é—´ç¼©çŸ­
   â€¢ æ€»æˆæœ¬å¯èƒ½æ›´ä½
```

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦å¸¦ä½ ï¼š**

**ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®å¹¶è¡Œå®æˆ˜**
- PyTorch DDP
- å®Œæ•´ç¤ºä¾‹
- æ€§èƒ½æµ‹è¯•

**ç¬¬äºŒéƒ¨åˆ†ï¼šDeepSpeedå…¥é—¨**
- ZeROé…ç½®
- è®­ç»ƒæµç¨‹
- æ•ˆæœå¯¹æ¯”

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šAccelerateä½¿ç”¨**
- ç®€åŒ–ä»£ç 
- è‡ªåŠ¨é€‚é…
- æœ€ä½³å®è·µ

**ç¬¬å››éƒ¨åˆ†ï¼šæ€§èƒ½ä¼˜åŒ–**
- é€šä¿¡ä¼˜åŒ–
- è´Ÿè½½å‡è¡¡
- é¿å‘æŒ‡å—

å­¦å®Œè¿™ä¸€è¯¾ï¼Œçªç ´å•å¡é™åˆ¶ï¼

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ï¼"

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šPyTorch DDPæ•°æ®å¹¶è¡Œ

### ä¸€ã€DDPåŸºç¡€å®ç°

```python
import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, DistributedSampler
import os

class DDPTrainer:
    """DDPè®­ç»ƒå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ"""
        
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒå¤šGPU
        if not torch.cuda.is_available():
            print("éœ€è¦GPU")
            return
        
        # ä»ç¯å¢ƒå˜é‡è·å–rankå’Œworld_size
        # é€šå¸¸ç”±torchrunè‡ªåŠ¨è®¾ç½®
        self.rank = int(os.environ.get("RANK", 0))
        self.local_rank = int(os.environ.get("LOCAL_RANK", 0))
        self.world_size = int(os.environ.get("WORLD_SIZE", 1))
        
        print(f"Rank {self.rank}/{self.world_size} åˆå§‹åŒ–...")
    
    def setup(self):
        """è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒ"""
        
        if self.world_size > 1:
            # åˆå§‹åŒ–è¿›ç¨‹ç»„
            dist.init_process_group(
                backend="nccl",  # NVIDIA GPUç”¨nccl
                init_method="env://",
                world_size=self.world_size,
                rank=self.rank
            )
            
            # è®¾ç½®å½“å‰è®¾å¤‡
            torch.cuda.set_device(self.local_rank)
            
            print(f"Rank {self.rank}: åˆ†å¸ƒå¼ç¯å¢ƒå·²è®¾ç½®")
    
    def cleanup(self):
        """æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ"""
        if self.world_size > 1:
            dist.destroy_process_group()
    
    def train(self, model, train_dataset, epochs=3, batch_size=32):
        """DDPè®­ç»ƒ"""
        
        print(f"\nRank {self.rank}: å¼€å§‹è®­ç»ƒ")
        
        # åŒ…è£…æ¨¡å‹ä¸ºDDP
        if self.world_size > 1:
            model = model.to(self.local_rank)
            model = DDP(model, device_ids=[self.local_rank])
        else:
            model = model.cuda()
        
        # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
        if self.world_size > 1:
            sampler = DistributedSampler(
                train_dataset,
                num_replicas=self.world_size,
                rank=self.rank,
                shuffle=True
            )
        else:
            sampler = None
        
        # åˆ›å»ºDataLoader
        dataloader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            sampler=sampler,
            num_workers=4,
            pin_memory=True
        )
        
        # ä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
        
        # è®­ç»ƒå¾ªç¯
        model.train()
        for epoch in range(epochs):
            if sampler is not None:
                sampler.set_epoch(epoch)  # é‡è¦ï¼ä¿è¯æ¯ä¸ªepochæ•°æ®ä¸åŒ
            
            epoch_loss = 0
            for batch_idx, batch in enumerate(dataloader):
                # ç§»åˆ°GPU
                inputs = batch['input_ids'].to(self.local_rank)
                labels = batch['labels'].to(self.local_rank)
                
                # å‰å‘ä¼ æ’­
                outputs = model(inputs, labels=labels)
                loss = outputs.loss
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                
                if batch_idx % 10 == 0 and self.rank == 0:
                    print(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            avg_loss = epoch_loss / len(dataloader)
            if self.rank == 0:
                print(f"Epoch {epoch} å¹³å‡Loss: {avg_loss:.4f}")
        
        # åªåœ¨rank 0ä¿å­˜æ¨¡å‹
        if self.rank == 0:
            if self.world_size > 1:
                # DDPåŒ…è£…çš„æ¨¡å‹éœ€è¦ç”¨.moduleè®¿é—®
                torch.save(model.module.state_dict(), "model_ddp.pt")
            else:
                torch.save(model.state_dict(), "model_ddp.pt")
            print("æ¨¡å‹å·²ä¿å­˜")

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆéœ€è¦é€šè¿‡torchrunå¯åŠ¨ï¼‰
"""
# å¯åŠ¨å‘½ä»¤ï¼š
# torchrun --nproc_per_node=4 train_script.py

trainer = DDPTrainer()
trainer.setup()

# åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
model = YourModel()
dataset = YourDataset()

# è®­ç»ƒ
trainer.train(model, dataset)

# æ¸…ç†
trainer.cleanup()
"""

print("DDPè®­ç»ƒå™¨å·²å°±ç»ª")
print("\nå¯åŠ¨æ–¹å¼ï¼š")
print("å•GPU: python train.py")
print("å¤šGPU: torchrun --nproc_per_node=4 train.py")
```

### äºŒã€å®ç”¨çš„DDPå¯åŠ¨è„šæœ¬

```python
import subprocess
import sys

def launch_ddp_training(
    script_path: str,
    num_gpus: int = 4,
    master_port: int = 29500
):
    """
    å¯åŠ¨DDPè®­ç»ƒ
    
    Args:
        script_path: è®­ç»ƒè„šæœ¬è·¯å¾„
        num_gpus: GPUæ•°é‡
        master_port: ä¸»èŠ‚ç‚¹ç«¯å£
    """
    
    print("="*60)
    print("å¯åŠ¨DDPè®­ç»ƒ")
    print("="*60)
    
    print(f"\né…ç½®:")
    print(f"  GPUæ•°é‡: {num_gpus}")
    print(f"  è®­ç»ƒè„šæœ¬: {script_path}")
    print(f"  ä¸»ç«¯å£: {master_port}")
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        "torchrun",
        f"--nproc_per_node={num_gpus}",
        f"--master_port={master_port}",
        script_path
    ]
    
    print(f"\næ‰§è¡Œå‘½ä»¤:")
    print(" ".join(cmd))
    
    # æ‰§è¡Œ
    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        print(f"è®­ç»ƒå¤±è´¥: {e}")
        sys.exit(1)
    
    print("\nè®­ç»ƒå®Œæˆï¼")

# ç¤ºä¾‹
# launch_ddp_training("train.py", num_gpus=4)
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šDeepSpeedå®æˆ˜

### ä¸€ã€DeepSpeedé…ç½®

```python
import json
from pathlib import Path

class DeepSpeedConfig:
    """DeepSpeedé…ç½®ç”Ÿæˆå™¨"""
    
    @staticmethod
    def create_zero_stage_1_config():
        """ZeRO Stage 1é…ç½®ï¼ˆä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡ï¼‰"""
        
        config = {
            "train_batch_size": 32,
            "train_micro_batch_size_per_gpu": 4,
            "gradient_accumulation_steps": 2,
            
            "optimizer": {
                "type": "AdamW",
                "params": {
                    "lr": 2e-5,
                    "betas": [0.9, 0.999],
                    "eps": 1e-8,
                    "weight_decay": 0.01
                }
            },
            
            "scheduler": {
                "type": "WarmupLR",
                "params": {
                    "warmup_min_lr": 0,
                    "warmup_max_lr": 2e-5,
                    "warmup_num_steps": 100
                }
            },
            
            "fp16": {
                "enabled": True,
                "loss_scale": 0,
                "loss_scale_window": 1000,
                "hysteresis": 2,
                "min_loss_scale": 1
            },
            
            "zero_optimization": {
                "stage": 1,  # Stage 1ï¼šä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡
                "allgather_partitions": True,
                "allgather_bucket_size": 5e8,
                "reduce_scatter": True,
                "reduce_bucket_size": 5e8,
                "overlap_comm": True,
                "contiguous_gradients": True
            }
        }
        
        return config
    
    @staticmethod
    def create_zero_stage_2_config():
        """ZeRO Stage 2é…ç½®ï¼ˆæ¢¯åº¦+ä¼˜åŒ–å™¨åˆ†ç‰‡ï¼‰"""
        
        config = DeepSpeedConfig.create_zero_stage_1_config()
        
        # å‡çº§åˆ°Stage 2
        config["zero_optimization"]["stage"] = 2
        
        return config
    
    @staticmethod
    def create_zero_stage_3_config():
        """ZeRO Stage 3é…ç½®ï¼ˆå…¨åˆ†ç‰‡ï¼‰"""
        
        config = DeepSpeedConfig.create_zero_stage_2_config()
        
        # å‡çº§åˆ°Stage 3
        config["zero_optimization"].update({
            "stage": 3,
            "stage3_max_live_parameters": 1e9,
            "stage3_max_reuse_distance": 1e9,
            "stage3_prefetch_bucket_size": 5e8,
            "stage3_param_persistence_threshold": 1e6,
            "sub_group_size": 1e9,
            "reduce_bucket_size": "auto",
            "stage3_gather_16bit_weights_on_model_save": True
        })
        
        return config
    
    @staticmethod
    def save_config(config: dict, path: str = "ds_config.json"):
        """ä¿å­˜é…ç½®"""
        
        with open(path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"DeepSpeedé…ç½®å·²ä¿å­˜åˆ°: {path}")
    
    @staticmethod
    def print_config_comparison():
        """æ‰“å°é…ç½®å¯¹æ¯”"""
        
        print("="*60)
        print("DeepSpeed ZeROé…ç½®å¯¹æ¯”")
        print("="*60)
        
        configs = {
            "Stage 1": {
                "ä¼˜åŒ–": "ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡",
                "æ˜¾å­˜èŠ‚çœ": "~4å€ï¼ˆ4å¡ï¼‰",
                "é€šä¿¡å¼€é”€": "ä½",
                "é€‚åˆ": "ä¸­å°æ¨¡å‹"
            },
            "Stage 2": {
                "ä¼˜åŒ–": "æ¢¯åº¦+ä¼˜åŒ–å™¨åˆ†ç‰‡",
                "æ˜¾å­˜èŠ‚çœ": "~8å€ï¼ˆ4å¡ï¼‰",
                "é€šä¿¡å¼€é”€": "ä¸­",
                "é€‚åˆ": "å¤§æ¨¡å‹"
            },
            "Stage 3": {
                "ä¼˜åŒ–": "å‚æ•°+æ¢¯åº¦+ä¼˜åŒ–å™¨å…¨åˆ†ç‰‡",
                "æ˜¾å­˜èŠ‚çœ": "~Nå€ï¼ˆNå¡ï¼‰",
                "é€šä¿¡å¼€é”€": "é«˜",
                "é€‚åˆ": "è¶…å¤§æ¨¡å‹"
            }
        }
        
        print(f"\n{'Stage':<15} {'ä¼˜åŒ–å†…å®¹':<25} {'æ˜¾å­˜èŠ‚çœ':<15} {'é€šä¿¡å¼€é”€':<10} {'é€‚åˆ'}")
        print("-"*80)
        
        for stage, info in configs.items():
            print(f"{stage:<15} {info['ä¼˜åŒ–']:<25} {info['æ˜¾å­˜èŠ‚çœ']:<15} "
                  f"{info['é€šä¿¡å¼€é”€']:<10} {info['é€‚åˆ']}")

# æ¼”ç¤º
config_gen = DeepSpeedConfig()

# ç”Ÿæˆå„é˜¶æ®µé…ç½®
config_1 = config_gen.create_zero_stage_1_config()
config_gen.save_config(config_1, "ds_config_stage1.json")

config_2 = config_gen.create_zero_stage_2_config()
config_gen.save_config(config_2, "ds_config_stage2.json")

config_3 = config_gen.create_zero_stage_3_config()
config_gen.save_config(config_3, "ds_config_stage3.json")

# æ‰“å°å¯¹æ¯”
config_gen.print_config_comparison()
```

### äºŒã€ä½¿ç”¨DeepSpeedè®­ç»ƒ

```python
import deepspeed
from transformers import AutoModelForCausalLM, AutoTokenizer

class DeepSpeedTrainer:
    """DeepSpeedè®­ç»ƒå™¨"""
    
    def __init__(self, model_name: str, ds_config_path: str):
        """
        åˆå§‹åŒ–
        
        Args:
            model_name: æ¨¡å‹åç§°
            ds_config_path: DeepSpeedé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.model_name = model_name
        self.ds_config_path = ds_config_path
    
    def train(self, train_dataset):
        """è®­ç»ƒ"""
        
        print("="*60)
        print("DeepSpeedè®­ç»ƒ")
        print("="*60)
        
        # åŠ è½½æ¨¡å‹
        print("\n1. åŠ è½½æ¨¡å‹...")
        model = AutoModelForCausalLM.from_pretrained(self.model_name)
        tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        
        # åŠ è½½é…ç½®
        print("\n2. åŠ è½½DeepSpeedé…ç½®...")
        with open(self.ds_config_path, 'r') as f:
            ds_config = json.load(f)
        
        # åˆå§‹åŒ–DeepSpeed
        print("\n3. åˆå§‹åŒ–DeepSpeed...")
        model_engine, optimizer, _, _ = deepspeed.initialize(
            model=model,
            config=ds_config
        )
        
        print(f"   ZeRO Stage: {ds_config['zero_optimization']['stage']}")
        
        # è®­ç»ƒå¾ªç¯
        print("\n4. å¼€å§‹è®­ç»ƒ...")
        model_engine.train()
        
        for epoch in range(3):
            for batch in train_dataset:
                # å‰å‘ä¼ æ’­
                outputs = model_engine(
                    input_ids=batch['input_ids'],
                    labels=batch['labels']
                )
                loss = outputs.loss
                
                # åå‘ä¼ æ’­ï¼ˆDeepSpeedç®¡ç†ï¼‰
                model_engine.backward(loss)
                model_engine.step()
                
                print(f"Epoch {epoch}, Loss: {loss.item():.4f}")
        
        # ä¿å­˜æ¨¡å‹
        print("\n5. ä¿å­˜æ¨¡å‹...")
        model_engine.save_checkpoint("./checkpoint")
        
        print("\nè®­ç»ƒå®Œæˆï¼")

# ä½¿ç”¨ç¤ºä¾‹
"""
# å‘½ä»¤è¡Œå¯åŠ¨ï¼š
deepspeed --num_gpus=4 train_script.py --deepspeed ds_config.json
"""

print("DeepSpeedè®­ç»ƒå™¨å·²å°±ç»ª")
```

---

## ğŸ¯ ç¬¬ä¸‰éƒ¨åˆ†ï¼šAccelerateç®€åŒ–æ–¹æ¡ˆ

### ä¸€ã€Accelerateç»Ÿä¸€æ¥å£

```python
from accelerate import Accelerator
from accelerate.utils import DistributedDataParallelKwargs
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

class AccelerateTrainer:
    """Accelerateè®­ç»ƒå™¨ï¼ˆè‡ªåŠ¨é€‚é…å•å¡/å¤šå¡/DeepSpeedï¼‰"""
    
    def __init__(self, model_name: str):
        """
        åˆå§‹åŒ–
        
        Args:
            model_name: æ¨¡å‹åç§°
        """
        self.model_name = model_name
        
        # åˆå§‹åŒ–Acceleratorï¼ˆè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒï¼‰
        self.accelerator = Accelerator(
            mixed_precision="fp16",  # æ··åˆç²¾åº¦
            gradient_accumulation_steps=4,
        )
        
        print(f"Acceleratoråˆå§‹åŒ–å®Œæˆ")
        print(f"  è®¾å¤‡: {self.accelerator.device}")
        print(f"  è¿›ç¨‹æ•°: {self.accelerator.num_processes}")
        print(f"  æ··åˆç²¾åº¦: {self.accelerator.mixed_precision}")
    
    def train(self, train_dataset, epochs=3, batch_size=4):
        """è®­ç»ƒï¼ˆè‡ªåŠ¨åˆ†å¸ƒå¼ï¼‰"""
        
        print("\n" + "="*60)
        print("Accelerateè®­ç»ƒ")
        print("="*60)
        
        # åŠ è½½æ¨¡å‹å’Œtokenizer
        print("\n1. åŠ è½½æ¨¡å‹...")
        model = AutoModelForCausalLM.from_pretrained(self.model_name)
        tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        
        # åˆ›å»ºDataLoader
        print("\n2. å‡†å¤‡æ•°æ®...")
        dataloader = torch.utils.data.DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True
        )
        
        # ä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
        
        # Accelerateå‡†å¤‡ï¼ˆè‡ªåŠ¨åˆ†å¸ƒå¼åŒ…è£…ï¼‰
        print("\n3. Accelerateå‡†å¤‡...")
        model, optimizer, dataloader = self.accelerator.prepare(
            model, optimizer, dataloader
        )
        
        # è®­ç»ƒå¾ªç¯ï¼ˆå’Œå•å¡ä»£ç å®Œå…¨ä¸€æ ·ï¼ï¼‰
        print("\n4. å¼€å§‹è®­ç»ƒ...")
        model.train()
        
        for epoch in range(epochs):
            epoch_loss = 0
            
            for batch_idx, batch in enumerate(dataloader):
                # å‰å‘ä¼ æ’­
                outputs = model(
                    input_ids=batch['input_ids'],
                    labels=batch['labels']
                )
                loss = outputs.loss
                
                # åå‘ä¼ æ’­ï¼ˆAccelerateè‡ªåŠ¨å¤„ç†æ¢¯åº¦ç´¯ç§¯ï¼‰
                self.accelerator.backward(loss)
                
                optimizer.step()
                optimizer.zero_grad()
                
                epoch_loss += loss.item()
                
                if batch_idx % 10 == 0:
                    self.accelerator.print(
                        f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}"
                    )
            
            avg_loss = epoch_loss / len(dataloader)
            self.accelerator.print(f"Epoch {epoch} å¹³å‡Loss: {avg_loss:.4f}")
        
        # ä¿å­˜æ¨¡å‹ï¼ˆAccelerateè‡ªåŠ¨å¤„ç†ï¼‰
        print("\n5. ä¿å­˜æ¨¡å‹...")
        self.accelerator.wait_for_everyone()
        unwrapped_model = self.accelerator.unwrap_model(model)
        unwrapped_model.save_pretrained(
            "./model_output",
            is_main_process=self.accelerator.is_main_process,
            save_function=self.accelerator.save,
        )
        
        self.accelerator.print("è®­ç»ƒå®Œæˆï¼")

# ä½¿ç”¨ç¤ºä¾‹
"""
# å•GPUï¼š
python train.py

# å¤šGPUï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ï¼š
accelerate launch --num_processes=4 train.py

# ä½¿ç”¨DeepSpeedï¼š
accelerate launch --config_file accelerate_config.yaml train.py
"""

print("Accelerateè®­ç»ƒå™¨å·²å°±ç»ª")
print("\nä¼˜åŠ¿ï¼š")
print("  â€¢ ä»£ç å’Œå•å¡å®Œå…¨ä¸€æ ·")
print("  â€¢ è‡ªåŠ¨é€‚é…å•å¡/å¤šå¡")
print("  â€¢ æ”¯æŒDeepSpeed")
print("  â€¢ ç®€å•æ˜“ç”¨")
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šDDPå®æˆ˜
ä½¿ç”¨DDPè®­ç»ƒä¸€ä¸ªå°æ¨¡å‹

### ç»ƒä¹ 2ï¼šDeepSpeedé…ç½®
åˆ›å»ºZeROä¸åŒé˜¶æ®µçš„é…ç½®

### ç»ƒä¹ 3ï¼šæ€§èƒ½å¯¹æ¯”
å¯¹æ¯”å•å¡ã€DDPã€DeepSpeedçš„æ€§èƒ½

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **æ•°æ®å¹¶è¡Œ**
   - æœ€å¸¸ç”¨
   - çº¿æ€§åŠ é€Ÿ
   - PyTorch DDP

2. **DeepSpeed ZeRO**
   - Stage 1-3
   - æ¶ˆé™¤å†—ä½™
   - è®­ç»ƒè¶…å¤§æ¨¡å‹

3. **Accelerate**
   - ç»Ÿä¸€æ¥å£
   - è‡ªåŠ¨é€‚é…
   - æ¨èä½¿ç”¨

4. **é€‰æ‹©ç­–ç•¥**
   - <13B: DDP
   - 13B-70B: ZeRO-2
   - >70B: ZeRO-3

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬99è¯¾ï¼šè®­ç»ƒç›‘æ§ä¸è°ƒè¯•æŠ€å·§**

- TensorBoard
- WandB
- æ—¥å¿—åˆ†æ
- è°ƒè¯•æŠ€å·§

**æŒæ§è®­ç»ƒå…¨æµç¨‹ï¼** ğŸ”¥

---

**ğŸ’ª è®°ä½ï¼šåˆ†å¸ƒå¼è®­ç»ƒçªç ´å•å¡é™åˆ¶ï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
