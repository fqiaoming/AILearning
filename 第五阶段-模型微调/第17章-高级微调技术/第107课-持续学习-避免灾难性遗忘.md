![高级微调技术](./images/advanced_ft.svg)
*图：高级微调技术*

# 第107课：持续学习-避免灾难性遗忘

> **本课目标**：掌握持续学习技术，让模型不断进化而不遗忘
> 
> **核心技能**：灾难性遗忘、EWC算法、增量学习、终身学习
> 
> **学习时长**：90分钟

---

## 📖 口播文案（7分钟）
![Lora](./images/lora.svg)
*图：Lora*


### 🎯 前言

"前面我们学习了各种微调技术。

但有个致命问题：

**模型会忘记！**

**灾难性遗忘（Catastrophic Forgetting）**

**真实场景：**

```
你训练了一个客服助手：
• 版本1：擅长售前咨询
• 效果：优秀（95%准确率）

3个月后，业务扩展：
• 需要增加售后服务能力
• 收集新数据，继续微调

结果：
• 售后服务：优秀（94%）
• 售前咨询：崩溃（30%）❌

模型把之前的知识忘光了！
```

**这就是灾难性遗忘！**

**更多例子：**

```
【例子1：语言模型】

原本：
• 会英文
• 会中文

学习日语后：
• 会日语 ✅
• 英文变差 ❌
• 中文忘记 ❌

【例子2：多任务】

原本：
• 会翻译
• 会总结

学习代码生成后：
• 会代码 ✅
• 翻译变差 ❌
• 总结遗忘 ❌

【例子3：领域迁移】

原本：
• 通用对话能力强

学习医疗领域后：
• 医疗专业 ✅
• 通用能力下降 ❌
```

**为什么会遗忘？**

```
【神经网络的天性】

训练新任务：
• 更新模型参数
• 原来的参数被覆盖
• 旧知识丢失

就像：
• 用铅笔写字
• 擦掉重写
• 原来的字消失了

根本原因：
• 参数固定
• 新旧任务共享参数
• 新任务优化破坏旧任务
```

**持续学习（Continual Learning）**

**目标：不断学习新知识，同时保留旧知识**

```
理想效果：

学习任务1 → 会任务1
学习任务2 → 会任务1 + 任务2
学习任务3 → 会任务1 + 任务2 + 任务3
...

就像人类：
• 学新知识
• 不忘旧知识
• 不断积累
```

**核心技术：**

```
【方法1：正则化方法】

代表：EWC（Elastic Weight Consolidation）

核心思想：
• 识别重要参数
• 限制重要参数变化
• 允许不重要参数变化

效果：
• 保留旧知识
• 学习新知识
• 平衡最好

【方法2：重放方法】

代表：Experience Replay

核心思想：
• 保存少量旧数据
• 新旧数据混合训练
• 持续复习旧知识

效果：
• 简单有效
• 但需要存储旧数据

【方法3：动态架构】

代表：Progressive Neural Networks

核心思想：
• 为新任务添加新模块
• 旧模块冻结
• 新模块连接旧模块

效果：
• 完全避免遗忘
• 但模型越来越大

【方法4：知识蒸馏】

代表：Learning without Forgetting

核心思想：
• 旧模型作为教师
• 新模型学习新任务
• 同时模仿旧模型输出

效果：
• 不需要旧数据
• 效果良好
```

**EWC算法详解：**

```
【原理】

Fisher信息矩阵：
• 衡量参数重要性
• 重要参数：对旧任务影响大
• 不重要参数：影响小

损失函数：
L = L_new + λ Σ F_i (θ_i - θ*_i)^2

含义：
• L_new：新任务损失
• 第二项：限制重要参数变化
• F_i：参数i的重要性
• θ*_i：旧任务的参数值
• λ：平衡系数

效果：
• 重要参数：不能动太多
• 不重要参数：可以大幅调整
• 平衡新旧任务

【直觉理解】

就像保护文物：
• 重要文物：严格保护
• 普通物品：随意处理

模型参数也一样：
• 重要参数：小心调整
• 普通参数：放心更新
```

**实际效果：**

```
【实验：顺序学习3个任务】

方案1：普通微调
• 任务1准确率：95% → 30% ❌
• 任务2准确率：- → 92% → 35% ❌
• 任务3准确率：- → - → 90% ✅
• 平均：51.7%

方案2：EWC
• 任务1准确率：95% → 87% → 85% ✅
• 任务2准确率：- → 92% → 88% ✅
• 任务3准确率：- → - → 90% ✅
• 平均：87.7%

提升：70%！
```

**实战应用场景：**

```
场景1：版本迭代
• V1.0：基础功能
• V2.0：增加新功能
• V3.0：再增加功能
→ 用EWC保持旧功能

场景2：领域扩展
• 先学通用知识
• 再学医疗
• 再学法律
→ 用重放保持通用能力

场景3：个性化
• 基础模型
• 为用户A定制
• 为用户B定制
→ 用知识蒸馏保持基础能力

场景4：增量学习
• 今天学100条
• 明天学100条
• 后天学100条
→ 用正则化避免遗忘
```

**挑战：**

```
挑战1：计算成本
• EWC需要计算Fisher矩阵
• 计算量大
• 存储也大

挑战2：效果权衡
• 完全不忘 vs 学新知识
• 需要平衡
• λ参数难调

挑战3：任务数量
• 学很多任务
• 限制越来越多
• 最终可能学不动

挑战4：任务冲突
• 新旧任务冲突
• 无法同时满足
• 必须取舍
```

**实用建议：**

```
【简单场景】
• 任务不多（<5个）
• 有旧数据
→ 用重放方法（最简单）

【中等场景】
• 任务较多（5-10个）
• 数据有限
→ 用EWC（效果好）

【复杂场景】
• 任务很多（>10个）
• 持续学习
→ 组合方法（EWC + 重放）

【大模型场景】
• 参数量巨大
• 计算受限
→ LoRA + EWC（高效）
```

**今天这一课，我要带你：**

**第一部分：灾难性遗忘**
- 现象分析
- 原因剖析
- 影响评估

**第二部分：EWC算法**
- 原理详解
- 数学推导
- 完整实现

**第三部分：其他方法**
- 重放方法
- 动态架构
- 知识蒸馏

**第四部分：实战应用**
- 增量微调
- 版本管理
- 最佳实践

学完这一课，让你的模型持续进化！

准备好了吗？让我们开始！"

---

## 📚 第一部分：灾难性遗忘详解

### 一、遗忘现象演示

```python
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

class ForgettingDemo:
    """灾难性遗忘演示"""
    
    @staticmethod
    def demonstrate_forgetting():
        """演示灾难性遗忘"""
        
        print("="*60)
        print("灾难性遗忘演示")
        print("="*60)
        
        print("""
【场景】

有一个简单分类器：
• 输入：2D点
• 输出：类别

任务A：分类红色和蓝色点
任务B：分类绿色和黄色点

【实验流程】

1. 在任务A上训练
   → 准确率：95%

2. 在任务B上训练（不用EWC）
   → 任务B准确率：94%
   → 任务A准确率：32% ❌（遗忘）

3. 在任务B上训练（用EWC）
   → 任务B准确率：92%
   → 任务A准确率：88% ✅（保持）

【关键发现】

不用EWC：
• 新任务学得好
• 旧任务忘得快
• 总体效果差

用EWC：
• 新任务略差
• 旧任务保持好
• 总体效果好

结论：EWC平衡新旧任务！
        """)
        
        # 模拟准确率变化
        print("\n准确率变化曲线：")
        print("\n不使用EWC：")
        print("  任务A: 95% → 32% (下降63%)")
        print("  任务B: 0% → 94%")
        print("  平均: 47.5% → 63%")
        
        print("\n使用EWC (λ=1000)：")
        print("  任务A: 95% → 88% (下降7%)")
        print("  任务B: 0% → 92%")
        print("  平均: 47.5% → 90%")
        
        print("\n提升：42.9%！")

# 演示
demo = ForgettingDemo()
demo.demonstrate_forgetting()
```

---

## 💻 第二部分：EWC算法实现

### 一、完整EWC实现

```python
class EWC:
    """Elastic Weight Consolidation"""
    
    def __init__(self, model, dataset, lambda_: float = 1000):
        """
        初始化EWC
        
        Args:
            model: PyTorch模型
            dataset: 旧任务数据集
            lambda_: 正则化强度
        """
        self.model = model
        self.lambda_ = lambda_
        
        # 保存旧任务的参数
        self.params = {
            n: p.clone().detach()
            for n, p in model.named_parameters()
            if p.requires_grad
        }
        
        # 计算Fisher信息矩阵
        self.fisher = self._compute_fisher(dataset)
        
        print("EWC初始化完成")
        print(f"  Lambda: {lambda_}")
        print(f"  保存参数数: {len(self.params)}")
    
    def _compute_fisher(self, dataset):
        """
        计算Fisher信息矩阵
        
        Args:
            dataset: 数据集
        
        Returns:
            Fisher信息矩阵字典
        """
        
        print("\n计算Fisher信息矩阵...")
        
        fisher = {
            n: torch.zeros_like(p)
            for n, p in self.model.named_parameters()
            if p.requires_grad
        }
        
        self.model.eval()
        
        # 对数据集采样
        for i, (data, target) in enumerate(dataset):
            if i >= 100:  # 限制采样数量
                break
            
            # 前向传播
            self.model.zero_grad()
            output = self.model(data)
            loss = nn.functional.cross_entropy(output, target)
            
            # 反向传播
            loss.backward()
            
            # 累积梯度平方
            for n, p in self.model.named_parameters():
                if p.grad is not None:
                    fisher[n] += p.grad.detach() ** 2
        
        # 平均
        for n in fisher:
            fisher[n] /= len(dataset)
        
        print("  Fisher矩阵计算完成")
        
        return fisher
    
    def penalty(self):
        """
        计算EWC惩罚项
        
        Returns:
            EWC损失
        """
        
        loss = 0
        
        for n, p in self.model.named_parameters():
            if n in self.fisher:
                # EWC惩罚：λ * Σ F_i (θ_i - θ*_i)^2
                loss += (
                    self.fisher[n] * 
                    (p - self.params[n]) ** 2
                ).sum()
        
        return self.lambda_ * loss
    
    def explain_ewc(self):
        """解释EWC原理"""
        
        print("\n" + "="*60)
        print("EWC原理详解")
        print("="*60)
        
        print("""
【Fisher信息矩阵】

物理意义：
• 衡量参数对旧任务的重要性
• Fisher值大 = 参数重要
• Fisher值小 = 参数不重要

计算方法：
F_i = E[(∂L/∂θ_i)^2]

近似：
对数据集采样，累积梯度平方

【EWC损失】

总损失：
L_total = L_new + L_EWC

其中：
L_new = 新任务损失
L_EWC = λ Σ F_i (θ_i - θ*_i)^2

含义：
• 学习新任务
• 限制重要参数变化
• λ控制权衡

【效果】

重要参数（F大）：
• 惩罚大
• 不敢动太多
• 保护旧知识

不重要参数（F小）：
• 惩罚小
• 可以大幅调整
• 学习新知识

平衡！
        """)

class EWCTrainer:
    """带EWC的训练器"""
    
    def __init__(self, model, ewc=None):
        """
        初始化
        
        Args:
            model: 模型
            ewc: EWC对象（可选）
        """
        self.model = model
        self.ewc = ewc
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    def train_step(self, data, target):
        """
        训练一步
        
        Args:
            data: 输入数据
            target: 目标标签
        
        Returns:
            总损失
        """
        
        self.optimizer.zero_grad()
        
        # 新任务损失
        output = self.model(data)
        loss_new = nn.functional.cross_entropy(output, target)
        
        # EWC惩罚
        loss_ewc = 0
        if self.ewc is not None:
            loss_ewc = self.ewc.penalty()
        
        # 总损失
        loss_total = loss_new + loss_ewc
        
        # 反向传播
        loss_total.backward()
        self.optimizer.step()
        
        return {
            'loss_total': loss_total.item(),
            'loss_new': loss_new.item(),
            'loss_ewc': loss_ewc.item() if self.ewc else 0
        }
    
    def demo_training(self):
        """演示训练过程"""
        
        print("\n" + "="*60)
        print("EWC训练演示")
        print("="*60)
        
        print("""
【训练流程】

Step 1: 在任务A上训练
• 普通训练
• 达到高准确率

Step 2: 计算Fisher矩阵
• 在任务A数据上计算
• 识别重要参数

Step 3: 在任务B上训练
• 使用EWC损失
• L = L_new + λ * L_EWC

Step 4: 评估
• 测试任务A性能（保持）
• 测试任务B性能（达标）

【损失变化】

Epoch 1:
  loss_new: 2.456
  loss_ewc: 150.3
  loss_total: 152.756

Epoch 10:
  loss_new: 0.523
  loss_ewc: 45.2
  loss_total: 45.723

Epoch 20:
  loss_new: 0.123
  loss_ewc: 12.5
  loss_total: 12.623

观察：
• 新任务损失下降
• EWC惩罚也下降（参数接近最优）
• 总损失收敛
        """)

# 演示
ewc = EWC(nn.Linear(10, 2), [], lambda_=1000)
ewc.explain_ewc()

trainer = EWCTrainer(nn.Linear(10, 2), ewc)
trainer.demo_training()
```

---

## 🎯 第三部分：其他持续学习方法

### 一、方法对比

```python
class ContinualLearningMethods:
    """持续学习方法对比"""
    
    @staticmethod
    def compare_methods():
        """对比不同方法"""
        
        print("\n" + "="*60)
        print("持续学习方法对比")
        print("="*60)
        
        methods = {
            "EWC": {
                "类型": "正则化",
                "保存旧数据": "否",
                "计算成本": "中",
                "存储成本": "中（Fisher矩阵）",
                "效果": "优秀",
                "适用": "任务不太多",
                "优点": "不需要旧数据",
                "缺点": "计算Fisher矩阵"
            },
            "Experience Replay": {
                "类型": "重放",
                "保存旧数据": "是（少量）",
                "计算成本": "低",
                "存储成本": "中（旧数据）",
                "效果": "优秀",
                "适用": "所有场景",
                "优点": "简单有效",
                "缺点": "需要存储旧数据"
            },
            "Progressive NN": {
                "类型": "动态架构",
                "保存旧数据": "否",
                "计算成本": "低",
                "存储成本": "高（模型增长）",
                "效果": "完美（无遗忘）",
                "适用": "任务有限",
                "优点": "完全避免遗忘",
                "缺点": "模型越来越大"
            },
            "Knowledge Distillation": {
                "类型": "蒸馏",
                "保存旧数据": "否",
                "计算成本": "中",
                "存储成本": "中（旧模型）",
                "效果": "良好",
                "适用": "所有场景",
                "优点": "不需要旧数据",
                "缺点": "需要保存旧模型"
            }
        }
        
        print(f"\n{'方法':<20} {'类型':<10} {'旧数据':<10} {'计算':<10} {'存储':<15} {'效果':<10}")
        print("-"*85)
        
        for method, info in methods.items():
            print(f"{method:<20} {info['类型']:<10} {info['保存旧数据']:<10} "
                  f"{info['计算成本']:<10} {info['存储成本']:<15} {info['效果']:<10}")
        
        print("\n推荐：")
        print("  • 有旧数据 → Experience Replay")
        print("  • 无旧数据 → EWC")
        print("  • 任务有限 → Progressive NN")
        print("  • 通用场景 → EWC + Replay组合")

# 演示
methods = ContinualLearningMethods()
methods.compare_methods()
```

---

## 📝 课后练习

### 练习1：理解遗忘
分析为什么会发生灾难性遗忘

### 练习2：实现EWC
实现简化版EWC算法

### 练习3：对比方法
对比EWC和重放方法

---

## 🎓 知识总结

### 核心要点

1. **灾难性遗忘**
   - 学新忘旧
   - 参数覆盖
   - 需要解决

2. **EWC算法**
   - Fisher信息矩阵
   - 保护重要参数
   - 平衡新旧任务

3. **其他方法**
   - 重放：简单有效
   - 动态架构：无遗忘
   - 蒸馏：无需旧数据

4. **实战建议**
   - 有数据用重放
   - 无数据用EWC
   - 组合使用最佳

---

## 🚀 下节预告

下一课：**第108课：微调模型部署-vLLM高性能推理**

- vLLM框架
- 高性能推理
- 部署优化
- 生产应用

**从训练到部署！** 🔥

---

**💪 恭喜完成第17章！掌握了所有高级微调技术！**

**下一课见！** 🎉
