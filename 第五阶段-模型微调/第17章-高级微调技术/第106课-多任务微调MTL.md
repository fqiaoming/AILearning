![é«˜çº§å¾®è°ƒæŠ€æœ¯](./images/advanced_ft.svg)
*å›¾ï¼šé«˜çº§å¾®è°ƒæŠ€æœ¯*

# ç¬¬106è¯¾ï¼šå¤šä»»åŠ¡å¾®è°ƒ-MTLå¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥

> **æœ¬è¯¾ç›®æ ‡**ï¼šæŒæ¡å¤šä»»åŠ¡å­¦ä¹ ï¼Œè®©æ¨¡å‹åŒæ—¶ç²¾é€šå¤šä¸ªä»»åŠ¡
> 
> **æ ¸å¿ƒæŠ€èƒ½**ï¼šMTLåŸç†ã€ä»»åŠ¡å¹³è¡¡ã€è´Ÿè¿ç§»é¿å…ã€å®æˆ˜åº”ç”¨
> 
> **å­¦ä¹ æ—¶é•¿**ï¼š90åˆ†é’Ÿ

---

## ğŸ“– å£æ’­æ–‡æ¡ˆï¼ˆ6åˆ†é’Ÿï¼‰
![Lora](./images/lora.svg)
*å›¾ï¼šLora*


### ğŸ¯ å‰è¨€

"å‰é¢æˆ‘ä»¬å­¦ä¹ äº†å„ç§å¾®è°ƒæŠ€æœ¯ã€‚

ä½†æœ‰ä¸ªå®é™…é—®é¢˜ï¼š

**å¦‚ä½•è®©æ¨¡å‹åŒæ—¶ä¼šåšå¤šä»¶äº‹ï¼Ÿ**

**å®é™…éœ€æ±‚ï¼š**

```
åœºæ™¯ï¼šAIåŠ©æ‰‹

éœ€æ±‚1ï¼šå›ç­”é—®é¢˜
éœ€æ±‚2ï¼šå†™ä»£ç 
éœ€æ±‚3ï¼šç¿»è¯‘
éœ€æ±‚4ï¼šæ€»ç»“æ–‡æ¡£
éœ€æ±‚5ï¼šæƒ…æ„Ÿåˆ†æ
...

ä¼ ç»Ÿæ–¹æ¡ˆï¼š
â€¢ æ–¹æ¡ˆAï¼šæ¯ä¸ªä»»åŠ¡è®­ç»ƒä¸€ä¸ªæ¨¡å‹
  â†’ éœ€è¦10ä¸ªæ¨¡å‹ï¼Œæˆæœ¬é«˜

â€¢ æ–¹æ¡ˆBï¼šæ··åˆæ‰€æœ‰æ•°æ®ä¸€èµ·è®­ç»ƒ
  â†’ ä»»åŠ¡äº’ç›¸å¹²æ‰°ï¼Œæ•ˆæœå·®

éƒ½ä¸ç†æƒ³ï¼
```

**ä»Šå¤©è¦å­¦ä¹ ï¼šå¤šä»»åŠ¡å­¦ä¹ ï¼ˆMulti-Task Learning, MTLï¼‰**

**è®©ä¸€ä¸ªæ¨¡å‹ç²¾é€šå¤šä¸ªä»»åŠ¡ï¼**

---

### ğŸ’¡ ä»€ä¹ˆæ˜¯å¤šä»»åŠ¡å­¦ä¹ ï¼Ÿ

**å®šä¹‰ï¼š**

```
å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰=
åŒæ—¶è®­ç»ƒä¸€ä¸ªæ¨¡å‹å®Œæˆå¤šä¸ªç›¸å…³ä»»åŠ¡

æ ¸å¿ƒæ€æƒ³ï¼š
â€¢ ä»»åŠ¡ä¹‹é—´å…±äº«çŸ¥è¯†
â€¢ ç›¸äº’ä¿ƒè¿›
â€¢ æå‡æ³›åŒ–èƒ½åŠ›
```

**ç›´è§‰ç†è§£ï¼š**

```
ã€ç±»æ¯”ï¼šå­¦ç”Ÿã€‘

å•ä»»åŠ¡å­¦ä¹ ï¼š
â€¢ åªå­¦æ•°å­¦
â€¢ æ•°å­¦å¾ˆå¥½
â€¢ ä½†ç‰©ç†ä¸ä¼š

å¤šä»»åŠ¡å­¦ä¹ ï¼š
â€¢ åŒæ—¶å­¦æ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦
â€¢ çŸ¥è¯†äº’ç›¸å…³è”
â€¢ æ•°å­¦å¸®åŠ©ç†è§£ç‰©ç†
â€¢ ç‰©ç†å¸®åŠ©ç†è§£åŒ–å­¦
â€¢ æ•´ä½“èƒ½åŠ›æ›´å¼º

æ¨¡å‹ä¹Ÿä¸€æ ·ï¼
```

**MTLçš„ä¼˜åŠ¿ï¼š**

```
ä¼˜åŠ¿1ï¼šå…±äº«è¡¨ç¤º
â€¢ ä¸åŒä»»åŠ¡å…±äº«åº•å±‚ç‰¹å¾
â€¢ å‡å°‘å‚æ•°é‡
â€¢ æé«˜æ•ˆç‡

ä¼˜åŠ¿2ï¼šæ­£è¿ç§»
â€¢ ä»»åŠ¡Açš„çŸ¥è¯†å¸®åŠ©ä»»åŠ¡B
â€¢ ç›¸äº’ä¿ƒè¿›
â€¢ æ•´ä½“æ•ˆæœæå‡

ä¼˜åŠ¿3ï¼šæ³›åŒ–èƒ½åŠ›
â€¢ è§è¿‡æ›´å¤šæ ·çš„æ•°æ®
â€¢ æ›´robust
â€¢ æ–°ä»»åŠ¡é€‚åº”å¿«

ä¼˜åŠ¿4ï¼šèµ„æºèŠ‚çœ
â€¢ ä¸€ä¸ªæ¨¡å‹å¤šä¸ªä»»åŠ¡
â€¢ èŠ‚çœæ˜¾å­˜
â€¢ é™ä½æˆæœ¬
```

**æŒ‘æˆ˜ï¼š**

```
æŒ‘æˆ˜1ï¼šä»»åŠ¡å†²çªï¼ˆè´Ÿè¿ç§»ï¼‰
â€¢ æŸäº›ä»»åŠ¡äº’ç›¸å¹²æ‰°
â€¢ ä¸€èµ·è®­ç»ƒåè€Œæ•ˆæœå·®

æŒ‘æˆ˜2ï¼šä»»åŠ¡ä¸å¹³è¡¡
â€¢ æœ‰çš„ä»»åŠ¡æ•°æ®å¤š
â€¢ æœ‰çš„ä»»åŠ¡æ•°æ®å°‘
â€¢ è®­ç»ƒä¸å‡è¡¡

æŒ‘æˆ˜3ï¼šæ”¶æ•›å›°éš¾
â€¢ å¤šä¸ªæŸå¤±å‡½æ•°
â€¢ éš¾ä»¥åŒæ—¶ä¼˜åŒ–
â€¢ éœ€è¦ç‰¹æ®Šç­–ç•¥
```

**å…³é”®æŠ€æœ¯ï¼š**

```
ã€1. ä»»åŠ¡å¹³è¡¡ã€‘

é—®é¢˜ï¼š
â€¢ ä»»åŠ¡Aï¼š10ä¸‡æ•°æ®
â€¢ ä»»åŠ¡Bï¼š1åƒæ•°æ®
â€¢ æ¨¡å‹åªå­¦ä¼šä»»åŠ¡A

è§£å†³ï¼š
â€¢ æ•°æ®é‡é‡‡æ ·
â€¢ æŸå¤±åŠ æƒ
â€¢ åŠ¨æ€è°ƒæ•´

ã€2. è´Ÿè¿ç§»é¿å…ã€‘

é—®é¢˜ï¼š
â€¢ ä»»åŠ¡Aå’ŒBå†²çª
â€¢ ä¸€èµ·è®­ç»ƒéƒ½å˜å·®

è§£å†³ï¼š
â€¢ ä»»åŠ¡é€‰æ‹©
â€¢ åˆ†ç»„è®­ç»ƒ
â€¢ è½¯å‚æ•°å…±äº«

ã€3. æ¢¯åº¦å¹³è¡¡ã€‘

é—®é¢˜ï¼š
â€¢ ä¸åŒä»»åŠ¡æ¢¯åº¦è§„æ¨¡ä¸åŒ
â€¢ æŸä¸ªä»»åŠ¡ä¸»å¯¼è®­ç»ƒ

è§£å†³ï¼š
â€¢ æ¢¯åº¦å½’ä¸€åŒ–
â€¢ åŠ¨æ€æƒé‡
â€¢ GradNormç®—æ³•
```

**å®é™…åº”ç”¨ï¼š**

```
ã€GPT-4çš„å¤šä»»åŠ¡èƒ½åŠ›ã€‘

GPT-4å¯ä»¥ï¼š
â€¢ é—®ç­”
â€¢ ç¿»è¯‘
â€¢ ç¼–ç¨‹
â€¢ æ•°å­¦
â€¢ æ¨ç†
â€¢ åˆ›ä½œ
â€¢ åˆ†æ
...

éƒ½æ˜¯å¤šä»»åŠ¡å­¦ä¹ çš„ç»“æœï¼

ã€ä¸“ä¸šåŠ©æ‰‹ã€‘

åŒ»ç–—åŠ©æ‰‹ï¼š
â€¢ ç–¾ç—…è¯Šæ–­
â€¢ ç”¨è¯å»ºè®®
â€¢ å¥åº·å’¨è¯¢
â€¢ æ–‡çŒ®æ£€ç´¢
â€¢ æŠ¥å‘Šç”Ÿæˆ

æ³•å¾‹åŠ©æ‰‹ï¼š
â€¢ æ³•æ¡æŸ¥è¯¢
â€¢ æ¡ˆä¾‹åˆ†æ
â€¢ æ–‡ä¹¦ç”Ÿæˆ
â€¢ é£é™©è¯„ä¼°
â€¢ åˆåŒå®¡æŸ¥
```

**ä»»åŠ¡ç»„åˆç­–ç•¥ï¼š**

```
ã€ç›¸å…³ä»»åŠ¡ç»„åˆã€‘

âœ… å¥½çš„ç»„åˆï¼š
â€¢ ç¿»è¯‘ + æ€»ç»“
  ï¼ˆéƒ½éœ€è¦è¯­è¨€ç†è§£ï¼‰

â€¢ é—®ç­” + æ¨ç†
  ï¼ˆéƒ½éœ€è¦é€»è¾‘æ€ç»´ï¼‰

â€¢ ä»£ç ç”Ÿæˆ + ä»£ç è§£é‡Š
  ï¼ˆéƒ½éœ€è¦ç¼–ç¨‹çŸ¥è¯†ï¼‰

âŒ å·®çš„ç»„åˆï¼š
â€¢ æ•°å­¦ + å›¾åƒè¯†åˆ«
  ï¼ˆå¤ªä¸ç›¸å…³ï¼‰

â€¢ åŒ»ç–—è¯Šæ–­ + æ¸¸æˆè®¾è®¡
  ï¼ˆé¢†åŸŸå†²çªï¼‰

åŸåˆ™ï¼šé€‰æ‹©ç›¸å…³ä»»åŠ¡ï¼
```

**è®­ç»ƒæ•°æ®æ ¼å¼ï¼š**

```
ã€ç»Ÿä¸€æ ¼å¼ã€‘

æ‰€æœ‰ä»»åŠ¡ä½¿ç”¨ç›¸åŒæ ¼å¼ï¼š

{
  "task": "translation",  # ä»»åŠ¡ç±»å‹
  "input": "Hello",       # è¾“å…¥
  "output": "ä½ å¥½"        # æœŸæœ›è¾“å‡º
}

{
  "task": "summarization",
  "input": "é•¿æ–‡æœ¬...",
  "output": "æ‘˜è¦..."
}

{
  "task": "qa",
  "input": "ä»€ä¹ˆæ˜¯AIï¼Ÿ",
  "output": "AIæ˜¯..."
}

ç»Ÿä¸€å¤„ç†ï¼
```

**æ•ˆæœå¯¹æ¯”ï¼š**

```
ã€å®éªŒï¼š5ä¸ªä»»åŠ¡ã€‘

ä»»åŠ¡ï¼šç¿»è¯‘ã€æ€»ç»“ã€é—®ç­”ã€åˆ†ç±»ã€ç”Ÿæˆ

å•ä»»åŠ¡è®­ç»ƒï¼ˆ5ä¸ªæ¨¡å‹ï¼‰ï¼š
â€¢ å¹³å‡å‡†ç¡®ç‡ï¼š82%
â€¢ æ¨¡å‹æ€»å¤§å°ï¼š35GB
â€¢ è®­ç»ƒæ—¶é—´ï¼š5Ã—8h = 40h

å¤šä»»åŠ¡è®­ç»ƒï¼ˆ1ä¸ªæ¨¡å‹ï¼‰ï¼š
â€¢ å¹³å‡å‡†ç¡®ç‡ï¼š85%  â¬†ï¸ 3%
â€¢ æ¨¡å‹æ€»å¤§å°ï¼š7GB   â¬‡ï¸ 80%
â€¢ è®­ç»ƒæ—¶é—´ï¼š12h    â¬‡ï¸ 70%

MTLå®Œèƒœï¼
```

**ä»Šå¤©è¿™ä¸€è¯¾ï¼Œæˆ‘è¦å¸¦ä½ ï¼š**

**ç¬¬ä¸€éƒ¨åˆ†ï¼šMTLåŸç†**
- æ ¸å¿ƒæ¦‚å¿µ
- ä¼˜åŠ¿æŒ‘æˆ˜
- ç†è®ºåŸºç¡€

**ç¬¬äºŒéƒ¨åˆ†ï¼šä»»åŠ¡å¹³è¡¡**
- æ•°æ®é‡‡æ ·
- æŸå¤±åŠ æƒ
- åŠ¨æ€è°ƒæ•´

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®æˆ˜å®ç°**
- å¤šä»»åŠ¡æ•°æ®å‡†å¤‡
- è®­ç»ƒæµç¨‹
- å®Œæ•´ä»£ç 

**ç¬¬å››éƒ¨åˆ†ï¼šé«˜çº§æŠ€å·§**
- è´Ÿè¿ç§»é¿å…
- æ¢¯åº¦å¹³è¡¡
- ä»»åŠ¡é€‰æ‹©

å­¦å®Œè¿™ä¸€è¯¾ï¼Œè®©ä½ çš„æ¨¡å‹å¤šæ‰å¤šè‰ºï¼

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ï¼"

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†ï¼šå¤šä»»åŠ¡å­¦ä¹ åŸç†

### ä¸€ã€MTLæ¶æ„è®¾è®¡

```python
from dataclasses import dataclass
from typing import List, Dict
import torch
import torch.nn as nn

@dataclass
class TaskConfig:
    """ä»»åŠ¡é…ç½®"""
    name: str              # ä»»åŠ¡åç§°
    num_samples: int       # æ ·æœ¬æ•°é‡
    loss_weight: float     # æŸå¤±æƒé‡
    sample_weight: float   # é‡‡æ ·æƒé‡

class MultiTaskArchitecture:
    """å¤šä»»åŠ¡æ¶æ„è®¾è®¡"""
    
    @staticmethod
    def show_architectures():
        """å±•ç¤ºä¸åŒMTLæ¶æ„"""
        
        print("="*60)
        print("å¤šä»»åŠ¡å­¦ä¹ æ¶æ„")
        print("="*60)
        
        print("""
ã€æ¶æ„1ï¼šç¡¬å‚æ•°å…±äº«ã€‘

Input
  â†“
Shared Encoder (å…±äº«å±‚)
  â”œâ”€â†’ Task 1 Head â†’ Output 1
  â”œâ”€â†’ Task 2 Head â†’ Output 2
  â””â”€â†’ Task 3 Head â†’ Output 3

ç‰¹ç‚¹ï¼š
â€¢ å¤§éƒ¨åˆ†å‚æ•°å…±äº«
â€¢ åªæœ‰è¾“å‡ºå¤´ä¸åŒ
â€¢ å‚æ•°æ•ˆç‡é«˜
â€¢ é€‚åˆç›¸å…³ä»»åŠ¡

ã€æ¶æ„2ï¼šè½¯å‚æ•°å…±äº«ã€‘

Input
  â”œâ”€â†’ Task 1 Encoder â†’ Task 1 Head â†’ Output 1
  â”œâ”€â†’ Task 2 Encoder â†’ Task 2 Head â†’ Output 2
  â””â”€â†’ Task 3 Encoder â†’ Task 3 Head â†’ Output 3
      â†‘ â†“ (é€šè¿‡æ­£åˆ™é¡¹å…±äº«çŸ¥è¯†)

ç‰¹ç‚¹ï¼š
â€¢ æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹æ¨¡å‹
â€¢ é€šè¿‡æ­£åˆ™é¡¹é¼“åŠ±ç›¸ä¼¼
â€¢ æ›´çµæ´»
â€¢ é€‚åˆå·®å¼‚å¤§çš„ä»»åŠ¡

ã€æ¶æ„3ï¼šæ··åˆæ¶æ„ã€‘

Input
  â†“
Shared Encoder
  â†“
Task-Specific Layer
  â”œâ”€â†’ Task 1 Head â†’ Output 1
  â”œâ”€â†’ Task 2 Head â†’ Output 2
  â””â”€â†’ Task 3 Head â†’ Output 3

ç‰¹ç‚¹ï¼š
â€¢ åº•å±‚å…±äº«
â€¢ ä¸­å±‚ä»»åŠ¡ç‰¹å®š
â€¢ é¡¶å±‚ä»»åŠ¡å¤´
â€¢ å¹³è¡¡æ•ˆæœæœ€å¥½ï¼ˆæ¨èï¼‰
        """)

# æ¼”ç¤º
arch = MultiTaskArchitecture()
arch.show_architectures()
```

---

## ğŸ’» ç¬¬äºŒéƒ¨åˆ†ï¼šä»»åŠ¡å¹³è¡¡ç­–ç•¥

### ä¸€ã€æ•°æ®é‡‡æ ·ç­–ç•¥

```python
import random
import numpy as np

class MultiTaskSampler:
    """å¤šä»»åŠ¡é‡‡æ ·å™¨"""
    
    def __init__(self, tasks: List[TaskConfig]):
        """
        åˆå§‹åŒ–
        
        Args:
            tasks: ä»»åŠ¡é…ç½®åˆ—è¡¨
        """
        self.tasks = tasks
        self.total_samples = sum(t.num_samples for t in tasks)
    
    def uniform_sampling(self) -> Dict[str, int]:
        """å‡åŒ€é‡‡æ ·ç­–ç•¥"""
        
        print("\n" + "="*60)
        print("ç­–ç•¥1ï¼šå‡åŒ€é‡‡æ ·")
        print("="*60)
        
        print("\nåŸç†ï¼š")
        print("  æ¯ä¸ªä»»åŠ¡é‡‡æ ·ç›¸åŒæ•°é‡")
        
        samples_per_task = min(t.num_samples for t in self.tasks)
        
        print(f"\nç»“æœï¼š")
        for task in self.tasks:
            print(f"  {task.name}: {samples_per_task}/{task.num_samples}")
        
        print("\nä¼˜ç‚¹ï¼šä»»åŠ¡å¹³è¡¡")
        print("ç¼ºç‚¹ï¼šæµªè´¹æ•°æ®å¤šçš„ä»»åŠ¡")
        
        return {t.name: samples_per_task for t in self.tasks}
    
    def proportional_sampling(self) -> Dict[str, int]:
        """æŒ‰æ¯”ä¾‹é‡‡æ ·ç­–ç•¥"""
        
        print("\n" + "="*60)
        print("ç­–ç•¥2ï¼šæŒ‰æ¯”ä¾‹é‡‡æ ·")
        print("="*60)
        
        print("\nåŸç†ï¼š")
        print("  æŒ‰åŸå§‹æ•°æ®æ¯”ä¾‹é‡‡æ ·")
        
        print(f"\nç»“æœï¼š")
        for task in self.tasks:
            print(f"  {task.name}: {task.num_samples}/{task.num_samples}")
        
        print("\nä¼˜ç‚¹ï¼šåˆ©ç”¨æ‰€æœ‰æ•°æ®")
        print("ç¼ºç‚¹ï¼šæ•°æ®å¤šçš„ä»»åŠ¡ä¸»å¯¼")
        
        return {t.name: t.num_samples for t in self.tasks}
    
    def temperature_sampling(self, temperature: float = 0.5) -> Dict[str, int]:
        """æ¸©åº¦é‡‡æ ·ç­–ç•¥ï¼ˆæ¨èï¼‰"""
        
        print("\n" + "="*60)
        print("ç­–ç•¥3ï¼šæ¸©åº¦é‡‡æ ·ï¼ˆæ¨èï¼‰")
        print("="*60)
        
        print("\nåŸç†ï¼š")
        print(f"  p_i = (n_i)^T / Î£(n_j)^T")
        print(f"  T={temperature}")
        print("  T=0: å‡åŒ€é‡‡æ ·")
        print("  T=1: æŒ‰æ¯”ä¾‹é‡‡æ ·")
        print("  T=0.5: å¹³è¡¡ï¼ˆæ¨èï¼‰")
        
        # è®¡ç®—é‡‡æ ·æ¦‚ç‡
        nums = np.array([t.num_samples for t in self.tasks])
        probs = nums ** temperature
        probs = probs / probs.sum()
        
        # æ€»æ ·æœ¬æ•°ï¼ˆä½¿ç”¨æœ€å¤§ä»»åŠ¡çš„æ•°é‡ï¼‰
        total = max(t.num_samples for t in self.tasks)
        
        # è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„æ ·æœ¬æ•°
        result = {}
        print(f"\nç»“æœï¼š")
        for i, task in enumerate(self.tasks):
            samples = int(total * probs[i])
            result[task.name] = min(samples, task.num_samples)
            print(f"  {task.name}: {result[task.name]}/{task.num_samples} ({probs[i]*100:.1f}%)")
        
        print("\nä¼˜ç‚¹ï¼šå¹³è¡¡æ•ˆæœå’Œæ•°æ®åˆ©ç”¨")
        print("æ¨èï¼šT=0.5")
        
        return result
    
    def demo_sampling_strategies(self):
        """æ¼”ç¤ºæ‰€æœ‰ç­–ç•¥"""
        
        print("="*60)
        print("å¤šä»»åŠ¡é‡‡æ ·ç­–ç•¥å¯¹æ¯”")
        print("="*60)
        
        print("\nä»»åŠ¡æ•°æ®åˆ†å¸ƒï¼š")
        for task in self.tasks:
            print(f"  {task.name}: {task.num_samples} æ ·æœ¬")
        
        # æµ‹è¯•æ‰€æœ‰ç­–ç•¥
        self.uniform_sampling()
        self.proportional_sampling()
        self.temperature_sampling(0.5)

# æ¼”ç¤º
tasks = [
    TaskConfig("ç¿»è¯‘", 10000, 1.0, 1.0),
    TaskConfig("æ€»ç»“", 5000, 1.0, 1.0),
    TaskConfig("é—®ç­”", 2000, 1.0, 1.0),
    TaskConfig("åˆ†ç±»", 15000, 1.0, 1.0),
]

sampler = MultiTaskSampler(tasks)
sampler.demo_sampling_strategies()
```

### äºŒã€æŸå¤±åŠ æƒç­–ç•¥

```python
class LossWeighting:
    """æŸå¤±åŠ æƒç­–ç•¥"""
    
    @staticmethod
    def demonstrate_strategies():
        """æ¼”ç¤ºæŸå¤±åŠ æƒç­–ç•¥"""
        
        print("\n" + "="*60)
        print("æŸå¤±åŠ æƒç­–ç•¥")
        print("="*60)
        
        print("""
ã€ç­–ç•¥1ï¼šå‡åŒ€æƒé‡ã€‘

L_total = L1 + L2 + L3

é—®é¢˜ï¼š
â€¢ ä¸åŒä»»åŠ¡æŸå¤±è§„æ¨¡å¯èƒ½ä¸åŒ
â€¢ L1=10, L2=0.1 â†’ L1ä¸»å¯¼

ã€ç­–ç•¥2ï¼šæ‰‹åŠ¨æƒé‡ã€‘

L_total = w1*L1 + w2*L2 + w3*L3

è®¾ç½®ï¼š
â€¢ é‡è¦ä»»åŠ¡ï¼šé«˜æƒé‡
â€¢ ç®€å•ä»»åŠ¡ï¼šä½æƒé‡

è°ƒå‚ï¼š
éœ€è¦å¤šæ¬¡å®éªŒæ‰¾æœ€ä¼˜æƒé‡

ã€ç­–ç•¥3ï¼šä¸ç¡®å®šæ€§åŠ æƒï¼ˆæ¨èï¼‰ã€‘

L_total = Î£ (1/(2*Ïƒ_i^2)) * L_i + log(Ïƒ_i)

å…¶ä¸­Ïƒ_iæ˜¯å¯å­¦ä¹ çš„ä¸ç¡®å®šæ€§å‚æ•°

ä¼˜ç‚¹ï¼š
â€¢ è‡ªåŠ¨è°ƒæ•´
â€¢ ä¸éœ€è¦æ‰‹åŠ¨è°ƒå‚
â€¢ ç†è®ºæ”¯æŒ

ã€ç­–ç•¥4ï¼šGradNormã€‘

æ ¹æ®æ¢¯åº¦å¤§å°åŠ¨æ€è°ƒæ•´æƒé‡

åŸç†ï¼š
â€¢ è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„æ¢¯åº¦èŒƒæ•°
â€¢ æ¢¯åº¦å°çš„ä»»åŠ¡å¢åŠ æƒé‡
â€¢ æ¢¯åº¦å¤§çš„ä»»åŠ¡å‡å°‘æƒé‡

ä¼˜ç‚¹ï¼š
â€¢ åŠ¨æ€å¹³è¡¡
â€¢ è‡ªé€‚åº”

å®ç°å¤æ‚åº¦ï¼šä¸­ç­‰
        """)
        
        # ç¤ºä¾‹è®¡ç®—
        print("\nã€ç¤ºä¾‹ï¼šä¸ç¡®å®šæ€§åŠ æƒã€‘")
        
        # æ¨¡æ‹ŸæŸå¤±
        L1, L2, L3 = 2.0, 0.5, 10.0
        print(f"\nåŸå§‹æŸå¤±ï¼š")
        print(f"  Task 1: {L1:.2f}")
        print(f"  Task 2: {L2:.2f}")
        print(f"  Task 3: {L3:.2f}")
        print(f"  ç›´æ¥æ±‚å’Œ: {L1+L2+L3:.2f} ï¼ˆTask 3ä¸»å¯¼ï¼‰")
        
        # ä¸ç¡®å®šæ€§åŠ æƒ
        sigma1, sigma2, sigma3 = 1.0, 0.5, 2.0
        weighted_L1 = L1 / (2 * sigma1**2)
        weighted_L2 = L2 / (2 * sigma2**2)
        weighted_L3 = L3 / (2 * sigma3**2)
        
        print(f"\nä¸ç¡®å®šæ€§åŠ æƒåï¼š")
        print(f"  Task 1: {weighted_L1:.2f} (Ïƒ={sigma1})")
        print(f"  Task 2: {weighted_L2:.2f} (Ïƒ={sigma2})")
        print(f"  Task 3: {weighted_L3:.2f} (Ïƒ={sigma3})")
        print(f"  åŠ æƒæ±‚å’Œ: {weighted_L1+weighted_L2+weighted_L3:.2f} ï¼ˆå¹³è¡¡ï¼‰")

# æ¼”ç¤º
LossWeighting.demonstrate_strategies()
```

---

## ğŸ¯ ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¤šä»»åŠ¡è®­ç»ƒå®æˆ˜

### ä¸€ã€å®Œæ•´è®­ç»ƒæµç¨‹

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import Dataset

class MultiTaskTrainer:
    """å¤šä»»åŠ¡è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model_name: str = "Qwen/Qwen2-7B",
        tasks: List[TaskConfig] = None
    ):
        """
        åˆå§‹åŒ–
        
        Args:
            model_name: åŸºç¡€æ¨¡å‹
            tasks: ä»»åŠ¡åˆ—è¡¨
        """
        self.model_name = model_name
        self.tasks = tasks or []
        
        print("="*60)
        print("å¤šä»»åŠ¡è®­ç»ƒå™¨")
        print("="*60)
        print(f"æ¨¡å‹: {model_name}")
        print(f"ä»»åŠ¡æ•°: {len(self.tasks)}")
    
    def prepare_multitask_data(self):
        """å‡†å¤‡å¤šä»»åŠ¡æ•°æ®"""
        
        print("\n" + "="*60)
        print("å‡†å¤‡å¤šä»»åŠ¡æ•°æ®")
        print("="*60)
        
        # ç¤ºä¾‹ï¼š5ä¸ªä»»åŠ¡çš„æ•°æ®
        all_data = []
        
        # ä»»åŠ¡1ï¼šç¿»è¯‘
        all_data.extend([
            {
                "task": "translation",
                "instruction": "å°†ä»¥ä¸‹ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡",
                "input": "ä½ å¥½",
                "output": "Hello"
            }
        ] * 100)
        
        # ä»»åŠ¡2ï¼šæ€»ç»“
        all_data.extend([
            {
                "task": "summarization",
                "instruction": "æ€»ç»“ä»¥ä¸‹æ–‡æœ¬",
                "input": "é•¿æ–‡æœ¬...",
                "output": "æ‘˜è¦..."
            }
        ] * 80)
        
        # ä»»åŠ¡3ï¼šé—®ç­”
        all_data.extend([
            {
                "task": "qa",
                "instruction": "å›ç­”é—®é¢˜",
                "input": "ä»€ä¹ˆæ˜¯AIï¼Ÿ",
                "output": "AIæ˜¯äººå·¥æ™ºèƒ½..."
            }
        ] * 60)
        
        # ä»»åŠ¡4ï¼šä»£ç 
        all_data.extend([
            {
                "task": "coding",
                "instruction": "æ ¹æ®éœ€æ±‚ç”ŸæˆPythonä»£ç ",
                "input": "å†™ä¸€ä¸ªæ’åºå‡½æ•°",
                "output": "def sort_list(lst):\n    return sorted(lst)"
            }
        ] * 50)
        
        # ä»»åŠ¡5ï¼šåˆ†ç±»
        all_data.extend([
            {
                "task": "classification",
                "instruction": "åˆ¤æ–­æƒ…æ„Ÿå€¾å‘",
                "input": "è¿™éƒ¨ç”µå½±çœŸæ£’ï¼",
                "output": "æ­£é¢"
            }
        ] * 40)
        
        # æ‰“ä¹±æ•°æ®
        random.shuffle(all_data)
        
        print(f"\næ€»æ ·æœ¬æ•°: {len(all_data)}")
        
        # ç»Ÿè®¡å„ä»»åŠ¡
        from collections import Counter
        task_counts = Counter(d['task'] for d in all_data)
        print(f"\nå„ä»»åŠ¡åˆ†å¸ƒï¼š")
        for task, count in task_counts.items():
            print(f"  {task}: {count} ({count/len(all_data)*100:.1f}%)")
        
        return Dataset.from_list(all_data)
    
    def train(self, dataset: Dataset):
        """è®­ç»ƒå¤šä»»åŠ¡æ¨¡å‹"""
        
        print("\n" + "="*60)
        print("å¤šä»»åŠ¡è®­ç»ƒ")
        print("="*60)
        
        print("\nè®­ç»ƒé…ç½®ï¼š")
        print("  â€¢ æ¶æ„ï¼šç¡¬å‚æ•°å…±äº«")
        print("  â€¢ é‡‡æ ·ï¼šæ¸©åº¦é‡‡æ ·(T=0.5)")
        print("  â€¢ æŸå¤±ï¼šä¸ç¡®å®šæ€§åŠ æƒ")
        print("  â€¢ Epochs: 3")
        
        print("\nè®­ç»ƒæµç¨‹ï¼š")
        print("  1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
        print("  2. æ·»åŠ ä»»åŠ¡ç‰¹å®šå±‚")
        print("  3. æ··åˆæ•°æ®è®­ç»ƒ")
        print("  4. åŠ¨æ€è°ƒæ•´æƒé‡")
        print("  5. è¯„ä¼°å„ä»»åŠ¡æ€§èƒ½")
        
        print("\nè®­ç»ƒä¸­...")
        print("  Epoch 1/3: æ‰€æœ‰ä»»åŠ¡æŸå¤±ä¸‹é™")
        print("  Epoch 2/3: ç»§ç»­ä¼˜åŒ–")
        print("  Epoch 3/3: æ”¶æ•›")
        
        print("\nâœ… å¤šä»»åŠ¡è®­ç»ƒå®Œæˆï¼")
        
        print("\næœ€ç»ˆæ€§èƒ½ï¼š")
        print("  ç¿»è¯‘: 92%")
        print("  æ€»ç»“: 88%")
        print("  é—®ç­”: 90%")
        print("  ä»£ç : 85%")
        print("  åˆ†ç±»: 94%")
        print("  å¹³å‡: 89.8%")

# æ¼”ç¤º
trainer = MultiTaskTrainer(tasks=tasks)
dataset = trainer.prepare_multitask_data()
trainer.train(dataset)
```

---

## ğŸ“ è¯¾åç»ƒä¹ 

### ç»ƒä¹ 1ï¼šæ•°æ®å‡†å¤‡
å‡†å¤‡3ä¸ªä»»åŠ¡çš„è®­ç»ƒæ•°æ®

### ç»ƒä¹ 2ï¼šé‡‡æ ·ç­–ç•¥
å¯¹æ¯”ä¸åŒé‡‡æ ·ç­–ç•¥æ•ˆæœ

### ç»ƒä¹ 3ï¼šå¤šä»»åŠ¡è®­ç»ƒ
è®­ç»ƒä¸€ä¸ªå¤šä»»åŠ¡æ¨¡å‹

---

## ğŸ“ çŸ¥è¯†æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **MTLä¼˜åŠ¿**
   - å…±äº«çŸ¥è¯†
   - æå‡æ³›åŒ–
   - èŠ‚çœèµ„æº

2. **ä»»åŠ¡å¹³è¡¡**
   - æ¸©åº¦é‡‡æ ·
   - æŸå¤±åŠ æƒ
   - åŠ¨æ€è°ƒæ•´

3. **æ¶æ„é€‰æ‹©**
   - ç¡¬å‚æ•°å…±äº«
   - è½¯å‚æ•°å…±äº«
   - æ··åˆæ¶æ„

4. **å®æˆ˜è¦ç‚¹**
   - é€‰æ‹©ç›¸å…³ä»»åŠ¡
   - é¿å…è´Ÿè¿ç§»
   - æŒç»­è¯„ä¼°

---

## ğŸš€ ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€è¯¾ï¼š**ç¬¬107è¯¾ï¼šæŒç»­å­¦ä¹ -é¿å…ç¾éš¾æ€§é—å¿˜**

- ç¾éš¾æ€§é—å¿˜
- EWCç®—æ³•
- å¢é‡å­¦ä¹ 
- ç»ˆèº«å­¦ä¹ 

**è®©æ¨¡å‹æŒç»­è¿›åŒ–ï¼** ğŸ”¥

---

**ğŸ’ª è®°ä½ï¼šå¤šä»»åŠ¡å­¦ä¹ è®©æ¨¡å‹æ›´å¼ºå¤§ï¼**

**ä¸‹ä¸€è¯¾è§ï¼** ğŸ‰
